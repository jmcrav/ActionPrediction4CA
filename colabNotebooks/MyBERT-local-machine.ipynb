{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4e26663",
   "metadata": {},
   "source": [
    "# Download GitHub repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9f42ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gian/content\n",
      "Clone in 'ActionPrediction4CA' in corso...\n",
      "remote: Enumerating objects: 393, done.\u001b[K\n",
      "remote: Counting objects: 100% (393/393), done.\u001b[K\n",
      "remote: Compressing objects: 100% (304/304), done.\u001b[K\n",
      "remote: Total 393 (delta 200), reused 267 (delta 82), pack-reused 0\u001b[K\n",
      "Ricezione degli oggetti: 100% (393/393), 48.60 MiB | 10.50 MiB/s, fatto.\n",
      "Risoluzione dei delta: 100% (200/200), fatto.\n"
     ]
    }
   ],
   "source": [
    "%cd ~/content/\n",
    "%rm -rf ~/content/ActionPrediction4CA\n",
    "%rm -rf ~/content/ActionPredictionBERT\n",
    "!git clone  --branch colab_exe https://github.com/jmcrav/ActionPrediction4CA.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36cb4f3",
   "metadata": {},
   "source": [
    "# Elimino i file inutili al modello \n",
    "Per fare il fine tuning del modello, abbiamo bisogno solo dei dati grezzi.\n",
    "Il tutor ha puntualizzato di usare SOLO lo script `simmc/mm_action_prediction/tools/extract_actions_fashion.py`, che costruisce un json con le lables associate alle azioni e agli attributi (è lo step 1 del preprocessing).\n",
    "Questo credo sia necessario perchè credo che la loro implementazione sia di un livello molto più basso di quello a cui dovremo lavorare noi.\n",
    "BERT è un metodo per effettuare il  pre-trained di modelli per il NLP di cui dobbiamo solo fare un fine-tuning accettabile, mentre il SIMMC deve addestrare un intero modello da zero(o comunque credo che il loro obiettivo sia cercare di creare un modello che riesca a funzionare bene col linguaggio multimodale.Non ho capito perchè non sia statu usato BERT anche da loro onestamente -  il task finale è diviso in 3 sottotask, e la prima è un problema di classificazione multi-classe per il quale BERT dovrebbe poter funzionare - forse perchè quella fornita è solo un implementazione di partenza e i concorrenti alla challenge hanno fornito le loro implementazioni dei modelli?). Praticamente tutte le operazioni che fanno loro sui dati credo servano ai loro dettagli implementativi di bassissimo livello; con BERT noi dovremo usare solo i metodi forniti dalla classe.\n",
    "In pratica, partendo dai dati grezzi, dobbiamo solo darli in pasto ai metodi forniti da BERT e magari lavorare un po' per migliorare i risultati, senza che sia necessario scendere fino al livello dei transformers\n",
    "\n",
    "\n",
    "**DA TENERE**\n",
    "* Output dell'extract actions\n",
    "*  `fashion_train_dials.json`:  per il training\n",
    "*  `fashion_dev_dials.json` : per la validation\n",
    "*  `fashion_teststd_dials_public.json` :per il \"report dei risultati finali\" (forse per darlo in pasto allo script di evaluation?) \n",
    "*   `fashion_metadata.json`, `fashion_devtest_dials.json` : necessari per il funzionamento dello script `extract_actions_fashion.py `\n",
    "\n",
    "**DA VERIFICARE**:\n",
    "\n",
    " forse potrebbe convenire anche usare il vocabolario che loro si costruiscono (step 2 del preprocessing) per inizializzare il Tokenizer di Bert, come fanno loro nel data loader (in `loaders/loader_simmc.py`)\n",
    " ![linea codice loader.jpg](data:image/jpeg;base64,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)\n",
    "\n",
    " Questo comando istanzia il tokenizer con una versione default o definita dall'utente (devo capire bene cosa significa, l'ho letto su https://huggingface.co/transformers/quickstart.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cd41deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gian/content/ActionPrediction4CA/tools\n",
      "/home/gian/content/ActionPrediction4CA/data/simmc_fashion\n",
      "/home/gian/content\n"
     ]
    }
   ],
   "source": [
    "%mkdir ~/content/ActionPredictionBERT ActionPredictionBERT/input_data ActionPredictionBERT/extr_output\n",
    "%cd ~/content/ActionPrediction4CA/tools\n",
    "%mv extract_actions_fashion.py ~/content/ActionPredictionBERT\n",
    "%mv action_evaluation.py ~/content/ActionPredictionBERT\n",
    "\n",
    "%cd ~/content/ActionPrediction4CA/data/simmc_fashion/\n",
    "%mv fashion_train_dials.json fashion_dev_dials.json fashion_teststd_dials_public.json fashion_metadata.json fashion_devtest_dials.json ~/content/ActionPredictionBERT/input_data\n",
    "%cd ~/content/\n",
    "%rm -rf ./ActionPrediction4CA/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c76fc6c",
   "metadata": {},
   "source": [
    "# Extract_actions_fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86671584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gian/content/ActionPredictionBERT\n",
      "Reading: ./input_data/fashion_train_dials.json\n",
      "Dialogue task Id missing: 3406\n",
      "Dialogue task Id missing: 3969\n",
      "Dialogue task Id missing: 4847\n",
      "Dialogue task Id missing: 321\n",
      "Dialogue task Id missing: 3455\n",
      "Dialogue task Id missing: 3414\n",
      "Saving: ./extr_output/fashion_train_dials_api_calls.json\n",
      "Reading: ./input_data/fashion_dev_dials.json\n",
      "Dialogue task Id missing: 2117\n",
      "Saving: ./extr_output/fashion_dev_dials_api_calls.json\n",
      "Reading: ./input_data/fashion_devtest_dials.json\n",
      "Dialogue task Id missing: 9308\n",
      "Saving: ./extr_output/fashion_devtest_dials_api_calls.json\n"
     ]
    }
   ],
   "source": [
    "%cd ~/content/ActionPredictionBERT/\n",
    "!python extract_actions_fashion.py --json_path=\"./input_data/fashion_train_dials.json ./input_data/fashion_dev_dials.json ./input_data/fashion_devtest_dials.json\" --save_root=\"./extr_output\"  --metadata_path=\"./fashion_metadata.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98da7846",
   "metadata": {},
   "source": [
    "# Notebook originale\n",
    "Script copiato dal colab di Chris McCormick e Nick Ryan\n",
    "https://colab.research.google.com/drive/1pTuQhug6Dhl9XalKB0zUGf4FIdYFlpcX#scrollTo=nSU7yERLP_66"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34794cb2",
   "metadata": {},
   "source": [
    "## 1.2. Installing the Hugging Face Library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1b3c76",
   "metadata": {},
   "source": [
    "\n",
    "Next, let's install the [transformers](https://github.com/huggingface/transformers) package from Hugging Face which will give us a pytorch interface for working with BERT. (This library contains interfaces for other pretrained language models like OpenAI's GPT and GPT-2.) We've selected the pytorch interface because it strikes a nice balance between the high-level APIs (which are easy to use but don't provide insight into how things work) and tensorflow code (which contains lots of details but often sidetracks us into lessons about tensorflow, when the purpose here is BERT!).\n",
    "\n",
    "At the moment, the Hugging Face library seems to be the most widely accepted and powerful pytorch interface for working with BERT. In addition to supporting a variety of different pre-trained transformer models, the library also includes pre-built modifications of these models suited to your specific task. For example, in this tutorial we will use `BertForSequenceClassification`.\n",
    "\n",
    "The library also includes task-specific classes for token classification, question answering, next sentence prediciton, etc. Using these pre-built classes simplifies the process of modifying BERT for your purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "466b6732",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install markdown\n",
    "#!pip install transformers\n",
    "#!pip install pandas\n",
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26608292",
   "metadata": {},
   "source": [
    "# Impostazione parametri esecuzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4aaed826",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_params = {\n",
    "    'batch': 12,\n",
    "    'epochs': 6,\n",
    "    'hidden_output_dim': 768,\n",
    "    'seed': 29869798,\n",
    "    'learning_rate': 5e-5,\n",
    "    'tolerance': 1e-8\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d9eda3",
   "metadata": {},
   "source": [
    "# Analisi Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4f4432",
   "metadata": {},
   "source": [
    "## train_dials\n",
    "\n",
    "Dati grezzi da preprocessare con lo script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7f4abad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "      <th>dialogue_idx</th>\n",
       "      <th>domains</th>\n",
       "      <th>dialogue_task_id</th>\n",
       "      <th>dialogue_coref_map.1426</th>\n",
       "      <th>dialogue_coref_map.1429</th>\n",
       "      <th>dialogue_coref_map.708</th>\n",
       "      <th>dialogue_coref_map.712</th>\n",
       "      <th>dialogue_coref_map.2401</th>\n",
       "      <th>dialogue_coref_map.2402</th>\n",
       "      <th>...</th>\n",
       "      <th>dialogue_coref_map.2335</th>\n",
       "      <th>dialogue_coref_map.713</th>\n",
       "      <th>dialogue_coref_map.1507</th>\n",
       "      <th>dialogue_coref_map.1509</th>\n",
       "      <th>dialogue_coref_map.949</th>\n",
       "      <th>dialogue_coref_map.1137</th>\n",
       "      <th>dialogue_coref_map.1872</th>\n",
       "      <th>dialogue_coref_map.1873</th>\n",
       "      <th>dialogue_coref_map.1753</th>\n",
       "      <th>dialogue_coref_map.834</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'belief_state': [{'act': 'DA:ASK:CHECK:CLOTH...</td>\n",
       "      <td>3094</td>\n",
       "      <td>[fashion]</td>\n",
       "      <td>1785.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'belief_state': [{'act': 'DA:INFORM:PREFER:C...</td>\n",
       "      <td>822</td>\n",
       "      <td>[fashion]</td>\n",
       "      <td>1720.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'belief_state': [{'act': 'DA:REQUEST:GET:CLO...</td>\n",
       "      <td>7411</td>\n",
       "      <td>[fashion]</td>\n",
       "      <td>2038.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'belief_state': [{'act': 'DA:INFORM:DISPREFE...</td>\n",
       "      <td>7029</td>\n",
       "      <td>[fashion]</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'belief_state': [{'act': 'DA:INFORM:DISPREFE...</td>\n",
       "      <td>1506</td>\n",
       "      <td>[fashion]</td>\n",
       "      <td>1686.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1648 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            dialogue  dialogue_idx    domains  \\\n",
       "0  [{'belief_state': [{'act': 'DA:ASK:CHECK:CLOTH...          3094  [fashion]   \n",
       "1  [{'belief_state': [{'act': 'DA:INFORM:PREFER:C...           822  [fashion]   \n",
       "2  [{'belief_state': [{'act': 'DA:REQUEST:GET:CLO...          7411  [fashion]   \n",
       "3  [{'belief_state': [{'act': 'DA:INFORM:DISPREFE...          7029  [fashion]   \n",
       "4  [{'belief_state': [{'act': 'DA:INFORM:DISPREFE...          1506  [fashion]   \n",
       "\n",
       "   dialogue_task_id  dialogue_coref_map.1426  dialogue_coref_map.1429  \\\n",
       "0            1785.0                      0.0                      1.0   \n",
       "1            1720.0                      NaN                      NaN   \n",
       "2            2038.0                      NaN                      NaN   \n",
       "3            2011.0                      NaN                      NaN   \n",
       "4            1686.0                      NaN                      NaN   \n",
       "\n",
       "   dialogue_coref_map.708  dialogue_coref_map.712  dialogue_coref_map.2401  \\\n",
       "0                     NaN                     NaN                      NaN   \n",
       "1                     0.0                     1.0                      NaN   \n",
       "2                     NaN                     NaN                      4.0   \n",
       "3                     NaN                     NaN                      NaN   \n",
       "4                     NaN                     NaN                      NaN   \n",
       "\n",
       "   dialogue_coref_map.2402  ...  dialogue_coref_map.2335  \\\n",
       "0                      NaN  ...                      NaN   \n",
       "1                      NaN  ...                      NaN   \n",
       "2                      0.0  ...                      NaN   \n",
       "3                      NaN  ...                      NaN   \n",
       "4                      NaN  ...                      NaN   \n",
       "\n",
       "   dialogue_coref_map.713  dialogue_coref_map.1507  dialogue_coref_map.1509  \\\n",
       "0                     NaN                      NaN                      NaN   \n",
       "1                     NaN                      NaN                      NaN   \n",
       "2                     NaN                      NaN                      NaN   \n",
       "3                     NaN                      NaN                      NaN   \n",
       "4                     NaN                      NaN                      NaN   \n",
       "\n",
       "   dialogue_coref_map.949  dialogue_coref_map.1137  dialogue_coref_map.1872  \\\n",
       "0                     NaN                      NaN                      NaN   \n",
       "1                     NaN                      NaN                      NaN   \n",
       "2                     NaN                      NaN                      NaN   \n",
       "3                     NaN                      NaN                      NaN   \n",
       "4                     NaN                      NaN                      NaN   \n",
       "\n",
       "   dialogue_coref_map.1873  dialogue_coref_map.1753  dialogue_coref_map.834  \n",
       "0                      NaN                      NaN                     NaN  \n",
       "1                      NaN                      NaN                     NaN  \n",
       "2                      NaN                      NaN                     NaN  \n",
       "3                      NaN                      NaN                     NaN  \n",
       "4                      NaN                      NaN                     NaN  \n",
       "\n",
       "[5 rows x 1648 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prima parte del fashion_train_dials\n",
    "import json \n",
    "import pandas as pd\n",
    "with open ('./input_data/fashion_train_dials.json',\"r\") as f:\n",
    "   data= json.load(f)\n",
    "\n",
    "result=[]\n",
    "row ={}\n",
    "for k in data:\n",
    "  row[k] = data[k]\n",
    "# []\n",
    "#prima parte del fashion_train_dials\n",
    "import json \n",
    "import pandas as pd\n",
    "with open ('./input_data/fashion_train_dials.json',\"r\") as f:\n",
    "   data= json.load(f)\n",
    "\n",
    "result=[]\n",
    "row ={}\n",
    "for k in data:\n",
    "  row[k] = data[k]\n",
    "# []\n",
    "\n",
    "dialogue_data = pd.json_normalize(row['dialogue_data'])\n",
    "type(dialogue_data)\n",
    "# dialogue = dialogue_data[\"dialogue\"]\n",
    "# for x in dialogue.head(1):\n",
    "#   display(x)\n",
    "# #dialogue.head(1)\n",
    "dialogue_data.head()\n",
    "\n",
    "\n",
    "\n",
    "dialogue_data = pd.json_normalize(row['dialogue_data'])\n",
    "type(dialogue_data)\n",
    "# dialogue = dialogue_data[\"dialogue\"]\n",
    "# for x in dialogue.head(1):\n",
    "#   display(x)\n",
    "# #dialogue.head(1)\n",
    "dialogue_data.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "625e5f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>image_ids</th>\n",
       "      <th>focus_image</th>\n",
       "      <th>memory_images</th>\n",
       "      <th>database_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2042</td>\n",
       "      <td>[2441, 2442, 2443, 2444, 2445, 2446, 2447, 244...</td>\n",
       "      <td>2441</td>\n",
       "      <td>[2442, 2443, 2444]</td>\n",
       "      <td>[2445, 2446, 2447, 2448, 2449, 2450]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2041</td>\n",
       "      <td>[2431, 2432, 2433, 2434, 2435, 2436, 2437, 243...</td>\n",
       "      <td>2431</td>\n",
       "      <td>[2432, 2433, 2434]</td>\n",
       "      <td>[2435, 2436, 2437, 2438, 2439, 2440]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2040</td>\n",
       "      <td>[2421, 2422, 2423, 2424, 2425, 2426, 2427, 242...</td>\n",
       "      <td>2421</td>\n",
       "      <td>[2422, 2423, 2424]</td>\n",
       "      <td>[2425, 2426, 2427, 2428, 2429, 2430]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2039</td>\n",
       "      <td>[2411, 2412, 2413, 2414, 2415, 2416, 2417, 241...</td>\n",
       "      <td>2411</td>\n",
       "      <td>[2412, 2413, 2414]</td>\n",
       "      <td>[2415, 2416, 2417, 2418, 2419, 2420]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2038</td>\n",
       "      <td>[2401, 2402, 2403, 2404, 2405, 2406, 2407, 240...</td>\n",
       "      <td>2401</td>\n",
       "      <td>[2402, 2403, 2404]</td>\n",
       "      <td>[2405, 2406, 2407, 2408, 2409, 2410]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   task_id                                          image_ids  focus_image  \\\n",
       "0     2042  [2441, 2442, 2443, 2444, 2445, 2446, 2447, 244...         2441   \n",
       "1     2041  [2431, 2432, 2433, 2434, 2435, 2436, 2437, 243...         2431   \n",
       "2     2040  [2421, 2422, 2423, 2424, 2425, 2426, 2427, 242...         2421   \n",
       "3     2039  [2411, 2412, 2413, 2414, 2415, 2416, 2417, 241...         2411   \n",
       "4     2038  [2401, 2402, 2403, 2404, 2405, 2406, 2407, 240...         2401   \n",
       "\n",
       "        memory_images                       database_images  \n",
       "0  [2442, 2443, 2444]  [2445, 2446, 2447, 2448, 2449, 2450]  \n",
       "1  [2432, 2433, 2434]  [2435, 2436, 2437, 2438, 2439, 2440]  \n",
       "2  [2422, 2423, 2424]  [2425, 2426, 2427, 2428, 2429, 2430]  \n",
       "3  [2412, 2413, 2414]  [2415, 2416, 2417, 2418, 2419, 2420]  \n",
       "4  [2402, 2403, 2404]  [2405, 2406, 2407, 2408, 2409, 2410]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#seconda parte del fashion_train_dials\n",
    "task_mapping = pd.json_normalize(row['task_mapping'])\n",
    "task_mapping.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9867cff",
   "metadata": {},
   "source": [
    "## dev_dials_api_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d5d29b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialog_id</th>\n",
       "      <th>actions</th>\n",
       "      <th>focus_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4146</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'None', 'action_sup...</td>\n",
       "      <td>[1646, 1646, 1646, 1649, 1649, 1649, 1649]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4260</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...</td>\n",
       "      <td>[2161, 2161, 2161, 2161]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8022</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SearchDatabase', '...</td>\n",
       "      <td>[1971, 1972, 1972, 1972, 1977, 1978]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4992</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'None', 'action_sup...</td>\n",
       "      <td>[1931, 1931, 1936, 1936, 1936]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5606</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'None', 'action_sup...</td>\n",
       "      <td>[1931, 1931, 1931, 1931, 1931]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dialog_id                                            actions  \\\n",
       "0       4146  [{'turn_idx': 0, 'action': 'None', 'action_sup...   \n",
       "1       4260  [{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...   \n",
       "2       8022  [{'turn_idx': 0, 'action': 'SearchDatabase', '...   \n",
       "3       4992  [{'turn_idx': 0, 'action': 'None', 'action_sup...   \n",
       "4       5606  [{'turn_idx': 0, 'action': 'None', 'action_sup...   \n",
       "\n",
       "                                 focus_images  \n",
       "0  [1646, 1646, 1646, 1649, 1649, 1649, 1649]  \n",
       "1                    [2161, 2161, 2161, 2161]  \n",
       "2        [1971, 1972, 1972, 1972, 1977, 1978]  \n",
       "3              [1931, 1931, 1936, 1936, 1936]  \n",
       "4              [1931, 1931, 1931, 1931, 1931]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dev_dials_api = pd.read_json('./extr_output/fashion_dev_dials_api_calls.json')\n",
    "dev_dials_api.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b899ff34",
   "metadata": {},
   "source": [
    "## devtest_dials_api_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f9c6435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialog_id</th>\n",
       "      <th>actions</th>\n",
       "      <th>focus_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2494</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SearchDatabase', '...</td>\n",
       "      <td>[1836, 1841, 1841, 1841, 1841]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3731</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SearchDatabase', '...</td>\n",
       "      <td>[1676, 1681, 1681, 1683, 1683]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8546</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...</td>\n",
       "      <td>[840, 840, 840, 849, 849, 843]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5590</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SearchDatabase', '...</td>\n",
       "      <td>[1616, 1618, 1618, 1618, 1618]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5452</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...</td>\n",
       "      <td>[2231, 2231, 2231, 2236, 2236]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dialog_id                                            actions  \\\n",
       "0       2494  [{'turn_idx': 0, 'action': 'SearchDatabase', '...   \n",
       "1       3731  [{'turn_idx': 0, 'action': 'SearchDatabase', '...   \n",
       "2       8546  [{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...   \n",
       "3       5590  [{'turn_idx': 0, 'action': 'SearchDatabase', '...   \n",
       "4       5452  [{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...   \n",
       "\n",
       "                     focus_images  \n",
       "0  [1836, 1841, 1841, 1841, 1841]  \n",
       "1  [1676, 1681, 1681, 1683, 1683]  \n",
       "2  [840, 840, 840, 849, 849, 843]  \n",
       "3  [1616, 1618, 1618, 1618, 1618]  \n",
       "4  [2231, 2231, 2231, 2236, 2236]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "devtest_dials_api = pd.read_json('./extr_output/fashion_devtest_dials_api_calls.json')\n",
    "devtest_dials_api.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3ba47e",
   "metadata": {},
   "source": [
    "## Funzione generazione dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe1973e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def createDataframe(json_file):\n",
    "  with open(json_file) as f:\n",
    "    dictftdac = json.load(f)\n",
    "\n",
    "  data = []\n",
    "\n",
    "  for e in dictftdac:\n",
    "    dialog_id = e['dialog_id']\n",
    "    actions = e['actions']\n",
    "    focus_images = e['focus_images']\n",
    "\n",
    "    for a in actions:\n",
    "      \n",
    "      turn_idx = a['turn_idx']\n",
    "      action = a['action']\n",
    "      action_supervision = a['action_supervision']\n",
    "      transcript = a['transcript']\n",
    "      transcript_annotated = a['transcript_annotated']\n",
    "      system_transcript = a['system_transcript']\n",
    "      system_transcript_annotated = a['system_transcript_annotated']\n",
    "\n",
    "      row = {\n",
    "          \"dialog_id\" : dialog_id,\n",
    "          'turn_idx' : turn_idx,\n",
    "          'action' : action,\n",
    "          'action_supervision' : action_supervision,\n",
    "          'focus_images' : focus_images,\n",
    "          'transcript': transcript,\n",
    "          'transcript_annotated': transcript_annotated,\n",
    "          'system_transcript': system_transcript,\n",
    "          'system_transcript_annotated':system_transcript_annotated,\n",
    "          'previous_transcript': \"\",\n",
    "          'previous_system_transcript': \"\"\n",
    "      }\n",
    "      if (action_supervision != None):\n",
    "        if 'focus' in action_supervision:\n",
    "          acsf = {'focus':action_supervision['focus']}\n",
    "        else:\n",
    "          acsf = {'focus':None}\n",
    "        \n",
    "        if 'attributes' in action_supervision:\n",
    "          acsa = {'attributes':action_supervision['attributes']}\n",
    "        else:\n",
    "          acsa = {'attributes':[]}\n",
    "      else:\n",
    "          acsf = {'focus':None}\n",
    "          acsa = {'attributes':[]}\n",
    "      \n",
    "        \n",
    "      row.update(acsf)\n",
    "      row.update(acsa)\n",
    "    \n",
    "      data.append(row)\n",
    "\n",
    "  # Conservo id turno e risposta sistema per provare a implementare una soluzione articolata\n",
    "  df = pd.DataFrame(data,columns=['dialog_id','turn_idx','transcript','action','attributes', 'system_transcript','transcript_annotated','system_transcript_annotated','previous_transcript','previous_system_transcript'])\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a30c6d",
   "metadata": {},
   "source": [
    "## train_dials_api_calls with transcript\n",
    "Dati per il training che usiamo ( per ora semplificati)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9d78e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  21196  elementi\n"
     ]
    }
   ],
   "source": [
    "df_training = createDataframe('./extr_output/fashion_train_dials_api_calls.json')\n",
    "print(\"Training: \",len(df_training),\" elementi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e542c9",
   "metadata": {},
   "source": [
    "## fashion_dev_dials_api_calls\n",
    "Dati per la validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d7d98f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:  3513  elementi\n"
     ]
    }
   ],
   "source": [
    "df_validation = createDataframe('./extr_output/fashion_dev_dials_api_calls.json')\n",
    "print(\"Validation: \",len(df_validation),\" elementi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f272d647",
   "metadata": {},
   "source": [
    "## fashion_devtest_dials_api_calls\n",
    "Dati per la valutazione delle performance del modello (test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8e22d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  5397  elementi\n"
     ]
    }
   ],
   "source": [
    "df_test = createDataframe('./extr_output/fashion_devtest_dials_api_calls.json')\n",
    "print(\"Test: \",len(df_test),\" elementi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc25d11d",
   "metadata": {},
   "source": [
    "# BERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4c901c",
   "metadata": {},
   "source": [
    "## Scelta tipo input\n",
    "\n",
    "Il valore di questa variabile determinerà se utilizzare i singoli transcript, o se concatenare ogni transcript a quello successivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef5cc083",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_next = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d30106",
   "metadata": {},
   "source": [
    "## Preparazione input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e090913a",
   "metadata": {},
   "source": [
    "### Generazione colonna previous_transcript\n",
    "\n",
    "Generazione della colonna contenente la frase del turno successivo del dialogo (se presente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fb54823",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "df_training.sort_values(by=['dialog_id', 'turn_idx'])\n",
    "for i in range(1,(len(df_training))):\n",
    "  if(i<(len(df_training)) and  df_training['dialog_id'][i] == df_training['dialog_id'][i-1]):\n",
    "    df_training.loc[i,'previous_transcript'] = df_training['transcript'][i-1]\n",
    "    df_training.loc[i,'previous_system_transcript'] = df_training['system_transcript'][i-1]\n",
    "\n",
    "#Validation\n",
    "df_validation.sort_values(by=['dialog_id', 'turn_idx'])\n",
    "for i in range(1,(len(df_validation))):\n",
    "  if(i<(len(df_validation)) and  df_validation['dialog_id'][i] == df_validation['dialog_id'][i-1]):\n",
    "    df_validation.loc[i,'previous_transcript'] = df_validation['transcript'][i-1]\n",
    "    df_validation.loc[i,'previous_system_transcript'] = df_validation['system_transcript'][i-1]\n",
    "\n",
    "#Evaluation\n",
    "df_test.sort_values(by=['dialog_id', 'turn_idx'])\n",
    "for i in range(1,(len(df_test))):\n",
    "  if(i<(len(df_test)) and  df_test['dialog_id'][i] == df_test['dialog_id'][i-1]):\n",
    "    df_test.loc[i,'previous_transcript'] = df_test['transcript'][i-1]\n",
    "    df_test.loc[i,'previous_system_transcript'] = df_test['system_transcript'][i-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb106a56",
   "metadata": {},
   "source": [
    "### Estrazione vettori colonna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78177045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de95a8f0",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f65ef34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA:\n",
      " Original:  Is there a pattern on this one? It's hard to see in the image.\n",
      "Tokenized:  ['is', 'there', 'a', 'pattern', 'on', 'this', 'one', '?', 'it', \"'\", 's', 'hard', 'to', 'see', 'in', 'the', 'image', '.']\n",
      "Token IDs:  [2003, 2045, 1037, 5418, 2006, 2023, 2028, 1029, 2009, 1005, 1055, 2524, 2000, 2156, 1999, 1996, 3746, 1012]\n"
     ]
    }
   ],
   "source": [
    "transcripts_tr = df_training.transcript.values\n",
    "previous_transcript_tr = df_training.previous_transcript.values\n",
    "previous_system_transcript_tr = df_training.previous_system_transcript.values\n",
    "action_labels_tr = df_training.action.values\n",
    "attributes_labels_tr=df_training.attributes.values\n",
    "\n",
    "print (\"TRAINING DATA:\")\n",
    "# Print the original sentence.\n",
    "print(' Original: ', transcripts_tr[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(transcripts_tr[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(transcripts_tr[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b5da556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T: Is there a pattern on this one? It's hard to see in the image. | PT:  | PST: \n",
      "T: That's fancy. Do you have anything in warmer colors like yellow or red? | PT: Is there a pattern on this one? It's hard to see in the image. | PST: I don't have any information on the pattern, but it has pointelle embellishments.\n",
      "T: Yeah, that sounds good. | PT: That's fancy. Do you have anything in warmer colors like yellow or red? | PST: I have a crew neck sweater in red, would you like to see it?\n",
      "T: Oh, I love that. Please tell me you have a small. | PT: Yeah, that sounds good. | PST: This is $187 from Downtown Stylists with a 3.62 rating.\n",
      "T: Yes, please! Thank you for your help with this | PT: Oh, I love that. Please tell me you have a small. | PST: It does come in small, shall I put one in your cart?\n",
      "T: How nice! Does this come in other colors? | PT:  | PST: \n",
      "T: Oh well.  Can you show me a dress that comes in red? | PT: How nice! Does this come in other colors? | PST: No, I'm sorry, It comes only in blue.\n",
      "T: Cute! Do these come in Small? | PT: Oh well.  Can you show me a dress that comes in red? | PST: This dress comes in many colors, including a bright red and a pinkish-red. What do you think?\n",
      "T: Awesome. Would you add a red one in S to my cart please? | PT: Cute! Do these come in Small? | PST: Yes, they do!\n",
      "T: That's all. Thanks! | PT: Awesome. Would you add a red one in S to my cart please? | PST: The red one is in your cart. Is there anything else I can find for you?\n"
     ]
    }
   ],
   "source": [
    "for k in range(0,10):\n",
    "  print(f\"T: {transcripts_tr[k]} | PT: {previous_transcript_tr[k]} | PST: {previous_system_transcript_tr[k]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef35705",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcd4e529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION DATA:\n",
      " Original:  What's the price of this sweater compared to the other blue and gray one I looked at?\n",
      "Tokenized:  ['what', \"'\", 's', 'the', 'price', 'of', 'this', 'sweater', 'compared', 'to', 'the', 'other', 'blue', 'and', 'gray', 'one', 'i', 'looked', 'at', '?']\n",
      "Token IDs:  [2054, 1005, 1055, 1996, 3976, 1997, 2023, 14329, 4102, 2000, 1996, 2060, 2630, 1998, 3897, 2028, 1045, 2246, 2012, 1029]\n",
      "Dialog IDs: [4146 4146 4146 4146 4146 4146 4146 4260 4260 4260 4260 8022 8022 8022\n",
      " 8022 8022 8022 4992 4992 4992]\n",
      "Turn IDs: [0 1 2 3 4 5 6 0 1 2 3 0 1 2 3 4 5 0 1 2]\n"
     ]
    }
   ],
   "source": [
    "transcripts_vd = df_validation.transcript.values\n",
    "previous_transcript_vd = df_validation.previous_transcript.values\n",
    "previous_system_transcript_vd = df_validation.previous_system_transcript.values\n",
    "action_labels_vd = df_validation.action.values\n",
    "attributes_labels_vd=df_validation.attributes.values\n",
    "dialog_ids_vd = df_validation.dialog_id.values\n",
    "turn_idxs_vd = df_validation.turn_idx.values\n",
    "\n",
    "print (\"VALIDATION DATA:\")\n",
    "\n",
    "# Print the original sentence.\n",
    "print(' Original: ', transcripts_vd[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(transcripts_vd[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(transcripts_vd[0])))\n",
    "\n",
    "# Print the dialog ids.\n",
    "print(f\"Dialog IDs: {dialog_ids_vd[0:20]}\")\n",
    "\n",
    "# Print the turn idxs.\n",
    "print(f\"Turn IDs: {turn_idxs_vd[0:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba6e6ef",
   "metadata": {},
   "source": [
    "#### Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "886bcaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATION DATA:\n",
      " Original:  That looks a little too light for what I need, do you have something else with a high customer rating?\n",
      "Tokenized:  ['that', 'looks', 'a', 'little', 'too', 'light', 'for', 'what', 'i', 'need', ',', 'do', 'you', 'have', 'something', 'else', 'with', 'a', 'high', 'customer', 'rating', '?']\n",
      "Token IDs:  [2008, 3504, 1037, 2210, 2205, 2422, 2005, 2054, 1045, 2342, 1010, 2079, 2017, 2031, 2242, 2842, 2007, 1037, 2152, 8013, 5790, 1029]\n",
      "Dialog IDs: [2494 2494 2494 2494 2494 3731 3731 3731 3731 3731 8546 8546 8546 8546\n",
      " 8546 8546 5590 5590 5590 5590]\n",
      "Turn IDs: [0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 5 0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "transcripts_tst = df_test.transcript.values\n",
    "previous_transcript_tst = df_test.previous_transcript.values\n",
    "previous_system_transcript_tst = df_test.previous_system_transcript.values\n",
    "action_labels_tst = df_test.action.values\n",
    "attributes_labels_tst=df_test.attributes.values\n",
    "dialog_ids_tst = df_test.dialog_id.values\n",
    "turn_idxs_tst = df_test.turn_idx.values\n",
    "\n",
    "print (\"EVALUATION DATA:\")\n",
    "\n",
    "# Print the original sentence.\n",
    "print(' Original: ', transcripts_tst[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(transcripts_tst[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(transcripts_tst[0])))\n",
    "\n",
    "# Print the dialog ids.\n",
    "print(f\"Dialog IDs: {dialog_ids_tst[0:20]}\")\n",
    "\n",
    "# Print the turn idxs.\n",
    "print(f\"Turn IDs: {turn_idxs_tst[0:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c049bbf",
   "metadata": {},
   "source": [
    "## Calcolo dimensione massima\n",
    "\n",
    "The above code left out a few required formatting steps that we'll look at here.\n",
    "\n",
    "We are required to:\n",
    "1. Add special tokens to the start and end of each sentence.\n",
    "2. Pad & truncate all sentences to a single constant length.\n",
    "3. Explicitly differentiate real tokens from padding tokens with the \"attention mask\".\n",
    "\n",
    "\n",
    "The sentences in our dataset obviously have varying lengths, so how does BERT handle this?\n",
    "\n",
    "BERT has two constraints:\n",
    "\n",
    "\n",
    "1.   All sentences must be padded or truncated to a single, fixed length.\n",
    "2.   The maximum sentence length is 512 tokens.\n",
    "\n",
    "\n",
    "Padding is done with a special [PAD] token, which is at index 0 in the BERT vocabulary. The below illustration demonstrates padding out to a \"MAX_LEN\" of 8 tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c16396",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8e5132e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max transcript length for training:  177\n"
     ]
    }
   ],
   "source": [
    "max_len_tr = 0\n",
    "\n",
    "# For every sentence...\n",
    "for i in range(0,len(transcripts_tr)):\n",
    "    \n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "\n",
    "    if (previous_transcript_tr[i] != \"\" and use_next):\n",
    "      input_ids = tokenizer.encode(previous_transcript_tr[i]+ \" \" + previous_system_transcript_tr[i],transcripts_tr[i], add_special_tokens=True)\n",
    "    else:\n",
    "      input_ids = tokenizer.encode(transcripts_tr[i], add_special_tokens=True)\n",
    "        \n",
    "    # Update the maximum sentence length.\n",
    "    max_len_tr = max(max_len_tr, len(input_ids))\n",
    "\n",
    "print('Max transcript length for training: ', max_len_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17363e3c",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92914388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max transcript length for validation:  133\n"
     ]
    }
   ],
   "source": [
    "max_len_vd = 0\n",
    "\n",
    "# For every sentence...\n",
    "for i in range(0,len(transcripts_vd)):\n",
    "\n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    if (previous_transcript_vd[i] != \"\" and use_next):\n",
    "      input_ids = tokenizer.encode(previous_transcript_vd[i]+ \" \" + previous_system_transcript_vd[i],transcripts_vd[i], add_special_tokens=True)\n",
    "    else:\n",
    "      input_ids = tokenizer.encode(transcripts_vd[i], add_special_tokens=True)\n",
    "    \n",
    "    # Update the maximum sentence length.\n",
    "    max_len_vd = max(max_len_vd, len(input_ids))\n",
    "\n",
    "print('Max transcript length for validation: ', max_len_vd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3412aa8",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aab75df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max transcript length for evaluation:  150\n"
     ]
    }
   ],
   "source": [
    "max_len_tst = 0\n",
    "\n",
    "#non sono sicuro che il controllo della lunghezza vada fatto anche sul test set, dopo la performance non è determinata\n",
    "#dalla conoscenza del test set?\n",
    "#è anche vero che in teoria per far funzionare BERT bisogna dargli in pasto dei dati tokenizzati, quindi in un caso reale il nostro\n",
    "#model non potrebbe prendere in ingresso del testo non trattato. Nel dubbio ho controllato le dimensioni\n",
    "\n",
    "for i in range(0,len(transcripts_tst)):\n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    if (previous_transcript_tst[i] != \"\" and use_next):\n",
    "      input_ids = tokenizer.encode(previous_transcript_tst[i]+ \" \" + previous_system_transcript_tst[i],transcripts_tst[i], add_special_tokens=True)\n",
    "    else:\n",
    "      input_ids = tokenizer.encode(transcripts_tst[i], add_special_tokens=True)\n",
    "\n",
    "    # Update the maximum sentence length.\n",
    "    max_len_tst = max(max_len_tst, len(input_ids))\n",
    "\n",
    "print(\"Max transcript length for evaluation: \",max_len_tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c277f0",
   "metadata": {},
   "source": [
    "### Risultato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26bd8ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La massima lunghezza dei token da gestire è quindi  177\n"
     ]
    }
   ],
   "source": [
    "max_len = max(max_len_tr, max_len_vd, max_len_tst)\n",
    "\n",
    "# if (max_len_tr >= max_len_vd):\n",
    "#   max_len = max_len_tr\n",
    "# else:\n",
    "#   max_len = max_len_vd\n",
    "# if (max_len_tst >= max_len):\n",
    "#   max_len = max_len_tst\n",
    "\n",
    "print(\"La massima lunghezza dei token da gestire è quindi \",max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcefd1f1",
   "metadata": {},
   "source": [
    "## Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54bc7c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "[('availableSizes',)]\n",
      "['ageRange' 'amountInStock' 'availableSizes' 'brand' 'clothingCategory'\n",
      " 'clothingStyle' 'color' 'customerRating' 'dressStyle' 'embellishment'\n",
      " 'forGender' 'forOccasion' 'hasPart' 'hemLength' 'hemStyle' 'info'\n",
      " 'jacketStyle' 'madeIn' 'material' 'necklineStyle' 'pattern' 'price'\n",
      " 'sequential' 'size' 'skirtLength' 'skirtStyle' 'sleeveLength'\n",
      " 'sleeveStyle' 'soldBy' 'sweaterStyle' 'waistStyle' 'warmthRating'\n",
      " 'waterResistance']\n",
      "Totale: 30106, Training: 21196, Validation: 3513, Evaluation: 5397\n",
      "Training: 21196, Validation: 3513, Evaluation: 5397\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "attributes_labels_all = np.concatenate((attributes_labels_tr, attributes_labels_vd,attributes_labels_tst), axis=None)\n",
    "attr_yt = mlb.fit_transform(attributes_labels_all)\n",
    "print(attr_yt[0:15])\n",
    "print(mlb.inverse_transform(attr_yt[3].reshape(1, -1)))\n",
    "print(mlb.classes_)\n",
    "print(f\"Totale: {len(attr_yt)}, Training: {len(attributes_labels_tr)}, Validation: {len(attributes_labels_vd)}, Evaluation: {len(attributes_labels_tst)}\")\n",
    "attributes_labels_tr_vect = attr_yt[0:len(attributes_labels_tr)]\n",
    "attributes_labels_vd_vect = attr_yt[len(attributes_labels_tr):(len(attributes_labels_tr)+len(attributes_labels_vd))]\n",
    "attributes_labels_tst_vect = attr_yt[(len(attributes_labels_tr)+len(attributes_labels_vd)):]\n",
    "print(f\"Training: {len(attributes_labels_tr_vect)}, Validation: {len(attributes_labels_vd_vect)}, Evaluation: {len(attributes_labels_tst_vect)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63925873",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9505e37",
   "metadata": {},
   "source": [
    "Now we're ready to perform the real tokenization.\n",
    "\n",
    "The tokenizer.encode_plus function combines multiple steps for us:\n",
    "\n",
    "Split the sentence into tokens.\n",
    "Add the special [CLS] and [SEP] tokens.\n",
    "Map the tokens to their IDs.\n",
    "Pad or truncate all sentences to the same length.\n",
    "Create the attention masks which explicitly differentiate real tokens from [PAD] tokens.\n",
    "The first four features are in tokenizer.encode, but I'm using tokenizer.encode_plus to get the fifth item (attention masks). Documentation is here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aff8d187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f4fe9850c70>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "# backends cudnn for out memory not necessary (resolved by batch size)\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "# torch.backends.cudnn.enabled = True\n",
    "# Set torch seed for deterministic behaviour\n",
    "torch.manual_seed(exec_params['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45855e8f",
   "metadata": {},
   "source": [
    "### Tokenize Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e32c330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21196 records to encode.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gian/anaconda3/envs/testcuda1/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2126: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING : \n",
      "Original:  Is there a pattern on this one? It's hard to see in the image.\n",
      "Token IDs: tensor([ 101, 2003, 2045, 1037, 5418, 2006, 2023, 2028, 1029, 2009, 1005, 1055,\n",
      "        2524, 2000, 2156, 1999, 1996, 3746, 1012,  102,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "\n",
    "#dobbiamo convertire le nostre lables da string a valori numerici, usiamo il metodo fornito da sklearn\n",
    "\n",
    "#TRAINING DATASET\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "action_labels_encoded_tr = le.fit_transform(action_labels_tr)\n",
    "\n",
    "input_ids_tr = []\n",
    "attention_masks_tr = []\n",
    "print(f\"{len(df_training)} records to encode.\")\n",
    "# For every sentence...\n",
    "for i in range(0,len(df_training)):\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "\n",
    "  if (previous_transcript_tr[i] != \"\" and use_next):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        previous_transcript_tr[i]+ \" \" + previous_system_transcript_tr[i],  # Sentence to encode.\n",
    "                        transcripts_tr[i], #next sentece to encode\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        truncation = True,\n",
    "                        max_length = max_len,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                    )\n",
    "  else:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        transcripts_tr[i],  # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        truncation = True,\n",
    "                        max_length = max_len,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                    )\n",
    "    \n",
    "\n",
    "    \n",
    "  # Add the encoded sentence to the list.    \n",
    "  input_ids_tr.append(encoded_dict['input_ids'])\n",
    "\n",
    "  # And its attention mask (simply differentiates padding from non-padding).\n",
    "  attention_masks_tr.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids_tr = torch.cat(input_ids_tr, dim=0)\n",
    "attention_masks_tr = torch.cat(attention_masks_tr, dim=0)\n",
    "labels_actions_tr = torch.tensor(action_labels_encoded_tr)\n",
    "labels_attributes_tr = torch.tensor(attributes_labels_tr_vect) \n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print (\"TRAINING : \")\n",
    "if (use_next):\n",
    "  print('Original: ', transcripts_tr[0])\n",
    "else:\n",
    "  print('Original: ', transcripts_tr[0])\n",
    "print('Token IDs:', input_ids_tr[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cda4541",
   "metadata": {},
   "source": [
    "### Tokenize Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5da13a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3513 records to encode.\n",
      "VALIDATION : \n",
      "Original:  What's the price of this sweater compared to the other blue and gray one I looked at?\n",
      "Token IDs: tensor([  101,  2054,  1005,  1055,  1996,  3976,  1997,  2023, 14329,  4102,\n",
      "         2000,  1996,  2060,  2630,  1998,  3897,  2028,  1045,  2246,  2012,\n",
      "         1029,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0])\n",
      "Dialog IDs: tensor([4146, 4146, 4146, 4146, 4146, 4146, 4146, 4260, 4260, 4260, 4260, 8022,\n",
      "        8022, 8022, 8022, 8022, 8022, 4992, 4992, 4992])\n",
      "Turn IDXs: tensor([0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 0, 1, 2, 3, 4, 5, 0, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "\n",
    "#dobbiamo convertire le nostre lables da string a valori numerici, usiamo il metodo fornito da sklearn\n",
    "\n",
    "#VALIDATION DATASET\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "action_labels_encoded_vd = le.fit_transform(action_labels_vd)\n",
    "\n",
    "input_ids_vd = []\n",
    "attention_masks_vd = []\n",
    "print(f\"{len(df_validation)} records to encode.\")\n",
    "# For every sentence...\n",
    "for i in range(0,len(df_validation)):\n",
    "  # `encode_plus` will:\n",
    "  #   (1) Tokenize the sentence.\n",
    "  #   (2) Prepend the `[CLS]` token to the start.\n",
    "  #   (3) Append the `[SEP]` token to the end.\n",
    "  #   (4) Map tokens to their IDs.\n",
    "  #   (5) Pad or truncate the sentence to `max_length`\n",
    "  #   (6) Create attention masks for [PAD] tokens.\n",
    "\n",
    "  if (previous_transcript_vd[i] != \"\" and use_next):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        previous_transcript_vd[i]+ \" \" + previous_system_transcript_vd[i],  # Sentence to encode.\n",
    "                        transcripts_vd[i], #next sentece to encode\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        truncation = True,\n",
    "                        max_length = max_len,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                    )\n",
    "  else:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        transcripts_vd[i],  # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        truncation = True,\n",
    "                        max_length = max_len,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                    )\n",
    "    \n",
    "  # Add the encoded sentence to the list.    \n",
    "  input_ids_vd.append(encoded_dict['input_ids'])\n",
    "  \n",
    "  # And its attention mask (simply differentiates padding from non-padding).\n",
    "  attention_masks_vd.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids_vd = torch.cat(input_ids_vd, dim=0)\n",
    "attention_masks_vd = torch.cat(attention_masks_vd, dim=0)\n",
    "labels_actions_vd = torch.tensor(action_labels_encoded_vd)\n",
    "labels_attributes_vd = torch.tensor(attributes_labels_vd_vect)\n",
    "# Check warning:\n",
    "# /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
    "dialog_ids_vd = torch.tensor(dialog_ids_vd)\n",
    "turn_idxs_vd = torch.tensor(turn_idxs_vd) \n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print (\"VALIDATION : \")\n",
    "if (use_next):\n",
    "  print('Original: ', transcripts_vd[0])\n",
    "else:\n",
    "  print('Original: ', transcripts_vd[0])\n",
    "print('Token IDs:', input_ids_vd[0])\n",
    "print(f\"Dialog IDs: {dialog_ids_vd[0:20]}\")\n",
    "print(f\"Turn IDXs: {turn_idxs_vd[0:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d364715",
   "metadata": {},
   "source": [
    "### Tokenize Evaluation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23888911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5397 records to encode.\n",
      "Evaluation : \n",
      "Original:  That looks a little too light for what I need, do you have something else with a high customer rating?\n",
      "Token IDs: tensor([ 101, 2008, 3504, 1037, 2210, 2205, 2422, 2005, 2054, 1045, 2342, 1010,\n",
      "        2079, 2017, 2031, 2242, 2842, 2007, 1037, 2152, 8013, 5790, 1029,  102,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0])\n",
      "Dialog IDs: tensor([2494, 2494, 2494, 2494, 2494, 3731, 3731, 3731, 3731, 3731, 8546, 8546,\n",
      "        8546, 8546, 8546, 8546, 5590, 5590, 5590, 5590])\n",
      "Turn IDXs: tensor([0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "\n",
    "#dobbiamo convertire le nostre lables da string a valori numerici, usiamo il metodo fornito da sklearn\n",
    "\n",
    "#EVALUATION DATASET\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "action_labels_encoded_tst = le.fit_transform(action_labels_tst)\n",
    "\n",
    "input_ids_tst = []\n",
    "attention_masks_tst = []\n",
    "print(f\"{len(df_test)} records to encode.\")\n",
    "# For every sentence...\n",
    "for i in range(0,len(df_test)):\n",
    "# for t in transcripts_tst:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "  \n",
    "  #Aggiungere \"and False\" PER UTILIZZARE sempre la tokenizzazione senza concatenazione\n",
    "  if (previous_transcript_tst[i] != \"\" and use_next):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                      previous_transcript_tst[i]+ \" \" + previous_system_transcript_tst[i],  # Sentence to encode.\n",
    "                      transcripts_tst[i], #next sentece to encode\n",
    "                      add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                      truncation = True,\n",
    "                      max_length = max_len,           # Pad & truncate all sentences.\n",
    "                      pad_to_max_length = True,\n",
    "                      return_attention_mask = True,   # Construct attn. masks.\n",
    "                      return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                  )\n",
    "  else:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                      transcripts_tst[i],  # Sentence to encode.\n",
    "                      add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                      truncation = True,\n",
    "                      max_length = max_len,           # Pad & truncate all sentences.\n",
    "                      pad_to_max_length = True,\n",
    "                      return_attention_mask = True,   # Construct attn. masks.\n",
    "                      return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                  )\n",
    "    \n",
    "  # Add the encoded sentence to the list.    \n",
    "  input_ids_tst.append(encoded_dict['input_ids'])\n",
    "  \n",
    "  # And its attention mask (simply differentiates padding from non-padding).\n",
    "  attention_masks_tst.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids_tst = torch.cat(input_ids_tst, dim=0)\n",
    "attention_masks_tst = torch.cat(attention_masks_tst, dim=0)\n",
    "labels_actions_tst = torch.tensor(action_labels_encoded_tst)\n",
    "labels_attributes_tst = torch.tensor(attributes_labels_tst_vect)\n",
    "# Check warning:\n",
    "# /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
    "dialog_ids_tst = torch.tensor(dialog_ids_tst)\n",
    "turn_idxs_tst = torch.tensor(turn_idxs_tst) \n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print (\"Evaluation : \")\n",
    "if (use_next):\n",
    "  print('Original: ', transcripts_tst[0])\n",
    "else:\n",
    "  print('Original: ', transcripts_tst[0])\n",
    "print('Token IDs:', input_ids_tst[0])\n",
    "print(f\"Dialog IDs: {dialog_ids_tst[0:20]}\")\n",
    "print(f\"Turn IDXs: {turn_idxs_tst[0:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af23bb7",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96157e27",
   "metadata": {},
   "source": [
    "# Data Split - AP4CA\n",
    "La nostra versione di split di dati per training e validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "680bdf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21,196 training samples\n",
      "3,513 validation samples\n",
      "5,397 evaluation samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "#labels_tr = {'actions': labels_actions_tr, 'attributes': labels_attributes_tr}\n",
    "#labels_vd = {'actions': labels_actions_vd, 'attributes': labels_attributes_vd}\n",
    "\n",
    "train_dataset = TensorDataset(input_ids_tr, attention_masks_tr, labels_actions_tr, labels_attributes_tr)\n",
    "val_dataset = TensorDataset(input_ids_vd, attention_masks_vd, labels_actions_vd, labels_attributes_vd, dialog_ids_vd, turn_idxs_vd)\n",
    "tst_dataset = TensorDataset(input_ids_tst, attention_masks_tst, labels_actions_tst, labels_attributes_tst, dialog_ids_tst, turn_idxs_tst)\n",
    "\n",
    "print('{:>5,} training samples'.format(len(train_dataset)))\n",
    "print('{:>5,} validation samples'.format(len(val_dataset)))\n",
    "print('{:>5,} evaluation samples'.format(len(tst_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed1196fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 101, 2008, 3504,  ...,    0,    0,    0],\n",
       "         [ 101, 2008, 3504,  ...,    0,    0,    0],\n",
       "         [ 101, 2040, 5617,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [ 101, 2821, 1045,  ...,    0,    0,    0],\n",
       "         [ 101, 4086, 1010,  ...,    0,    0,    0],\n",
       "         [ 101, 1045, 2066,  ...,    0,    0,    0]]),\n",
       " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " tensor([2, 4, 4, 0, 1, 2, 1, 2, 0, 1]),\n",
       " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " tensor([2494, 2494, 2494, 2494, 2494, 3731, 3731, 3731, 3731, 3731]),\n",
       " tensor([0, 1, 2, 3, 4, 0, 1, 2, 3, 4]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check evaluation TensorDataset content\n",
    "tst_dataset[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d01df19",
   "metadata": {},
   "source": [
    "## Check GPU for Training\n",
    "\n",
    "In questa versione la GPU è impostata fissa.\n",
    "Con una GPU in più a disposizione possiamo usare DataParallel e aumentare il batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31bf32c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2060\n"
     ]
    }
   ],
   "source": [
    "# Tell PyTorch to use the GPU.    \n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "print('We will use the GPU:', torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2045d72f",
   "metadata": {},
   "source": [
    "### Creazione Data Loaders per Training, Validation ed Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d9f42ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "# With size 32 GeForce RTX 2060 with 6GB run out of memory\n",
    "batch_size = exec_params['batch']\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )\n",
    "\n",
    "#ho controllato nel colab su cui ci basiamo, anche lui usa un Sequential Sampler per il dataset di evaluation\n",
    "evaluation_dataloader = DataLoader(\n",
    "            tst_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(tst_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040d27c5",
   "metadata": {},
   "source": [
    "## Train BERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc8111f",
   "metadata": {},
   "source": [
    "For this task, we first want to modify the pre-trained BERT model to give outputs for classification, and then we want to continue training the model on our dataset until that the entire model, end-to-end, is well-suited for our task. \n",
    "\n",
    "Thankfully, the huggingface pytorch implementation includes a set of interfaces designed for a variety of NLP tasks. Though these interfaces are all built on top of a trained BERT model, each has different top layers and output types designed to accomodate their specific NLP task.  \n",
    "\n",
    "Here is the current list of classes provided for fine-tuning:\n",
    "* BertModel\n",
    "* BertForPreTraining\n",
    "* BertForMaskedLM\n",
    "* BertForNextSentencePrediction\n",
    "* **BertForSequenceClassification** - The one we'll use.\n",
    "* BertForTokenClassification\n",
    "* BertForQuestionAnswering\n",
    "\n",
    "The documentation for these can be found under [here](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbd23ca",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We'll be using [BertForSequenceClassification](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#bertforsequenceclassification). This is the normal BERT model with an added single linear layer on top for classification that we will use as a sentence classifier. As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task. \n",
    "\n",
    "NB anche nell'articolo che sto leggendo sulla classificazione multi-label si parte da questo modello\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba0360b",
   "metadata": {},
   "source": [
    "OK, let's load BERT! There are a few different pre-trained BERT models available. \"bert-base-uncased\" means the version that has only lowercase letters (\"uncased\") and is the smaller version of the two (\"base\" vs \"large\").\n",
    "\n",
    "The documentation for `from_pretrained` can be found [here](https://huggingface.co/transformers/v2.2.0/main_classes/model.html#transformers.PreTrainedModel.from_pretrained), with the additional parameters defined [here](https://huggingface.co/transformers/v2.2.0/main_classes/configuration.html#transformers.PretrainedConfig)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "242aa137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DA SISTEMARE\n",
    "from transformers import BertModel\n",
    "from  torch import  nn\n",
    "\n",
    "class CustomBERTModel(nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "\n",
    "    super(CustomBERTModel, self).__init__()\n",
    "    self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "    ### New layers:\n",
    "    self.linear_intermedio = nn.Linear(768, exec_params['hidden_output_dim'])\n",
    "    #provare ad aggiungere ulteriori layer intermedi per ridurre le dimensioni fino ad arrivare all'output richiesto\n",
    "    self.linear_actions = nn.Linear(exec_params['hidden_output_dim'], 5) \n",
    "    self.linear_attributes = nn.Linear(exec_params['hidden_output_dim'], len(mlb.classes_)) #num attributi? \n",
    "\n",
    "  def forward(self, ids, mask):\n",
    "    #controllare che l'output non rappresenti solo lo stato interno dovuto al token CLS\n",
    "    output = self.bert(ids,attention_mask=mask)\n",
    "    # print(f\"Type output{type(output)}\")\n",
    "    # for p in output:\n",
    "    #   print(p)\n",
    "    #   print(type(output[p]))\n",
    "    #   print(output[p])\n",
    "\n",
    "    #prendiamo il campo last_hidden_state dall'oggetto output; last hidden state rappresenta il tensore\n",
    "    #in uscita dallo step di forward del BertModel\n",
    "    last_hidden_state_output = output[\"last_hidden_state\"]\n",
    "    # last_hidden_state has the following shape: (batch_size, sequence_length, 768)\n",
    "    #stiamo passando solo il token CLS ai layer successivi\n",
    "    linear_output_intermedio = self.linear_intermedio(last_hidden_state_output[:,0,:].view(-1,768)) \n",
    "    # linear_output_intermedio = self.linear_intermedio(pooled_output) \n",
    "    \n",
    "    linear_output_actions = self.linear_actions(linear_output_intermedio)\n",
    "    # linear_output_actions = self.sftmx(linear_output_actions)\n",
    "    # linear_output_actions = nn.functional.softmax(linear_output_actions)\n",
    "    # Test sigmoid for increasing perplexity performance\n",
    "    linear_output_actions = torch.sigmoid(linear_output_actions)\n",
    "    linear_output_attributes = self.linear_attributes(linear_output_intermedio)\n",
    "    # linear_output_attributes = self.sig(linear_output_attributes)\n",
    "    linear_output_attributes = torch.sigmoid(linear_output_attributes)\n",
    "\n",
    "    return {'actions': linear_output_actions, 'attributes': linear_output_attributes}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ceefd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomBERTModel(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (linear_intermedio): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (linear_actions): Linear(in_features=768, out_features=5, bias=True)\n",
       "  (linear_attributes): Linear(in_features=768, out_features=33, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test istanziazione del custom model\n",
    "model = CustomBERTModel()\n",
    "\n",
    "# model.bert.config\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cb0c4c",
   "metadata": {},
   "source": [
    "Just for curiosity's sake, we can browse all of the model's parameters by name here.\n",
    "\n",
    "In the below cell, I've printed out the names and dimensions of the weights for:\n",
    "\n",
    "1. The embedding layer.\n",
    "2. The first of the twelve transformers.\n",
    "3. The output layer.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c48662a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 205 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "linear_actions.weight                                       (5, 768)\n",
      "linear_actions.bias                                             (5,)\n",
      "linear_attributes.weight                                   (33, 768)\n",
      "linear_attributes.bias                                         (33,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655b5929",
   "metadata": {},
   "source": [
    "## 4.2. Optimizer & Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2ee817",
   "metadata": {},
   "source": [
    "Now that we have our model loaded we need to grab the training hyperparameters from within the stored model.\n",
    "\n",
    "For the purposes of fine-tuning, the authors recommend choosing from the following values (from Appendix A.3 of the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf)):\n",
    "\n",
    ">- **Batch size:** 16, 32  \n",
    "- **Learning rate (Adam):** 5e-5, 3e-5, 2e-5  \n",
    "- **Number of epochs:** 2, 3, 4 \n",
    "\n",
    "We chose:\n",
    "* Batch size: 32 (set when creating our DataLoaders)\n",
    "* Learning rate: 2e-5\n",
    "* Epochs: 4 (we'll see that this is probably too many...)\n",
    "\n",
    "The epsilon parameter `eps = 1e-8` is \"a very small number to prevent any division by zero in the implementation\" (from [here](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)).\n",
    "\n",
    "You can find the creation of the AdamW optimizer in `run_glue.py` [here](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "295fde1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = exec_params['learning_rate'], # args.learning_rate - default is 5e-5\n",
    "                  eps = exec_params['tolerance'] # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4faef5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = exec_params['epochs']\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eccdf3c",
   "metadata": {},
   "source": [
    "## 4.3. Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1141dfa",
   "metadata": {},
   "source": [
    "Below is our training loop. There's a lot going on, but fundamentally for each pass in our loop we have a trianing phase and a validation phase. \n",
    "\n",
    "> *Thank you to [Stas Bekman](https://ca.linkedin.com/in/stasbekman) for contributing the insights and code for using validation loss to detect over-fitting!*\n",
    "\n",
    "**Training:**\n",
    "- Unpack our data inputs and labels\n",
    "- Load data onto the GPU for acceleration\n",
    "- Clear out the gradients calculated in the previous pass. \n",
    "    - In pytorch the gradients accumulate by default (useful for things like RNNs) unless you explicitly clear them out.\n",
    "- Forward pass (feed input data through the network)\n",
    "- Backward pass (backpropagation)\n",
    "- Tell the network to update parameters with optimizer.step()\n",
    "- Track variables for monitoring progress\n",
    "\n",
    "**Evalution:**\n",
    "- Unpack our data inputs and labels\n",
    "- Load data onto the GPU for acceleration\n",
    "- Forward pass (feed input data through the network)\n",
    "- Compute loss on our validation data and track variables for monitoring progress\n",
    "\n",
    "Pytorch hides all of the detailed calculations from us, but we've commented the code to point out which of the above steps are happening on each line. \n",
    "\n",
    "> *PyTorch also has some [beginner tutorials](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py) which you may also find helpful.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d699904",
   "metadata": {},
   "source": [
    "Define a helper function for calculating accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df633469",
   "metadata": {},
   "source": [
    "### Flat accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef1a2d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy_actions(preds, labels):\n",
    "    #print(f\"[FA] preds: {preds} / labels: {labels}\")\n",
    "    #print(f\"[FA-Actions] {type(preds)} {type(labels)}\")\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()   \n",
    "    return {'matched': np.sum(pred_flat == labels_flat), 'counts': len(labels_flat)}\n",
    "\n",
    "def flat_accuracy_attributes(preds, labels):\n",
    "  #print(f\"[FA-Attributess] {type(preds)} {type(labels)}\")\n",
    "  tot_preds = preds.shape[0]\n",
    "  preds_int = np.rint(preds)\n",
    "  tot_eq = 0\n",
    "  for i in range(tot_preds):\n",
    "    comparison = preds_int[i] == labels[i]\n",
    "    if comparison.all():\n",
    "      tot_eq += 1\n",
    "  return {'matched': tot_eq, 'counts' : tot_preds}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc1a792",
   "metadata": {},
   "source": [
    "Helper function for formatting elapsed times as `hh:mm:ss`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "903c3769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdd0590",
   "metadata": {},
   "source": [
    "### Loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0629812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "# Loss function definition\n",
    "def MyBERT_loss(logits, actions_labels, attributes_labels):\n",
    "  actions_logits = logits['actions']\n",
    "  attributes_logits = logits['attributes']\n",
    "  loss_actions_fn = nn.CrossEntropyLoss()\n",
    "  loss_attributes_fn = nn.BCELoss()\n",
    "  loss_actions = loss_actions_fn(actions_logits, actions_labels)\n",
    "  loss_attributes = loss_attributes_fn(attributes_logits, attributes_labels.float())\n",
    "  return loss_actions + loss_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fea679",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We're ready to kick off the training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aab27b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 6 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  4% | 30% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  4% | 30% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:52.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 87% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:46.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 87% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:40.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 87% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:35.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "End of epoch 0\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 92% | 88% |\n",
      "\n",
      "  Average training loss: 1.12\n",
      "  Training epcoh took: 0:08:25\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8446\n",
      "  Accuracy for multilabel-classification (attributes): 0.8933\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8445772843723314, 'action_perplexity': 2.555760073652333, 'attribute_accuracy': 0.7110534145783265, 'confusion_matrix': array([[ 450.,   29.,    6.,    0.,    6.],\n",
      "       [  29.,  682.,   51.,    9.,   15.],\n",
      "       [   8.,  148.,  509.,   59.,   28.],\n",
      "       [   0.,    0.,    0.,    0.,    0.],\n",
      "       [   5.,   49.,   58.,   46., 1326.]])}\n",
      "  Validation Loss: 1.0703\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "======== Epoch 2 / 6 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 94% | 88% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 94% | 88% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:57.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:55.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:52.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:49.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "End of epoch 1\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "\n",
      "  Average training loss: 1.06\n",
      "  Training epcoh took: 0:08:37\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8503\n",
      "  Accuracy for multilabel-classification (attributes): 0.9083\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8502704241389126, 'action_perplexity': 2.443421177024809, 'attribute_accuracy': 0.7503371866487125, 'confusion_matrix': array([[4.610e+02, 3.500e+01, 4.000e+00, 1.000e+00, 3.000e+00],\n",
      "       [1.800e+01, 6.760e+02, 2.900e+01, 8.000e+00, 3.000e+01],\n",
      "       [1.000e+01, 1.530e+02, 5.510e+02, 7.500e+01, 4.300e+01],\n",
      "       [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
      "       [3.000e+00, 4.400e+01, 4.000e+01, 3.000e+01, 1.299e+03]])}\n",
      "  Validation Loss: 1.0627\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "======== Epoch 3 / 6 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 98% | 88% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 98% | 88% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:57.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 87% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:51.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 87% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:46.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 94% | 87% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:41.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 87% |\n",
      "End of epoch 2\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 87% |\n",
      "\n",
      "  Average training loss: 1.05\n",
      "  Training epcoh took: 0:08:29\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8491\n",
      "  Accuracy for multilabel-classification (attributes): 0.9180\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8491317961855963, 'action_perplexity': 2.4138892306615856, 'attribute_accuracy': 0.7514352857814925, 'confusion_matrix': array([[ 471.,   38.,    5.,    0.,    7.],\n",
      "       [   9.,  687.,   43.,    8.,   31.],\n",
      "       [  10.,  138.,  519.,   65.,   31.],\n",
      "       [   0.,    0.,    0.,    0.,    0.],\n",
      "       [   2.,   45.,   57.,   41., 1306.]])}\n",
      "  Validation Loss: 1.0581\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "======== Epoch 4 / 6 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 98% | 87% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 98% | 87% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:55.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 87% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:50.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 87% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:44.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 87% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:39.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 87% |\n",
      "End of epoch 3\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 87% |\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epcoh took: 0:08:27\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8577\n",
      "  Accuracy for multilabel-classification (attributes): 0.9377\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8576715058354683, 'action_perplexity': 2.3954488414639985, 'attribute_accuracy': 0.79220514957234, 'confusion_matrix': array([[4.610e+02, 3.200e+01, 1.000e+00, 0.000e+00, 5.000e+00],\n",
      "       [1.700e+01, 6.850e+02, 2.900e+01, 7.000e+00, 1.700e+01],\n",
      "       [1.200e+01, 1.470e+02, 5.270e+02, 4.500e+01, 2.800e+01],\n",
      "       [0.000e+00, 1.000e+00, 1.200e+01, 2.100e+01, 6.000e+00],\n",
      "       [2.000e+00, 4.300e+01, 5.500e+01, 4.100e+01, 1.319e+03]])}\n",
      "  Validation Loss: 1.0486\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "======== Epoch 5 / 6 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 89% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 89% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:55.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 89% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:49.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 89% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:43.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 88% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:38.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 87% |\n",
      "End of epoch 4\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 87% |\n",
      "\n",
      "  Average training loss: 1.01\n",
      "  Training epcoh took: 0:08:26\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8562\n",
      "  Accuracy for multilabel-classification (attributes): 0.9428\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8562482208938229, 'action_perplexity': 2.610903403038199, 'attribute_accuracy': 0.7838886789602357, 'confusion_matrix': array([[4.640e+02, 2.900e+01, 3.000e+00, 0.000e+00, 6.000e+00],\n",
      "       [1.900e+01, 7.070e+02, 5.900e+01, 9.000e+00, 2.700e+01],\n",
      "       [8.000e+00, 1.300e+02, 4.980e+02, 3.500e+01, 1.800e+01],\n",
      "       [0.000e+00, 1.000e+00, 1.100e+01, 2.200e+01, 7.000e+00],\n",
      "       [1.000e+00, 4.100e+01, 5.300e+01, 4.800e+01, 1.317e+03]])}\n",
      "  Validation Loss: 1.0497\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "======== Epoch 6 / 6 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 87% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 87% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:54.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 88% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:50.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:44.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 88% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:39.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 88% |\n",
      "End of epoch 5\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 87% |\n",
      "\n",
      "  Average training loss: 1.00\n",
      "  Training epcoh took: 0:08:27\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8580\n",
      "  Accuracy for multilabel-classification (attributes): 0.9448\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8579561628237973, 'action_perplexity': 2.6464887446905356, 'attribute_accuracy': 0.7917846388581217, 'confusion_matrix': array([[4.660e+02, 3.100e+01, 1.000e+00, 0.000e+00, 5.000e+00],\n",
      "       [1.200e+01, 7.040e+02, 5.500e+01, 9.000e+00, 2.600e+01],\n",
      "       [1.000e+01, 1.290e+02, 4.970e+02, 3.300e+01, 1.900e+01],\n",
      "       [0.000e+00, 1.000e+00, 2.000e+01, 3.200e+01, 1.000e+01],\n",
      "       [4.000e+00, 4.300e+01, 5.100e+01, 4.000e+01, 1.315e+03]])}\n",
      "  Validation Loss: 1.0499\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:53:33 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import action_evaluation as evaluation\n",
    "import json\n",
    "from  GPUtil import showUtilization as gpu_usage\n",
    "with open('./extr_output/fashion_dev_dials_api_calls.json') as f:\n",
    "  dev_dials = json.load(f)\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = exec_params['seed']\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "#torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "test_batch = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    print(\"GPU before train\")\n",
    "    gpu_usage()\n",
    "\n",
    "    model.train()\n",
    "    print(\"GPU after train\")\n",
    "    gpu_usage()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 400 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "            gpu_usage()\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: actions labels \n",
    "        #   [3]: attributes labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels_actions = batch[2].to(device)\n",
    "        b_labels_attributes = batch[3].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
    "        # function and pass down the arguments. The `forward` function is \n",
    "        # documented here: \n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
    "        # The results are returned in a results object, documented here:\n",
    "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
    "        # Specifically, we'll get the loss (because we provided labels) and the\n",
    "        # \"logits\"--the model outputs prior to activation.\n",
    "        result = model(b_input_ids, \n",
    "                       mask=b_input_mask)\n",
    "        \n",
    "        loss = MyBERT_loss(result, b_labels_actions, b_labels_attributes)\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.from transformers import BertModel, BertConfig\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    print(f\"End of epoch {epoch_i}\")\n",
    "    gpu_usage()\n",
    "    \n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.mlb.inverse_transform(attr_yt[3].reshape(1, -1))\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy_classification = { 'matched': 0, 'counts': 0}\n",
    "    total_eval_accuracy_multilabel = { 'matched': 0, 'counts': 0}\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    batch_number = 0\n",
    "\n",
    "    # Dictionary for action_evaluation\n",
    "    model_actions = {}\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        batch_number += 1\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels_actions = batch[2].to(device)\n",
    "        b_labels_attributes = batch[3].to(device)\n",
    "        b_dialog_ids = batch[4].to(device).detach().cpu().numpy()\n",
    "        b_turn_idxs = batch[5].to(device).detach().cpu().numpy()\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            result = model(b_input_ids, \n",
    "                       mask=b_input_mask)\n",
    "\n",
    "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
    "        # output values prior to applying an activation function like the \n",
    "        # softmax.\n",
    "        loss = MyBERT_loss(result, b_labels_actions, b_labels_attributes)\n",
    "            \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        # logits = logits.detach().cpu().numpy()\n",
    "        # label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        \n",
    "        actions_logits_foracc=result['actions'].detach().cpu().numpy()\n",
    "        attributes_logits_foracc=result['attributes'].detach().cpu().numpy()\n",
    "        actions_labels_foracc= b_labels_actions.to('cpu').numpy()\n",
    "        attributes_labels_foracc =b_labels_attributes.to('cpu').numpy()\n",
    "\n",
    "        #TODO: definire la nostra funzione di accuracy\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        accuracy_classification = flat_accuracy_actions(actions_logits_foracc, actions_labels_foracc)\n",
    "        accuracy_multilabel = flat_accuracy_attributes(attributes_logits_foracc, attributes_labels_foracc)\n",
    "        \n",
    "        total_eval_accuracy_classification['matched'] += accuracy_classification['matched']\n",
    "        total_eval_accuracy_classification['counts'] += accuracy_classification['counts']\n",
    "        total_eval_accuracy_multilabel['matched'] += accuracy_multilabel['matched']\n",
    "        total_eval_accuracy_multilabel['counts'] += accuracy_multilabel['counts']\n",
    "        # Salvo dati elaborazione batch per debug/analisi\n",
    "        test_batch.append({\n",
    "            'epoch' : epoch_i + 1,\n",
    "            'batchnum' : batch_number,\n",
    "            'actions_logits' : actions_logits_foracc,\n",
    "            'actions_labels' : actions_labels_foracc,\n",
    "            'attributes_logits' : attributes_logits_foracc,\n",
    "            'attributes_labels' : attributes_labels_foracc,\n",
    "            'accuracy_classification' : accuracy_classification,\n",
    "            'accuracy_multilabel' : accuracy_multilabel,\n",
    "        })\n",
    "\n",
    "        # Fill dictionary for action_evaluation\n",
    "        for el_i in range(len(actions_logits_foracc)):\n",
    "          dialog_id = b_dialog_ids[el_i]\n",
    "          action_log_prob = {}\n",
    "          for act_i in range(len(actions_logits_foracc[el_i])):\n",
    "            #todo: controllare che la probabilità predetta sia in scala logaritmica (?? potrebbe essere fonte di errori)\n",
    "            action_log_prob[le.classes_[act_i]] = np.log(actions_logits_foracc[el_i][act_i])\n",
    "          #attributes = {}\n",
    "          attributes = []\n",
    "          #attributes_list = np.rint(attributes_logits_foracc[el_i])\n",
    "          attributes_list = np.array(attributes_logits_foracc[el_i])\n",
    "          for attr in range(len(attributes_list)):\n",
    "            attribute = mlb.classes_[attr]\n",
    "            #attributes[mlb.classes_[attr]] = attributes_list[attr]\n",
    "            if attributes_list[attr] >= 0.5:\n",
    "              attributes.append(attribute)\n",
    "          prediction = {\n",
    "              'action': le.classes_[np.argmax(actions_logits_foracc[el_i])],\n",
    "              'action_log_prob': action_log_prob,\n",
    "              'attributes': {'attributes': attributes},\n",
    "              'turn_id': b_turn_idxs[el_i]\n",
    "          }\n",
    "          if dialog_id in model_actions:\n",
    "            model_actions[dialog_id]['predictions'].append(prediction)\n",
    "          else:\n",
    "            predictions = list()\n",
    "            predictions.append(prediction)\n",
    "            model_actions[dialog_id] = {\n",
    "                'dialog_id': dialog_id,\n",
    "                'predictions': predictions\n",
    "            }\n",
    "          \n",
    "\n",
    "    # Report the final accuracy for this validation \n",
    "\n",
    "    #avg_val_accuracy_classification = total_eval_accuracy_classification / len(validation_dataloader)\n",
    "    #avg_val_accuracy_multilabel = total_eval_accuracy_multilabel / len(validation_dataloader)\n",
    "    avg_val_accuracy_classification = total_eval_accuracy_classification['matched'] / total_eval_accuracy_classification['counts']\n",
    "    avg_val_accuracy_multilabel = total_eval_accuracy_multilabel['matched'] / total_eval_accuracy_multilabel['counts']\n",
    "    print(\"  Accuracy for classification (actions): {0:.4f}\".format(avg_val_accuracy_classification))\n",
    "    print(\"  Accuracy for multilabel-classification (attributes): {0:.4f}\".format(avg_val_accuracy_multilabel))\n",
    "\n",
    "    # Reference implementation: evaluation of action prediction along with attributes\n",
    "    metrics = evaluation.evaluate_action_prediction(dev_dials, model_actions.values())\n",
    "    # print(\"model_actions passed to the evaluator:\")\n",
    "    # for v in model_actions.values():\n",
    "    #   print(v)\n",
    "    print(\"***************************************\")\n",
    "    print(\"Reference evaluation metrics:\")\n",
    "    print(metrics)\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.4f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,  \n",
    "            'Valid. Accur. class.': avg_val_accuracy_classification,\n",
    "            'Valid. Accur. mult.label': avg_val_accuracy_multilabel,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time,\n",
    "            'metrics': metrics\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ac0f0f",
   "metadata": {},
   "source": [
    "## Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b6d29e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy for classification (actions): 0.8523\n",
      "  Accuracy for multilabel-classification (attributes): 0.9368\n",
      "#Instances evaluated API: 5397\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.852325365944043, 'action_perplexity': 2.877918457578552, 'attribute_accuracy': 0.7788140156946991, 'confusion_matrix': array([[ 743.,   43.,    9.,    2.,   13.],\n",
      "       [  28., 1073.,   85.,   13.,   38.],\n",
      "       [  11.,  183.,  738.,   67.,   20.],\n",
      "       [   0.,    5.,   17.,   48.,   19.],\n",
      "       [  11.,   82.,   95.,   56., 1998.]])}\n"
     ]
    }
   ],
   "source": [
    "#Prediction on test set\n",
    "#quale modello gli viene passato? da controllare se BERT da solo riesce a tenere traccia del modello che ha dato l'epoca migliore\n",
    "\n",
    "\n",
    "with open('./extr_output/fashion_devtest_dials_api_calls.json') as f:\n",
    "  devtest_dials = json.load(f)\n",
    "\n",
    "# Tracking variables \n",
    "total_eval_accuracy_classification = { 'matched': 0, 'counts': 0}\n",
    "total_eval_accuracy_multilabel = { 'matched': 0, 'counts': 0}\n",
    "\n",
    "model_actions = {}\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "for batch in evaluation_dataloader:\n",
    "\n",
    "    # Unpack this training batch from our dataloader. \n",
    "    #\n",
    "    # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "    # the `to` method.\n",
    "    #\n",
    "    # `batch` contains three pytorch tensors:\n",
    "    #   [0]: input ids \n",
    "    #   [1]: attention masks\n",
    "    #   [2]: labels \n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels_actions = batch[2].to(device)\n",
    "    b_labels_attributes = batch[3].to(device)\n",
    "    b_dialog_ids = batch[4].to(device).detach().cpu().numpy()\n",
    "    b_turn_idxs = batch[5].to(device).detach().cpu().numpy()\n",
    "    \n",
    "    # Tell pytorch not to bother with constructing the compute graph during\n",
    "    # the forward pass, since this is only needed for backprop (training).\n",
    "    with torch.no_grad():        \n",
    "        # Forward pass, calculate logit predictions.\n",
    "        # token_type_ids is the same as the \"segment ids\", which \n",
    "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "        result = model(b_input_ids,mask=b_input_mask)\n",
    "\n",
    "    \n",
    "    actions_logits_foracc=result['actions'].detach().cpu().numpy()\n",
    "    attributes_logits_foracc=result['attributes'].detach().cpu().numpy()\n",
    "    actions_labels_foracc= b_labels_actions.to('cpu').numpy()\n",
    "    attributes_labels_foracc =b_labels_attributes.to('cpu').numpy()\n",
    "\n",
    "    # Calculate the accuracy for this batch of test sentences, and\n",
    "    # accumulate it over all batches.\n",
    "    accuracy_classification = flat_accuracy_actions(actions_logits_foracc, actions_labels_foracc)\n",
    "    accuracy_multilabel = flat_accuracy_attributes(attributes_logits_foracc, attributes_labels_foracc)\n",
    "    \n",
    "    total_eval_accuracy_classification['matched'] += accuracy_classification['matched']\n",
    "    total_eval_accuracy_classification['counts'] += accuracy_classification['counts']\n",
    "    total_eval_accuracy_multilabel['matched'] += accuracy_multilabel['matched']\n",
    "    total_eval_accuracy_multilabel['counts'] += accuracy_multilabel['counts']\n",
    "    \n",
    "\n",
    "    # Fill dictionary for action_evaluation\n",
    "    for el_i in range(len(actions_logits_foracc)):\n",
    "      dialog_id = b_dialog_ids[el_i]\n",
    "      action_log_prob = {}\n",
    "      for act_i in range(len(actions_logits_foracc[el_i])):\n",
    "        #todo: controllare che la probabilità predetta sia in scala logaritmica (?? potrebbe essere fonte di errori)\n",
    "        action_log_prob[le.classes_[act_i]] = np.log(actions_logits_foracc[el_i][act_i])\n",
    "      #attributes = {}\n",
    "      attributes = []\n",
    "      #attributes_list = np.rint(attributes_logits_foracc[el_i])\n",
    "      attributes_list = np.array(attributes_logits_foracc[el_i])\n",
    "      for attr in range(len(attributes_list)):\n",
    "        attribute = mlb.classes_[attr]\n",
    "        #attributes[mlb.classes_[attr]] = attributes_list[attr]\n",
    "        if attributes_list[attr] >= 0.5:\n",
    "          attributes.append(attribute)\n",
    "      prediction = {\n",
    "          'action': le.classes_[np.argmax(actions_logits_foracc[el_i])],\n",
    "          'action_log_prob': action_log_prob,\n",
    "          'attributes': {'attributes': attributes},\n",
    "          'turn_id': b_turn_idxs[el_i]\n",
    "      }\n",
    "      if dialog_id in model_actions:\n",
    "        model_actions[dialog_id]['predictions'].append(prediction)\n",
    "      else:\n",
    "        predictions = list()\n",
    "        predictions.append(prediction)\n",
    "        model_actions[dialog_id] = {\n",
    "            'dialog_id': dialog_id,\n",
    "            'predictions': predictions\n",
    "        }\n",
    "      \n",
    "\n",
    "# Report the final accuracy for this validation \n",
    "\n",
    "#avg_val_accuracy_classification = total_eval_accuracy_classification / len(validation_dataloader)\n",
    "#avg_val_accuracy_multilabel = total_eval_accuracy_multilabel / len(validation_dataloader)\n",
    "avg_val_accuracy_classification = total_eval_accuracy_classification['matched'] / total_eval_accuracy_classification['counts']\n",
    "avg_val_accuracy_multilabel = total_eval_accuracy_multilabel['matched'] / total_eval_accuracy_multilabel['counts']\n",
    "print(\"  Accuracy for classification (actions): {0:.4f}\".format(avg_val_accuracy_classification))\n",
    "print(\"  Accuracy for multilabel-classification (attributes): {0:.4f}\".format(avg_val_accuracy_multilabel))\n",
    "\n",
    "# Reference implementation: evaluation of action prediction along with attributes\n",
    "metrics = evaluation.evaluate_action_prediction(devtest_dials, model_actions.values())\n",
    "# print(\"model_actions passed to the evaluator:\")\n",
    "# for v in model_actions.values():\n",
    "#   print(v)\n",
    "print(\"***************************************\")\n",
    "print(\"Reference evaluation metrics:\")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a059e49",
   "metadata": {},
   "source": [
    "# OTHER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ca179f",
   "metadata": {},
   "source": [
    "Let's view the summary of the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "03bdf5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "401e879c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>batchnum</th>\n",
       "      <th>actions_logits</th>\n",
       "      <th>actions_labels</th>\n",
       "      <th>attributes_logits</th>\n",
       "      <th>attributes_labels</th>\n",
       "      <th>accuracy_classification</th>\n",
       "      <th>accuracy_multilabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.0002790156, 0.9670287, 0.0036740534, 0.000...</td>\n",
       "      <td>[1, 4, 2, 4, 0, 1, 1, 4, 4, 0, 1, 2]</td>\n",
       "      <td>[[0.00021209536, 0.0002003255, 0.003312983, 0....</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>{'matched': 12, 'counts': 12}</td>\n",
       "      <td>{'matched': 11, 'counts': 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0.00083208777, 0.99984264, 0.00021892982, 6....</td>\n",
       "      <td>[1, 4, 2, 2, 0, 1, 2, 1, 1, 1, 1, 4]</td>\n",
       "      <td>[[0.00015562818, 0.00012504886, 0.0029583515, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>{'matched': 10, 'counts': 12}</td>\n",
       "      <td>{'matched': 11, 'counts': 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[[0.0004017245, 0.000779635, 0.00022936364, 3....</td>\n",
       "      <td>[4, 1, 1, 1, 4, 2, 1, 2, 0, 1, 1, 1]</td>\n",
       "      <td>[[5.9910773e-05, 4.8709655e-05, 0.96560806, 0....</td>\n",
       "      <td>[[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>{'matched': 9, 'counts': 12}</td>\n",
       "      <td>{'matched': 11, 'counts': 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[[0.99992895, 0.0011218796, 0.00026538435, 0.0...</td>\n",
       "      <td>[0, 0, 1, 2, 0, 1, 4, 4, 0, 1, 1, 4]</td>\n",
       "      <td>[[0.00034110897, 0.0001272221, 0.011743937, 0....</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>{'matched': 9, 'counts': 12}</td>\n",
       "      <td>{'matched': 10, 'counts': 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[[6.598799e-05, 0.0012814496, 0.00060107204, 0...</td>\n",
       "      <td>[1, 4, 2, 4, 0, 3, 1, 1, 2, 4, 1, 1]</td>\n",
       "      <td>[[0.0003209937, 0.0002695334, 0.007662571, 0.0...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>{'matched': 10, 'counts': 12}</td>\n",
       "      <td>{'matched': 10, 'counts': 12}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  batchnum                                     actions_logits  \\\n",
       "0      1         1  [[0.0002790156, 0.9670287, 0.0036740534, 0.000...   \n",
       "1      1         2  [[0.00083208777, 0.99984264, 0.00021892982, 6....   \n",
       "2      1         3  [[0.0004017245, 0.000779635, 0.00022936364, 3....   \n",
       "3      1         4  [[0.99992895, 0.0011218796, 0.00026538435, 0.0...   \n",
       "4      1         5  [[6.598799e-05, 0.0012814496, 0.00060107204, 0...   \n",
       "\n",
       "                         actions_labels  \\\n",
       "0  [1, 4, 2, 4, 0, 1, 1, 4, 4, 0, 1, 2]   \n",
       "1  [1, 4, 2, 2, 0, 1, 2, 1, 1, 1, 1, 4]   \n",
       "2  [4, 1, 1, 1, 4, 2, 1, 2, 0, 1, 1, 1]   \n",
       "3  [0, 0, 1, 2, 0, 1, 4, 4, 0, 1, 1, 4]   \n",
       "4  [1, 4, 2, 4, 0, 3, 1, 1, 2, 4, 1, 1]   \n",
       "\n",
       "                                   attributes_logits  \\\n",
       "0  [[0.00021209536, 0.0002003255, 0.003312983, 0....   \n",
       "1  [[0.00015562818, 0.00012504886, 0.0029583515, ...   \n",
       "2  [[5.9910773e-05, 4.8709655e-05, 0.96560806, 0....   \n",
       "3  [[0.00034110897, 0.0001272221, 0.011743937, 0....   \n",
       "4  [[0.0003209937, 0.0002695334, 0.007662571, 0.0...   \n",
       "\n",
       "                                   attributes_labels  \\\n",
       "0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "2  [[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "3  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "4  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "         accuracy_classification            accuracy_multilabel  \n",
       "0  {'matched': 12, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
       "1  {'matched': 10, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
       "2   {'matched': 9, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
       "3   {'matched': 9, 'counts': 12}  {'matched': 10, 'counts': 12}  \n",
       "4  {'matched': 10, 'counts': 12}  {'matched': 10, 'counts': 12}  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert test data to dataframe\n",
    "df_test = pd.DataFrame(data = test_batch)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dbd5290d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur. class.</th>\n",
       "      <th>Valid. Accur. mult.label</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "      <th>metrics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.12</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0:08:25</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8445772843723314, 'actio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.06</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0:08:37</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8502704241389126, 'actio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.05</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0:08:29</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8491317961855963, 'actio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.03</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0:08:27</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8576715058354683, 'actio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.01</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0:08:26</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8562482208938229, 'actio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0:08:27</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8579561628237973, 'actio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. class.  \\\n",
       "epoch                                                     \n",
       "1               1.12         1.07                  0.84   \n",
       "2               1.06         1.06                  0.85   \n",
       "3               1.05         1.06                  0.85   \n",
       "4               1.03         1.05                  0.86   \n",
       "5               1.01         1.05                  0.86   \n",
       "6               1.00         1.05                  0.86   \n",
       "\n",
       "       Valid. Accur. mult.label Training Time Validation Time  \\\n",
       "epoch                                                           \n",
       "1                          0.89       0:08:25         0:00:27   \n",
       "2                          0.91       0:08:37         0:00:27   \n",
       "3                          0.92       0:08:29         0:00:27   \n",
       "4                          0.94       0:08:27         0:00:27   \n",
       "5                          0.94       0:08:26         0:00:27   \n",
       "6                          0.94       0:08:27         0:00:27   \n",
       "\n",
       "                                                 metrics  \n",
       "epoch                                                     \n",
       "1      {'action_accuracy': 0.8445772843723314, 'actio...  \n",
       "2      {'action_accuracy': 0.8502704241389126, 'actio...  \n",
       "3      {'action_accuracy': 0.8491317961855963, 'actio...  \n",
       "4      {'action_accuracy': 0.8576715058354683, 'actio...  \n",
       "5      {'action_accuracy': 0.8562482208938229, 'actio...  \n",
       "6      {'action_accuracy': 0.8579561628237973, 'actio...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display floats with two decimal places.\n",
    "pd.set_option('precision', 2)\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap.\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Display the table.\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "69386886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Objects serialization\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "testdata_filename = f\"testdata-{timestr}\"\n",
    "stats_filename = f\"stats-{timestr}\"\n",
    "#outtest = open(testdata_filename, \"wb\")\n",
    "#outstats = open(stats_filename, \"wb\")\n",
    "#pk.dump(obj=df_test, file=outtest)\n",
    "#outtest.close()\n",
    "#pk.dump(obj=df_stats, file=outstats)\n",
    "#outstats.close()\n",
    "df_test.to_pickle(testdata_filename)\n",
    "df_stats.to_pickle(stats_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb5a6cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testdata-20210802-000025\n",
      "       Training Loss  Valid. Loss  Valid. Accur. class.  \\\n",
      "epoch                                                     \n",
      "1               1.12         1.07                  0.84   \n",
      "2               1.06         1.06                  0.85   \n",
      "3               1.05         1.06                  0.85   \n",
      "4               1.03         1.05                  0.86   \n",
      "5               1.01         1.05                  0.86   \n",
      "\n",
      "       Valid. Accur. mult.label Training Time Validation Time  \\\n",
      "epoch                                                           \n",
      "1                          0.89       0:08:25         0:00:27   \n",
      "2                          0.91       0:08:37         0:00:27   \n",
      "3                          0.92       0:08:29         0:00:27   \n",
      "4                          0.94       0:08:27         0:00:27   \n",
      "5                          0.94       0:08:26         0:00:27   \n",
      "\n",
      "                                                 metrics  \n",
      "epoch                                                     \n",
      "1      {'action_accuracy': 0.8445772843723314, 'actio...  \n",
      "2      {'action_accuracy': 0.8502704241389126, 'actio...  \n",
      "3      {'action_accuracy': 0.8491317961855963, 'actio...  \n",
      "4      {'action_accuracy': 0.8576715058354683, 'actio...  \n",
      "5      {'action_accuracy': 0.8562482208938229, 'actio...  \n",
      "   epoch  batchnum                                     actions_logits  \\\n",
      "0      1         1  [[0.0002790156, 0.9670287, 0.0036740534, 0.000...   \n",
      "1      1         2  [[0.00083208777, 0.99984264, 0.00021892982, 6....   \n",
      "2      1         3  [[0.0004017245, 0.000779635, 0.00022936364, 3....   \n",
      "3      1         4  [[0.99992895, 0.0011218796, 0.00026538435, 0.0...   \n",
      "4      1         5  [[6.598799e-05, 0.0012814496, 0.00060107204, 0...   \n",
      "\n",
      "                         actions_labels  \\\n",
      "0  [1, 4, 2, 4, 0, 1, 1, 4, 4, 0, 1, 2]   \n",
      "1  [1, 4, 2, 2, 0, 1, 2, 1, 1, 1, 1, 4]   \n",
      "2  [4, 1, 1, 1, 4, 2, 1, 2, 0, 1, 1, 1]   \n",
      "3  [0, 0, 1, 2, 0, 1, 4, 4, 0, 1, 1, 4]   \n",
      "4  [1, 4, 2, 4, 0, 3, 1, 1, 2, 4, 1, 1]   \n",
      "\n",
      "                                   attributes_logits  \\\n",
      "0  [[0.00021209536, 0.0002003255, 0.003312983, 0....   \n",
      "1  [[0.00015562818, 0.00012504886, 0.0029583515, ...   \n",
      "2  [[5.9910773e-05, 4.8709655e-05, 0.96560806, 0....   \n",
      "3  [[0.00034110897, 0.0001272221, 0.011743937, 0....   \n",
      "4  [[0.0003209937, 0.0002695334, 0.007662571, 0.0...   \n",
      "\n",
      "                                   attributes_labels  \\\n",
      "0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
      "1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
      "2  [[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
      "3  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
      "4  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
      "\n",
      "         accuracy_classification            accuracy_multilabel  \n",
      "0  {'matched': 12, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
      "1  {'matched': 10, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
      "2   {'matched': 9, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
      "3   {'matched': 9, 'counts': 12}  {'matched': 10, 'counts': 12}  \n",
      "4  {'matched': 10, 'counts': 12}  {'matched': 10, 'counts': 12}  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Test reimport data\n",
    "df_stats_reload = pd.read_pickle(stats_filename)\n",
    "df_test_reload = pd.read_pickle(testdata_filename)\n",
    "\n",
    "print(testdata_filename)\n",
    "print(df_stats_reload.head())\n",
    "print(df_test_reload.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1af435",
   "metadata": {},
   "source": [
    "## Plot di training & validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2c4fe674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks([x+1 for x in range(exec_params['epochs'])])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add9f100",
   "metadata": {},
   "source": [
    "## Plot accuracy and perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5c6601f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvAAAAGXCAYAAADVv2QFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAB+qElEQVR4nO3dd1iT5/4G8DshhL2HA1QQBFTUujdYlLr3rlLb42irWLXW2lNrT0+PHb9WxUHdra3aahUEFTdatU6srdUqiIIDB8oKYY/k/f2BREIAgwIhcH+uy0t45zd5QO/3yfM+r0gQBAFERERERKQXxLougIiIiIiItMcAT0RERESkRxjgiYiIiIj0CAM8EREREZEeYYAnIiIiItIjDPBERERERHqEAZ6IarXdu3fD09MTFy5c0HUptZKfnx8CAgJ0XYZWVq9eDU9PT9y/f7/CZUREVDEGeCJ6Ienp6WjTpg08PT2xZ8+elzrWhQsXsHr1asjl8iqqjl6GXC7H6tWry7xoqmhdbRMZGYnVq1frugwioirHAE9EL2Tfvn0oKCiAs7MzQkJCXupYUVFRCA4OLjPADx8+HFeuXEHnzp1f6hykPblcjuDgYERFRVVq3fO8++67uHLlCpycnKqizOeKjIxEcHBwjZyLiKgmMcAT0QsJCQlB165dMWXKFFy8eBH37t2rlvMYGBjAyMgIYjH/udJXmZmZAACJRAIjIyOIRCIdV0TaKm47Iqpd+D8iEVXatWvXEB0djZEjR2Lo0KGQSCQIDQ0tc9v8/Hxs3LgRw4cPR7t27dCxY0eMGjUK27ZtAwB89NFHql7Svn37wtPTE56enqqhD+WNgU9NTcV///tf+Pr6wtvbG76+vvjvf/+LtLQ0te2K9z937hy+//579OvXD97e3ujfvz/CwsI06j1x4gQmT56Mrl27om3btujTpw8CAwNx+/bt574vp0+fxty5c9G3b1+0bdsWnTp1wr/+9a8ye6sDAgLg5+eHx48f4/3330fnzp3xyiuvYOrUqWWe69GjR5gzZw46duyIDh064J133qnURZNSqcTatWsxadIk9OzZE97e3ujTpw/+85//qL1nFy5cQN++fQEAwcHBqvbw8/OrcB0A3L9/X9V2Bw4cwKhRo9C2bVssWbIEQMXj3XNycrBkyRL07NkTbdu2xdixY3Hu3Dm1bUoev7TSxw4ICFC1b3Gdnp6e2L17t2qfJ0+e4D//+Q/69OkDb29v9OrVC4sXL0ZKSorasWUyGb788kv069cPbdq0QdeuXTFq1Chs2rTpue97ZmYmgoKCMHbsWHTt2hXe3t7w9/fH0qVLkZOTo7G9IAjYuXMnxo4di/bt26N9+/YYOnQoVq5cqbbd836vgKLfLU9PzzLr8vT0xEcffaT6/nltFxcXh88++wyDBw9G+/bt0a5dO4waNQo7d+6s8HUPHDhQ9Z5NnDgR+/fvBwAsWbIEnp6euHPnjsa+T548QatWrfDxxx9X/OYS1WMSXRdARPonJCQEpqameO2112Bqaoo+ffogPDwcc+bMUespz8/Px9SpUxEVFYVevXph2LBhMDIyQmxsLI4cOYLJkydj/PjxyMzMxNGjR/Hvf/8bNjY2AFBu8ACAjIwMTJw4EXfv3sXo0aPRqlUrREdHY/v27Th//jx27doFc3NztX2CgoKQm5uL8ePHQyqVYvv27fjoo4/QtGlTdOzYEUDRUJ53330XHh4eePvtt2FhYYEnT57g3LlzuHfvHlxdXSt8X8LCwpCeno4RI0agYcOGePz4MXbt2oU333wTW7ZsQadOndS2z87OxuTJk9GuXTvMmzcP9+/fx5YtWzBz5kxERETAwMAAQNGwlUmTJiExMRETJkyAm5sbLl68iDfeeAO5ublatVlBQQG+//57vPbaa+jbty9MTExw9epVhIaG4s8//0RoaCikUinc3Nzw73//G1999RX8/f3h7+8PADAzM6twXUmRkZHYunUrJk6ciAkTJmi0RVkWLlwIsViM6dOnIzMzE7/++iumTZuGjRs3okePHlq9xpLeeecdKJVK/PHHH/jmm29Uyzt06AAAePjwIcaPH4+CggKMGTMGTZs2xd27d7F9+3ZcuHABoaGhsLCwAADMmTMHf/zxB8aPHw8vLy/k5OQgPj4eUVFRmDZtWoV1PH78GCEhIXjttdcwZMgQSCQSREVFYdOmTYiOjsb333+vtv2CBQuwb98+tGvXDu+88w4sLCwQHx+Pw4cPY86cOQC0+716UeW1XVRUFP744w/06dMHzs7OyMnJwaFDh7B48WKkpaXh7bffVh1DLpfj9ddfx82bN9G/f39MnDgRSqUS169fx2+//YbBgwdj/Pjx2Lp1K0JDQzF//ny1GsLDw6FQKDBmzJgXfh1EdZ5ARFQJubm5QufOnYWFCxeqlh09elTw8PAQTpw4obbthg0bBA8PD2HZsmUax1EoFKqvV61aJXh4eAgJCQka24WGhgoeHh7C+fPnVcuWL18ueHh4CNu2bVPbdtu2bYKHh4cQFBSksf/w4cOFvLw81fLExEShdevWwrx581TLvvzyS8HDw0NITk7W4p3QlJWVpbEsKSlJ6NKlizBt2jS15ZMnTxY8PDyEDRs2qC3fuHGj4OHhIZw6dUq1bNmyZYKHh4cQEhKitu2SJUsEDw8PYfLkyc+tTalUCjk5ORrLd+7cKXh4eAj79+9XLUtISBA8PDyEVatWaWyvzbpWrVoJt27d0lhfVjsXLxszZoxa+zx69Eh45ZVXhAEDBmh17rKOvXDhQsHDw6Ost0N45513hG7dugmPHj1SW37lyhWhZcuWqnPI5XLBw8ND+M9//lPmcZ4nLy9PyM/P11geFBQkeHh4CH///bdq2f79+wUPDw/hgw8+UPv9EAT13xdtf68qev0eHh5qv8PPa7uyfrYVCoUwefJkoUOHDmqv8T//+Y/g4eEh7Nixo8L6xo8fL/Ts2VMoKChQ2+a1114TBg4cWGbdRFSEQ2iIqFKOHDmi6mUu1qdPH9jZ2WkMo9m3bx+srKwwa9YsjeO8zJj2o0ePwtbWFuPHj1dbPn78eNjY2CAyMlJjn9dffx1SqVT1fYMGDeDq6qr2EX5xj+vhw4dRWFhY6bpMTU1VX2dlZSEtLQ1isRjt2rXDlStXNLYXi8V444031JZ169YNAHD37l3VssjISNjb26u95wAwffp0rWsTiUQwNjYGACgUCsjlcqSmpqrOV1Z9L8rX1xdubm6V2ufNN99Ua5+GDRti6NChiI+PR1xcXJXVBhR9gnPixAn4+flBKpUiNTVV9cfJyQlNmzbFmTNnAABGRkaQSqW4cuXKC011KZVKYWhoCAAoLCxEeno6UlNTVZ8q/P3336pt9+3bB+DZpxEllfy+un6vgPLbruTPdl5eHtLS0iCTydCzZ09kZmYiPj4eQNFQrQMHDsDNzQ3jxo2rsL5x48YhKSkJp06dUi27ePEi7ty5w953oufgEBoiqpSQkBDY2tqiYcOGaiGzR48eOHToEFJTU2FrawugKIS2bNkSRkZGVVrD/fv34e3tDYlE/Z8wiUQCV1dXXL9+XWOfJk2aaCyztrbGgwcPVN9PmjQJx44dw3//+18sXboUHTt2RO/evTFkyBDVa6rIvXv3EBQUhNOnT2vMqFPWjZuOjo4a7421tTWAonHXxRISEtCmTRvVkJqS+1taWj63rmIHDhzA5s2bER0djYKCArV16enpWh/neVxcXCq9T1mhsXhZQkJCpS8IKnL79m0olUqEhISUO4NS8c+LVCrFxx9/jC+++AJ9+/aFu7s7unXrhn79+qF79+5ane/nn3/Gjh07cOvWLSiVSrV1Jd/3u3fvwsHBAfb29hUer7p+r4Dy2y4rKwvBwcE4ePAgHj16pLG++Oc9LS0N6enp6N2793NvVh40aBC+/PJLhISEqO6jCAkJgaGhocbFKhGpY4AnIq0lJCTgwoULEAQB/fv3L3ObvXv34s0336zZwrSgTc+kjY0NQkJC8Mcff+Ds2bO4ePEivvrqK6xevRobNmxA+/bty903KysLkyZNQk5ODqZMmQIPDw+YmZlBLBZj/fr1OH/+vMY+pQN5SYIgqH1fXhgqvV15jhw5gnnz5qFt27b4+OOP0ahRIxgZGUGhUGDatGlaH0cbJiYmVXIcbd8DAJX6xKT4uMOGDcPIkSPL3KZkOJ44cSL69u2LkydPIioqCocPH8a2bdswaNAgBAUFVXiuzZs34+uvv0avXr3wxhtvwNHREYaGhnj8+DE++ugjtdcoCEKVztBT3rEqeq/Ka7v58+fjxIkTGDduHDp37gwrKytIJBKcPHkSP/74o+rCpDI/R8bGxhg2bBh+/fVXJCUlwcTEBIcPH4afn59WF8xE9RkDPBFpbffu3RAEAUuWLFENNylpxYoVCA0NVQV4FxcXxMfHIz8/X214RGmVDS1NmjTB7du3UVhYqNYLX1hYiDt37pTZ264tAwMDdO3aFV27dgUAxMTEYPTo0Vi7di02bNhQ7n7nzp3DkydP8OWXX2L06NFq61asWPHC9QBFr/fOnTtQKBRqof/JkyfIyMjQ6hh79uyBkZERtmzZohbSyhqeUlF7VNcUkHFxcfDy8lJbVjwso7g9raysAJT9aUFZw1vKq7Vp06YQiUQoKCjQ+gZZR0dHjB07FmPHjoVCocCHH36IiIgIvPXWW2jbtm25++3ZswdOTk7YuHGj2kVkyWEjxVxdXXHs2DEkJydX2Auv7e9V8fslk8lUn+wARRfilSGXy3HixAkMHz4cn3/+udq6s2fPqn1va2sLKysrxMTEaHXscePG4eeff0Z4eDgsLCyQk5PD4TNEWuAYeCLSilKpRFhYGDw8PDB27FgMGDBA48+QIUMQGxurGk89dOhQpKenY82aNRrHK9lTVzy+VtthHP369UNqaip27dqltnznzp1ITU1Fv379Xug1pqamaixr3rw5jIyMnltbcbAu3QN5+vRptXHOL6Jv375ITk5GeHi42vKNGzdqfQwDAwOIRCK1IRyCIGDt2rUa21bUHpVtK239+OOPyM/PV32fmJiIffv2wdXVVTV8xtzcHA4ODjh//rza+5yQkFDmfQ/FtZYcjgQUfdLi6+uLo0eP4vLlyxr7CYKg+lnIycnRmO7RwMBANUvS894HsVgMkUikVm9hYWGZbTd06FAAwLfffqsx1Kbk/tr+XhUPhykdsjdv3lxhzWW9htLHBoouIEv/DorFYgwePBi3bt3SWFfWMby8vNC2bVuEhoYiJCQEjRs3Rq9evSpVH1F9xB54ItLK6dOn8ejRowp7x1577TWsXr0aISEhaNu2Ld544w389ttvWLt2La5evYpevXpBKpXi1q1buH37Nn788UcAQLt27QAAS5cuxdChQ2FkZIQWLVrAw8OjzPNMmzYNhw4dwueff47r16+jZcuWiI6ORkhICFxdXZ87tV95Fi9ejMTERPTq1QuNGzdGbm4uDh48iKysLAwfPrzCfTt27AgHBwf83//9Hx48eICGDRsiOjoae/bsgYeHB2JjY1+oJqDo9UZERGDx4sW4du0a3N3dERUVhcuXL6um3Xye/v374/Dhw5gyZQpGjBiBwsJCREZGljkXuY2NDZo1a4b9+/ejSZMmsLe3h4mJCfz8/Cpc9zIUCgUmTZqEwYMHIysrCzt27EBeXh4++eQTte0mTZqEFStWYNq0aejXrx+ePHmCHTt2oEWLFrh69aratu3atcO2bdtUzwswNDRE27Zt0aRJE3z22Wd4/fXXMXnyZAwfPhytWrWCUqlEQkICjh07hhEjRmD27Nm4c+cOJk+eDH9/f7Ro0QKWlpaIj4/H9u3b4ezsrDE1aGkDBgzAsmXLMH36dPj7+yMzMxMREREa928AwMCBA3HkyBGEh4fj7t278PPzg6WlJe7cuYPTp08jIiICALT+vRoyZAiCgoLw6aefIj4+HjY2Njh16pTGsxKex9zcHD179sTevXthbGyMNm3a4MGDB/j111/h7OyscYE0d+5cnD9/Hp988gnOnDmDjh07QhAEREdHo7CwEN9++63a9uPGjVO1c2BgIB/aRqQFBngi0krxzX7Fc3+XxcPDAy4uLjhw4AA+/vhjGBsb44cffsAPP/yAiIgILF++HEZGRmjWrBlGjRql2q9jx4744IMPsGPHDixevBiFhYUIDAwsN8BbWFhg+/btWLVqFY4fP47du3fDzs4OEyZMwOzZs7Wad7wsw4cPx+7duxEWFobU1FSYm5vD3d0dq1atKnfMfzFLS0ts2rQJ3377LbZt24bCwkJ4e3tj48aNCAkJeakAb2VlhZ9//hlff/01wsPDIQgCunbtii1btmh9v0FxMP7xxx/xf//3f7CyssKrr76K+fPnq4YLlbR06VJ8+eWXCAoKQk5ODpycnFQhvaJ1L+r//u//sGPHDmzcuBFyuRyenp74+uuv0bNnT7Xtpk+fjoyMDOzduxdRUVFwd3fHF198gWvXrmkE+CFDhiA6Ohr79+/HoUOHoFQq8dVXX6FJkyZo1KgRQkNDsXHjRhw/fhx79+6FkZERGjVqhFdffRUDBw4EUDQbzujRo3HhwgVERkYiPz8fDRo0wNixYzF9+vTnjvefOnUqBEFASEgIvvjiCzg4OGDgwIEYPXo0Bg0apLH9smXL0KlTJ4SEhOC7776DWCyGs7MzBgwYoNpGKpVq9Xtlbm6ODRs24KuvvsL69etVz2749ttv0blz50q1z7fffotly5bh+PHjCAsLg4uLC+bNmweJRIJ///vfattaWVnh119/xbp163D06FFERkaqniNQ1hz1gwcPxtdff43s7Gy1+omofCKhKu9cIiIiIqqE/Px89OrVC23atNF4sBURlY2fUxEREZHO7N27F+np6RrPdSCi8rEHnoiIiGrc8ePH8fDhQ6xevRr29vbYu3dvhVOrEtEzDPBERERU4/z8/PDkyRO0bt0aS5YsQYsWLXRdEpHeYIAnIiIiItIjHANPRERERKRHGOCJiIiIiPQI54GvpLS0LCiVNT/qyM7OHCkpmTV+XqpZbOe6j21cP7Cd6we2c/2gi3YWi0WwsTErdz0DfCUplYJOAnzxuanuYzvXfWzj+oHtXD+wneuH2tbOHEJDRERERKRHGOCJiIiIiPSITofQZGVlISgoCIcOHYJcLoe7uztmzZqFvn37Pnffw4cPY/PmzYiLiwMANG/eHFOmTMGgQYM0tk1ISMCqVatw9uxZpKenw8HBAb6+vvjss8+q+iUREREREVUrnQb4wMBAXL9+HR988AGcnZ0RFhaGwMBArFu3Dr6+vuXuFxYWho8++gj9+/fHu+++CwAIDQ3FvHnzkJ2djTFjxqi2jYmJwRtvvAFvb28sXrwYtra2ePjwIaKjo6v99RERERERVTWdPcjp5MmTmDFjBoKDg+Hv7w8AEAQBr7/+OmQyGQ4ePFjuvgEBAXjw4AEiIyMhFheNAlIqlejXrx+cnJywdetW1fGGDRuGxo0bY926dRCJRC9dd0pKpk5uZHBwsEBSUkaNn5dqFtu57mMb1w9s5/qB7Vw/6KKdxWIR7OzMy19fg7WoOXr0KCwsLNSGy4hEIowcORLx8fG4detWuftKJBKYmpqqwjsAiMVimJqaQiqVqpZFRUUhNjYWU6dOrZLwTkRERESkazoL8Ddv3oS7u7taCAcAT09PAEBsbGy5+06aNAlxcXFYu3YtUlNTkZqairVr1+L27duYMmWKaruLFy8CKOqdnzhxIry9vdG5c2e8//77ePz4cTW8KiIiIiKi6qWzAC+TyWBlZaWxvHiZTCYrd99+/fph7dq1+OGHH9C9e3d0794dGzZswMqVK+Hj46Pa7smTJwCA2bNno3379ti0aRMWLFiAs2fPIiAgADk5OVX7ooiIiIiIqplOb2KtaFhLRevOnDmD+fPnY/Dgwejfvz8UCgX27duH999/H6tWrUKfPn0AFI2BB4CBAwfiww8/BAB069YNjo6OePvttxEREYGxY8dWquaKxiNVNwcHC52dm2oO27nuYxvXD2zn+oHtXD/UtnbWWYC3trYus5c9PT0dAMrsnQeKQvnChQvRrVs3fP7556rlPj4+SExMxP/+9z9VgLe2tgYA9O7dW+0YPXv2hIGBAa5du1bpAM+bWKk6sZ3rPrZx/cB2rh/YznXbuWuJ2H0yDqnyPNhaGmGUrxu6t25YI+d+3k2sOgvw7u7uOHLkCJRKpdo4+OKx7x4eHmXul5ycjKSkJHh7e2us8/b2RlRUFPLy8mBkZFTuMYqVHn9PRET0MnT5Hz4RVZ1z1xLx08EY5BcqAQAp8jz8dDAGAGrF77TOAry/vz9CQkJw/Phx9OvXT7U8PDwcrq6ucHd3L3M/KysrGBkZ4cqVKxrr/v77b1hbW8PIyAhAUa+8sbExTp48qZqqEgB+//13KBQKtG3btopfFRER1Vdl/Yf/48EYyLPz0dnTERIDMSQGIhg8/VssEnGGNKJKEgQBCqWAgkIlChVKFCoEFCiURd+rlhV9X/B0feHTrwvKWl8oqL4vVBQvU+LanTQUKpRq584vVGL3ybj6HeB9fX3RtWtXLFq0CDKZDM7OzggPD8elS5ewZs0a1XYBAQGIiorCjRs3AABSqRQTJkzATz/9hEWLFqF///5QKpWqfefOnava18rKCrNmzUJQUBDMzc3h4+ODO3fuYOXKlfDy8irzqa1EREQVKVQokSLPxZO0HDxOzcaTtBw8keXgn9upGkMsCwqV+PXYLfx6THNqZBGgCvMSAzEMDESQiEt9byBWBX+JgRgGYlGpCwExJOLS24tgUN5xxEX7GZbcv8RFRfH5DUqdkxca6urbJy2CIBQF5ZIBuGQgLhRQUKhAgUIoIyA/Ddkl15dYVxyySwfoZ/sqUVDy3IVKVNVAZkmJ3w1DiRiGBmJIJEU/+6XDe7EUeV4Vnf3l6CzAi0QirFmzBsuXL0dQUBDkcjnc3d0RHBwMPz+/CvdduHAhmjdvjp07d+Lw4cMQi8VwcXHBN998g2HDhqltO2PGDFhYWGDr1q3Ytm0bLC0t8dprr2H+/Plqc8YTEREVK1QokZye+yygp+XgsSwbT1JzkJyeC2WJZyAaGRqggY1JhfdHTRngiUKFAIVCiUKloOo5VBT3ECqVz75WKKEoDjrKom3yC5TIzi0s2kf5rOex9HGU1fRsRs0Lh6Kwr3bRYFAUgMq9EClj+/IvGsQlwtWzkPXsWOrbF+8vroELjZoaWqFUCk/DrbJUD7JQRkAutb6wVIguDtkKBQoK1UP2s9AslArVSrVe7qogAp4G5OLA/LT9SoRnQwMxTKQSGD4N0oal1kueXoAaSgyK2v/pOkOJ+FkYL14vET39vtR6yfN/XhasOVNmWLezNKqS9+Jl6exJrPqKN7FSdWI7131s49qjoFCJJFnO04CejceyHDxJzcbjtBykyHNR8n9HY6kBGtiYwtHGBI42JqqvG9iYwNJMCpFIVOF/+N/O7Fkjr0mpLA74pcK9stSFQYmLg7IuGjS2LbnN0wsIRYlzFF2AlHfOEvWUOGd1EItEZX6CUOZFg6ScTy+eXmyUPk7xRUP47/HIyi3UOLepkQQDuzVVD9lqvdQlA3OpYRtqfz9936ooa4hFIkgkpYJwiUBrWCIEl7W+eF/1AKzeW116vURSYpun75+hRL8+zSl9oQYAUokYUwZ61cinLbX2JlYiIqLqll+gUIX0x8VB/WmPeqo8V+2jeBMjCRrYmKB5Y0t0b91QLahbmBo+N3iM8nUr8z/8Ub5u1fTqNInFIojFBjCs5f+7F49jVl0QFD67EFD7ZKL4AkDjoqL0RUPJiwvNbRXKonCsKPHpR25eYRnnfLZ9cU+2tjE6O68QoSfjATz9xEKtZ1ikHnwNxDAxksDStDg0i9RDdem/S63X7HUWlQrVz84lFutHYK5tikN6bR0qVct/xYmIiCqWV6BAkkZAz8YTWQ5SS/WImxlL4GhjihZNrOBo3fBZT7qtKcyMJS/VO1jb/8OvTURPe8olBoARDHRdToWUSvWLhv/+cBFpmZqftNhYGOHrt7vV2FAeqn7dWzdE99YNa+UnpwzwRERU6+XmFz4bi56Wrfa1LDNfbVsLU0M42pjAs4kNGtiYwNG2qCfdwdoE5iaG1Vpnbf4Pn16MWCyCVGwA6dMfnTGvlv1Jy5g+bjCU1O6LEao7GOCJiKhWyMkrLDOgP0nLQXqWeki3NJPC0cYErV1s4WhrWhTUbUzgaG0CU+PqDelUv/GTFqoNGOCJiKjGZOcWqMaglxyP/iQtG/LsArVtrcylaGBtgjZudk8DuikcrYuCuokR//si3eEnLaRr/BeQiIiqVGZOQamAnq26iTQzRz2k21gYoYGNCV5pYa8K6A1sTeFgbQxjKf+LIiIqC/91JCKiShEEQRXS1Ye7FIX1klPsiQDYWhrB0cYUHT0d1KZidLA2gZEhxwwTEVUWAzwREWkQBAEZ2QWqgF56CsacvBIhXQTYWRrD0cYEXVo2UAX0oh51Y97YR0RUxRjgiYjqKUEQkJ6Vr9aTXnLIS26+QrWtSATYWxmjgY0p3BpbFoXzpw8ysrcygaFErMNXQkRUvzDAE9UC564lckYDqhZKQUB6Zr6q97zkkJcnaTnIK3gW0g3EIthbGRfNk+5srXqQUQMbE9hZGUNiwJBORFQbMMAT6VjpxzWnyPPw08EYAGCIJ60oBQGyjLwyAnrR1yXnqzYQi+DwdCYXr6Y2ql50x6ch3UDMkE5EVNsxwBPpkFIQEHIiTi1gAUB+oRI7j9+Ck70ZDMQiGBiIi/4u/bVYBAMDEcQi0Us9QZJqP6VSQGpGrtq0i8+GvOSgUPHsZ0hiUBTSG9iYopWLrWoKxgY2JrC1NOaj1YmI9BwDPFE1yCtQID0rH/LMfKRn5UGWmV/0fVYe0p9+XfR9PhRKocxjpGfl47PNF7U+Z3GYNxCL1cJ90dfioq9FpbZ5zvbip8slxfuXuIgQPz2WpNRFhbjE/pKS24vV95eU3L7E/pKnNdW1kKnNMCmFUokUeZ4qnD9Jy8Hj1Gw8keUgSZaDQsWznxVDiVjVe962uV2JnnRT2FgY1bn3j4iInmGAJ9KSUikgIztfFcbTs/Igz8pXC+TpmXlIz8pXu/mvmAiAhZkU1mZSWJpL4eRgBiszI5y4/ADZJabdK2ZhYog3BnhCoRSgUAgoVCqhUApQPv1eoRSgUCqfrnu6/On3JdcphBLbK5RP1xX9yStQQKEofLas1PqS3yuf/l1TRMDTcK9+wSEpdZHw/AuUUttofF3GJxsan3KU+r7kstIXQRrrRPgj5gm2HYlVGya1+UA0/olPgZmxIZ7IinrSk2U5au+x1FAMR2tTNLYzwyst7IumYHw6/MXawghifupCRFQvMcBTvSYIAnLyFM/CeMlA/jSMF//JyM6HUEZ+NTEygKWZEazMpGjawAJWZlJYmUthZWb09O+iP+amhmWOL3ZyMFMbAw8AUokYE/q1QEdPx+p8+ZUmCCXDfdFFQnGwLywZ+BUClMKzbQrL2L7kRYlC8ewCoeRFiWr70hcl5VxkKBRK5BUoa+1FSUmFCgHnrj2GkdQADaxN0MTRHJ08HVQBvYGtKazMpBwaRUREGhjgqU4qVChLBXL1oSvF38uz8jXGnwNFw1EsnwZvO0tjuDayLBHMi8K55dOvX/ZBNMXDKPRhFhqRqGiIi8QAgKGuq6kaNXFRsvO3W+Wef808H4Z0IiKqFAZ40huCICArt/BZz3iJoSzF38uz8iHLzFN7EmRJZsYSWJsbwdJMCndnK1UYVwvn5kYwNZbU6PCE7q0bonvrhnBwsEBSUkaNnZdq5qLk2KUEpMjzNJbbWRoxvBMRUaUxwJPO5RUoSowlVw/nxYG8ohs+DSViVQBvYGsKjybWaj3lxV9bmEr5sBnSiVG+bmUOkxrl66bDqoiISF8xwFO1KL7hM730MJZSN33Ks/KQk1f+DZ/Fwbz4hs+SPeWWZlJYmxvBWGrAXkyq1fRpmBQREdV+DPCkNUEQkJuv0LzBs0Q4lxf3nJdzw6ex1ABW5k9v+HQ0h5WZLazMn4Xx593wSaSvOEyKiIiqCgM8qd/wWSqcyzPVb/p83g2fNhZGcGlkAUszI1iXvuHTVAoj6cvd8ElERERU3zHA13LaPPylLKobPksG8qc3eZYeypKZU1DmMcyMJarecjcn9Rs+i2dgsdbBDZ9ERERE9RkDfC127lqi2o1vKfI8/HQwBvLsfLg1tnoayIvCuKyMcK71DZ+lAjlv+CQiIiKqvRjga7HdJ+M0hqzkFyrx6zH1OaXVbvg0k6KxnRkszaWwLjEDi+XT3nMTI97wSURERKTPGOBrsbLmjS42d2y7pz3mvOGTiIiIqD5hgK/F7CyNyn34S1s3Ox1URERERES6xm7bWmyUrxukpcah8+EvRERERPWbTgN8VlYWlixZgl69eqFt27YYNWoUjh07ptW+hw8fxoQJE9C5c2d07twZ48ePx4EDByrc58KFC/Dy8oKnpyfkcnlVvIRq1b11Q0wZ6FX0uHUU9bxPGejFh78QERER1WM6HUITGBiI69ev44MPPoCzszPCwsIQGBiIdevWwdfXt9z9wsLC8NFHH6F///549913AQChoaGYN28esrOzMWbMGI19cnNz8cknn8De3h5JSUnV9pqqGh/+QkREREQl6SzAnzx5EmfPnkVwcDD8/f0BAN26dUNCQgK+/vrrCgP87t274eTkhBUrVkD89ObN3r17o1+/ftizZ0+ZAX7lypUwMzPDoEGDsG7duup5UURERERE1UxnQ2iOHj0KCwsL9O3bV7VMJBJh5MiRiI+Px61bt8rdVyKRwNTUVBXeAUAsFsPU1BRSqVRj+ytXrmDr1q34/PPPIZHwvl0iIiIi0l86C/A3b96Eu7u7WggHAE9PTwBAbGxsuftOmjQJcXFxWLt2LVJTU5Gamoq1a9fi9u3bmDJlitq2BQUFWLRoESZOnIi2bdtW/QshIiIiIqpBOuuOlslkcHFx0VhuZWWlWl+efv36Ye3atViwYAFWrFgBADA1NcXKlSvh4+Ojtu369euRkZGBuXPnVlHlRERERES6o9PxJBU9EbSidWfOnMH8+fMxePBg9O/fHwqFAvv27cP777+PVatWoU+fPgCKevnXrVuH1atXw8zMrEpqtrMzr5LjvAgHBwudnZtqDtu57mMb1w9s5/qB7Vw/1LZ21lmAt7a2LrOXPT09HcCznvjSBEHAwoUL0a1bN3z++eeq5T4+PkhMTMT//vc/VYBfvHgxevbsiY4dO6qmjczLK3owUkZGBgwMDCod7FNSMqFUCpXapypwFpr6ge1c97GN6we2c/3Adq4fdNHOYrGowk5jnQV4d3d3HDlyBEqlUm0cfPHYdw8PjzL3S05ORlJSEry9vTXWeXt7IyoqCnl5eTAyMsKtW7eQkZGBzp07a2zr5+eHdu3aYefOnVX0ioiIiIiIqp/OAry/vz9CQkJw/Phx9OvXT7U8PDwcrq6ucHd3L3M/KysrGBkZ4cqVKxrr/v77b1hbW8PIyAgAsG7dOigUCrVtwsLCEBYWhnXr1sHR0bEKXxERERERUfXTWYD39fVF165dsWjRIshkMjg7OyM8PByXLl3CmjVrVNsFBAQgKioKN27cAABIpVJMmDABP/30ExYtWoT+/ftDqVSq9i15s2qnTp00zhsVFQUA6NixIywtLav3RRIRERERVTGdBXiRSIQ1a9Zg+fLlCAoKglwuh7u7O4KDg+Hn51fhvgsXLkTz5s2xc+dOHD58GGKxGC4uLvjmm28wbNiwGnoFREREREQ1TyQIQs3fkanHeBMrVSe2c93HNq4f2M71A9u5fqiNN7Hq7EFORERERERUeQzwRERERER6hAGeiIiIiEiPMMATEREREekRBngiIiIiIj3CAE9EREREpEcY4ImIiIiI9AgDPBERERGRHmGAJyIiIiLSIwzwRERERER6hAGeiIiIiEiPMMATEREREekRBngiIiIiIj3CAE9EREREpEcY4ImIiIiI9AgDPBERERGRHmGAJyIiIiLSIwzwRERERER6hAGeiIiIiEiPMMATEREREekRBngiIiIiIj3CAE9EREREpEcY4ImIiIiI9AgDPBERERGRHmGAJyIiIiLSIwzwRERERER6hAGeiIiIiEiPMMATEREREekRiS5PnpWVhaCgIBw6dAhyuRzu7u6YNWsW+vbt+9x9Dx8+jM2bNyMuLg4A0Lx5c0yZMgWDBg1SbXP79m3s2LEDFy5cQEJCAiQSCdzc3DB16lStzkFEREREVNvotAc+MDAQ+/btw5w5c7B+/Xq4u7sjMDAQJ0+erHC/sLAwvPfee3B0dMTSpUuxdOlSNGjQAPPmzUNISIhquzNnzuDUqVMYMGAAVq1ahW+++QYNGzbEzJkz8eOPP1bzqyMiIiIiqnoiQRAEXZz45MmTmDFjBoKDg+Hv7w8AEAQBr7/+OmQyGQ4ePFjuvgEBAXjw4AEiIyMhFhddgyiVSvTr1w9OTk7YunUrACA1NRU2NjYQiUQa+8fGxuLChQuVrjslJRNKZc2/ZQ4OFkhKyqjx81LNYjvXfWzj+oHtXD+wnesHXbSzWCyCnZ15+etrsBY1R48ehYWFhdpQFpFIhJEjRyI+Ph63bt0qd1+JRAJTU1NVeAcAsVgMU1NTSKVS1TJbW1uN8A4Abdq0gUwmQ25ubhW9GiIiIiKimqGzAH/z5k24u7urhXAA8PT0BADExsaWu++kSZMQFxeHtWvXIjU1FampqVi7di1u376NKVOmVHheQRBw4cIFNGnSBMbGxi//QoiIiIiIapDObmKVyWRwcXHRWG5lZaVaX55+/fph7dq1WLBgAVasWAEAMDU1xcqVK+Hj41PheX/66Sf8888/+PLLL1+0dCIiIiIindHpLDRlDW/RZt2ZM2cwf/58DB48GP3794dCocC+ffvw/vvvY9WqVejTp0+Z+0VGRuKbb77BqFGjMHr06BequaLxSNXNwcFCZ+emmsN2rvvYxvUD27l+YDvXD7WtnXUW4K2trcvsZU9PTwfwrCe+NEEQsHDhQnTr1g2ff/65armPjw8SExPxv//9r8wAf+LECcydOxf+/v5YsmTJC9fNm1ipOrGd6z62cf3Adq4f2M71A29iLcHd3R1xcXFQKpVqy4vHvnt4eJS5X3JyMpKSkuDt7a2xztvbG/fv30deXp7a8pMnTyIwMBA+Pj5YunQpDAwMquhVEBERERHVLJ0FeH9/f8jlchw/flxteXh4OFxdXeHu7l7mflZWVjAyMsKVK1c01v3999+wtraGkZGRatnvv/+OwMBA9OjRAytWrIChoWHVvhAiIiIiohqksyE0vr6+6Nq1KxYtWgSZTAZnZ2eEh4fj0qVLWLNmjWq7gIAAREVF4caNGwAAqVSKCRMm4KeffsKiRYvQv39/KJVK1b5z585V7fvHH38gMDAQDRo0wLRp03D9+nW1Glq1aqU27SQRERERUW2nswAvEomwZs0aLF++HEFBQZDL5XB3d0dwcDD8/Pwq3HfhwoVo3rw5du7cicOHD0MsFsPFxQXffPMNhg0bptru3LlzyM3NRUJCAgICAjSOc+zYMTg7O1f5ayMiIiIiqi46exKrvuJNrFSd2M51H9u4fmA71w9s5/qBN7ESEREREdFLYYAnIiIiItIjDPBERERERHqEAZ6IiIiISI8wwBMRERER6REGeCIiIiIiPcIAT0RERESkRxjgiYiIiIj0CAM8EREREZEeYYAnIiIiItIjDPBERERERHqEAZ6IiIiISI8wwBMRERER6REGeCIiIiIiPcIAT0RERESkRxjgiYiIiIj0CAM8EREREZEeYYAnIiIiItIjDPBERERERHqEAZ6IiIiISI8wwBMRERER6REGeCIiIiIiPcIAT0RERESkRxjgiYiIiIj0CAM8EREREZEe0TrAr127Fo8fP67OWoiIiIiI6Dm0DvArV66En58f3nnnHURGRkKhUFRnXUREREREVAatA/zOnTsxevRo/PHHH5g9ezZ8fX2xdOlS3L59+4VPnpWVhSVLlqBXr15o27YtRo0ahWPHjmm17+HDhzFhwgR07twZnTt3xvjx43HgwIEyt92yZQv69+8Pb29v9OvXDxs3boRSqXzhuomIiIiIdEXrAN+2bVt8/vnnOH36NL766iu4uLhg06ZNGDRoECZNmoTw8HDk5uZW6uSBgYHYt28f5syZg/Xr18Pd3R2BgYE4efJkhfuFhYXhvffeg6OjI5YuXYqlS5eiQYMGmDdvHkJCQtS2XbNmDb766isMGjQI33//PcaMGYMVK1Zg+fLllaqViIiIiKg2EAmCILzoznfv3kVISAjCw8ORnJwMMzMzDBkyBOPHj0fLli0r3PfkyZOYMWMGgoOD4e/vDwAQBAGvv/46ZDIZDh48WO6+AQEBePDgASIjIyEWF12DKJVK9OvXD05OTti6dSsAIC0tDb6+vhg3bhw++eQT1f5BQUHYtGkTjh07hoYNG1bqNaekZEKpfOG37IU5OFggKSmjxs9LNYvtXPexjesHtnP9wHauH3TRzmKxCHZ25uWvf5mDOzk5oXXr1nBzc4MgCMjOzsauXbswatQozJgxA0+ePCl336NHj8LCwgJ9+/ZVLROJRBg5ciTi4+Nx69atcveVSCQwNTVVhXcAEIvFMDU1hVQqVS37/fffkZeXh5EjR6rtP3LkSBQWFmo9XIeIiIiIqLZ4oQB/8+ZNfPXVV+jduzfmzZuH27dv491330VkZCROnDiBd955BxcuXMDHH39c4THc3d3VQjgAeHp6AgBiY2PL3XfSpEmIi4vD2rVrkZqaitTUVKxduxa3b9/GlClT1M4hEonQokULtf1dXFxgbGyMmzdvvsjLJyIiIiLSGYm2G2ZlZWH//v0ICQnB1atXIRaL0bt3b4wbNw59+vRRC+Jz5syBqakpvvvuu3KPJ5PJ4OLiorHcyspKtb48/fr1w9q1a7FgwQKsWLECAGBqaoqVK1fCx8dH7RwmJiZqvfLFLC0tKzwHEREREVFtpHWA79WrF3Jzc9GwYUPMmjULY8aMqXD8uJOT03NvahWJRC+07syZM5g/fz4GDx6M/v37Q6FQYN++fXj//fexatUq9OnT57mv53nnKE9F45Gqm4ODhc7OTTWH7Vz3sY3rB7Zz/cB2rh9qWztrHeC7deuG8ePHw8fHR2PYS1kGDRqEQYMGlbve2tq6zB7w9PR0AM964ksTBAELFy5Et27d8Pnnn6uW+/j4IDExEf/73/9UAd7a2ho5OTnIz8/X6IWXy+XlnqMivImVqhPbue5jG9cPbOf6ge1cP+j1Taxr167VGCrzMtzd3REXF6cxH3vx2HcPD48y90tOTkZSUhK8vb011nl7e+P+/fvIy8tTnUMQBI2x7nfv3kVubq7G2HgiIiIiotpO6zR+7tw5LFu2rNz1y5Ytw/nz57U+sb+/P+RyOY4fP662PDw8HK6urnB3dy9zPysrKxgZGeHKlSsa6/7++29YW1vDyMgIQFGvvFQqxZ49e9S2CwsLg0QigZ+fn9b1EhERERHVBloPodm4cSPMzcvvyr9//z42btyIbt26aXU8X19fdO3aFYsWLYJMJoOzszPCw8Nx6dIlrFmzRrVdQEAAoqKicOPGDQCAVCrFhAkT8NNPP2HRokXo378/lEqlat+5c+eq9rWxscHbb7+NNWvWwMLCAl27dsXly5exadMmvPHGG2jUqJG2L5+IiIiIqFbQOsDHxMRg2rRp5a5v164dNm3apPWJRSIR1qxZg+XLlyMoKAhyuRzu7u4IDg5+bs/4woUL0bx5c+zcuROHDx+GWCyGi4sLvvnmGwwbNkxt21mzZsHc3By//PIL1q9fD0dHR8yePRvTp0/XulYiIiIiotpC6yextmnTBh9//DEmTpxY5vrt27fjyy+/xNWrV6u0wNqGN7FSdWI7131s4/qB7Vw/sJ3rB72+ibVBgwa4du1aueuvXbsGBweHylVHRERERESVonWA79OnD8LDw3H27FmNdefOnUN4eLjaQ5SIiIiIiKjqaT0G/p133sHhw4cxdepU+Pj4wMvLCyKRCNHR0Th16hTs7e0xc+bM6qyViIiIiKje0zrA29vbY8eOHfjss89w6tQpnDx5EkDRzag+Pj5YvHgxHB0dq61QIiIiIiKqRIAHACcnJ2zcuBHp6em4e/cuAKBZs2Yv9ERTIiIiIiKqvEoF+GJWVlZo27ZtVddCRERERETP8UIBPisrCxkZGVAqlRrrGjdu/NJFERER6aOoxD+xN+4QZHkyWBtZY5jbAHRp2EHXZRFRHVOpAL9//36sXbsWcXFx5W4THR390kURERHpm6jEP/FLTCgKlAUAgLQ8GX6JCQUAhngiPVSbL8i1DvCRkZGYP38+XFxcMH78eOzYsQNDhgyBQqFAZGQkPDw88Oqrr1ZnrURERLXW3rhDqvBerEBZgO0xu5GamwZ7Ezs4PP1jamiqoyqJSBtRjy7hlxu7a+0FudYB/vvvv4ebmxt2796NrKws7NixA6NHj0b37t0RGxuLiRMnwsvLqzprJSIiqpWUghJpebIy1+Ur87Ev/rDaMlOJCRxM7GFvYgsHE7uicG9a9L2V1BIikagGqiaq3/IU+UjJSUVyTgpSctOe/p2K5JxUPMp6rLF9gbIAe+MO6VeAv3HjBt59910YGRkhJycHAFRj4D08PDBu3Dhs2LAB/fr1q55KiYiIaqHH2UnYen1nuettjKyxuNsHSM5JQVJOyrO/s1NwR56AP59cgQBBtb2h2FAV6osCvr3qe1tjaxiIDWriZRHpPYVSAVleOpJzUlXBXPV3TioyCjLVtjcykMLOuOh3rqwAD6DcC/WapnWAVyqVsLa2BgAYGxsDADIyMlTrmzdvjh07dlRtdURERLWUUlDi5P2z2BN3EBKxBL0bd8P5xEtqw2gMxYYY5jYARgZSOJk3gpN5I43jKJQKpOSmqcJ9UcBPxpOcZESn3kCBslC1rVgkhq2xzbNee7W/bSE1kNbIayeqDQRBQFZB9tNQnoKUnDQk5z79OycFqXkyKIVnE66IRWLYGFnD3sQWbexbwd7EFnYmtkV/G9vC3NBM9enXJ2e+LDOs2xhZ19Crq5jWAb5BgwZ4+PAhgKIAb2dnh3/++QcDBgwAAMTHx8PExKR6qiQiIqpFknNSsS16J27K4tHazguve42GtZEVmlu7VPqmNwOxARxN7eFoaq+xTikoIc/PQFJ2MpKeftSflJOM5Jyi3vucwhy17a2kls/G2pvacdw96b18RQFSn/aaJ+cW9ZynlPg6V5Gntr25oRnsTezQzLIJOpq8AjsTG9gb28HOxBY2RlZaf4I1zG2A2k3pwLML8tpA6wDfoUMHnDt3DnPmzAEA+Pn5YcuWLTA2NoYgCPjll194EysREdVpgiDg9MPz2H1rP8QQYZLXWHRv1EnVa9elYQd0adgBDg4WSErKeM7Rnk8sEsPayArWRlZoYeOmsT6rILso0GenICknVRXuo1Nv4Hyi+vlNJSZqgd5eNfbejuPuSWeUghLpefKiT59y05CSk4LknDSk5KYgJScV6fnqP8eGYsOiXnNjW7hbN1f1nhf/bSwxqpK6ii+8a+ssNCJBEITnbwZcuXIFkZGRmDlzJoyNjZGamoq33noLN27cAAC0aNECGzZsQKNGmh8P1iUpKZlQKrV6y6pUVf1nQLUb27nuYxvrr7RcGbZF70JM2k142bTApJZjYGtsU+a2taGd8xT5JYbkPBt3X9bQAkOxoWq8ffGNtUVfc9x9RWpDO+uD7IJstR70kj3pKblpUAgK1bYiiGBtZPVseIuxXVEvuokd7IxtYSk1r/GLTV20s1gsgp2debnrtQ7w5YmJiYGBgQHc3NwgFotf5lB6gQGeqhPbue5jG+sfQRBw/tEfCLm5D0ooMdJtMHo7daswRNT2di4ed69xY+3TPxrj7o2sn86SU/rG2vo97r62t3NNKVAWIjU3TXVzaPLT3vPisJ5TmKu2vZnEFHaqgK4+Dt3W2BoS8Qs9Z7Ta1MYAr9U7lJ2djR9++AHt2rVD79691dZx6kgiIqqr0vPk+CUmFP+kRMPd2hUBLcfB3sRO12W9NO3G3aeUurH2+ePui4fkFH9txnH3dULxz0RyqfHnxbO6pOfJ1WZSkoglsDO2hZ2JDVytXNR60O1NbGAi4T2TL0urAG9qaor169fj008/re56iIiIdE4QBFx6fBm/xoajQFmA0S2Goo9zT4hFdf+TZvVx98011mcVZBcF+lI31kan3tAYr8xx9/ojpzC3xDSL6jO6pOSmorDEpzIiiGBlZAk7Y1t42rhr9KRbSi3qxe+KLmn9GUXTpk2RlJRUnbUQERHpXEZ+JnbcCMPlpKtwtWyKgJbj0MDMUddl1RpmhqYwMzRFM8smGuvyFflIfnozbVHvfSqSspNxV56Av5KuljnuvnTAdzCx57j7alCoLERqrkxtHvSSY9GzCrPVtjeRGMPe2BaNzBzhbe+lmsnF3sQWtsY2MKxlw1zqG63f/ddffx2bNm3CxIkTYWNT9k07RERE+uyvJ1ex48Zu5BbmYnjzgejb1IdBshKkBlI0Nm+IxuYNNdYplAqk5spUM+UklRh3H5N6U226vuJx9yWfUPvsxtr6Pe6+PIIgIKMg81k4L9GbnpyTClleutowFwORAeyMbWBnYoumls7PetCfzujCaUdrN60DvJmZGaysrDBgwACMHDkSzZo1K3Pe9xEjRlRlfURERNUuqyAbO2PD8cfjy2hi4YQ3Wo4vM4TSizMQGxSNjzfVvIeg5Lj70jPn/PH4chnj7i1gX+IJtQ4mtqqbbOvyuPvcwjyk5JY9Dj0lJxX5JS6CgKL3yc6keLpFG9iZ2MHeuGg8upWRJYe56DGtZ6HR5mZVkUiE6Ojoly6qNuMsNFSd2M51H9u49vknORq/xIQgoyALA136on8zv5fudWc7Vy3VuPucFFXIL+69T8+Xq21rIjEpNSTn2bj7qh6bXdXtrFAqkJaXXmIml6KZgopnDMosyFLb3shAWnRfwdPe85I96LbGtpAaGFZZbfWZ3s5CAwBbtmypkoKIiIhqg5zCHITc3Ifzj/5AY7OGeLfdv9DEwknXZVEZtBt3X/yU2qJhI3cz7pcx7l7y7EbaUjfW2hnbaH3hFpX45ws94EcQBGQWZKmPQ1cNdUlFWqn5+UsOJWrn0FpjTnQzQ1PeCFxPaR3gu3TpUp11EBER1ZjolFhsi9mF9Dw5Xmv2Kga5+vOmPD2lzbj74plyim+sfd64e3tTzYBv9HTcfVTin/glJlS1b1qeDL/EhAIoenpnviJf1WNeciaXop70VOQp8tVqtDA0h52JLVytmqKT8StPb+wtmhPd2siK92BQmV76QU71DYfQUHViO9d9bGPdyi3MQ1jcfpx+cB4NTB0Q0HI8XK2aVvl52M61nyAISM+Xq2bKKX1jbXaZ4+7tkJDxEPnKfI3jSUQGMDU0hbzUVJpSsaHag4qKe/uLnnJrA2OJUbW+Tnp5ej2EJjg4+LnbiEQizJo1S9tDEhER1ZibaXHYGr0Lqblp6NvEB0Oa9+cY4XpMJBKp5rt3t3bVWF9y3H3J8fdlhXcAKBQUaG3nVSKoF41JtzA05zAXqnJVEuBFIhEEQWCAJyKiWidfkY+9cYfw2/3TsDexw9wO75QZ2IhKKm/c/SdnvkRankxjexsja0xuObaGqqP6TusAf+zYMY1lCoUC9+7dw48//ojMzEx8/fXXlTp5VlYWgoKCcOjQIcjlcri7u2PWrFno27dvhfv5+fnhwYMHZa5zdXXFoUOHVN8nJSVhzZo1OHXqFJKSkmBvb49evXph1qxZaNCgQaXqJSIi/RKffhdbr/+KJznJ8HHqgRHug1RjmYlexDC3AWpj4IGih1INcxugw6qovtE6wDs5lX1nftOmTdGzZ09MmjQJu3fvxvvvv6/1yQMDA3H9+nV88MEHcHZ2RlhYGAIDA7Fu3Tr4+vqWu19wcDDy89U/woqNjcXixYvRr18/1bL8/HxMnjwZ6enpeO+99+Dm5oa4uDisWrUK58+fR0REBKRS/kNORFTXFCgKsP/2UUTeOwlrIyvMfmU6vGxb6LosqgOKZ5t5kVloiKpKldxyLxKJ0L9/f3z//fdaB/iTJ0/i7NmzCA4Ohr+/PwCgW7duSEhIwNdff11hgG/VqpXGsoiICADA6NGjVcv++usv3LlzB0uWLMHYsUUfa3Xt2hWGhob45JNP8Ndff6Fr165av04iIqr97snv46foX5GY9Rg9GnXBqBZDYCIx1nVZVId0adgBXRp24M3KpDNV9jSDgoICyGQyrbc/evQoLCws1IbLiEQijBw5EvHx8bh165bWx8rPz8e+ffvQsWNHuLo+G9cokRRdn1hYWKhtX/w9e9+JiOqOQmUhIuIP49tLwcgpyMHMdv/CpJZjGN6JqM6pkh74q1evYsuWLXBzc9N6n5s3b8Ld3R1isfo1hKenJ4CiITHu7u5aHSsyMhIymUyt9x0AXnnlFbRt2xbBwcFwcnJC8+bNER8fj+DgYHTu3Bnt2rXTul4iIqq9HmQ+wpbrv+J+5kN0adgBY1sMg6mhqa7LIiKqFloH+PJuLE1PT0dWVhYMDAywZMkSrU8sk8ng4uKisdzKykq1XluhoaEwNTXFwIED1ZYbGBjgxx9/xIcffogxY8aolvfu3RsrV67UuHggIiL9olAqcPTeCRy4HQlTiQlmtJmCdg6tdV0WEVG10jrAN27cWGOZSCRC69at4eLignHjxsHZ2blSJ69oXlRt50xNTEzE2bNnMWrUKJiaqve2FBQUYP78+bh58ya+/PJLNGvWDHFxcQgODsbMmTOxadMmGBpWbg7giibVr24ODhbP34j0Htu57mMbV4378kf47sJPiEu9i+5NOmJqxwmwNNLdv9GlsZ3rB7Zz/VDb2lnrAL9169YqPbG1tXWZvezp6ekAnvXEP8/u3buhVCo1hs8ART3zv/32G/bs2QMvLy8AQKdOneDq6oqAgADs378fI0aMqFTdfBIrVSe2c93HNn55SkGJ4wm/Y1/8YRgZSPGv1pPQsUE75MkFJKF2vLds5/qB7Vw/6PWTWKuau7s7jhw5AqVSqTaUJTY2FgDg4eHx3GMIgoCwsDA0b94cHTpoTt90/fp1GBoaqsJ7MW9vbwCo1I2yRESke0+yk7E1eifi0++grX1rTPAcBSuj2tUzRkRU3bQeBH7gwAF8+OGH5a5fuHCh2gOUnsff3x9yuRzHjx9XWx4eHg5XV1etbmCNiorCvXv3yux9BwBHR0cUFBTg+vXrassvX74MAHyQExGRnlAKSpy4fwZfRQXhUVYi3mg5HjPavMHwTkT1ktY98Nu2bUPTpk3LXS8Wi7Ft2zYMGKDdk8h8fX3RtWtXLFq0CDKZDM7OzggPD8elS5ewZs0a1XYBAQGIiorCjRs3NI4RGhoKiURS7jCYUaNG4ccff0RgYCDeffddNGnSBHFxcVizZg3s7e0xZMgQrWolIiLdSclJxbboXYiVxaGVrScmtRwDayPthlkSEdVFWgf4uLg49O/fv9z1rVq1wm+//ab1iUUiEdasWYPly5cjKCgIcrkc7u7uCA4Ohp+f33P3z8zMxJEjR+Dj4wN7e/syt2ncuDF27dqF4OBgrF27FsnJyXBwcICvry8CAwNhY2Ojdb1ERFSzBEHAmYcXsPtW0YP6XvcajR6Numg9yQERUV2ldYDPycmBgYFBuetFIhGysrIqdXJzc3N8+umn+PTTT8vdprybZ83NzVVDYSri6uqKZcuWVaouIiLSrbRcGX6OCUF0aiw8rN0wueVY2JnY6rosIqJaQesA7+zsjEuXLmHy5Mllrr906VKZU00SERFpSxAERCX+iV0390ChVGCcxwj0duoGsYjP7SAiKqb1v4j+/v44dOgQdu3apbEuJCQEhw4dgr+/f5UWR0RE9Ud6XgbWX/0JW6J/RWOzhvh3l3nwde7B8E5EVIrWPfDTp0/HsWPH8Omnn+Knn36Cl5cXRCIRYmJicOvWLbi6uuKdd96pzlqJiKiOuvT4Mn69EY48ZT5GuQ/Bq016MbgTEZVD6wBvbm6O7du3Y9myZTh48KBqDnUrKytMnDgRc+fOhbl57XkCHhER1X6Z+VnYERuGv55cQTOLJnij1Tg0NOMUv0REFREJglDpx4oKgoC0tDQIggBbW9t6NSMAn8RK1YntXPexjZ/5O+kfbI/ZjezCHAxy9Yd/U18YiMufLEGfsJ3rB7Zz/VBnnsQqEolga8vZAIiIqPKyC7KxM3YvLj7+E03MG2N2++lwMm+k67KIiPSG1gMMf/75Z7z55pvlrv/Xv/6FHTt2VEVNRERUR11LicGSC8tx6cllDHLphwWdZjO8ExFVktYBfvfu3WjWrFm5611cXBAaGlolRRERUd2SU5iLn6N3Yc3fP8DU0AQLOgZicPPX6syQGSKimqT1EJq7d+9i1KhR5a53d3dHRERElRRFRER1R0zqTWyL3gVZXjr8m/bB4OavwVD8QiM4iYgIlQjwhYWFyM/PL3d9fn4+8vLyqqQoIiLSf7mFedgTdwCnHpyDo6k95necCVer8j/JJSIi7Wgd4F1cXHDmzBm89dZbZa4/ffo0mjZtWmWFERGR/rolu42t139FSm4aXm3SC8OaD4DUQKrrsoiI6gStx8APHjwYZ86cwYoVK9R64gsKCrBq1SqcOXMGQ4YMqZYiiYhIP+QrChB6cx9W/LkOAoA57d/GmBbDGN6JiKqQ1j3wb775Jk6dOoV169Zh+/btaN68OUQiEeLi4pCeno5OnTqV2ztPRER13+30e9ga/SseZyeht1N3jHAbBGOJka7LIiKqc7QO8IaGhvjhhx/w448/IiIiAtHR0QCKhtbMmDEDU6ZMgVKprLZCiYiodipQFuLA7aM4evcErI2sMPuV6fCybaHrsoiI6qxKTQNgaGiI6dOnY/r06WrL//nnHyxZsgQHDx7EhQsXqrRAIiKqve5l3MfW6zvxMCsR3Rt1xugWQ2AiMdF1WUREddoLz+Mlk8mwd+9ehISE4ObNmxAEAS4uLlVYGhER1VYKpQKH7h7HoTvHYGFohnfbvgVv+5a6LouIqF6odID//fffERoaiuPHj6OgoAAuLi6YNWsW+vfvjxYt+JEpEVFd9zAzEVuif0VCxgN0btAeYz2Gw8zQVNdlERHVG1oF+ISEBOzevRvh4eFITEyEra0t+vfvj4iICMybNw+vvfZadddJREQ6plAqEHnvJA7cPgpjiTGmt3kDrzh467osIqJ6p8IAv2/fPoSEhODixYswMDBAnz598Mknn6BPnz64f/8+9u3bV1N1EhGRDj3OeoIt0TtxR34Przi0wQTPkbCQmuu6LCKieqnCAL9gwQI0adIEH3/8MYYMGQJra2vVOpFIVN21ERGRjikFJU4knMbe+EOQiqV4q/Xr6OjYjv8HEBHpUIUB3tDQEA8ePMCxY8dgaWmJ1157DcbGxjVVGxER6VBSdgq2Ru9EXPpttLFviYmeo2FlZKnrsoiI6r0KA/yZM2ewd+9ehIaG4sMPP8Rnn32GAQMGYOTIkXB0dKypGomIqAYpBSVOPziPsFv7IRYZIKDlOHRt2JG97kREtUSFAd7S0hKTJ0/G5MmTce3aNYSEhODAgQMICwuDra0tRCIRMjIyaqpWIiKqZqm5adgWvQs30m6hpa0HJnmNgY2xta7LIiKiEkSCIAiV2SE/Px+HDx9GSEgIoqKiAAAeHh7o378//P396/xUkikpmVAqK/WWVQkHBwskJfFiqa5jO9d9tbWNBUHAuUcXEXpzH5QQMMp9CHo17spe9xdUW9uZqhbbuX7QRTuLxSLY2ZU/UUClA3xJ9+/fR2hoKMLDw/Ho0SOIxWJcv379RQ+nFxjgqTqxneu+2tjGsrx0/BITimspMWhh3RyTW46DvYmtrsvSa7WxnanqsZ3rh9oY4F/4SawA4OzsjDlz5uC9995TPeCJiIj0gyAIuPj4L+yM3YNCZSHGtBgGX+ceEIvEui6NiIgq8FIBvphIJIKPjw98fHyq4nBERFTN5PkZ2HEjDH8n/QNXy2YIaDUODUwddF0WERFpoUoCPBER6Y8/n1zBrzfCkKvIwwi3Qejb1Ie97kREekSnAT4rKwtBQUE4dOgQ5HI53N3dMWvWLPTt27fC/fz8/PDgwYMy17m6uuLQoUNqyxISErBq1SqcPXsW6enpcHBwgK+vLz777LOqeilERLVeZkEWdt4Ix6Unf6OphTPeaDUejcwa6LosIiKqJJ0G+MDAQFy/fh0ffPABnJ2dERYWhsDAQKxbtw6+vr7l7hccHIz8/Hy1ZbGxsVi8eDH69euntjwmJgZvvPEGvL29sXjxYtja2uLhw4eIjo6ultdERFQbXUm6hl9uhCK7IAdDXPvjtWZ9YCA20HVZRET0AnQW4E+ePImzZ88iODgY/v7+AIBu3bohISEBX3/9dYUBvlWrVhrLIiIiAACjR49WLRMEAQsWLED79u2xbt06tenQRowYUUWvhIio9souyEHIzb24kHgJTuaNENhuGpwtGuu6LCIiegk6G/R49OhRWFhYqA2XEYlEGDlyJOLj43Hr1i2tj5Wfn499+/ahY8eOcHV1VS2PiopCbGwspk6dyrmMiajeuZ5yA19ELcfFx39hgEtffNhpNsM7EVEdoLMe+Js3b8Ld3R1isfo1hKenJ4CiITHu7u5aHSsyMhIymUyt9x0ALl68CABQKpWYOHEirl69ChMTE/Tu3RsLFy5EgwYc+0lEdU9uYS5234rAmYdRaGjqiBkd30Azyya6LouIiKqIznrgZTIZrKysNJYXL5PJZFofKzQ0FKamphg4cKDa8idPngAAZs+ejfbt22PTpk1YsGABzp49i4CAAOTk5Lz4CyAiqoVi027hy6ggnH14Ef2a+uKjznMY3omI6hid3sRa0bAWbYe8JCYm4uzZsxg1ahRMTU3V1hU/ZHbgwIH48MMPARSNs3d0dMTbb7+NiIgIjB07tlI1V/RUrOrm4GChs3NTzWE7133V0ca5hXn45Uo4Dt08gYbmDvi873x42rtV+XlIe/xdrh/YzvVDbWtnnQV4a2vrMnvZ09PTAaDM3vmy7N69G0qlUmP4TPE5AKB3795qy3v27AkDAwNcu3at0gE+JSUTSqVQqX2qAh/XXD+wneu+6mjjONkdbI3+FUk5Kejj3BPD3QZCKkj5s6RD/F2uH9jO9YMu2lksFlXYaayzAO/u7o4jR45AqVSqjYOPjY0FAHh4eDz3GIIgICwsDM2bN0eHDh001j/vGKXH3xMR6ZMCRQH23T6M4/d+h62xNea0fxseNux1JyKq63SWYP39/SGXy3H8+HG15eHh4XB1ddXqBtaoqCjcu3evzN53APDx8YGxsTFOnjyptvz333+HQqFA27ZtX/wFEBHp0F15Ar6+uBLH7p1Cz8Zd8HGXeQzvRET1hM564H19fdG1a1csWrQIMpkMzs7OCA8Px6VLl7BmzRrVdgEBAYiKisKNGzc0jhEaGgqJRFLunO5WVlaYNWsWgoKCYG5uDh8fH9y5cwcrV66El5cXBg0aVF0vj4ioWhQqC3HwdiSO3DsBS6kFZrWbilZ2nroui4iIapDOArxIJMKaNWuwfPlyBAUFQS6Xw93dHcHBwfDz83vu/pmZmThy5Ah8fHxgb29f7nYzZsyAhYUFtm7dim3btsHS0hKvvfYa5s+fD6lUWpUviYioWiVkPMTW6F/xIPMRujXshNEthsLU0ETXZRERUQ0TCcVTtZBWeBMrVSe2c933Im2sUCpw5O5vOHAnEuaGZnjdazTa2Gs+kZpqD/4u1w9s5/qBN7ESEVGlPMxMxNboX3Ev4wE6NXgFYz2Gw9zQTNdlERGRDjHAExHVQkpBiWP3TiEi/jCMJcaY6j0ZHRx54z0RETHAExHVOo+zk7D1+k7clt9FOwdvTPQcBQup7h4iR0REtQsDPBFRLaEUlDh5/yz2xB2EoViCN1tNRKcGr2j9ZGoiIqofGOCJiGqB5JxUbIveiZuyeLS288LrXqNhbaTdE6mJiKh+YYAnItIhQRBw+uF57L61H2KIMMlrLLo36sRedyIiKhcDPBGRjqTlyrAtehdi0m7Cy6YFJrUcA1tjG12XRUREtRwDPBFRDYhK/BN74w5BlieDtZE1Wtl54tLjv6GEEuM9RqK3Uzf2uhMRkVYY4ImIqllU4p/4JSYUBcoCAEBangxnHl6Ao4k9Zr0yFfYmdjqukIiI9AkDPFEtULp3dpjbAHRp2EHXZekNQRCgEBRQCEooBQUUSiUUggJKQalarlCWWP/0+2fri7/WXK4QlFA+3VfxdPmz74uPWXx89XMW1xIri0OhslCj7gJlIcM7ERFVGgM8kY6V1Tv7S0woAFRpiC8OuaqAqVSWCLTVEHI1Qm15xyuq5XnHU99XvUYBQpW9T9oQQQQDkRhisQEMRAYwEImLvi/++ulysUgMA5FBmeEdKGprIiKiymKAJ9KxvXGHVOG9WIGyANtjQnE1+XqlQm75PcFFf2pSZUOugVgMsUgMQ7EhjIuXiw2e7iNWHUP9eCXWl3O8om1KH6/E/mLx0/XPajQQG1Swb9GfyvjkzJdlhnUbI+uqebOJiKheYYAn0rHyemHzlQV4kPmojCBZFHKNVAG0OGxWV8gtY7/i9arwq1lLZUNuXTbMbYDapywAYCg2xDC3ATqsioiI9BUDPJGOpOfJsTM2vNz1NkbW+LTbgporiKpN8VAo3udARERVgQGeqIYJgoDziZcQenMfCpQF6ODYFleTo9k7W8d1adgBXRp2gIODBZKSMnRdDhER6TEGeKIalJKThu03QhGdGgs3KxdM8hqDBmaOnIWGiIiItMYAT1QDlIISpx6cw564gwCAcR4j0Nupm2qcOHtniYiISFsM8ETV7HHWE/wcE4K49DtoaeuBiZ6jYWdio+uyiIiISE8xwBNVE4VSgWMJp7D/9lFIxYYIaDkOXRt2hEgk0nVpREREpMcY4Imqwf2Mh9gWswsJGQ/wioM3xnmMhJWRha7LIiIiojqAAZ6oChUoC3HozjEcufsbzAxNMc07AO0d2+i6LCIiIqpDGOCJqsjt9LvYFr0LidlP0LVhR4xuMRRmhqa6LouIiIjqGAZ4opeUp8jHvvhDOJFwBtZGVpjZ7l9obeel67KIiIiojmKAJ3oJN1Jv4ZeYECTnpsLHqTuGuw2EscRY12URERFRHcYAT/QCcgpzsPvmfpx9FAVHE3vMbf8OWtg013VZREREVA8wwBNV0tXk69gesxvy/Az4N+2DQa7+kBoY6rosIiIiqicY4Im0lJGfiZCbe/HH48tobNYQb7edgmaWTXRdFhEREdUzOg3wWVlZCAoKwqFDhyCXy+Hu7o5Zs2ahb9++Fe7n5+eHBw8elLnO1dUVhw4dKnPdhQsXMGXKFAiCgIsXL8LS0vKlXwPVfYIg4NLjy9h1cy9yCnMx2NUfrzV7FRIxr3+JiIio5uk0gQQGBuL69ev44IMP4OzsjLCwMAQGBmLdunXw9fUtd7/g4GDk5+erLYuNjcXixYvRr1+/MvfJzc3FJ598Ant7eyQlJVXp66C6S5aXju0xu/FPSjSaWTbBZK+xaGzeUNdlERERUT2mswB/8uRJnD17FsHBwfD39wcAdOvWDQkJCfj6668rDPCtWrXSWBYREQEAGD16dJn7rFy5EmZmZhg0aBDWrVtXBa+A6jJBEHD2YRR239oPhaDAKPcheLVJL4hFYl2XRkRERPWcztLI0aNHYWFhoTZcRiQSYeTIkYiPj8etW7e0PlZ+fj727duHjh07wtXVVWP9lStXsHXrVnz++eeQSDjsgSqWlJ2CVX9twC83QtHEojE+7jIPfZv6MLwTERFRraCzNHvz5k24u7tDLFYPRZ6engCKhsS4u7trdazIyEjIZLIye98LCgqwaNEiTJw4EW3btsXJkydfvniqk5SCEicSTmNv/GEYiMSY6DkKPRp3YXAnIiKiWkVnAV4mk8HFxUVjuZWVlWq9tkJDQ2FqaoqBAwdqrFu/fj0yMjIwd+7cF6yU6oNHWY/xc/Qu3Jbfg7edFyZ4joKNsbWuyyIiIiLSoNPxJCKR6IXWlZSYmIizZ89i1KhRMDU1VVt38+ZNrFu3DqtXr4aZmdlL1VrMzs68So7zIhwcLHR27rqqUKlAePRh7L5+ECYSI7zX7S30bNpZ65+/6sB2rvvYxvUD27l+YDvXD7WtnXUW4K2trcvsZU9PTwfwrCf+eXbv3g2lUlnm8JnFixejZ8+e6NixI+RyOQAgLy8PAJCRkQEDA4NKB/uUlEwolUKl9qkKDg4WSErKqPHz1mX35PexLWYXHmQ+QkfHdhjrMRwWUnMkJ2fqrCa2c93HNq4f2M71A9u5ftBFO4vFogo7jXUW4N3d3XHkyBEolUq1cfCxsbEAAA8Pj+ceQxAEhIWFoXnz5ujQoYPG+lu3biEjIwOdO3fWWOfn54d27dph586dL/EqSB/lKwpw4PZRHEs4BQtDM7zdZgraOrTWdVlEREREWtFZgPf390dISAiOHz+uNnd7eHg4XF1dtbqBNSoqCvfu3cOCBQvKXL9u3TooFAq1ZWFhYQgLC8O6devg6Oj4ci+C9M4t2W38HLMLT7KT0aNRZ4x0HwJTQxNdl0VERESkNZ0FeF9fX3Tt2hWLFi2CTCaDs7MzwsPDcenSJaxZs0a1XUBAAKKionDjxg2NY4SGhkIikWDEiBFlnqNTp04ay6KiogAAHTt25JNY65HcwlzsiTuEUw/Ows7YFrNfmQ4v2xa6LouIiIio0nQW4EUiEdasWYPly5cjKCgIcrkc7u7uCA4Ohp+f33P3z8zMxJEjR+Dj4wN7e/saqJj01fWUG/glJhSyvHS86twLQ90GwMhAquuyiIiIiF6ISBCEmr8jU4/xJlb9kVWQjdCb+3Ah8RIamDpicssxaG7louuyKsR2rvvYxvUD27l+YDvXD7yJlaiGXH5yFTtiw5BVkI0BzfwwwKUvDA0MdV0WERER0UtjgKc6JT0vAztjw3E56SqamDfGrHbT0MSisa7LIiIiIqoyDPBUJwiCgKjEPxFycy/ylQUY3nwg+jb1gYHYQNelEREREVUpBnjSe6m5adgesxvXU2+guZULJnmNQUMzThFKREREdRMDPOktpaDE6QfnER53AAKAsS2Gw8e5O8Qi8XP3JSIiItJXDPCklx5nJ+Hn6BDEpd+Gl00LvO41GnYmtroui4iIiKjaMcCTXlEoFTie8Dv23z4CidgQk73GolujThCJRLoujYiIiKhGMMCT3niQ+QjbonfiXsYDtHPwxniPEbAy4tN0iYiodsjJyUJmpgwKRaGuS6Eq9OSJGEqlssqOZ2Aggbm5NUxMzF74GAzwVOsVKAtx+M4xHL77G8wkppjqPRntHdqw152IiGqNnJwsZGSkwdraAYaGUv4fVYdIJGIUFlZNgBcEAQUF+ZDJkgDghUM8AzzVarfT72FbzC4kZj1Gl4YdMLrFUJgbvvgVKxERUXXIzJTB2toBUqmRrkuhWkwkEkEqNYK1tQPS05MZ4KluyVfkY1/8YfyWcBpWRpZ4t+1b8LZvqeuyiIiIyqRQFMLQUKrrMkhPGBpKX2qoFQM81Tqxabfwc3QIknNT0dupO4a7DYSJxFjXZREREVWIw2ZIWy/7s8IAT7VGTmEOwm4dwJmHF+BgYoe57d9GCxs3XZdFREREVKvwiTdUK1xNvo4lF5bj7MMo9G3qg4+7zGN4JyIiqkW2bPkBvXp1QmDgjBfa/59/ruL779cjIyNDY12vXp3w/ffrX7bEeoM98KRTmflZ2HVzD/54fBmNzRpiRps30Myyia7LIiIiolIOHIgAAPz991948OA+nJycK7X/9etXsXnzRgwaNBQWFhZq69at2wxHR8cqq7WuYw886YQgCPjj8WX878JS/PXkKga5+mNh5/cY3omIiGqhy5f/xP3799CzZ28IgoD9+/dW6fG9vdvA0bFBlR6zLmMPPNU4WV46dtwIw9Xk62hm0QSTW45FY/OGui6LiIioVjl3LRG7T8YhRZ4HO0sjjPJ1Q/fWuvn/cv/+vRCJRJg370M8fPgAhw7tx7Rp70AsftYXfPt2PDZv3oi//rqEzMwM2NnZo1OnLvjoo8X4/vv12Lx5IwBg7Nhhqn127dqLRo0ao1evTnjrremYOvVt1bo///wDP/ywATEx1wEAXl6tMHXq22jfvqNqm+Ljbtu2Cz/8sAHnz5+FkZERunfviffemw9zc3PVtsePR2L79i24e/cuBEEJOzt79OjRC++9N7/a3rfqwgBPNUYQBJx7dBG7b0WgUFmIke6D4dekN8QifhBERERU0rlrifjpYAzynz5AKEWeh58OxgBAjYf47OxsnDhxDB06dEbDho0waNAwfPfdCkRFnUe3bj0AALGxMZg1azrs7OwxY8ZMODk54/HjRJw69RsAYOjQEcjKysTOndvxxRffws7OHgBUf5f2xx9RmD9/Nlq18sYnn/wXALBjx8+YO3cmgoK+Q4cOndS2X7RoAfz8/DF06AjExd3Ehg1rAAAff/wfAMCVK5fxn//8GyNHjsH06TMhFovx6NFD1cWBvmGApxqRnJOKX2JCcCPtFlpYN8frXmPgaFr2Ly0REVFdcObqI5y+8uiF9o17mI5ChaC2LL9Qic0HonHq8sNKHatX20bo2abRC9UBAMeOHUFOTg4GDx4KABgwYBDWrVuN/fv3qgL86tVBkEql2LDhR1haWqn2HThwCADA0bEBGjYsqsHDwxONGjWu8Jzr138HW1s7rFixBkZGRQ/H6t69J8aNG4H167/D+vWb1bYfNmwkxo+fBADo3LkrHjx4gP379+Lf//4UIpEI//xzFWZm5nj//YVq+w0dOuIF3xXdYtcnVSuloMRvCafxxYVluCtPwATPUXiv/QyGdyIiogqUDu/PW16d9u/fCzMzM/j6vgoAsLGxRY8evXD69Emkp8uQm5uLK1cuw8/vNbXw/qJycnIQE3Mdffr0VYV3ADAyMsarr/ZDdPQ15Obmqu3Tq5ev2vdubu7Iz89DamoKAKB1a29kZmZg8eKPcPr0SchkspeuU5fYA0/VJjHrMbZFh+C2/C5a23lhouco2Bhb67osIiKiGtGzzYv3fC9YcwYp8jyN5XaWRlg4qcPLlqa1e/fu4J9/rqB//4HIzy9Afn4BAKBPn774/feTOHLkEPr08YNCoaiyWWQyMuQQBAG2tnYa6+zs7KFUKpGRIYex8bOHPJa+cJBKi56Km5+fDwBo1649vvxyKUJCdmDx4o9QWFgIL6+W+Ne/3kb37j2rpO6axABPVU6hVODovRM4eDsSRhIjTGk1AZ0btOcT6oiIiLQ0ytdNbQw8AEglYozyrdlnpERE7AEAHD58EIcPH9RYv3//XgwbNgIGBgZ48uRJlZzTwsISIpFI1XteUkpKMsRiMSwsLCt9XB+fPvDx6YOCggJcvfo3Nm/eiI8+eh9bt/6Kpk1dqqDymsMAT1XqXsZ9bIvehQeZj9DBsS3GeYyAhdT8+TsSERGRSvGNqrqchaawsBCHDx9As2YumD//I431hw7tx4ED+3Dnzh20a9cev/12FNOnvwtLy7LDtaFhUa94Xp7mJwslmZiYoFUrb5w4cQzvvBOoGkaTl5eHkyePo1Urb7Xe98oyNDREhw6dIBKJMHv227h9+zYDPNVPBYoCHLgTich7J2FhaIYZbd5AOwdvXZdFRESkt7q3bqizaSMB4Pz5M0hJScGkSVM0Zn0BAAcHRxw4sA/79+9BYOBczJo1HTNmTMHkyVPQuLEzkpOTcerUcSxZ8g0AoHnzok8PQkN3on//gZBIJHBzawFDQ0ONY7/99izMmzcLc+fOxIQJkwEI2LHjZ6SlpeI//1lS6deyadM6JCU9QceOXeDg4AC5PB2//LIV5uYW8PZuU+nj6RoDPL20W7Lb+DlmF55kJ6N7o84Y5T4Ypoamui6LiIiIXsL+/fsglUoxYMDgMtc3adIU7dt3xNGjhzFr1lysX78Z33+/HmvWrEZOTjbs7R3QqVMX1fbt2rXH5Mlv4uDBfdizJxRKpVI1D3xpHTp0QlDQd/jhhw343/8WAyiaB37lyrVo1659pV9Lq1beCA3diTVrViI9XQYLC0u0bu2N+fMXljuVZW0mEgSh5m9n1mMpKZlQKmv+LXNwsEBSUkaNn7ciuYV52Bt/EKfun4OtsTUmeo1GS1sPXZel12pjO1PVYhvXD2zn+qFkOycm3kXDhs10XBFVB4lEjMIS9yJUlYp+ZsRiEezsyh+CzB54eiHRKbH45UYo0nJl8HXugaHNB8BYYvT8HYmIiIjopeg0wGdlZSEoKAiHDh2CXC6Hu7s7Zs2ahb59+1a4n5+fHx48eFDmOldXVxw6dAgAcPv2bezYsQMXLlxAQkLC07FWbpg6depzz0Flyy7IRujNCJxP/AMNTB0wr8O7cLN20XVZRERERPWGTgN8YGAgrl+/jg8++ADOzs4ICwtDYGAg1q1bB19f33L3Cw4OVs3rWSw2NhaLFy9Gv379VMvOnDmDU6dOYfjw4WjTpg0KCwuxZ88ezJw5E//+97/x5ptvVtdLq5MuJ/2DX2+EIbMgC/2b+WGgS18YGmjeeEJERERE1UdnAf7kyZM4e/YsgoOD4e/vDwDo1q0bEhIS8PXXX1cY4Fu1aqWxLCIiAgAwevRo1bJBgwZh0qRJavOP+/r6IikpCWvXrmWA15I8PwM7Y/fgrydX4GzeGDPb/QtNLJx0XRYRERFRvSTW1YmPHj0KCwsLtaEsIpEII0eORHx8PG7duqX1sfLz87Fv3z507NgRrq6uquW2trZlPjyoTZs2kMlkGo/hJXWCIODCo0tYcn4ZriZdw9DmA/Bhp9kM70REREQ6pLMe+Js3b8Ld3R1isfo1hKenJ4CiITHu7u5aHSsyMhIymUyt9708giDgwoULaNKkyUs9BKCuS8uV4ZcbobiecgPNrZphktdYNDSrmkckExEREdGL01mAl8lkcHFx0VhuZWWlWq+t0NBQmJqaYuDAgc/d9qeffsI///yDL7/8Uuvj1ydKQYkzDy8g/NYBKAUlxrQYBl/nHhCLdPZhDRERERGVoNObWMsa3qLNupISExNx9uxZjBo1CqamFT88KDIyEt988w1GjRqlVW99WSqak7O6OThYVOvxH2U8wfqL23A96SbaNPDC250mwdFc/x5uoO+qu51J99jG9QPbuX4obucnT8SQSNjZVVdVR9uKxeIX/ndCZwHe2tq6zF729PR0AM964p9n9+7dUCqVzw3kJ06cwNy5c+Hv748lSyr/CN5idfFBTgqlAr/dP42I+MOQiCWY5DUW3Rt1gihHhKQcPoikJvHhL3Uf27h+YDvXDyXbWalUVsvDfkj3qutBTkqlstx/J2rtg5zc3d1x5MgRKJVKtXHwsbGxAAAPj+c/0VMQBISFhaF58+bo0KFDududPHkSgYGB8PHxwdKlS2FgYPDyL6COeJD5CD9Hh+BuRgLa2rfGeM8RsDbS7uKJiIiIiGqezj7r8ff3h1wux/Hjx9WWh4eHw9XVVasbWKOionDv3r0Ke99///13BAYGokePHlixYgUMDTlvOQAUKguxP/4I/u/iKqTkpuJfrSdhRps3GN6JiIiIajmdBXhfX1907doVixYtQkhICM6fP4+PPvoIly5dwocffqjaLiAgQDUzTWmhoaGQSCQYMWJEmev/+OMPBAYGokGDBpg2bRquX7+Oy5cvq/6UfhhUfXFHfg9fX1yJA3ci0cGxHRZ3/QAdG7TT+r4DIiIiqn+2bPkBvXp1QmDgDI11//xzFd9/vx4ZGZpDQrZu/RGnTp2o1Lm++OIzjBkzVPX9o0cP0atXJ+zc+Uul6y5PXl4evv9+Pf78848qO2ZN0dkQGpFIhDVr1mD58uUICgqCXC6Hu7s7goOD4efn99z9MzMzceTIEfj4+MDevuwbLc+dO4fc3FwkJCQgICBAY/2xY8fg7Oz80q9FX+Qr8hERfwTHE36HlZEl3m37FrztW+q6LCIiItIDBw4UPTTz77//woMH9+Hk9CxDXb9+FZs3b8SgQUNhYaF+Y+bPP/+I3r37wMenj9bnevPNaRg7dkKV1F2e/Px8bN68EQDQoUOnaj1XVdPpLDTm5ub49NNP8emnn5a7zdatW8vd9/LlyxUef/bs2Zg9e/bLlFhnxKbF4eeYECTnpKBX464Y4T4YJhLOg09ERETPd/nyn7h//x569uyNM2d+x/79ezFjxswqP09+fj6kUqnaxQFp0mmAp+qXU5iL8Fv7cfrhBdib2GFO+7fhYeOm67KIiIjoOaIS/8TeuENIy5PBxsgaw9wGoEvD8iftqE779++FSCTCvHkf4uHDBzh0aD+mTXsHYrEY33+/XtWTPXbsMNU+u3btVX1/8GAEDh4s6sEfOHAIFi36TLXf999vw/ffr8fly3/C09MLq1evxxdffIa//rqEkJB9anUoFEps3LgWERF7kJEhh5dXK7z33vvw8mql2qZ4iE9w8Aa1fUse89Gjh6raNm/eqKr/rbemY+rUtwEA//xzBZs3b8K1a1eQn18Ad/cWmDbtHXTp0k11zLS0NGzY8B0uXDiHtLRUmJmZw8XFFe+++x5at/Z++Te+HAzwddg/ydHYfmM30vPk6NvEB0OavwapgVTXZREREdFzRCX+iV9iQlGgLAAApOXJ8EtMKADUeIjPzs7GiRPH0KFDZzRs2AiDBg3Dd9+tQFTUeXTr1gNDh45AVlYmdu7cji+++BZ2dkVDm+3s7LFu3WbMmzcLr7zSHlOmTAMA2NjYqB1/0aIFGDhwCMaNmwilsuLpGnft2o4mTZpiwYJ/IycnB5s3b8R7772LzZt/rlSvvZ2dPYKCvsO8ebMwZMhwDBkyAgDg6Fj01PmoqPP48MO5aN++IxYt+g8kEkPs3RuOBQvm4NtvV6pC/P/+txgPHtzH9OnvolGjxkhPT8f16/9ALk/XupYXwQBfB2XmZyHk5l5cfPwXGpk1wPQ2AXCxbKrrsoiIiOqVC48u4dyjiy+07+30eygUCtWWFSgL8HN0CM4+jKrUsbo36oyujTq+UB0AcOzYEeTk5GDw4KKbSgcMGIR161Zj//696NatBxwdG6Bhw0YAAA8PTzRq1Fi1r7d3GxgYiGFtbQNv7zZlHn/o0BGYMmWqVrWIRCIsW7YaEklRhG3b9hWMHz8CP//8Ez78cJHWr0kqlap67R0cHDVqW778G3h4eGHZstWQSiUoLFSiW7eemDo1ABs2rFEF+KtX/8b06TMxcOAQ1b6+vq9qXceLYoCvQwRBwJ9PrmBnbDiyC3MwyKUf+rv4QSJmMxMREemT0uH9ecur0/79e2FmZqYKpjY2tujRoxdOnz6J9HQZrKysX+r4Pj7aB15f31dV4R0AGjRoiDZt2uHy5T9fqoaS7t9PwP379zBnzgdPH9BVqHqQU7duPbB162ZkZ2fD1NQUrVp54+eff4JCoUCnTp3RvLl7jTxviMmujpDlpWPnjXD8nXwNTS2c8V7LGXAyb6TrsoiIiOqtro06vnDP9ydnvkRankxjuY2RNeZ2eOclK9PevXt38M8/V9C//0Dk5xcgP79oSE+fPn3x++8nceTIoZeeLaZ4yI02bG3tylhmi9u3416qhpJSU1MAACtXLsXKlUvL3EYul8PU1BT//e9X+PHHTdi1azu++24FLC2t0Lfva5gxY6bGbDxViQFezwmCgHOP/sDuW/tQqCzESPfBeNW5FwzEfNosERGRvhrmNkBtDDwAGIoNMcxtQI3WERGxBwBw+PBBHD58UGP9/v17XzrAV+Y5NMXhWn1ZKiwtnz2IUio1QlZWpsZ26ekyrc5hbW0NoGgqy169fGBgIIZCoT42387OTrXt3LkfYO7cD/D4cSJOnDiG9eu/Q3Z2FhYv/lzLV1V5DPB6LCUnFb/EhCIm7SbcrV0xyWsMHE0ddF0WERERvaTiG1V1OQtNYWEhDh8+gGbNXDB//kca6w8d2o8DB/bhxo0YGBoWTZKRl5ensZ2hobTM5S/i5MnfMHPmHNUwmsePE3H16t8YNOjZQ58aNWqE3347ppqSEigK71evXoGZmZlqO6nUsMyamzRphsaNnRAXdxPTpr0DiUSsGkJTkQYNGmL8+Ek4ffoUbt26+dKvtSIM8HpIKShx8v5Z7I0/BBGA8R4j0cupK8QinT1Yl4iIiKpYl4YddDZtJACcP38GKSkpmDRpSpkPOnJwcMSBA/uwf/8e9O37GgAgNHQn+vcfCIlEAje3FjA0NETz5m64fPlPnD17Gra2trCysla70bUyBEHA/PmzMXbsBOTm5uKHHzZAKjXCpElTVNu89tog7NmzG59/vhjDho1EeroMv/yyRS28A4CRkTEaN3bC2bO/o3PnrrCwsIC9vQPs7R3wwQf/xocfzsWHH87FwIGDYWNjh/R0GW7duomUlGR8+OEiZGZm4r333oG//wA0a+YCY2NjXLlyGVeuXMaECZNf6PVpiwG+liueA1aWJ4O1kTV8nXvgSvI1xKffRStbT0z0GgVbY5vnH4iIiIioEvbv3wepVIoBAwaXub5Jk6Zo374jjh49jFmz5mLy5Ddx8OA+7NkTCqVSiV279qJRo8YIDJyHpUu/wiefLER+fp5qHvgXMXbsRGRmZuDbb79CRoYcnp4tsXjx52pTSLZr9woWLfoMP//8Ez76aD4aN3bCW29Nx/nzZ/DXX5fUjvfhh4uwenUQPvxwLgoKClTzwHfp0g3r1m3Gli0/YNmy/0NmZiasrW3g7t5CNeOMVCpFq1atcfDgPiQmJkKpVKBhw8aYNu1dvP56wAu9Pm2JBEEQqvUMdUxKSiaUypp5y0rPAVtMKjLEBK9R6NKwQ6XGjVHt5+BggaSkDF2XQdWIbVw/sJ3rh5LtnJh4Fw0bNtNxRVQdtB1CU1kV/cyIxSLY2ZmXX1OVV0NVZm/cIY3wDgCmUtOXms+ViIiIiPQXB03XYmVNHwUUTRlJRERERPUTA3wtZmNkXanlRERERFT3McDXYsPcBsBQbKi2TBdzwBIRERFR7cEx8LVYyTlgi2ehqek5YImIiIiodmGAr+WK54DljAZERES1myAInB2OtPKyk0ByCA0RERHRSzIwkKCgIF/XZZCeKCjIh4HBi/ejM8ATERERvSRzc2vIZEnIz8976d5VqrsEQUB+fh5ksiSYm1u/8HE4hIaIiIjoJZmYmAEA0tOToVAU6rgaqkpisRhKZdU9yMnAQAILCxvVz8yLYIAnIiIiqgImJmYvFcqodqqN9yFyCA0RERERkR5hgCciIiIi0iMM8EREREREeoQBnoiIiIhIjzDAExERERHpEc5CU0lise6esKbLc1PNYTvXfWzj+oHtXD+wneuHmm7n551PJPBpA0REREREeoNDaIiIiIiI9AgDPBERERGRHmGAJyIiIiLSIwzwRERERER6hAGeiIiIiEiPMMATEREREekRBngiIiIiIj3CAE9EREREpEcY4ImIiIiI9IhE1wVQ2RITE7Fp0yZcu3YNMTExyM7OxpYtW9C1a1ddl0ZV6Ny5c9izZw/++usvJCYmwsrKCm3btsXs2bPh6emp6/KoCvz555/47rvvEBsbC5lMBjMzM3h4eGDq1Knw9fXVdXlUjVavXo3g4GB4eXlhz549ui6HqsCFCxfwxhtvlLnuwIEDcHNzq+GKqLpcuHAB69evx5UrV1BQUAAnJydMmTIF48eP13VpABjga627d+9i//79aNWqFbp164bjx4/ruiSqBtu3b4dMJsObb74JNzc3JCcnY9OmTRgzZgy2bt2KV155Rdcl0kuSy+VwdXXFqFGjYG9vD7lcjl9//RUzZszA8uXLMXjwYF2XSNXg5s2b2LhxI+zt7XVdClWDDz74AJ07d1Zb5uzsrKNqqKqFhYVh0aJFGDt2LN58800YGhoiPj4eBQUFui5NRSQIgqDrIkiTUqmEWFw0wikyMhKzZs1iD3wdlJKSAjs7O7Vlcrkcffv2Rbdu3bB69WodVUbVqbCwEH379kWzZs2wZcsWXZdDVUypVGLChAlo06YNYmNjIZfL2QNfRxT3wH/33Xfo16+frsuhavDo0SMMGDAAgYGBmD59uq7LKRfHwNdSxeGd6rbS4R0ALC0t0axZMyQmJuqgIqoJEokEFhYWMDQ01HUpVA1+/PFHJCYmYt68ebouhYgqKSQkBAAQEBCg40oqxpRIVMukpqbi5s2baNGiha5LoSqkVCpRWFiIx48fY9WqVbhz5w6mTJmi67KoiiUkJGDVqlX49NNPYW5urutyqJp8+umnaNWqFTp27Ii3334b//zzj65Loipy8eJFuLm54ciRI+jfvz9atmwJHx8fLF26FPn5+bouT4Vj4IlqEUEQsHjxYiiVSkydOlXX5VAVmjt3Lg4fPgwAMDc3x4oVK+Dj46PjqqgqCYKATz75BL169eLwijrKwsICU6ZMQZcuXWBtbY24uDhs2LABEydOxLZt29CuXTtdl0gv6cmTJ3jy5AmWLFmCOXPmwN3dHefPn8eGDRvw6NEjLFu2TNclAmCAJ6pVvvnmG0RGRuKrr77ibAZ1zIIFCzBt2jQkJycjIiICc+fOxddff40hQ4boujSqIjt37sQ///yDAwcO6LoUqiatWrVCq1atVN936tQJfn5+GDJkCIKCgvDjjz/qrjiqEoIgICsrS22Sga5duyI3Nxc//PAD3nvvPTRr1kzHVXIIDVGtERQUhB9++AGLFi3CqFGjdF0OVbEmTZqgbdu28PPzw/Lly9GrVy98/vnnUCqVui6NqkBqaiq+/fZbvP322zAxMYFcLodcLkdhYSGUSiXkcjny8vJ0XSZVAwcHB/Tq1Qt///23rkuhKmBtbQ0A6NWrl9ry4k9Mr127VtMllYkBnqgWWLlyJdatW4cFCxaUO8cw1S1t2rRBeno6UlNTdV0KVYHHjx8jIyMDy5YtQ+fOnVV//vzzT8TGxqJz586cVaoO44V43eHh4VHh+toyyQiH0BDpWHBwMNasWYM5c+Zg2rRpui6HaoAgCIiKioKlpaWqt4f0W9OmTcucEvTLL79EdnY2lixZgsaNG+ugMqpuSUlJOHv2LJ/bUUf4+/tj586dOHnyJIYNG6ZafvLkSYhEIrRp00aH1T3DAF+LHTp0CABw9epVAEV3RqelpcHExIRPcKwjfvjhB6xevRqvvvoqevTogcuXL6vWSaVStbGWpJ/mz58PJycntG7dGjY2NkhKSkJYWBjOnz+PxYsXQyLhP8N1gZmZWZnP6bC0tAQAPsOjjpg/fz6aNGmC1q1bw9LSEvHx8di4cSNyc3Px/vvv67o8qgI+Pj7w8fHB559/jrS0NLRo0QLnz5/Hli1bMGHCBDg5Oem6RAB8kFOt5unpWeZyJycnPpm1jggICEBUVFSZ69jOdcO2bduwb98+3LlzBxkZGbCwsIC3tzcmTZoEPz8/XZdH1SwgIIAPcqpDNmzYgP379+PBgwfIycmBtbU1unTpgnffffe5Qy9If2RnZ2P16tWIiIhAWloaGjVqhLFjx2LatGm1ZggNAzwRERERkR6pHZcRRERERESkFQZ4IiIiIiI9wgBPRERERKRHGOCJiIiIiPQIAzwRERERkR5hgCciIiIi0iMM8EREVOsFBARw3nwioqf4CEAionrqwoULeOONN8pdb2BggOvXr9dgRUREpA0GeCKiem7IkCHw8fHRWF5bnjhIRETqGOCJiOq5Vq1aYfjw4boug4iItMTuFSIiqtD9+/fh6emJ1atXIyIiAkOHDkWbNm3Qp08frF69GoWFhRr7xMTEYNasWejatSvatGmDQYMGYePGjVAoFBrbJiUlYcmSJejbty+8vb3RvXt3vPXWWzhz5ozGto8fP8b777+Pzp0745VXXsHUqVNx+/btanndRES1FXvgiYjquZycHKSmpmosl0qlMDc3V33/22+/4aeffsKkSZNgb2+P48ePIzg4GA8fPsRXX32l2u7q1asICAiARCJRbfvbb79h6dKliImJwbJly1Tb3r9/HxMnTkRKSgqGDx8Ob29v5OTk4O+//8bZs2fRs2dP1bbZ2dmYPHky2rVrh3nz5uH+/fvYsmULZs6ciYiICBgYGFTTO0REVLswwBMR1XOrV6/G6tWrNZb36dMH69evV30fHR2NkJAQtG7dGgAwefJkBAYGYvfu3Rg/fjxeeeUVAMAXX3yB/Px87NixA15eXqpt586di4iICIwZMwbdu3cHAPz3v//FkydPsGnTJvTu3Vvt/EqlUu37tLQ0TJ06FdOnT1cts7W1xbfffouzZ89q7E9EVFcxwBMR1XPjx4/HgAEDNJbb2tqqfd+jRw9VeAcAkUiEadOmITIyEkePHsUrr7yClJQU/PXXX/D391eF9+Jt33nnHRw6dAhHjx5F9+7dIZPJ8Pvvv6N3795lhu/SN9GKxWKNWXO6desGALh79y4DPBHVGwzwRET1XLNmzdCjR4/nbufm5qaxzN3dHQCQkJAAoGhITMnlpfcXi8Wqbe/duwdBENCqVSut6nR0dISRkZHaMmtrawCATCbT6hhERHUBb2IlIiKtiESi524jCILWxyveVpvjAqhwjHtlzktEpO8Y4ImISCu3bt0qd1mTJk3U/i5r2/j4eCiVStU2zZo1g0gk4sOiiIgqiQGeiIi0cvbsWVy7dk31vSAI2LRpEwCgX79+AAA7Ozu0b98ev/32G2JjY9W23bBhAwDA398fQNHwFx8fH5w6dQpnz57VOB971YmIysYx8ERE9dz169exZ8+eMtcVB3MA8PLywpQpUzBp0iQ4ODjg2LFjOHv2LIYPH4727durtlu0aBECAgIwadIkvP7663BwcMBvv/2G06dPY8iQIaoZaABg8eLFuH79OqZPn44RI0agdevWyMvLw99//w0nJycsWLCg+l44EZGeYoAnIqrnIiIiEBERUea6I0eOqMae+/n5wdXVFevXr8ft27dhZ2eHmTNnYubMmWr7tGnTBjt27MCqVauwfft2ZGdno0mTJvjggw/wr3/9S23bJk2aIDQ0FN999x1OnTqFPXv2wNLSEl5eXhg/fnz1vGAiIj0nEvgZJRERVeD+/fvo27cvAgMDMXv2bF2XQ0RU73EMPBERERGRHmGAJyIiIiLSIwzwRERERER6hGPgiYiIiIj0CHvgiYiIiIj0CAM8EREREZEeYYAnIiIiItIjDPBERERERHqEAZ6IiIiISI8wwBMRERER6ZH/Bz2za7rFsnqAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "act_acc = [x['action_accuracy'] for x in df_stats.metrics]\n",
    "att_acc = [x['attribute_accuracy'] for x in df_stats.metrics]\n",
    "x_ticks = [x for x in range(len(act_acc))]\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(act_acc, 'b-o', label=\"Actions\")\n",
    "plt.plot(att_acc, 'g-o', label=\"Attributes\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Actions and attributes accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.xticks(ticks = x_ticks, labels = [str(x+1) for x in x_ticks])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1a2d0d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "act_per = [x['action_perplexity'] for x in df_stats.metrics]\n",
    "x_ticks = [x for x in range(len(act_acc))]\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(act_per, 'b-o')\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Actions perplexity\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Perplexity\")\n",
    "plt.xticks(ticks = x_ticks, labels = [str(x+1) for x in x_ticks])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bea685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
