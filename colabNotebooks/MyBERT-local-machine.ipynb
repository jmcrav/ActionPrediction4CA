{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4e26663",
   "metadata": {},
   "source": [
    "# Download GitHub repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9f42ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gian/content\n",
      "Clone in 'ActionPrediction4CA' in corso...\n",
      "remote: Enumerating objects: 366, done.\u001b[K\n",
      "remote: Counting objects: 100% (366/366), done.\u001b[K\n",
      "remote: Compressing objects: 100% (277/277), done.\u001b[K\n",
      "remote: Total 366 (delta 183), reused 257 (delta 82), pack-reused 0\u001b[K\n",
      "Ricezione degli oggetti: 100% (366/366), 47.41 MiB | 10.54 MiB/s, fatto.\n",
      "Risoluzione dei delta: 100% (183/183), fatto.\n"
     ]
    }
   ],
   "source": [
    "%cd ~/content/\n",
    "%rm -rf ~/content/ActionPrediction4CA\n",
    "%rm -rf ~/content/ActionPredictionBERT\n",
    "!git clone  --branch colab_exe https://github.com/jmcrav/ActionPrediction4CA.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36cb4f3",
   "metadata": {},
   "source": [
    "# Elimino i file inutili al modello \n",
    "Per fare il fine tuning del modello, abbiamo bisogno solo dei dati grezzi.\n",
    "Il tutor ha puntualizzato di usare SOLO lo script `simmc/mm_action_prediction/tools/extract_actions_fashion.py`, che costruisce un json con le lables associate alle azioni e agli attributi (è lo step 1 del preprocessing).\n",
    "Questo credo sia necessario perchè credo che la loro implementazione sia di un livello molto più basso di quello a cui dovremo lavorare noi.\n",
    "BERT è un metodo per effettuare il  pre-trained di modelli per il NLP di cui dobbiamo solo fare un fine-tuning accettabile, mentre il SIMMC deve addestrare un intero modello da zero(o comunque credo che il loro obiettivo sia cercare di creare un modello che riesca a funzionare bene col linguaggio multimodale.Non ho capito perchè non sia statu usato BERT anche da loro onestamente -  il task finale è diviso in 3 sottotask, e la prima è un problema di classificazione multi-classe per il quale BERT dovrebbe poter funzionare - forse perchè quella fornita è solo un implementazione di partenza e i concorrenti alla challenge hanno fornito le loro implementazioni dei modelli?). Praticamente tutte le operazioni che fanno loro sui dati credo servano ai loro dettagli implementativi di bassissimo livello; con BERT noi dovremo usare solo i metodi forniti dalla classe.\n",
    "In pratica, partendo dai dati grezzi, dobbiamo solo darli in pasto ai metodi forniti da BERT e magari lavorare un po' per migliorare i risultati, senza che sia necessario scendere fino al livello dei transformers\n",
    "\n",
    "\n",
    "**DA TENERE**\n",
    "* Output dell'extract actions\n",
    "*  `fashion_train_dials.json`:  per il training\n",
    "*  `fashion_dev_dials.json` : per la validation\n",
    "*  `fashion_teststd_dials_public.json` :per il \"report dei risultati finali\" (forse per darlo in pasto allo script di evaluation?) \n",
    "*   `fashion_metadata.json`, `fashion_devtest_dials.json` : necessari per il funzionamento dello script `extract_actions_fashion.py `\n",
    "\n",
    "**DA VERIFICARE**:\n",
    "\n",
    " forse potrebbe convenire anche usare il vocabolario che loro si costruiscono (step 2 del preprocessing) per inizializzare il Tokenizer di Bert, come fanno loro nel data loader (in `loaders/loader_simmc.py`)\n",
    " ![linea codice loader.jpg](data:image/jpeg;base64,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)\n",
    "\n",
    " Questo comando istanzia il tokenizer con una versione default o definita dall'utente (devo capire bene cosa significa, l'ho letto su https://huggingface.co/transformers/quickstart.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cd41deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gian/content/ActionPrediction4CA/tools\n",
      "/home/gian/content/ActionPrediction4CA/data/simmc_fashion\n",
      "/home/gian/content\n"
     ]
    }
   ],
   "source": [
    "%mkdir ~/content/ActionPredictionBERT ActionPredictionBERT/input_data ActionPredictionBERT/extr_output\n",
    "%cd ~/content/ActionPrediction4CA/tools\n",
    "%mv extract_actions_fashion.py ~/content/ActionPredictionBERT\n",
    "%mv action_evaluation.py ~/content/ActionPredictionBERT\n",
    "\n",
    "%cd ~/content/ActionPrediction4CA/data/simmc_fashion/\n",
    "%mv fashion_train_dials.json fashion_dev_dials.json fashion_teststd_dials_public.json fashion_metadata.json fashion_devtest_dials.json ~/content/ActionPredictionBERT/input_data\n",
    "%cd ~/content/\n",
    "%rm -rf ./ActionPrediction4CA/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c76fc6c",
   "metadata": {},
   "source": [
    "# Extract_actions_fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86671584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gian/content/ActionPredictionBERT\n",
      "Reading: ./input_data/fashion_train_dials.json\n",
      "Dialogue task Id missing: 3406\n",
      "Dialogue task Id missing: 3969\n",
      "Dialogue task Id missing: 4847\n",
      "Dialogue task Id missing: 321\n",
      "Dialogue task Id missing: 3455\n",
      "Dialogue task Id missing: 3414\n",
      "Saving: ./extr_output/fashion_train_dials_api_calls.json\n",
      "Reading: ./input_data/fashion_dev_dials.json\n",
      "Dialogue task Id missing: 2117\n",
      "Saving: ./extr_output/fashion_dev_dials_api_calls.json\n",
      "Reading: ./input_data/fashion_devtest_dials.json\n",
      "Dialogue task Id missing: 9308\n",
      "Saving: ./extr_output/fashion_devtest_dials_api_calls.json\n"
     ]
    }
   ],
   "source": [
    "%cd ~/content/ActionPredictionBERT/\n",
    "!python extract_actions_fashion.py --json_path=\"./input_data/fashion_train_dials.json ./input_data/fashion_dev_dials.json ./input_data/fashion_devtest_dials.json\" --save_root=\"./extr_output\"  --metadata_path=\"./fashion_metadata.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98da7846",
   "metadata": {},
   "source": [
    "# Notebook originale\n",
    "Script copiato dal colab di Chris McCormick e Nick Ryan\n",
    "https://colab.research.google.com/drive/1pTuQhug6Dhl9XalKB0zUGf4FIdYFlpcX#scrollTo=nSU7yERLP_66"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34794cb2",
   "metadata": {},
   "source": [
    "## 1.2. Installing the Hugging Face Library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1b3c76",
   "metadata": {},
   "source": [
    "\n",
    "Next, let's install the [transformers](https://github.com/huggingface/transformers) package from Hugging Face which will give us a pytorch interface for working with BERT. (This library contains interfaces for other pretrained language models like OpenAI's GPT and GPT-2.) We've selected the pytorch interface because it strikes a nice balance between the high-level APIs (which are easy to use but don't provide insight into how things work) and tensorflow code (which contains lots of details but often sidetracks us into lessons about tensorflow, when the purpose here is BERT!).\n",
    "\n",
    "At the moment, the Hugging Face library seems to be the most widely accepted and powerful pytorch interface for working with BERT. In addition to supporting a variety of different pre-trained transformer models, the library also includes pre-built modifications of these models suited to your specific task. For example, in this tutorial we will use `BertForSequenceClassification`.\n",
    "\n",
    "The library also includes task-specific classes for token classification, question answering, next sentence prediciton, etc. Using these pre-built classes simplifies the process of modifying BERT for your purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5e83197",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install markdown\n",
    "#!pip install transformers\n",
    "#!pip install pandas\n",
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79c94ee",
   "metadata": {},
   "source": [
    "# Impostazione parametri esecuzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba50e083",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_params = {\n",
    "    'batch': 12,\n",
    "    'epochs': 2,\n",
    "    'hidden_output_dim': 256,\n",
    "    'seed': 193598\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d9eda3",
   "metadata": {},
   "source": [
    "# Analisi Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4f4432",
   "metadata": {},
   "source": [
    "## train_dials\n",
    "\n",
    "Dati grezzi da preprocessare con lo script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7f4abad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "      <th>dialogue_idx</th>\n",
       "      <th>domains</th>\n",
       "      <th>dialogue_task_id</th>\n",
       "      <th>dialogue_coref_map.1426</th>\n",
       "      <th>dialogue_coref_map.1429</th>\n",
       "      <th>dialogue_coref_map.708</th>\n",
       "      <th>dialogue_coref_map.712</th>\n",
       "      <th>dialogue_coref_map.2401</th>\n",
       "      <th>dialogue_coref_map.2402</th>\n",
       "      <th>...</th>\n",
       "      <th>dialogue_coref_map.2335</th>\n",
       "      <th>dialogue_coref_map.713</th>\n",
       "      <th>dialogue_coref_map.1507</th>\n",
       "      <th>dialogue_coref_map.1509</th>\n",
       "      <th>dialogue_coref_map.949</th>\n",
       "      <th>dialogue_coref_map.1137</th>\n",
       "      <th>dialogue_coref_map.1872</th>\n",
       "      <th>dialogue_coref_map.1873</th>\n",
       "      <th>dialogue_coref_map.1753</th>\n",
       "      <th>dialogue_coref_map.834</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'belief_state': [{'act': 'DA:ASK:CHECK:CLOTH...</td>\n",
       "      <td>3094</td>\n",
       "      <td>[fashion]</td>\n",
       "      <td>1785.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'belief_state': [{'act': 'DA:INFORM:PREFER:C...</td>\n",
       "      <td>822</td>\n",
       "      <td>[fashion]</td>\n",
       "      <td>1720.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'belief_state': [{'act': 'DA:REQUEST:GET:CLO...</td>\n",
       "      <td>7411</td>\n",
       "      <td>[fashion]</td>\n",
       "      <td>2038.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'belief_state': [{'act': 'DA:INFORM:DISPREFE...</td>\n",
       "      <td>7029</td>\n",
       "      <td>[fashion]</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'belief_state': [{'act': 'DA:INFORM:DISPREFE...</td>\n",
       "      <td>1506</td>\n",
       "      <td>[fashion]</td>\n",
       "      <td>1686.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1648 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            dialogue  dialogue_idx    domains  \\\n",
       "0  [{'belief_state': [{'act': 'DA:ASK:CHECK:CLOTH...          3094  [fashion]   \n",
       "1  [{'belief_state': [{'act': 'DA:INFORM:PREFER:C...           822  [fashion]   \n",
       "2  [{'belief_state': [{'act': 'DA:REQUEST:GET:CLO...          7411  [fashion]   \n",
       "3  [{'belief_state': [{'act': 'DA:INFORM:DISPREFE...          7029  [fashion]   \n",
       "4  [{'belief_state': [{'act': 'DA:INFORM:DISPREFE...          1506  [fashion]   \n",
       "\n",
       "   dialogue_task_id  dialogue_coref_map.1426  dialogue_coref_map.1429  \\\n",
       "0            1785.0                      0.0                      1.0   \n",
       "1            1720.0                      NaN                      NaN   \n",
       "2            2038.0                      NaN                      NaN   \n",
       "3            2011.0                      NaN                      NaN   \n",
       "4            1686.0                      NaN                      NaN   \n",
       "\n",
       "   dialogue_coref_map.708  dialogue_coref_map.712  dialogue_coref_map.2401  \\\n",
       "0                     NaN                     NaN                      NaN   \n",
       "1                     0.0                     1.0                      NaN   \n",
       "2                     NaN                     NaN                      4.0   \n",
       "3                     NaN                     NaN                      NaN   \n",
       "4                     NaN                     NaN                      NaN   \n",
       "\n",
       "   dialogue_coref_map.2402  ...  dialogue_coref_map.2335  \\\n",
       "0                      NaN  ...                      NaN   \n",
       "1                      NaN  ...                      NaN   \n",
       "2                      0.0  ...                      NaN   \n",
       "3                      NaN  ...                      NaN   \n",
       "4                      NaN  ...                      NaN   \n",
       "\n",
       "   dialogue_coref_map.713  dialogue_coref_map.1507  dialogue_coref_map.1509  \\\n",
       "0                     NaN                      NaN                      NaN   \n",
       "1                     NaN                      NaN                      NaN   \n",
       "2                     NaN                      NaN                      NaN   \n",
       "3                     NaN                      NaN                      NaN   \n",
       "4                     NaN                      NaN                      NaN   \n",
       "\n",
       "   dialogue_coref_map.949  dialogue_coref_map.1137  dialogue_coref_map.1872  \\\n",
       "0                     NaN                      NaN                      NaN   \n",
       "1                     NaN                      NaN                      NaN   \n",
       "2                     NaN                      NaN                      NaN   \n",
       "3                     NaN                      NaN                      NaN   \n",
       "4                     NaN                      NaN                      NaN   \n",
       "\n",
       "   dialogue_coref_map.1873  dialogue_coref_map.1753  dialogue_coref_map.834  \n",
       "0                      NaN                      NaN                     NaN  \n",
       "1                      NaN                      NaN                     NaN  \n",
       "2                      NaN                      NaN                     NaN  \n",
       "3                      NaN                      NaN                     NaN  \n",
       "4                      NaN                      NaN                     NaN  \n",
       "\n",
       "[5 rows x 1648 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prima parte del fashion_train_dials\n",
    "import json \n",
    "import pandas as pd\n",
    "with open ('./input_data/fashion_train_dials.json',\"r\") as f:\n",
    "   data= json.load(f)\n",
    "\n",
    "result=[]\n",
    "row ={}\n",
    "for k in data:\n",
    "  row[k] = data[k]\n",
    "# []\n",
    "#prima parte del fashion_train_dials\n",
    "import json \n",
    "import pandas as pd\n",
    "with open ('./input_data/fashion_train_dials.json',\"r\") as f:\n",
    "   data= json.load(f)\n",
    "\n",
    "result=[]\n",
    "row ={}\n",
    "for k in data:\n",
    "  row[k] = data[k]\n",
    "# []\n",
    "\n",
    "dialogue_data = pd.json_normalize(row['dialogue_data'])\n",
    "type(dialogue_data)\n",
    "# dialogue = dialogue_data[\"dialogue\"]\n",
    "# for x in dialogue.head(1):\n",
    "#   display(x)\n",
    "# #dialogue.head(1)\n",
    "dialogue_data.head()\n",
    "\n",
    "\n",
    "\n",
    "dialogue_data = pd.json_normalize(row['dialogue_data'])\n",
    "type(dialogue_data)\n",
    "# dialogue = dialogue_data[\"dialogue\"]\n",
    "# for x in dialogue.head(1):\n",
    "#   display(x)\n",
    "# #dialogue.head(1)\n",
    "dialogue_data.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "625e5f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>image_ids</th>\n",
       "      <th>focus_image</th>\n",
       "      <th>memory_images</th>\n",
       "      <th>database_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2042</td>\n",
       "      <td>[2441, 2442, 2443, 2444, 2445, 2446, 2447, 244...</td>\n",
       "      <td>2441</td>\n",
       "      <td>[2442, 2443, 2444]</td>\n",
       "      <td>[2445, 2446, 2447, 2448, 2449, 2450]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2041</td>\n",
       "      <td>[2431, 2432, 2433, 2434, 2435, 2436, 2437, 243...</td>\n",
       "      <td>2431</td>\n",
       "      <td>[2432, 2433, 2434]</td>\n",
       "      <td>[2435, 2436, 2437, 2438, 2439, 2440]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2040</td>\n",
       "      <td>[2421, 2422, 2423, 2424, 2425, 2426, 2427, 242...</td>\n",
       "      <td>2421</td>\n",
       "      <td>[2422, 2423, 2424]</td>\n",
       "      <td>[2425, 2426, 2427, 2428, 2429, 2430]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2039</td>\n",
       "      <td>[2411, 2412, 2413, 2414, 2415, 2416, 2417, 241...</td>\n",
       "      <td>2411</td>\n",
       "      <td>[2412, 2413, 2414]</td>\n",
       "      <td>[2415, 2416, 2417, 2418, 2419, 2420]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2038</td>\n",
       "      <td>[2401, 2402, 2403, 2404, 2405, 2406, 2407, 240...</td>\n",
       "      <td>2401</td>\n",
       "      <td>[2402, 2403, 2404]</td>\n",
       "      <td>[2405, 2406, 2407, 2408, 2409, 2410]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   task_id                                          image_ids  focus_image  \\\n",
       "0     2042  [2441, 2442, 2443, 2444, 2445, 2446, 2447, 244...         2441   \n",
       "1     2041  [2431, 2432, 2433, 2434, 2435, 2436, 2437, 243...         2431   \n",
       "2     2040  [2421, 2422, 2423, 2424, 2425, 2426, 2427, 242...         2421   \n",
       "3     2039  [2411, 2412, 2413, 2414, 2415, 2416, 2417, 241...         2411   \n",
       "4     2038  [2401, 2402, 2403, 2404, 2405, 2406, 2407, 240...         2401   \n",
       "\n",
       "        memory_images                       database_images  \n",
       "0  [2442, 2443, 2444]  [2445, 2446, 2447, 2448, 2449, 2450]  \n",
       "1  [2432, 2433, 2434]  [2435, 2436, 2437, 2438, 2439, 2440]  \n",
       "2  [2422, 2423, 2424]  [2425, 2426, 2427, 2428, 2429, 2430]  \n",
       "3  [2412, 2413, 2414]  [2415, 2416, 2417, 2418, 2419, 2420]  \n",
       "4  [2402, 2403, 2404]  [2405, 2406, 2407, 2408, 2409, 2410]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#seconda parte del fashion_train_dials\n",
    "task_mapping = pd.json_normalize(row['task_mapping'])\n",
    "task_mapping.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9867cff",
   "metadata": {},
   "source": [
    "## dev_dials_api_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d5d29b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialog_id</th>\n",
       "      <th>actions</th>\n",
       "      <th>focus_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4146</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'None', 'action_sup...</td>\n",
       "      <td>[1646, 1646, 1646, 1649, 1649, 1649, 1649]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4260</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...</td>\n",
       "      <td>[2161, 2161, 2161, 2161]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8022</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SearchDatabase', '...</td>\n",
       "      <td>[1971, 1972, 1972, 1972, 1977, 1978]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4992</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'None', 'action_sup...</td>\n",
       "      <td>[1931, 1931, 1936, 1936, 1936]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5606</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'None', 'action_sup...</td>\n",
       "      <td>[1931, 1931, 1931, 1931, 1931]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dialog_id                                            actions  \\\n",
       "0       4146  [{'turn_idx': 0, 'action': 'None', 'action_sup...   \n",
       "1       4260  [{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...   \n",
       "2       8022  [{'turn_idx': 0, 'action': 'SearchDatabase', '...   \n",
       "3       4992  [{'turn_idx': 0, 'action': 'None', 'action_sup...   \n",
       "4       5606  [{'turn_idx': 0, 'action': 'None', 'action_sup...   \n",
       "\n",
       "                                 focus_images  \n",
       "0  [1646, 1646, 1646, 1649, 1649, 1649, 1649]  \n",
       "1                    [2161, 2161, 2161, 2161]  \n",
       "2        [1971, 1972, 1972, 1972, 1977, 1978]  \n",
       "3              [1931, 1931, 1936, 1936, 1936]  \n",
       "4              [1931, 1931, 1931, 1931, 1931]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dev_dials_api = pd.read_json('./extr_output/fashion_dev_dials_api_calls.json')\n",
    "dev_dials_api.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b899ff34",
   "metadata": {},
   "source": [
    "## devtest_dials_api_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f9c6435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialog_id</th>\n",
       "      <th>actions</th>\n",
       "      <th>focus_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2494</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SearchDatabase', '...</td>\n",
       "      <td>[1836, 1841, 1841, 1841, 1841]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3731</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SearchDatabase', '...</td>\n",
       "      <td>[1676, 1681, 1681, 1683, 1683]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8546</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...</td>\n",
       "      <td>[840, 840, 840, 849, 849, 843]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5590</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SearchDatabase', '...</td>\n",
       "      <td>[1616, 1618, 1618, 1618, 1618]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5452</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...</td>\n",
       "      <td>[2231, 2231, 2231, 2236, 2236]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dialog_id                                            actions  \\\n",
       "0       2494  [{'turn_idx': 0, 'action': 'SearchDatabase', '...   \n",
       "1       3731  [{'turn_idx': 0, 'action': 'SearchDatabase', '...   \n",
       "2       8546  [{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...   \n",
       "3       5590  [{'turn_idx': 0, 'action': 'SearchDatabase', '...   \n",
       "4       5452  [{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...   \n",
       "\n",
       "                     focus_images  \n",
       "0  [1836, 1841, 1841, 1841, 1841]  \n",
       "1  [1676, 1681, 1681, 1683, 1683]  \n",
       "2  [840, 840, 840, 849, 849, 843]  \n",
       "3  [1616, 1618, 1618, 1618, 1618]  \n",
       "4  [2231, 2231, 2231, 2236, 2236]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "devtest_dials_api = pd.read_json('./extr_output/fashion_devtest_dials_api_calls.json')\n",
    "devtest_dials_api.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3ba47e",
   "metadata": {},
   "source": [
    "## Funzione generazione dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe1973e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def createDataframe(json_file):\n",
    "  with open(json_file) as f:\n",
    "    dictftdac = json.load(f)\n",
    "\n",
    "  data = []\n",
    "\n",
    "  for e in dictftdac:\n",
    "    dialog_id = e['dialog_id']\n",
    "    actions = e['actions']\n",
    "    focus_images = e['focus_images']\n",
    "\n",
    "    for a in actions:\n",
    "      \n",
    "      turn_idx = a['turn_idx']\n",
    "      action = a['action']\n",
    "      action_supervision = a['action_supervision']\n",
    "      transcript = a['transcript']\n",
    "      transcript_annotated = a['transcript_annotated']\n",
    "      system_transcript = a['system_transcript']\n",
    "      system_transcript_annotated = a['system_transcript_annotated']\n",
    "\n",
    "      row = {\n",
    "          \"dialog_id\" : dialog_id,\n",
    "          'turn_idx' : turn_idx,\n",
    "          'action' : action,\n",
    "          'action_supervision' : action_supervision,\n",
    "          'focus_images' : focus_images,\n",
    "          'transcript': transcript,\n",
    "          'transcript_annotated': transcript_annotated,\n",
    "          'system_transcript': system_transcript,\n",
    "          'system_transcript_annotated':system_transcript_annotated,\n",
    "          'previous_transcript': \"\",\n",
    "          'previous_system_transcript': \"\"\n",
    "      }\n",
    "      if (action_supervision != None):\n",
    "        if 'focus' in action_supervision:\n",
    "          acsf = {'focus':action_supervision['focus']}\n",
    "        else:\n",
    "          acsf = {'focus':None}\n",
    "        \n",
    "        if 'attributes' in action_supervision:\n",
    "          acsa = {'attributes':action_supervision['attributes']}\n",
    "        else:\n",
    "          acsa = {'attributes':[]}\n",
    "      else:\n",
    "          acsf = {'focus':None}\n",
    "          acsa = {'attributes':[]}\n",
    "      \n",
    "        \n",
    "      row.update(acsf)\n",
    "      row.update(acsa)\n",
    "    \n",
    "      data.append(row)\n",
    "\n",
    "  # Conservo id turno e risposta sistema per provare a implementare una soluzione articolata\n",
    "  df = pd.DataFrame(data,columns=['dialog_id','turn_idx','transcript','action','attributes', 'system_transcript','transcript_annotated','system_transcript_annotated','previous_transcript','previous_system_transcript'])\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a30c6d",
   "metadata": {},
   "source": [
    "## train_dials_api_calls with transcript\n",
    "Dati per il training che usiamo ( per ora semplificati)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9d78e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  21196  elementi\n"
     ]
    }
   ],
   "source": [
    "df_training = createDataframe('./extr_output/fashion_train_dials_api_calls.json')\n",
    "print(\"Training: \",len(df_training),\" elementi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e542c9",
   "metadata": {},
   "source": [
    "## fashion_dev_dials_api_calls\n",
    "Dati per la validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d7d98f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:  3513  elementi\n"
     ]
    }
   ],
   "source": [
    "df_validation = createDataframe('./extr_output/fashion_dev_dials_api_calls.json')\n",
    "print(\"Validation: \",len(df_validation),\" elementi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f272d647",
   "metadata": {},
   "source": [
    "## fashion_devtest_dials_api_calls\n",
    "Dati per la valutazione delle performance del modello (test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8e22d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  5397  elementi\n"
     ]
    }
   ],
   "source": [
    "df_test = createDataframe('./extr_output/fashion_devtest_dials_api_calls.json')\n",
    "print(\"Test: \",len(df_test),\" elementi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc25d11d",
   "metadata": {},
   "source": [
    "# BERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4c901c",
   "metadata": {},
   "source": [
    "## Scelta tipo input\n",
    "\n",
    "Il valore di questa variabile determinerà se utilizzare i singoli transcript, o se concatenare ogni transcript a quello successivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef5cc083",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_next = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d30106",
   "metadata": {},
   "source": [
    "## Preparazione input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e090913a",
   "metadata": {},
   "source": [
    "### Generazione colonna previous_transcript\n",
    "\n",
    "Generazione della colonna contenente la frase del turno successivo del dialogo (se presente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fb54823",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "df_training.sort_values(by=['dialog_id', 'turn_idx'])\n",
    "for i in range(1,(len(df_training))):\n",
    "  if(i<(len(df_training)) and  df_training['dialog_id'][i] == df_training['dialog_id'][i-1]):\n",
    "    df_training.loc[i,'previous_transcript'] = df_training['transcript'][i-1]\n",
    "    df_training.loc[i,'previous_system_transcript'] = df_training['system_transcript'][i-1]\n",
    "\n",
    "#Validation\n",
    "df_validation.sort_values(by=['dialog_id', 'turn_idx'])\n",
    "for i in range(1,(len(df_validation))):\n",
    "  if(i<(len(df_validation)) and  df_validation['dialog_id'][i] == df_validation['dialog_id'][i-1]):\n",
    "    df_validation.loc[i,'previous_transcript'] = df_validation['transcript'][i-1]\n",
    "    df_validation.loc[i,'previous_system_transcript'] = df_validation['system_transcript'][i-1]\n",
    "\n",
    "#Evaluation\n",
    "df_test.sort_values(by=['dialog_id', 'turn_idx'])\n",
    "for i in range(1,(len(df_test))):\n",
    "  if(i<(len(df_test)) and  df_test['dialog_id'][i] == df_test['dialog_id'][i-1]):\n",
    "    df_test.loc[i,'previous_transcript'] = df_test['transcript'][i-1]\n",
    "    df_test.loc[i,'previous_system_transcript'] = df_test['system_transcript'][i-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb106a56",
   "metadata": {},
   "source": [
    "### Estrazione vettori colonna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78177045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de95a8f0",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f65ef34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA:\n",
      " Original:  Is there a pattern on this one? It's hard to see in the image.\n",
      "Tokenized:  ['is', 'there', 'a', 'pattern', 'on', 'this', 'one', '?', 'it', \"'\", 's', 'hard', 'to', 'see', 'in', 'the', 'image', '.']\n",
      "Token IDs:  [2003, 2045, 1037, 5418, 2006, 2023, 2028, 1029, 2009, 1005, 1055, 2524, 2000, 2156, 1999, 1996, 3746, 1012]\n"
     ]
    }
   ],
   "source": [
    "transcripts_tr = df_training.transcript.values\n",
    "previous_transcript_tr = df_training.previous_transcript.values\n",
    "previous_system_transcript_tr = df_training.previous_system_transcript.values\n",
    "action_labels_tr = df_training.action.values\n",
    "attributes_labels_tr=df_training.attributes.values\n",
    "\n",
    "print (\"TRAINING DATA:\")\n",
    "# Print the original sentence.\n",
    "print(' Original: ', transcripts_tr[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(transcripts_tr[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(transcripts_tr[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b5da556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T: Is there a pattern on this one? It's hard to see in the image. | PT:  | PST: \n",
      "T: That's fancy. Do you have anything in warmer colors like yellow or red? | PT: Is there a pattern on this one? It's hard to see in the image. | PST: I don't have any information on the pattern, but it has pointelle embellishments.\n",
      "T: Yeah, that sounds good. | PT: That's fancy. Do you have anything in warmer colors like yellow or red? | PST: I have a crew neck sweater in red, would you like to see it?\n",
      "T: Oh, I love that. Please tell me you have a small. | PT: Yeah, that sounds good. | PST: This is $187 from Downtown Stylists with a 3.62 rating.\n",
      "T: Yes, please! Thank you for your help with this | PT: Oh, I love that. Please tell me you have a small. | PST: It does come in small, shall I put one in your cart?\n",
      "T: How nice! Does this come in other colors? | PT:  | PST: \n",
      "T: Oh well.  Can you show me a dress that comes in red? | PT: How nice! Does this come in other colors? | PST: No, I'm sorry, It comes only in blue.\n",
      "T: Cute! Do these come in Small? | PT: Oh well.  Can you show me a dress that comes in red? | PST: This dress comes in many colors, including a bright red and a pinkish-red. What do you think?\n",
      "T: Awesome. Would you add a red one in S to my cart please? | PT: Cute! Do these come in Small? | PST: Yes, they do!\n",
      "T: That's all. Thanks! | PT: Awesome. Would you add a red one in S to my cart please? | PST: The red one is in your cart. Is there anything else I can find for you?\n"
     ]
    }
   ],
   "source": [
    "for k in range(0,10):\n",
    "  print(f\"T: {transcripts_tr[k]} | PT: {previous_transcript_tr[k]} | PST: {previous_system_transcript_tr[k]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef35705",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcd4e529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION DATA:\n",
      " Original:  What's the price of this sweater compared to the other blue and gray one I looked at?\n",
      "Tokenized:  ['what', \"'\", 's', 'the', 'price', 'of', 'this', 'sweater', 'compared', 'to', 'the', 'other', 'blue', 'and', 'gray', 'one', 'i', 'looked', 'at', '?']\n",
      "Token IDs:  [2054, 1005, 1055, 1996, 3976, 1997, 2023, 14329, 4102, 2000, 1996, 2060, 2630, 1998, 3897, 2028, 1045, 2246, 2012, 1029]\n",
      "Dialog IDs: [4146 4146 4146 4146 4146 4146 4146 4260 4260 4260 4260 8022 8022 8022\n",
      " 8022 8022 8022 4992 4992 4992]\n",
      "Turn IDs: [0 1 2 3 4 5 6 0 1 2 3 0 1 2 3 4 5 0 1 2]\n"
     ]
    }
   ],
   "source": [
    "transcripts_vd = df_validation.transcript.values\n",
    "previous_transcript_vd = df_validation.previous_transcript.values\n",
    "previous_system_transcript_vd = df_validation.previous_system_transcript.values\n",
    "action_labels_vd = df_validation.action.values\n",
    "attributes_labels_vd=df_validation.attributes.values\n",
    "dialog_ids_vd = df_validation.dialog_id.values\n",
    "turn_idxs_vd = df_validation.turn_idx.values\n",
    "\n",
    "print (\"VALIDATION DATA:\")\n",
    "\n",
    "# Print the original sentence.\n",
    "print(' Original: ', transcripts_vd[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(transcripts_vd[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(transcripts_vd[0])))\n",
    "\n",
    "# Print the dialog ids.\n",
    "print(f\"Dialog IDs: {dialog_ids_vd[0:20]}\")\n",
    "\n",
    "# Print the turn idxs.\n",
    "print(f\"Turn IDs: {turn_idxs_vd[0:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba6e6ef",
   "metadata": {},
   "source": [
    "#### Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "886bcaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATION DATA:\n",
      " Original:  That looks a little too light for what I need, do you have something else with a high customer rating?\n",
      "Tokenized:  ['that', 'looks', 'a', 'little', 'too', 'light', 'for', 'what', 'i', 'need', ',', 'do', 'you', 'have', 'something', 'else', 'with', 'a', 'high', 'customer', 'rating', '?']\n",
      "Token IDs:  [2008, 3504, 1037, 2210, 2205, 2422, 2005, 2054, 1045, 2342, 1010, 2079, 2017, 2031, 2242, 2842, 2007, 1037, 2152, 8013, 5790, 1029]\n",
      "Dialog IDs: [2494 2494 2494 2494 2494 3731 3731 3731 3731 3731 8546 8546 8546 8546\n",
      " 8546 8546 5590 5590 5590 5590]\n",
      "Turn IDs: [0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 5 0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "transcripts_tst = df_test.transcript.values\n",
    "previous_transcript_tst = df_test.previous_transcript.values\n",
    "previous_system_transcript_tst = df_test.previous_system_transcript.values\n",
    "action_labels_tst = df_test.action.values\n",
    "attributes_labels_tst=df_test.attributes.values\n",
    "dialog_ids_tst = df_test.dialog_id.values\n",
    "turn_idxs_tst = df_test.turn_idx.values\n",
    "\n",
    "print (\"EVALUATION DATA:\")\n",
    "\n",
    "# Print the original sentence.\n",
    "print(' Original: ', transcripts_tst[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(transcripts_tst[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(transcripts_tst[0])))\n",
    "\n",
    "# Print the dialog ids.\n",
    "print(f\"Dialog IDs: {dialog_ids_tst[0:20]}\")\n",
    "\n",
    "# Print the turn idxs.\n",
    "print(f\"Turn IDs: {turn_idxs_tst[0:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c049bbf",
   "metadata": {},
   "source": [
    "## Calcolo dimensione massima\n",
    "\n",
    "The above code left out a few required formatting steps that we'll look at here.\n",
    "\n",
    "We are required to:\n",
    "1. Add special tokens to the start and end of each sentence.\n",
    "2. Pad & truncate all sentences to a single constant length.\n",
    "3. Explicitly differentiate real tokens from padding tokens with the \"attention mask\".\n",
    "\n",
    "\n",
    "The sentences in our dataset obviously have varying lengths, so how does BERT handle this?\n",
    "\n",
    "BERT has two constraints:\n",
    "\n",
    "\n",
    "1.   All sentences must be padded or truncated to a single, fixed length.\n",
    "2.   The maximum sentence length is 512 tokens.\n",
    "\n",
    "\n",
    "Padding is done with a special [PAD] token, which is at index 0 in the BERT vocabulary. The below illustration demonstrates padding out to a \"MAX_LEN\" of 8 tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c16396",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8e5132e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max transcript length for training:  177\n"
     ]
    }
   ],
   "source": [
    "max_len_tr = 0\n",
    "\n",
    "# For every sentence...\n",
    "for i in range(0,len(transcripts_tr)):\n",
    "    \n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "\n",
    "    if (previous_transcript_tr[i] != \"\" and use_next):\n",
    "      input_ids = tokenizer.encode(previous_transcript_tr[i]+ \" \" + previous_system_transcript_tr[i],transcripts_tr[i], add_special_tokens=True)\n",
    "    else:\n",
    "      input_ids = tokenizer.encode(transcripts_tr[i], add_special_tokens=True)\n",
    "        \n",
    "    # Update the maximum sentence length.\n",
    "    max_len_tr = max(max_len_tr, len(input_ids))\n",
    "\n",
    "print('Max transcript length for training: ', max_len_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17363e3c",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92914388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max transcript length for validation:  133\n"
     ]
    }
   ],
   "source": [
    "max_len_vd = 0\n",
    "\n",
    "# For every sentence...\n",
    "for i in range(0,len(transcripts_vd)):\n",
    "\n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    if (previous_transcript_vd[i] != \"\" and use_next):\n",
    "      input_ids = tokenizer.encode(previous_transcript_vd[i]+ \" \" + previous_system_transcript_vd[i],transcripts_vd[i], add_special_tokens=True)\n",
    "    else:\n",
    "      input_ids = tokenizer.encode(transcripts_vd[i], add_special_tokens=True)\n",
    "    \n",
    "    # Update the maximum sentence length.\n",
    "    max_len_vd = max(max_len_vd, len(input_ids))\n",
    "\n",
    "print('Max transcript length for validation: ', max_len_vd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3412aa8",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aab75df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max transcript length for evaluation:  150\n"
     ]
    }
   ],
   "source": [
    "max_len_tst = 0\n",
    "\n",
    "#non sono sicuro che il controllo della lunghezza vada fatto anche sul test set, dopo la performance non è determinata\n",
    "#dalla conoscenza del test set?\n",
    "#è anche vero che in teoria per far funzionare BERT bisogna dargli in pasto dei dati tokenizzati, quindi in un caso reale il nostro\n",
    "#model non potrebbe prendere in ingresso del testo non trattato. Nel dubbio ho controllato le dimensioni\n",
    "\n",
    "for i in range(0,len(transcripts_tst)):\n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    if (previous_transcript_tst[i] != \"\" and use_next):\n",
    "      input_ids = tokenizer.encode(previous_transcript_tst[i]+ \" \" + previous_system_transcript_tst[i],transcripts_tst[i], add_special_tokens=True)\n",
    "    else:\n",
    "      input_ids = tokenizer.encode(transcripts_tst[i], add_special_tokens=True)\n",
    "\n",
    "    # Update the maximum sentence length.\n",
    "    max_len_tst = max(max_len_tst, len(input_ids))\n",
    "\n",
    "print(\"Max transcript length for evaluation: \",max_len_tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c277f0",
   "metadata": {},
   "source": [
    "### Risultato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26bd8ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La massima lunghezza dei token da gestire è quindi  177\n"
     ]
    }
   ],
   "source": [
    "max_len = max(max_len_tr, max_len_vd, max_len_tst)\n",
    "\n",
    "# if (max_len_tr >= max_len_vd):\n",
    "#   max_len = max_len_tr\n",
    "# else:\n",
    "#   max_len = max_len_vd\n",
    "# if (max_len_tst >= max_len):\n",
    "#   max_len = max_len_tst\n",
    "\n",
    "print(\"La massima lunghezza dei token da gestire è quindi \",max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcefd1f1",
   "metadata": {},
   "source": [
    "## Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54bc7c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "[('availableSizes',)]\n",
      "['ageRange' 'amountInStock' 'availableSizes' 'brand' 'clothingCategory'\n",
      " 'clothingStyle' 'color' 'customerRating' 'dressStyle' 'embellishment'\n",
      " 'forGender' 'forOccasion' 'hasPart' 'hemLength' 'hemStyle' 'info'\n",
      " 'jacketStyle' 'madeIn' 'material' 'necklineStyle' 'pattern' 'price'\n",
      " 'sequential' 'size' 'skirtLength' 'skirtStyle' 'sleeveLength'\n",
      " 'sleeveStyle' 'soldBy' 'sweaterStyle' 'waistStyle' 'warmthRating'\n",
      " 'waterResistance']\n",
      "Totale: 30106, Training: 21196, Validation: 3513, Evaluation: 5397\n",
      "Training: 21196, Validation: 3513, Evaluation: 5397\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "attributes_labels_all = np.concatenate((attributes_labels_tr, attributes_labels_vd,attributes_labels_tst), axis=None)\n",
    "attr_yt = mlb.fit_transform(attributes_labels_all)\n",
    "print(attr_yt[0:15])\n",
    "print(mlb.inverse_transform(attr_yt[3].reshape(1, -1)))\n",
    "print(mlb.classes_)\n",
    "print(f\"Totale: {len(attr_yt)}, Training: {len(attributes_labels_tr)}, Validation: {len(attributes_labels_vd)}, Evaluation: {len(attributes_labels_tst)}\")\n",
    "attributes_labels_tr_vect = attr_yt[0:len(attributes_labels_tr)]\n",
    "attributes_labels_vd_vect = attr_yt[len(attributes_labels_tr):(len(attributes_labels_tr)+len(attributes_labels_vd))]\n",
    "attributes_labels_tst_vect = attr_yt[(len(attributes_labels_tr)+len(attributes_labels_vd)):]\n",
    "print(f\"Training: {len(attributes_labels_tr_vect)}, Validation: {len(attributes_labels_vd_vect)}, Evaluation: {len(attributes_labels_tst_vect)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63925873",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9505e37",
   "metadata": {},
   "source": [
    "Now we're ready to perform the real tokenization.\n",
    "\n",
    "The tokenizer.encode_plus function combines multiple steps for us:\n",
    "\n",
    "Split the sentence into tokens.\n",
    "Add the special [CLS] and [SEP] tokens.\n",
    "Map the tokens to their IDs.\n",
    "Pad or truncate all sentences to the same length.\n",
    "Create the attention masks which explicitly differentiate real tokens from [PAD] tokens.\n",
    "The first four features are in tokenizer.encode, but I'm using tokenizer.encode_plus to get the fifth item (attention masks). Documentation is here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aff8d187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f18953576f0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "# backends cudnn for out memory not necessary (resolved by batch size)\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "# torch.backends.cudnn.enabled = True\n",
    "# Set torch seed for deterministic behaviour\n",
    "torch.manual_seed(exec_params['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45855e8f",
   "metadata": {},
   "source": [
    "### Tokenize Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e32c330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21196 records to encode.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gian/anaconda3/envs/testcuda1/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2126: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING : \n",
      "Original:  Is there a pattern on this one? It's hard to see in the image.\n",
      "Token IDs: tensor([ 101, 2003, 2045, 1037, 5418, 2006, 2023, 2028, 1029, 2009, 1005, 1055,\n",
      "        2524, 2000, 2156, 1999, 1996, 3746, 1012,  102,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "\n",
    "#dobbiamo convertire le nostre lables da string a valori numerici, usiamo il metodo fornito da sklearn\n",
    "\n",
    "#TRAINING DATASET\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "action_labels_encoded_tr = le.fit_transform(action_labels_tr)\n",
    "\n",
    "input_ids_tr = []\n",
    "attention_masks_tr = []\n",
    "print(f\"{len(df_training)} records to encode.\")\n",
    "# For every sentence...\n",
    "for i in range(0,len(df_training)):\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "\n",
    "  if (previous_transcript_tr[i] != \"\" and use_next):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        previous_transcript_tr[i]+ \" \" + previous_system_transcript_tr[i],  # Sentence to encode.\n",
    "                        transcripts_tr[i], #next sentece to encode\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        truncation = True,\n",
    "                        max_length = max_len,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                    )\n",
    "  else:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        transcripts_tr[i],  # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        truncation = True,\n",
    "                        max_length = max_len,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                    )\n",
    "    \n",
    "\n",
    "    \n",
    "  # Add the encoded sentence to the list.    \n",
    "  input_ids_tr.append(encoded_dict['input_ids'])\n",
    "\n",
    "  # And its attention mask (simply differentiates padding from non-padding).\n",
    "  attention_masks_tr.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids_tr = torch.cat(input_ids_tr, dim=0)\n",
    "attention_masks_tr = torch.cat(attention_masks_tr, dim=0)\n",
    "labels_actions_tr = torch.tensor(action_labels_encoded_tr)\n",
    "labels_attributes_tr = torch.tensor(attributes_labels_tr_vect) \n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print (\"TRAINING : \")\n",
    "if (use_next):\n",
    "  print('Original: ', transcripts_tr[0])\n",
    "else:\n",
    "  print('Original: ', transcripts_tr[0])\n",
    "print('Token IDs:', input_ids_tr[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cda4541",
   "metadata": {},
   "source": [
    "### Tokenize Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5da13a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3513 records to encode.\n",
      "VALIDATION : \n",
      "Original:  What's the price of this sweater compared to the other blue and gray one I looked at?\n",
      "Token IDs: tensor([  101,  2054,  1005,  1055,  1996,  3976,  1997,  2023, 14329,  4102,\n",
      "         2000,  1996,  2060,  2630,  1998,  3897,  2028,  1045,  2246,  2012,\n",
      "         1029,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0])\n",
      "Dialog IDs: tensor([4146, 4146, 4146, 4146, 4146, 4146, 4146, 4260, 4260, 4260, 4260, 8022,\n",
      "        8022, 8022, 8022, 8022, 8022, 4992, 4992, 4992])\n",
      "Turn IDXs: tensor([0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 0, 1, 2, 3, 4, 5, 0, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "\n",
    "#dobbiamo convertire le nostre lables da string a valori numerici, usiamo il metodo fornito da sklearn\n",
    "\n",
    "#VALIDATION DATASET\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "action_labels_encoded_vd = le.fit_transform(action_labels_vd)\n",
    "\n",
    "input_ids_vd = []\n",
    "attention_masks_vd = []\n",
    "print(f\"{len(df_validation)} records to encode.\")\n",
    "# For every sentence...\n",
    "for i in range(0,len(df_validation)):\n",
    "  # `encode_plus` will:\n",
    "  #   (1) Tokenize the sentence.\n",
    "  #   (2) Prepend the `[CLS]` token to the start.\n",
    "  #   (3) Append the `[SEP]` token to the end.\n",
    "  #   (4) Map tokens to their IDs.\n",
    "  #   (5) Pad or truncate the sentence to `max_length`\n",
    "  #   (6) Create attention masks for [PAD] tokens.\n",
    "\n",
    "  if (previous_transcript_vd[i] != \"\" and use_next):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        previous_transcript_vd[i]+ \" \" + previous_system_transcript_vd[i],  # Sentence to encode.\n",
    "                        transcripts_vd[i], #next sentece to encode\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        truncation = True,\n",
    "                        max_length = max_len,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                    )\n",
    "  else:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        transcripts_vd[i],  # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        truncation = True,\n",
    "                        max_length = max_len,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                    )\n",
    "    \n",
    "  # Add the encoded sentence to the list.    \n",
    "  input_ids_vd.append(encoded_dict['input_ids'])\n",
    "  \n",
    "  # And its attention mask (simply differentiates padding from non-padding).\n",
    "  attention_masks_vd.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids_vd = torch.cat(input_ids_vd, dim=0)\n",
    "attention_masks_vd = torch.cat(attention_masks_vd, dim=0)\n",
    "labels_actions_vd = torch.tensor(action_labels_encoded_vd)\n",
    "labels_attributes_vd = torch.tensor(attributes_labels_vd_vect)\n",
    "# Check warning:\n",
    "# /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
    "dialog_ids_vd = torch.tensor(dialog_ids_vd)\n",
    "turn_idxs_vd = torch.tensor(turn_idxs_vd) \n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print (\"VALIDATION : \")\n",
    "if (use_next):\n",
    "  print('Original: ', transcripts_vd[0])\n",
    "else:\n",
    "  print('Original: ', transcripts_vd[0])\n",
    "print('Token IDs:', input_ids_vd[0])\n",
    "print(f\"Dialog IDs: {dialog_ids_vd[0:20]}\")\n",
    "print(f\"Turn IDXs: {turn_idxs_vd[0:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d364715",
   "metadata": {},
   "source": [
    "### Tokenize Evaluation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23888911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5397 records to encode.\n",
      "Evaluation : \n",
      "Original:  That looks a little too light for what I need, do you have something else with a high customer rating?\n",
      "Token IDs: tensor([ 101, 2008, 3504, 1037, 2210, 2205, 2422, 2005, 2054, 1045, 2342, 1010,\n",
      "        2079, 2017, 2031, 2242, 2842, 2007, 1037, 2152, 8013, 5790, 1029,  102,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0])\n",
      "Dialog IDs: tensor([2494, 2494, 2494, 2494, 2494, 3731, 3731, 3731, 3731, 3731, 8546, 8546,\n",
      "        8546, 8546, 8546, 8546, 5590, 5590, 5590, 5590])\n",
      "Turn IDXs: tensor([0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "\n",
    "#dobbiamo convertire le nostre lables da string a valori numerici, usiamo il metodo fornito da sklearn\n",
    "\n",
    "#EVALUATION DATASET\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "action_labels_encoded_tst = le.fit_transform(action_labels_tst)\n",
    "\n",
    "input_ids_tst = []\n",
    "attention_masks_tst = []\n",
    "print(f\"{len(df_test)} records to encode.\")\n",
    "# For every sentence...\n",
    "for i in range(0,len(df_test)):\n",
    "# for t in transcripts_tst:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "  \n",
    "  #Aggiungere \"and False\" PER UTILIZZARE sempre la tokenizzazione senza concatenazione\n",
    "  if (previous_transcript_tst[i] != \"\" and use_next):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                      previous_transcript_tst[i]+ \" \" + previous_system_transcript_tst[i],  # Sentence to encode.\n",
    "                      transcripts_tst[i], #next sentece to encode\n",
    "                      add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                      truncation = True,\n",
    "                      max_length = max_len,           # Pad & truncate all sentences.\n",
    "                      pad_to_max_length = True,\n",
    "                      return_attention_mask = True,   # Construct attn. masks.\n",
    "                      return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                  )\n",
    "  else:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                      transcripts_tst[i],  # Sentence to encode.\n",
    "                      add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                      truncation = True,\n",
    "                      max_length = max_len,           # Pad & truncate all sentences.\n",
    "                      pad_to_max_length = True,\n",
    "                      return_attention_mask = True,   # Construct attn. masks.\n",
    "                      return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                  )\n",
    "    \n",
    "  # Add the encoded sentence to the list.    \n",
    "  input_ids_tst.append(encoded_dict['input_ids'])\n",
    "  \n",
    "  # And its attention mask (simply differentiates padding from non-padding).\n",
    "  attention_masks_tst.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids_tst = torch.cat(input_ids_tst, dim=0)\n",
    "attention_masks_tst = torch.cat(attention_masks_tst, dim=0)\n",
    "labels_actions_tst = torch.tensor(action_labels_encoded_tst)\n",
    "labels_attributes_tst = torch.tensor(attributes_labels_tst_vect)\n",
    "# Check warning:\n",
    "# /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
    "dialog_ids_tst = torch.tensor(dialog_ids_tst)\n",
    "turn_idxs_tst = torch.tensor(turn_idxs_tst) \n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print (\"Evaluation : \")\n",
    "if (use_next):\n",
    "  print('Original: ', transcripts_tst[0])\n",
    "else:\n",
    "  print('Original: ', transcripts_tst[0])\n",
    "print('Token IDs:', input_ids_tst[0])\n",
    "print(f\"Dialog IDs: {dialog_ids_tst[0:20]}\")\n",
    "print(f\"Turn IDXs: {turn_idxs_tst[0:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af23bb7",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96157e27",
   "metadata": {},
   "source": [
    "# Data Split - AP4CA\n",
    "La nostra versione di split di dati per training e validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "680bdf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21,196 training samples\n",
      "3,513 validation samples\n",
      "5,397 evaluation samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "#labels_tr = {'actions': labels_actions_tr, 'attributes': labels_attributes_tr}\n",
    "#labels_vd = {'actions': labels_actions_vd, 'attributes': labels_attributes_vd}\n",
    "\n",
    "train_dataset = TensorDataset(input_ids_tr, attention_masks_tr, labels_actions_tr, labels_attributes_tr)\n",
    "val_dataset = TensorDataset(input_ids_vd, attention_masks_vd, labels_actions_vd, labels_attributes_vd, dialog_ids_vd, turn_idxs_vd)\n",
    "tst_dataset = TensorDataset(input_ids_tst, attention_masks_tst, labels_actions_tst, labels_attributes_tst, dialog_ids_tst, turn_idxs_tst)\n",
    "\n",
    "print('{:>5,} training samples'.format(len(train_dataset)))\n",
    "print('{:>5,} validation samples'.format(len(val_dataset)))\n",
    "print('{:>5,} evaluation samples'.format(len(tst_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed1196fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 101, 2008, 3504,  ...,    0,    0,    0],\n",
       "         [ 101, 2008, 3504,  ...,    0,    0,    0],\n",
       "         [ 101, 2040, 5617,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [ 101, 2821, 1045,  ...,    0,    0,    0],\n",
       "         [ 101, 4086, 1010,  ...,    0,    0,    0],\n",
       "         [ 101, 1045, 2066,  ...,    0,    0,    0]]),\n",
       " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " tensor([2, 4, 4, 0, 1, 2, 1, 2, 0, 1]),\n",
       " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " tensor([2494, 2494, 2494, 2494, 2494, 3731, 3731, 3731, 3731, 3731]),\n",
       " tensor([0, 1, 2, 3, 4, 0, 1, 2, 3, 4]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check evaluation TensorDataset content\n",
    "tst_dataset[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d01df19",
   "metadata": {},
   "source": [
    "## Check GPU for Training\n",
    "\n",
    "In questa versione la GPU è impostata fissa.\n",
    "Con una GPU in più a disposizione possiamo usare DataParallel e aumentare il batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31bf32c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2060\n"
     ]
    }
   ],
   "source": [
    "# Tell PyTorch to use the GPU.    \n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "print('We will use the GPU:', torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2045d72f",
   "metadata": {},
   "source": [
    "### Creazione Data Loaders per Training, Validation ed Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d9f42ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "# With size 32 GeForce RTX 2060 with 6GB run out of memory\n",
    "batch_size = exec_params['batch']\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )\n",
    "\n",
    "#ho controllato nel colab su cui ci basiamo, anche lui usa un Sequential Sampler per il dataset di evaluation\n",
    "evaluation_dataloader = DataLoader(\n",
    "            tst_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(tst_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040d27c5",
   "metadata": {},
   "source": [
    "## Train BERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc8111f",
   "metadata": {},
   "source": [
    "For this task, we first want to modify the pre-trained BERT model to give outputs for classification, and then we want to continue training the model on our dataset until that the entire model, end-to-end, is well-suited for our task. \n",
    "\n",
    "Thankfully, the huggingface pytorch implementation includes a set of interfaces designed for a variety of NLP tasks. Though these interfaces are all built on top of a trained BERT model, each has different top layers and output types designed to accomodate their specific NLP task.  \n",
    "\n",
    "Here is the current list of classes provided for fine-tuning:\n",
    "* BertModel\n",
    "* BertForPreTraining\n",
    "* BertForMaskedLM\n",
    "* BertForNextSentencePrediction\n",
    "* **BertForSequenceClassification** - The one we'll use.\n",
    "* BertForTokenClassification\n",
    "* BertForQuestionAnswering\n",
    "\n",
    "The documentation for these can be found under [here](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbd23ca",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We'll be using [BertForSequenceClassification](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#bertforsequenceclassification). This is the normal BERT model with an added single linear layer on top for classification that we will use as a sentence classifier. As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task. \n",
    "\n",
    "NB anche nell'articolo che sto leggendo sulla classificazione multi-label si parte da questo modello\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba0360b",
   "metadata": {},
   "source": [
    "OK, let's load BERT! There are a few different pre-trained BERT models available. \"bert-base-uncased\" means the version that has only lowercase letters (\"uncased\") and is the smaller version of the two (\"base\" vs \"large\").\n",
    "\n",
    "The documentation for `from_pretrained` can be found [here](https://huggingface.co/transformers/v2.2.0/main_classes/model.html#transformers.PreTrainedModel.from_pretrained), with the additional parameters defined [here](https://huggingface.co/transformers/v2.2.0/main_classes/configuration.html#transformers.PretrainedConfig)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "242aa137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DA SISTEMARE\n",
    "from transformers import BertModel\n",
    "from  torch import  nn\n",
    "\n",
    "class CustomBERTModel(nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "\n",
    "    super(CustomBERTModel, self).__init__()\n",
    "    self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "    ### New layers:\n",
    "    self.linear_intermedio = nn.Linear(768, exec_params['hidden_output_dim'])\n",
    "    #provare ad aggiungere ulteriori layer intermedi per ridurre le dimensioni fino ad arrivare all'output richiesto\n",
    "    self.linear_actions = nn.Linear(exec_params['hidden_output_dim'], 5) \n",
    "    self.linear_attributes = nn.Linear(exec_params['hidden_output_dim'], len(mlb.classes_)) #num attributi? \n",
    "\n",
    "  def forward(self, ids, mask):\n",
    "    #controllare che l'output non rappresenti solo lo stato interno dovuto al token CLS\n",
    "    output = self.bert(ids,attention_mask=mask)\n",
    "    # print(f\"Type output{type(output)}\")\n",
    "    # for p in output:\n",
    "    #   print(p)\n",
    "    #   print(type(output[p]))\n",
    "    #   print(output[p])\n",
    "\n",
    "    #prendiamo il campo last_hidden_state dall'oggetto output; last hidden state rappresenta il tensore\n",
    "    #in uscita dallo step di forward del BertModel\n",
    "    last_hidden_state_output = output[\"last_hidden_state\"]\n",
    "    # last_hidden_state has the following shape: (batch_size, sequence_length, 768)\n",
    "    #stiamo passando solo il token CLS ai layer successivi\n",
    "    linear_output_intermedio = self.linear_intermedio(last_hidden_state_output[:,0,:].view(-1,768)) \n",
    "    # linear_output_intermedio = self.linear_intermedio(pooled_output) \n",
    "    \n",
    "    linear_output_actions = self.linear_actions(linear_output_intermedio)\n",
    "    # linear_output_actions = self.sftmx(linear_output_actions)\n",
    "    # linear_output_actions = nn.functional.softmax(linear_output_actions)\n",
    "    # Test sigmoid for increasing perplexity performance\n",
    "    linear_output_actions = torch.sigmoid(linear_output_actions)\n",
    "    linear_output_attributes = self.linear_attributes(linear_output_intermedio)\n",
    "    # linear_output_attributes = self.sig(linear_output_attributes)\n",
    "    linear_output_attributes = torch.sigmoid(linear_output_attributes)\n",
    "\n",
    "    return {'actions': linear_output_actions, 'attributes': linear_output_attributes}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ceefd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomBERTModel(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (linear_intermedio): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (linear_actions): Linear(in_features=256, out_features=5, bias=True)\n",
       "  (linear_attributes): Linear(in_features=256, out_features=33, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test istanziazione del custom model\n",
    "model = CustomBERTModel()\n",
    "\n",
    "# model.bert.config\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cb0c4c",
   "metadata": {},
   "source": [
    "Just for curiosity's sake, we can browse all of the model's parameters by name here.\n",
    "\n",
    "In the below cell, I've printed out the names and dimensions of the weights for:\n",
    "\n",
    "1. The embedding layer.\n",
    "2. The first of the twelve transformers.\n",
    "3. The output layer.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c48662a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 205 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "linear_actions.weight                                       (5, 256)\n",
      "linear_actions.bias                                             (5,)\n",
      "linear_attributes.weight                                   (33, 256)\n",
      "linear_attributes.bias                                         (33,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655b5929",
   "metadata": {},
   "source": [
    "## 4.2. Optimizer & Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2ee817",
   "metadata": {},
   "source": [
    "Now that we have our model loaded we need to grab the training hyperparameters from within the stored model.\n",
    "\n",
    "For the purposes of fine-tuning, the authors recommend choosing from the following values (from Appendix A.3 of the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf)):\n",
    "\n",
    ">- **Batch size:** 16, 32  \n",
    "- **Learning rate (Adam):** 5e-5, 3e-5, 2e-5  \n",
    "- **Number of epochs:** 2, 3, 4 \n",
    "\n",
    "We chose:\n",
    "* Batch size: 32 (set when creating our DataLoaders)\n",
    "* Learning rate: 2e-5\n",
    "* Epochs: 4 (we'll see that this is probably too many...)\n",
    "\n",
    "The epsilon parameter `eps = 1e-8` is \"a very small number to prevent any division by zero in the implementation\" (from [here](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)).\n",
    "\n",
    "You can find the creation of the AdamW optimizer in `run_glue.py` [here](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "295fde1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 5e-5, # args.learning_rate - default is 5e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4faef5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = exec_params['epochs']\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eccdf3c",
   "metadata": {},
   "source": [
    "## 4.3. Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1141dfa",
   "metadata": {},
   "source": [
    "Below is our training loop. There's a lot going on, but fundamentally for each pass in our loop we have a trianing phase and a validation phase. \n",
    "\n",
    "> *Thank you to [Stas Bekman](https://ca.linkedin.com/in/stasbekman) for contributing the insights and code for using validation loss to detect over-fitting!*\n",
    "\n",
    "**Training:**\n",
    "- Unpack our data inputs and labels\n",
    "- Load data onto the GPU for acceleration\n",
    "- Clear out the gradients calculated in the previous pass. \n",
    "    - In pytorch the gradients accumulate by default (useful for things like RNNs) unless you explicitly clear them out.\n",
    "- Forward pass (feed input data through the network)\n",
    "- Backward pass (backpropagation)\n",
    "- Tell the network to update parameters with optimizer.step()\n",
    "- Track variables for monitoring progress\n",
    "\n",
    "**Evalution:**\n",
    "- Unpack our data inputs and labels\n",
    "- Load data onto the GPU for acceleration\n",
    "- Forward pass (feed input data through the network)\n",
    "- Compute loss on our validation data and track variables for monitoring progress\n",
    "\n",
    "Pytorch hides all of the detailed calculations from us, but we've commented the code to point out which of the above steps are happening on each line. \n",
    "\n",
    "> *PyTorch also has some [beginner tutorials](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py) which you may also find helpful.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d699904",
   "metadata": {},
   "source": [
    "Define a helper function for calculating accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df633469",
   "metadata": {},
   "source": [
    "### Flat accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef1a2d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy_actions(preds, labels):\n",
    "    #print(f\"[FA] preds: {preds} / labels: {labels}\")\n",
    "    #print(f\"[FA-Actions] {type(preds)} {type(labels)}\")\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()   \n",
    "    return {'matched': np.sum(pred_flat == labels_flat), 'counts': len(labels_flat)}\n",
    "\n",
    "def flat_accuracy_attributes(preds, labels):\n",
    "  #print(f\"[FA-Attributess] {type(preds)} {type(labels)}\")\n",
    "  tot_preds = preds.shape[0]\n",
    "  preds_int = np.rint(preds)\n",
    "  tot_eq = 0\n",
    "  for i in range(tot_preds):\n",
    "    comparison = preds_int[i] == labels[i]\n",
    "    if comparison.all():\n",
    "      tot_eq += 1\n",
    "  return {'matched': tot_eq, 'counts' : tot_preds}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc1a792",
   "metadata": {},
   "source": [
    "Helper function for formatting elapsed times as `hh:mm:ss`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "903c3769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdd0590",
   "metadata": {},
   "source": [
    "### Loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0629812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "# Loss function definition\n",
    "def MyBERT_loss(logits, actions_labels, attributes_labels):\n",
    "  actions_logits = logits['actions']\n",
    "  attributes_logits = logits['attributes']\n",
    "  loss_actions_fn = nn.CrossEntropyLoss()\n",
    "  loss_attributes_fn = nn.BCELoss()\n",
    "  loss_actions = loss_actions_fn(actions_logits, actions_labels)\n",
    "  loss_attributes = loss_attributes_fn(attributes_logits, attributes_labels.float())\n",
    "  return loss_actions + loss_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fea679",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We're ready to kick off the training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aab27b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  5% | 34% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  5% | 34% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:56.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 91% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:50.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 94% | 91% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:44.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 90% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:39.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 90% |\n",
      "End of epoch 0\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 90% |\n",
      "\n",
      "  Average training loss: 1.13\n",
      "  Training epcoh took: 0:08:27\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8480\n",
      "  Accuracy for multilabel-classification (attributes): 0.8856\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8479931682322801, 'action_perplexity': 1.9686127817817451, 'attribute_accuracy': 0.6858987152319531, 'confusion_matrix': array([[4.700e+02, 3.900e+01, 2.000e+00, 0.000e+00, 1.000e+01],\n",
      "       [1.000e+01, 6.520e+02, 2.200e+01, 4.000e+00, 9.000e+00],\n",
      "       [1.100e+01, 1.520e+02, 5.200e+02, 4.400e+01, 1.900e+01],\n",
      "       [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
      "       [1.000e+00, 6.500e+01, 8.000e+01, 6.600e+01, 1.337e+03]])}\n",
      "  Validation Loss: 1.0648\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 98% | 90% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 98% | 90% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:55.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 90% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:49.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:43.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:38.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 91% |\n",
      "End of epoch 1\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "\n",
      "  Average training loss: 1.05\n",
      "  Training epcoh took: 0:08:26\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8551\n",
      "  Accuracy for multilabel-classification (attributes): 0.9149\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8551095929405067, 'action_perplexity': 1.9346124902317008, 'attribute_accuracy': 0.7396553439840098, 'confusion_matrix': array([[4.690e+02, 3.400e+01, 2.000e+00, 0.000e+00, 6.000e+00],\n",
      "       [1.000e+01, 6.770e+02, 3.400e+01, 8.000e+00, 1.400e+01],\n",
      "       [1.200e+01, 1.460e+02, 5.250e+02, 4.200e+01, 2.200e+01],\n",
      "       [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
      "       [1.000e+00, 5.100e+01, 6.300e+01, 6.400e+01, 1.333e+03]])}\n",
      "  Validation Loss: 1.0538\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:17:46 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import action_evaluation as evaluation\n",
    "import json\n",
    "from  GPUtil import showUtilization as gpu_usage\n",
    "with open('./extr_output/fashion_dev_dials_api_calls.json') as f:\n",
    "  dev_dials = json.load(f)\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = exec_params['seed']\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "#torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "test_batch = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    print(\"GPU before train\")\n",
    "    gpu_usage()\n",
    "\n",
    "    model.train()\n",
    "    print(\"GPU after train\")\n",
    "    gpu_usage()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 400 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "            gpu_usage()\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: actions labels \n",
    "        #   [3]: attributes labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels_actions = batch[2].to(device)\n",
    "        b_labels_attributes = batch[3].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
    "        # function and pass down the arguments. The `forward` function is \n",
    "        # documented here: \n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
    "        # The results are returned in a results object, documented here:\n",
    "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
    "        # Specifically, we'll get the loss (because we provided labels) and the\n",
    "        # \"logits\"--the model outputs prior to activation.\n",
    "        result = model(b_input_ids, \n",
    "                       mask=b_input_mask)\n",
    "        \n",
    "        loss = MyBERT_loss(result, b_labels_actions, b_labels_attributes)\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.from transformers import BertModel, BertConfig\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    print(f\"End of epoch {epoch_i}\")\n",
    "    gpu_usage()\n",
    "    \n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.mlb.inverse_transform(attr_yt[3].reshape(1, -1))\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy_classification = { 'matched': 0, 'counts': 0}\n",
    "    total_eval_accuracy_multilabel = { 'matched': 0, 'counts': 0}\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    batch_number = 0\n",
    "\n",
    "    # Dictionary for action_evaluation\n",
    "    model_actions = {}\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        batch_number += 1\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels_actions = batch[2].to(device)\n",
    "        b_labels_attributes = batch[3].to(device)\n",
    "        b_dialog_ids = batch[4].to(device).detach().cpu().numpy()\n",
    "        b_turn_idxs = batch[5].to(device).detach().cpu().numpy()\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            result = model(b_input_ids, \n",
    "                       mask=b_input_mask)\n",
    "\n",
    "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
    "        # output values prior to applying an activation function like the \n",
    "        # softmax.\n",
    "        loss = MyBERT_loss(result, b_labels_actions, b_labels_attributes)\n",
    "            \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        # logits = logits.detach().cpu().numpy()\n",
    "        # label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        \n",
    "        actions_logits_foracc=result['actions'].detach().cpu().numpy()\n",
    "        attributes_logits_foracc=result['attributes'].detach().cpu().numpy()\n",
    "        actions_labels_foracc= b_labels_actions.to('cpu').numpy()\n",
    "        attributes_labels_foracc =b_labels_attributes.to('cpu').numpy()\n",
    "\n",
    "        #TODO: definire la nostra funzione di accuracy\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        accuracy_classification = flat_accuracy_actions(actions_logits_foracc, actions_labels_foracc)\n",
    "        accuracy_multilabel = flat_accuracy_attributes(attributes_logits_foracc, attributes_labels_foracc)\n",
    "        \n",
    "        total_eval_accuracy_classification['matched'] += accuracy_classification['matched']\n",
    "        total_eval_accuracy_classification['counts'] += accuracy_classification['counts']\n",
    "        total_eval_accuracy_multilabel['matched'] += accuracy_multilabel['matched']\n",
    "        total_eval_accuracy_multilabel['counts'] += accuracy_multilabel['counts']\n",
    "        # Salvo dati elaborazione batch per debug/analisi\n",
    "        test_batch.append({\n",
    "            'epoch' : epoch_i + 1,\n",
    "            'batchnum' : batch_number,\n",
    "            'actions_logits' : actions_logits_foracc,\n",
    "            'actions_labels' : actions_labels_foracc,\n",
    "            'attributes_logits' : attributes_logits_foracc,\n",
    "            'attributes_labels' : attributes_labels_foracc,\n",
    "            'accuracy_classification' : accuracy_classification,\n",
    "            'accuracy_multilabel' : accuracy_multilabel,\n",
    "        })\n",
    "\n",
    "        # Fill dictionary for action_evaluation\n",
    "        for el_i in range(len(actions_logits_foracc)):\n",
    "          dialog_id = b_dialog_ids[el_i]\n",
    "          action_log_prob = {}\n",
    "          for act_i in range(len(actions_logits_foracc[el_i])):\n",
    "            #todo: controllare che la probabilità predetta sia in scala logaritmica (?? potrebbe essere fonte di errori)\n",
    "            action_log_prob[le.classes_[act_i]] = np.log(actions_logits_foracc[el_i][act_i])\n",
    "          #attributes = {}\n",
    "          attributes = []\n",
    "          #attributes_list = np.rint(attributes_logits_foracc[el_i])\n",
    "          attributes_list = np.array(attributes_logits_foracc[el_i])\n",
    "          for attr in range(len(attributes_list)):\n",
    "            attribute = mlb.classes_[attr]\n",
    "            #attributes[mlb.classes_[attr]] = attributes_list[attr]\n",
    "            if attributes_list[attr] >= 0.5:\n",
    "              attributes.append(attribute)\n",
    "          prediction = {\n",
    "              'action': le.classes_[np.argmax(actions_logits_foracc[el_i])],\n",
    "              'action_log_prob': action_log_prob,\n",
    "              'attributes': {'attributes': attributes},\n",
    "              'turn_id': b_turn_idxs[el_i]\n",
    "          }\n",
    "          if dialog_id in model_actions:\n",
    "            model_actions[dialog_id]['predictions'].append(prediction)\n",
    "          else:\n",
    "            predictions = list()\n",
    "            predictions.append(prediction)\n",
    "            model_actions[dialog_id] = {\n",
    "                'dialog_id': dialog_id,\n",
    "                'predictions': predictions\n",
    "            }\n",
    "          \n",
    "\n",
    "    # Report the final accuracy for this validation \n",
    "\n",
    "    #avg_val_accuracy_classification = total_eval_accuracy_classification / len(validation_dataloader)\n",
    "    #avg_val_accuracy_multilabel = total_eval_accuracy_multilabel / len(validation_dataloader)\n",
    "    avg_val_accuracy_classification = total_eval_accuracy_classification['matched'] / total_eval_accuracy_classification['counts']\n",
    "    avg_val_accuracy_multilabel = total_eval_accuracy_multilabel['matched'] / total_eval_accuracy_multilabel['counts']\n",
    "    print(\"  Accuracy for classification (actions): {0:.4f}\".format(avg_val_accuracy_classification))\n",
    "    print(\"  Accuracy for multilabel-classification (attributes): {0:.4f}\".format(avg_val_accuracy_multilabel))\n",
    "\n",
    "    # Reference implementation: evaluation of action prediction along with attributes\n",
    "    metrics = evaluation.evaluate_action_prediction(dev_dials, model_actions.values())\n",
    "    # print(\"model_actions passed to the evaluator:\")\n",
    "    # for v in model_actions.values():\n",
    "    #   print(v)\n",
    "    print(\"***************************************\")\n",
    "    print(\"Reference evaluation metrics:\")\n",
    "    print(metrics)\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.4f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,  \n",
    "            'Valid. Accur. class.': avg_val_accuracy_classification,\n",
    "            'Valid. Accur. mult.label': avg_val_accuracy_multilabel,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time,\n",
    "            'metrics': metrics\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ac0f0f",
   "metadata": {},
   "source": [
    "## Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b6d29e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy for classification (actions): 0.8473\n",
      "  Accuracy for multilabel-classification (attributes): 0.9085\n",
      "#Instances evaluated API: 5397\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8473225866221975, 'action_perplexity': 2.0228244439013636, 'attribute_accuracy': 0.7247635676024746, 'confusion_matrix': array([[ 747.,   48.,    8.,    4.,   15.],\n",
      "       [  28., 1042.,   60.,   14.,   30.],\n",
      "       [  13.,  223.,  762.,   97.,   21.],\n",
      "       [   0.,    0.,    0.,    0.,    0.],\n",
      "       [   5.,   73.,  114.,   71., 2022.]])}\n"
     ]
    }
   ],
   "source": [
    "#Prediction on test set\n",
    "#quale modello gli viene passato? da controllare se BERT da solo riesce a tenere traccia del modello che ha dato l'epoca migliore\n",
    "\n",
    "\n",
    "with open('./extr_output/fashion_devtest_dials_api_calls.json') as f:\n",
    "  devtest_dials = json.load(f)\n",
    "\n",
    "# Tracking variables \n",
    "total_eval_accuracy_classification = { 'matched': 0, 'counts': 0}\n",
    "total_eval_accuracy_multilabel = { 'matched': 0, 'counts': 0}\n",
    "\n",
    "model_actions = {}\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "for batch in evaluation_dataloader:\n",
    "\n",
    "    # Unpack this training batch from our dataloader. \n",
    "    #\n",
    "    # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "    # the `to` method.\n",
    "    #\n",
    "    # `batch` contains three pytorch tensors:\n",
    "    #   [0]: input ids \n",
    "    #   [1]: attention masks\n",
    "    #   [2]: labels \n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels_actions = batch[2].to(device)\n",
    "    b_labels_attributes = batch[3].to(device)\n",
    "    b_dialog_ids = batch[4].to(device).detach().cpu().numpy()\n",
    "    b_turn_idxs = batch[5].to(device).detach().cpu().numpy()\n",
    "    \n",
    "    # Tell pytorch not to bother with constructing the compute graph during\n",
    "    # the forward pass, since this is only needed for backprop (training).\n",
    "    with torch.no_grad():        \n",
    "        # Forward pass, calculate logit predictions.\n",
    "        # token_type_ids is the same as the \"segment ids\", which \n",
    "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "        result = model(b_input_ids,mask=b_input_mask)\n",
    "\n",
    "    \n",
    "    actions_logits_foracc=result['actions'].detach().cpu().numpy()\n",
    "    attributes_logits_foracc=result['attributes'].detach().cpu().numpy()\n",
    "    actions_labels_foracc= b_labels_actions.to('cpu').numpy()\n",
    "    attributes_labels_foracc =b_labels_attributes.to('cpu').numpy()\n",
    "\n",
    "    # Calculate the accuracy for this batch of test sentences, and\n",
    "    # accumulate it over all batches.\n",
    "    accuracy_classification = flat_accuracy_actions(actions_logits_foracc, actions_labels_foracc)\n",
    "    accuracy_multilabel = flat_accuracy_attributes(attributes_logits_foracc, attributes_labels_foracc)\n",
    "    \n",
    "    total_eval_accuracy_classification['matched'] += accuracy_classification['matched']\n",
    "    total_eval_accuracy_classification['counts'] += accuracy_classification['counts']\n",
    "    total_eval_accuracy_multilabel['matched'] += accuracy_multilabel['matched']\n",
    "    total_eval_accuracy_multilabel['counts'] += accuracy_multilabel['counts']\n",
    "    \n",
    "\n",
    "    # Fill dictionary for action_evaluation\n",
    "    for el_i in range(len(actions_logits_foracc)):\n",
    "      dialog_id = b_dialog_ids[el_i]\n",
    "      action_log_prob = {}\n",
    "      for act_i in range(len(actions_logits_foracc[el_i])):\n",
    "        #todo: controllare che la probabilità predetta sia in scala logaritmica (?? potrebbe essere fonte di errori)\n",
    "        action_log_prob[le.classes_[act_i]] = np.log(actions_logits_foracc[el_i][act_i])\n",
    "      #attributes = {}\n",
    "      attributes = []\n",
    "      #attributes_list = np.rint(attributes_logits_foracc[el_i])\n",
    "      attributes_list = np.array(attributes_logits_foracc[el_i])\n",
    "      for attr in range(len(attributes_list)):\n",
    "        attribute = mlb.classes_[attr]\n",
    "        #attributes[mlb.classes_[attr]] = attributes_list[attr]\n",
    "        if attributes_list[attr] >= 0.5:\n",
    "          attributes.append(attribute)\n",
    "      prediction = {\n",
    "          'action': le.classes_[np.argmax(actions_logits_foracc[el_i])],\n",
    "          'action_log_prob': action_log_prob,\n",
    "          'attributes': {'attributes': attributes},\n",
    "          'turn_id': b_turn_idxs[el_i]\n",
    "      }\n",
    "      if dialog_id in model_actions:\n",
    "        model_actions[dialog_id]['predictions'].append(prediction)\n",
    "      else:\n",
    "        predictions = list()\n",
    "        predictions.append(prediction)\n",
    "        model_actions[dialog_id] = {\n",
    "            'dialog_id': dialog_id,\n",
    "            'predictions': predictions\n",
    "        }\n",
    "      \n",
    "\n",
    "# Report the final accuracy for this validation \n",
    "\n",
    "#avg_val_accuracy_classification = total_eval_accuracy_classification / len(validation_dataloader)\n",
    "#avg_val_accuracy_multilabel = total_eval_accuracy_multilabel / len(validation_dataloader)\n",
    "avg_val_accuracy_classification = total_eval_accuracy_classification['matched'] / total_eval_accuracy_classification['counts']\n",
    "avg_val_accuracy_multilabel = total_eval_accuracy_multilabel['matched'] / total_eval_accuracy_multilabel['counts']\n",
    "print(\"  Accuracy for classification (actions): {0:.4f}\".format(avg_val_accuracy_classification))\n",
    "print(\"  Accuracy for multilabel-classification (attributes): {0:.4f}\".format(avg_val_accuracy_multilabel))\n",
    "\n",
    "# Reference implementation: evaluation of action prediction along with attributes\n",
    "metrics = evaluation.evaluate_action_prediction(devtest_dials, model_actions.values())\n",
    "# print(\"model_actions passed to the evaluator:\")\n",
    "# for v in model_actions.values():\n",
    "#   print(v)\n",
    "print(\"***************************************\")\n",
    "print(\"Reference evaluation metrics:\")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a059e49",
   "metadata": {},
   "source": [
    "# OTHER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ca179f",
   "metadata": {},
   "source": [
    "Let's view the summary of the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "03bdf5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "401e879c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>batchnum</th>\n",
       "      <th>actions_logits</th>\n",
       "      <th>actions_labels</th>\n",
       "      <th>attributes_logits</th>\n",
       "      <th>attributes_labels</th>\n",
       "      <th>accuracy_classification</th>\n",
       "      <th>accuracy_multilabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.0012399926, 0.9980248, 0.0003851334, 5.960...</td>\n",
       "      <td>[1, 4, 2, 4, 0, 1, 1, 4, 4, 0, 1, 2]</td>\n",
       "      <td>[[0.00047568898, 0.00026087053, 0.0065372945, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>{'matched': 11, 'counts': 12}</td>\n",
       "      <td>{'matched': 11, 'counts': 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0.0026353563, 0.999603, 0.00027183903, 4.091...</td>\n",
       "      <td>[1, 4, 2, 2, 0, 1, 2, 1, 1, 1, 1, 4]</td>\n",
       "      <td>[[0.00040428797, 0.00021374444, 0.0047078524, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>{'matched': 9, 'counts': 12}</td>\n",
       "      <td>{'matched': 10, 'counts': 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[[0.003784226, 0.002402325, 0.00045004822, 8.0...</td>\n",
       "      <td>[4, 1, 1, 1, 4, 2, 1, 2, 0, 1, 1, 1]</td>\n",
       "      <td>[[0.00029864442, 0.00017513818, 0.95808214, 0....</td>\n",
       "      <td>[[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>{'matched': 8, 'counts': 12}</td>\n",
       "      <td>{'matched': 11, 'counts': 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[[0.9996886, 0.0059155338, 0.00061059726, 0.00...</td>\n",
       "      <td>[0, 0, 1, 2, 0, 1, 4, 4, 0, 1, 1, 4]</td>\n",
       "      <td>[[0.0016101466, 0.00030576988, 0.009783978, 0....</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>{'matched': 10, 'counts': 12}</td>\n",
       "      <td>{'matched': 11, 'counts': 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[[0.0005817234, 0.0056745363, 0.00016123817, 0...</td>\n",
       "      <td>[1, 4, 2, 4, 0, 3, 1, 1, 2, 4, 1, 1]</td>\n",
       "      <td>[[0.0005157384, 0.0007204198, 0.042778593, 0.0...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>{'matched': 9, 'counts': 12}</td>\n",
       "      <td>{'matched': 11, 'counts': 12}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  batchnum                                     actions_logits  \\\n",
       "0      1         1  [[0.0012399926, 0.9980248, 0.0003851334, 5.960...   \n",
       "1      1         2  [[0.0026353563, 0.999603, 0.00027183903, 4.091...   \n",
       "2      1         3  [[0.003784226, 0.002402325, 0.00045004822, 8.0...   \n",
       "3      1         4  [[0.9996886, 0.0059155338, 0.00061059726, 0.00...   \n",
       "4      1         5  [[0.0005817234, 0.0056745363, 0.00016123817, 0...   \n",
       "\n",
       "                         actions_labels  \\\n",
       "0  [1, 4, 2, 4, 0, 1, 1, 4, 4, 0, 1, 2]   \n",
       "1  [1, 4, 2, 2, 0, 1, 2, 1, 1, 1, 1, 4]   \n",
       "2  [4, 1, 1, 1, 4, 2, 1, 2, 0, 1, 1, 1]   \n",
       "3  [0, 0, 1, 2, 0, 1, 4, 4, 0, 1, 1, 4]   \n",
       "4  [1, 4, 2, 4, 0, 3, 1, 1, 2, 4, 1, 1]   \n",
       "\n",
       "                                   attributes_logits  \\\n",
       "0  [[0.00047568898, 0.00026087053, 0.0065372945, ...   \n",
       "1  [[0.00040428797, 0.00021374444, 0.0047078524, ...   \n",
       "2  [[0.00029864442, 0.00017513818, 0.95808214, 0....   \n",
       "3  [[0.0016101466, 0.00030576988, 0.009783978, 0....   \n",
       "4  [[0.0005157384, 0.0007204198, 0.042778593, 0.0...   \n",
       "\n",
       "                                   attributes_labels  \\\n",
       "0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "2  [[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "3  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "4  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "         accuracy_classification            accuracy_multilabel  \n",
       "0  {'matched': 11, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
       "1   {'matched': 9, 'counts': 12}  {'matched': 10, 'counts': 12}  \n",
       "2   {'matched': 8, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
       "3  {'matched': 10, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
       "4   {'matched': 9, 'counts': 12}  {'matched': 11, 'counts': 12}  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert test data to dataframe\n",
    "df_test = pd.DataFrame(data = test_batch)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dbd5290d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur. class.</th>\n",
       "      <th>Valid. Accur. mult.label</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "      <th>metrics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.13</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0:08:27</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8479931682322801, 'actio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.05</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0:08:26</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8551095929405067, 'actio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. class.  \\\n",
       "epoch                                                     \n",
       "1               1.13         1.06                  0.85   \n",
       "2               1.05         1.05                  0.86   \n",
       "\n",
       "       Valid. Accur. mult.label Training Time Validation Time  \\\n",
       "epoch                                                           \n",
       "1                          0.89       0:08:27         0:00:27   \n",
       "2                          0.91       0:08:26         0:00:27   \n",
       "\n",
       "                                                 metrics  \n",
       "epoch                                                     \n",
       "1      {'action_accuracy': 0.8479931682322801, 'actio...  \n",
       "2      {'action_accuracy': 0.8551095929405067, 'actio...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display floats with two decimal places.\n",
    "pd.set_option('precision', 2)\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap.\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Display the table.\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "69386886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Objects serialization\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "testdata_filename = f\"testdata-{timestr}\"\n",
    "stats_filename = f\"stats-{timestr}\"\n",
    "#outtest = open(testdata_filename, \"wb\")\n",
    "#outstats = open(stats_filename, \"wb\")\n",
    "#pk.dump(obj=df_test, file=outtest)\n",
    "#outtest.close()\n",
    "#pk.dump(obj=df_stats, file=outstats)\n",
    "#outstats.close()\n",
    "df_test.to_pickle(testdata_filename)\n",
    "df_stats.to_pickle(stats_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb5a6cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testdata-20210801-010111\n",
      "       Training Loss  Valid. Loss  Valid. Accur. class.  \\\n",
      "epoch                                                     \n",
      "1               1.13         1.06                  0.85   \n",
      "2               1.05         1.05                  0.86   \n",
      "\n",
      "       Valid. Accur. mult.label Training Time Validation Time  \\\n",
      "epoch                                                           \n",
      "1                          0.89       0:08:27         0:00:27   \n",
      "2                          0.91       0:08:26         0:00:27   \n",
      "\n",
      "                                                 metrics  \n",
      "epoch                                                     \n",
      "1      {'action_accuracy': 0.8479931682322801, 'actio...  \n",
      "2      {'action_accuracy': 0.8551095929405067, 'actio...  \n",
      "   epoch  batchnum                                     actions_logits  \\\n",
      "0      1         1  [[0.0012399926, 0.9980248, 0.0003851334, 5.960...   \n",
      "1      1         2  [[0.0026353563, 0.999603, 0.00027183903, 4.091...   \n",
      "2      1         3  [[0.003784226, 0.002402325, 0.00045004822, 8.0...   \n",
      "3      1         4  [[0.9996886, 0.0059155338, 0.00061059726, 0.00...   \n",
      "4      1         5  [[0.0005817234, 0.0056745363, 0.00016123817, 0...   \n",
      "\n",
      "                         actions_labels  \\\n",
      "0  [1, 4, 2, 4, 0, 1, 1, 4, 4, 0, 1, 2]   \n",
      "1  [1, 4, 2, 2, 0, 1, 2, 1, 1, 1, 1, 4]   \n",
      "2  [4, 1, 1, 1, 4, 2, 1, 2, 0, 1, 1, 1]   \n",
      "3  [0, 0, 1, 2, 0, 1, 4, 4, 0, 1, 1, 4]   \n",
      "4  [1, 4, 2, 4, 0, 3, 1, 1, 2, 4, 1, 1]   \n",
      "\n",
      "                                   attributes_logits  \\\n",
      "0  [[0.00047568898, 0.00026087053, 0.0065372945, ...   \n",
      "1  [[0.00040428797, 0.00021374444, 0.0047078524, ...   \n",
      "2  [[0.00029864442, 0.00017513818, 0.95808214, 0....   \n",
      "3  [[0.0016101466, 0.00030576988, 0.009783978, 0....   \n",
      "4  [[0.0005157384, 0.0007204198, 0.042778593, 0.0...   \n",
      "\n",
      "                                   attributes_labels  \\\n",
      "0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
      "1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
      "2  [[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
      "3  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
      "4  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
      "\n",
      "         accuracy_classification            accuracy_multilabel  \n",
      "0  {'matched': 11, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
      "1   {'matched': 9, 'counts': 12}  {'matched': 10, 'counts': 12}  \n",
      "2   {'matched': 8, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
      "3  {'matched': 10, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
      "4   {'matched': 9, 'counts': 12}  {'matched': 11, 'counts': 12}  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Test reimport data\n",
    "df_stats_reload = pd.read_pickle(stats_filename)\n",
    "df_test_reload = pd.read_pickle(testdata_filename)\n",
    "\n",
    "print(testdata_filename)\n",
    "print(df_stats_reload.head())\n",
    "print(df_test_reload.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1af435",
   "metadata": {},
   "source": [
    "## Plot di training & validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2c4fe674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks([x+1 for x in range(exec_params['epochs'])])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b962a382",
   "metadata": {},
   "source": [
    "## Plot accuracy and perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "064dfb51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "act_acc = [x['action_accuracy'] for x in df_stats.metrics]\n",
    "att_acc = [x['attribute_accuracy'] for x in df_stats.metrics]\n",
    "x_ticks = [x for x in range(len(act_acc))]\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(act_acc, 'b-o', label=\"Actions\")\n",
    "plt.plot(att_acc, 'g-o', label=\"Attributes\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Actions and attributes accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.xticks(ticks = x_ticks, labels = [str(x+1) for x in x_ticks])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c3c70640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "act_per = [x['action_perplexity'] for x in df_stats.metrics]\n",
    "x_ticks = [x for x in range(len(act_acc))]\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(act_per, 'b-o')\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Actions perplexity\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Perplexity\")\n",
    "plt.xticks(ticks = x_ticks, labels = [str(x+1) for x in x_ticks])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bee77e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
