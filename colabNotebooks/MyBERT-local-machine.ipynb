{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4e26663",
   "metadata": {},
   "source": [
    "# Download GitHub repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9f42ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gian/content\n",
      "Clone in 'ActionPrediction4CA' in corso...\n",
      "remote: Enumerating objects: 360, done.\u001b[K\n",
      "remote: Counting objects: 100% (360/360), done.\u001b[K\n",
      "remote: Compressing objects: 100% (272/272), done.\u001b[K\n",
      "remote: Total 360 (delta 179), reused 254 (delta 81), pack-reused 0\u001b[K\n",
      "Ricezione degli oggetti: 100% (360/360), 46.95 MiB | 10.50 MiB/s, fatto.\n",
      "Risoluzione dei delta: 100% (179/179), fatto.\n"
     ]
    }
   ],
   "source": [
    "%cd ~/content/\n",
    "%rm -rf ~/content/ActionPrediction4CA\n",
    "%rm -rf ~/content/ActionPredictionBERT\n",
    "!git clone  --branch colab_exe https://github.com/jmcrav/ActionPrediction4CA.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36cb4f3",
   "metadata": {},
   "source": [
    "# Elimino i file inutili al modello \n",
    "Per fare il fine tuning del modello, abbiamo bisogno solo dei dati grezzi.\n",
    "Il tutor ha puntualizzato di usare SOLO lo script `simmc/mm_action_prediction/tools/extract_actions_fashion.py`, che costruisce un json con le lables associate alle azioni e agli attributi (è lo step 1 del preprocessing).\n",
    "Questo credo sia necessario perchè credo che la loro implementazione sia di un livello molto più basso di quello a cui dovremo lavorare noi.\n",
    "BERT è un metodo per effettuare il  pre-trained di modelli per il NLP di cui dobbiamo solo fare un fine-tuning accettabile, mentre il SIMMC deve addestrare un intero modello da zero(o comunque credo che il loro obiettivo sia cercare di creare un modello che riesca a funzionare bene col linguaggio multimodale.Non ho capito perchè non sia statu usato BERT anche da loro onestamente -  il task finale è diviso in 3 sottotask, e la prima è un problema di classificazione multi-classe per il quale BERT dovrebbe poter funzionare - forse perchè quella fornita è solo un implementazione di partenza e i concorrenti alla challenge hanno fornito le loro implementazioni dei modelli?). Praticamente tutte le operazioni che fanno loro sui dati credo servano ai loro dettagli implementativi di bassissimo livello; con BERT noi dovremo usare solo i metodi forniti dalla classe.\n",
    "In pratica, partendo dai dati grezzi, dobbiamo solo darli in pasto ai metodi forniti da BERT e magari lavorare un po' per migliorare i risultati, senza che sia necessario scendere fino al livello dei transformers\n",
    "\n",
    "\n",
    "**DA TENERE**\n",
    "* Output dell'extract actions\n",
    "*  `fashion_train_dials.json`:  per il training\n",
    "*  `fashion_dev_dials.json` : per la validation\n",
    "*  `fashion_teststd_dials_public.json` :per il \"report dei risultati finali\" (forse per darlo in pasto allo script di evaluation?) \n",
    "*   `fashion_metadata.json`, `fashion_devtest_dials.json` : necessari per il funzionamento dello script `extract_actions_fashion.py `\n",
    "\n",
    "**DA VERIFICARE**:\n",
    "\n",
    " forse potrebbe convenire anche usare il vocabolario che loro si costruiscono (step 2 del preprocessing) per inizializzare il Tokenizer di Bert, come fanno loro nel data loader (in `loaders/loader_simmc.py`)\n",
    " ![linea codice loader.jpg](data:image/jpeg;base64,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)\n",
    "\n",
    " Questo comando istanzia il tokenizer con una versione default o definita dall'utente (devo capire bene cosa significa, l'ho letto su https://huggingface.co/transformers/quickstart.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cd41deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gian/content/ActionPrediction4CA/tools\n",
      "/home/gian/content/ActionPrediction4CA/data/simmc_fashion\n",
      "/home/gian/content\n"
     ]
    }
   ],
   "source": [
    "%mkdir ~/content/ActionPredictionBERT ActionPredictionBERT/input_data ActionPredictionBERT/extr_output\n",
    "%cd ~/content/ActionPrediction4CA/tools\n",
    "%mv extract_actions_fashion.py ~/content/ActionPredictionBERT\n",
    "%mv action_evaluation.py ~/content/ActionPredictionBERT\n",
    "\n",
    "%cd ~/content/ActionPrediction4CA/data/simmc_fashion/\n",
    "%mv fashion_train_dials.json fashion_dev_dials.json fashion_teststd_dials_public.json fashion_metadata.json fashion_devtest_dials.json ~/content/ActionPredictionBERT/input_data\n",
    "%cd ~/content/\n",
    "%rm -rf ./ActionPrediction4CA/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c76fc6c",
   "metadata": {},
   "source": [
    "# Extract_actions_fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86671584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gian/content/ActionPredictionBERT\n",
      "Reading: ./input_data/fashion_train_dials.json\n",
      "Dialogue task Id missing: 3406\n",
      "Dialogue task Id missing: 3969\n",
      "Dialogue task Id missing: 4847\n",
      "Dialogue task Id missing: 321\n",
      "Dialogue task Id missing: 3455\n",
      "Dialogue task Id missing: 3414\n",
      "Saving: ./extr_output/fashion_train_dials_api_calls.json\n",
      "Reading: ./input_data/fashion_dev_dials.json\n",
      "Dialogue task Id missing: 2117\n",
      "Saving: ./extr_output/fashion_dev_dials_api_calls.json\n",
      "Reading: ./input_data/fashion_devtest_dials.json\n",
      "Dialogue task Id missing: 9308\n",
      "Saving: ./extr_output/fashion_devtest_dials_api_calls.json\n"
     ]
    }
   ],
   "source": [
    "%cd ~/content/ActionPredictionBERT/\n",
    "!python extract_actions_fashion.py --json_path=\"./input_data/fashion_train_dials.json ./input_data/fashion_dev_dials.json ./input_data/fashion_devtest_dials.json\" --save_root=\"./extr_output\"  --metadata_path=\"./fashion_metadata.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98da7846",
   "metadata": {},
   "source": [
    "# Notebook originale\n",
    "Script copiato dal colab di Chris McCormick e Nick Ryan\n",
    "https://colab.research.google.com/drive/1pTuQhug6Dhl9XalKB0zUGf4FIdYFlpcX#scrollTo=nSU7yERLP_66"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34794cb2",
   "metadata": {},
   "source": [
    "## 1.2. Installing the Hugging Face Library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1b3c76",
   "metadata": {},
   "source": [
    "\n",
    "Next, let's install the [transformers](https://github.com/huggingface/transformers) package from Hugging Face which will give us a pytorch interface for working with BERT. (This library contains interfaces for other pretrained language models like OpenAI's GPT and GPT-2.) We've selected the pytorch interface because it strikes a nice balance between the high-level APIs (which are easy to use but don't provide insight into how things work) and tensorflow code (which contains lots of details but often sidetracks us into lessons about tensorflow, when the purpose here is BERT!).\n",
    "\n",
    "At the moment, the Hugging Face library seems to be the most widely accepted and powerful pytorch interface for working with BERT. In addition to supporting a variety of different pre-trained transformer models, the library also includes pre-built modifications of these models suited to your specific task. For example, in this tutorial we will use `BertForSequenceClassification`.\n",
    "\n",
    "The library also includes task-specific classes for token classification, question answering, next sentence prediciton, etc. Using these pre-built classes simplifies the process of modifying BERT for your purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18cbfc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install markdown\n",
    "#!pip install transformers\n",
    "#!pip install pandas\n",
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e99038",
   "metadata": {},
   "source": [
    "# Impostazione parametri esecuzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40d46229",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_params = {\n",
    "    'batch': 12,\n",
    "    'epochs': 10,\n",
    "    'hidden_output_dim': 256\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d9eda3",
   "metadata": {},
   "source": [
    "# Analisi Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4f4432",
   "metadata": {},
   "source": [
    "## train_dials\n",
    "\n",
    "Dati grezzi da preprocessare con lo script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7f4abad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "      <th>dialogue_idx</th>\n",
       "      <th>domains</th>\n",
       "      <th>dialogue_task_id</th>\n",
       "      <th>dialogue_coref_map.1426</th>\n",
       "      <th>dialogue_coref_map.1429</th>\n",
       "      <th>dialogue_coref_map.708</th>\n",
       "      <th>dialogue_coref_map.712</th>\n",
       "      <th>dialogue_coref_map.2401</th>\n",
       "      <th>dialogue_coref_map.2402</th>\n",
       "      <th>...</th>\n",
       "      <th>dialogue_coref_map.2335</th>\n",
       "      <th>dialogue_coref_map.713</th>\n",
       "      <th>dialogue_coref_map.1507</th>\n",
       "      <th>dialogue_coref_map.1509</th>\n",
       "      <th>dialogue_coref_map.949</th>\n",
       "      <th>dialogue_coref_map.1137</th>\n",
       "      <th>dialogue_coref_map.1872</th>\n",
       "      <th>dialogue_coref_map.1873</th>\n",
       "      <th>dialogue_coref_map.1753</th>\n",
       "      <th>dialogue_coref_map.834</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'belief_state': [{'act': 'DA:ASK:CHECK:CLOTH...</td>\n",
       "      <td>3094</td>\n",
       "      <td>[fashion]</td>\n",
       "      <td>1785.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'belief_state': [{'act': 'DA:INFORM:PREFER:C...</td>\n",
       "      <td>822</td>\n",
       "      <td>[fashion]</td>\n",
       "      <td>1720.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'belief_state': [{'act': 'DA:REQUEST:GET:CLO...</td>\n",
       "      <td>7411</td>\n",
       "      <td>[fashion]</td>\n",
       "      <td>2038.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'belief_state': [{'act': 'DA:INFORM:DISPREFE...</td>\n",
       "      <td>7029</td>\n",
       "      <td>[fashion]</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'belief_state': [{'act': 'DA:INFORM:DISPREFE...</td>\n",
       "      <td>1506</td>\n",
       "      <td>[fashion]</td>\n",
       "      <td>1686.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1648 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            dialogue  dialogue_idx    domains  \\\n",
       "0  [{'belief_state': [{'act': 'DA:ASK:CHECK:CLOTH...          3094  [fashion]   \n",
       "1  [{'belief_state': [{'act': 'DA:INFORM:PREFER:C...           822  [fashion]   \n",
       "2  [{'belief_state': [{'act': 'DA:REQUEST:GET:CLO...          7411  [fashion]   \n",
       "3  [{'belief_state': [{'act': 'DA:INFORM:DISPREFE...          7029  [fashion]   \n",
       "4  [{'belief_state': [{'act': 'DA:INFORM:DISPREFE...          1506  [fashion]   \n",
       "\n",
       "   dialogue_task_id  dialogue_coref_map.1426  dialogue_coref_map.1429  \\\n",
       "0            1785.0                      0.0                      1.0   \n",
       "1            1720.0                      NaN                      NaN   \n",
       "2            2038.0                      NaN                      NaN   \n",
       "3            2011.0                      NaN                      NaN   \n",
       "4            1686.0                      NaN                      NaN   \n",
       "\n",
       "   dialogue_coref_map.708  dialogue_coref_map.712  dialogue_coref_map.2401  \\\n",
       "0                     NaN                     NaN                      NaN   \n",
       "1                     0.0                     1.0                      NaN   \n",
       "2                     NaN                     NaN                      4.0   \n",
       "3                     NaN                     NaN                      NaN   \n",
       "4                     NaN                     NaN                      NaN   \n",
       "\n",
       "   dialogue_coref_map.2402  ...  dialogue_coref_map.2335  \\\n",
       "0                      NaN  ...                      NaN   \n",
       "1                      NaN  ...                      NaN   \n",
       "2                      0.0  ...                      NaN   \n",
       "3                      NaN  ...                      NaN   \n",
       "4                      NaN  ...                      NaN   \n",
       "\n",
       "   dialogue_coref_map.713  dialogue_coref_map.1507  dialogue_coref_map.1509  \\\n",
       "0                     NaN                      NaN                      NaN   \n",
       "1                     NaN                      NaN                      NaN   \n",
       "2                     NaN                      NaN                      NaN   \n",
       "3                     NaN                      NaN                      NaN   \n",
       "4                     NaN                      NaN                      NaN   \n",
       "\n",
       "   dialogue_coref_map.949  dialogue_coref_map.1137  dialogue_coref_map.1872  \\\n",
       "0                     NaN                      NaN                      NaN   \n",
       "1                     NaN                      NaN                      NaN   \n",
       "2                     NaN                      NaN                      NaN   \n",
       "3                     NaN                      NaN                      NaN   \n",
       "4                     NaN                      NaN                      NaN   \n",
       "\n",
       "   dialogue_coref_map.1873  dialogue_coref_map.1753  dialogue_coref_map.834  \n",
       "0                      NaN                      NaN                     NaN  \n",
       "1                      NaN                      NaN                     NaN  \n",
       "2                      NaN                      NaN                     NaN  \n",
       "3                      NaN                      NaN                     NaN  \n",
       "4                      NaN                      NaN                     NaN  \n",
       "\n",
       "[5 rows x 1648 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prima parte del fashion_train_dials\n",
    "import json \n",
    "import pandas as pd\n",
    "with open ('./input_data/fashion_train_dials.json',\"r\") as f:\n",
    "   data= json.load(f)\n",
    "\n",
    "result=[]\n",
    "row ={}\n",
    "for k in data:\n",
    "  row[k] = data[k]\n",
    "# []\n",
    "#prima parte del fashion_train_dials\n",
    "import json \n",
    "import pandas as pd\n",
    "with open ('./input_data/fashion_train_dials.json',\"r\") as f:\n",
    "   data= json.load(f)\n",
    "\n",
    "result=[]\n",
    "row ={}\n",
    "for k in data:\n",
    "  row[k] = data[k]\n",
    "# []\n",
    "\n",
    "dialogue_data = pd.json_normalize(row['dialogue_data'])\n",
    "type(dialogue_data)\n",
    "# dialogue = dialogue_data[\"dialogue\"]\n",
    "# for x in dialogue.head(1):\n",
    "#   display(x)\n",
    "# #dialogue.head(1)\n",
    "dialogue_data.head()\n",
    "\n",
    "\n",
    "\n",
    "dialogue_data = pd.json_normalize(row['dialogue_data'])\n",
    "type(dialogue_data)\n",
    "# dialogue = dialogue_data[\"dialogue\"]\n",
    "# for x in dialogue.head(1):\n",
    "#   display(x)\n",
    "# #dialogue.head(1)\n",
    "dialogue_data.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "625e5f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>image_ids</th>\n",
       "      <th>focus_image</th>\n",
       "      <th>memory_images</th>\n",
       "      <th>database_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2042</td>\n",
       "      <td>[2441, 2442, 2443, 2444, 2445, 2446, 2447, 244...</td>\n",
       "      <td>2441</td>\n",
       "      <td>[2442, 2443, 2444]</td>\n",
       "      <td>[2445, 2446, 2447, 2448, 2449, 2450]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2041</td>\n",
       "      <td>[2431, 2432, 2433, 2434, 2435, 2436, 2437, 243...</td>\n",
       "      <td>2431</td>\n",
       "      <td>[2432, 2433, 2434]</td>\n",
       "      <td>[2435, 2436, 2437, 2438, 2439, 2440]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2040</td>\n",
       "      <td>[2421, 2422, 2423, 2424, 2425, 2426, 2427, 242...</td>\n",
       "      <td>2421</td>\n",
       "      <td>[2422, 2423, 2424]</td>\n",
       "      <td>[2425, 2426, 2427, 2428, 2429, 2430]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2039</td>\n",
       "      <td>[2411, 2412, 2413, 2414, 2415, 2416, 2417, 241...</td>\n",
       "      <td>2411</td>\n",
       "      <td>[2412, 2413, 2414]</td>\n",
       "      <td>[2415, 2416, 2417, 2418, 2419, 2420]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2038</td>\n",
       "      <td>[2401, 2402, 2403, 2404, 2405, 2406, 2407, 240...</td>\n",
       "      <td>2401</td>\n",
       "      <td>[2402, 2403, 2404]</td>\n",
       "      <td>[2405, 2406, 2407, 2408, 2409, 2410]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   task_id                                          image_ids  focus_image  \\\n",
       "0     2042  [2441, 2442, 2443, 2444, 2445, 2446, 2447, 244...         2441   \n",
       "1     2041  [2431, 2432, 2433, 2434, 2435, 2436, 2437, 243...         2431   \n",
       "2     2040  [2421, 2422, 2423, 2424, 2425, 2426, 2427, 242...         2421   \n",
       "3     2039  [2411, 2412, 2413, 2414, 2415, 2416, 2417, 241...         2411   \n",
       "4     2038  [2401, 2402, 2403, 2404, 2405, 2406, 2407, 240...         2401   \n",
       "\n",
       "        memory_images                       database_images  \n",
       "0  [2442, 2443, 2444]  [2445, 2446, 2447, 2448, 2449, 2450]  \n",
       "1  [2432, 2433, 2434]  [2435, 2436, 2437, 2438, 2439, 2440]  \n",
       "2  [2422, 2423, 2424]  [2425, 2426, 2427, 2428, 2429, 2430]  \n",
       "3  [2412, 2413, 2414]  [2415, 2416, 2417, 2418, 2419, 2420]  \n",
       "4  [2402, 2403, 2404]  [2405, 2406, 2407, 2408, 2409, 2410]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#seconda parte del fashion_train_dials\n",
    "task_mapping = pd.json_normalize(row['task_mapping'])\n",
    "task_mapping.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9867cff",
   "metadata": {},
   "source": [
    "## dev_dials_api_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d5d29b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialog_id</th>\n",
       "      <th>actions</th>\n",
       "      <th>focus_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4146</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'None', 'action_sup...</td>\n",
       "      <td>[1646, 1646, 1646, 1649, 1649, 1649, 1649]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4260</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...</td>\n",
       "      <td>[2161, 2161, 2161, 2161]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8022</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SearchDatabase', '...</td>\n",
       "      <td>[1971, 1972, 1972, 1972, 1977, 1978]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4992</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'None', 'action_sup...</td>\n",
       "      <td>[1931, 1931, 1936, 1936, 1936]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5606</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'None', 'action_sup...</td>\n",
       "      <td>[1931, 1931, 1931, 1931, 1931]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dialog_id                                            actions  \\\n",
       "0       4146  [{'turn_idx': 0, 'action': 'None', 'action_sup...   \n",
       "1       4260  [{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...   \n",
       "2       8022  [{'turn_idx': 0, 'action': 'SearchDatabase', '...   \n",
       "3       4992  [{'turn_idx': 0, 'action': 'None', 'action_sup...   \n",
       "4       5606  [{'turn_idx': 0, 'action': 'None', 'action_sup...   \n",
       "\n",
       "                                 focus_images  \n",
       "0  [1646, 1646, 1646, 1649, 1649, 1649, 1649]  \n",
       "1                    [2161, 2161, 2161, 2161]  \n",
       "2        [1971, 1972, 1972, 1972, 1977, 1978]  \n",
       "3              [1931, 1931, 1936, 1936, 1936]  \n",
       "4              [1931, 1931, 1931, 1931, 1931]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dev_dials_api = pd.read_json('./extr_output/fashion_dev_dials_api_calls.json')\n",
    "dev_dials_api.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b899ff34",
   "metadata": {},
   "source": [
    "## devtest_dials_api_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f9c6435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialog_id</th>\n",
       "      <th>actions</th>\n",
       "      <th>focus_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2494</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SearchDatabase', '...</td>\n",
       "      <td>[1836, 1841, 1841, 1841, 1841]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3731</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SearchDatabase', '...</td>\n",
       "      <td>[1676, 1681, 1681, 1683, 1683]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8546</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...</td>\n",
       "      <td>[840, 840, 840, 849, 849, 843]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5590</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SearchDatabase', '...</td>\n",
       "      <td>[1616, 1618, 1618, 1618, 1618]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5452</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...</td>\n",
       "      <td>[2231, 2231, 2231, 2236, 2236]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dialog_id                                            actions  \\\n",
       "0       2494  [{'turn_idx': 0, 'action': 'SearchDatabase', '...   \n",
       "1       3731  [{'turn_idx': 0, 'action': 'SearchDatabase', '...   \n",
       "2       8546  [{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...   \n",
       "3       5590  [{'turn_idx': 0, 'action': 'SearchDatabase', '...   \n",
       "4       5452  [{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...   \n",
       "\n",
       "                     focus_images  \n",
       "0  [1836, 1841, 1841, 1841, 1841]  \n",
       "1  [1676, 1681, 1681, 1683, 1683]  \n",
       "2  [840, 840, 840, 849, 849, 843]  \n",
       "3  [1616, 1618, 1618, 1618, 1618]  \n",
       "4  [2231, 2231, 2231, 2236, 2236]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "devtest_dials_api = pd.read_json('./extr_output/fashion_devtest_dials_api_calls.json')\n",
    "devtest_dials_api.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3ba47e",
   "metadata": {},
   "source": [
    "## Funzione generazione dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe1973e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def createDataframe(json_file):\n",
    "  with open(json_file) as f:\n",
    "    dictftdac = json.load(f)\n",
    "\n",
    "  data = []\n",
    "\n",
    "  for e in dictftdac:\n",
    "    dialog_id = e['dialog_id']\n",
    "    actions = e['actions']\n",
    "    focus_images = e['focus_images']\n",
    "\n",
    "    for a in actions:\n",
    "      \n",
    "      turn_idx = a['turn_idx']\n",
    "      action = a['action']\n",
    "      action_supervision = a['action_supervision']\n",
    "      transcript = a['transcript']\n",
    "      transcript_annotated = a['transcript_annotated']\n",
    "      system_transcript = a['system_transcript']\n",
    "      system_transcript_annotated = a['system_transcript_annotated']\n",
    "\n",
    "      row = {\n",
    "          \"dialog_id\" : dialog_id,\n",
    "          'turn_idx' : turn_idx,\n",
    "          'action' : action,\n",
    "          'action_supervision' : action_supervision,\n",
    "          'focus_images' : focus_images,\n",
    "          'transcript': transcript,\n",
    "          'transcript_annotated': transcript_annotated,\n",
    "          'system_transcript': system_transcript,\n",
    "          'system_transcript_annotated':system_transcript_annotated,\n",
    "          'previous_transcript': \"\",\n",
    "          'previous_system_transcript': \"\"\n",
    "      }\n",
    "      if (action_supervision != None):\n",
    "        if 'focus' in action_supervision:\n",
    "          acsf = {'focus':action_supervision['focus']}\n",
    "        else:\n",
    "          acsf = {'focus':None}\n",
    "        \n",
    "        if 'attributes' in action_supervision:\n",
    "          acsa = {'attributes':action_supervision['attributes']}\n",
    "        else:\n",
    "          acsa = {'attributes':[]}\n",
    "      else:\n",
    "          acsf = {'focus':None}\n",
    "          acsa = {'attributes':[]}\n",
    "      \n",
    "        \n",
    "      row.update(acsf)\n",
    "      row.update(acsa)\n",
    "    \n",
    "      data.append(row)\n",
    "\n",
    "  # Conservo id turno e risposta sistema per provare a implementare una soluzione articolata\n",
    "  df = pd.DataFrame(data,columns=['dialog_id','turn_idx','transcript','action','attributes', 'system_transcript','transcript_annotated','system_transcript_annotated','previous_transcript','previous_system_transcript'])\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a30c6d",
   "metadata": {},
   "source": [
    "## train_dials_api_calls with transcript\n",
    "Dati per il training che usiamo ( per ora semplificati)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9d78e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  21196  elementi\n"
     ]
    }
   ],
   "source": [
    "df_training = createDataframe('./extr_output/fashion_train_dials_api_calls.json')\n",
    "print(\"Training: \",len(df_training),\" elementi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e542c9",
   "metadata": {},
   "source": [
    "## fashion_dev_dials_api_calls\n",
    "Dati per la validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d7d98f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:  3513  elementi\n"
     ]
    }
   ],
   "source": [
    "df_validation = createDataframe('./extr_output/fashion_dev_dials_api_calls.json')\n",
    "print(\"Validation: \",len(df_validation),\" elementi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f272d647",
   "metadata": {},
   "source": [
    "## fashion_devtest_dials_api_calls\n",
    "Dati per la valutazione delle performance del modello (test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8e22d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  5397  elementi\n"
     ]
    }
   ],
   "source": [
    "df_test = createDataframe('./extr_output/fashion_devtest_dials_api_calls.json')\n",
    "print(\"Test: \",len(df_test),\" elementi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc25d11d",
   "metadata": {},
   "source": [
    "# BERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4c901c",
   "metadata": {},
   "source": [
    "## Scelta tipo input\n",
    "\n",
    "Il valore di questa variabile determinerà se utilizzare i singoli transcript, o se concatenare ogni transcript a quello successivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef5cc083",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_next = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d30106",
   "metadata": {},
   "source": [
    "## Preparazione input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e090913a",
   "metadata": {},
   "source": [
    "### Generazione colonna previous_transcript\n",
    "\n",
    "Generazione della colonna contenente la frase del turno successivo del dialogo (se presente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fb54823",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "df_training.sort_values(by=['dialog_id', 'turn_idx'])\n",
    "for i in range(1,(len(df_training))):\n",
    "  if(i<(len(df_training)) and  df_training['dialog_id'][i] == df_training['dialog_id'][i-1]):\n",
    "    df_training.loc[i,'previous_transcript'] = df_training['transcript'][i-1]\n",
    "    df_training.loc[i,'previous_system_transcript'] = df_training['system_transcript'][i-1]\n",
    "\n",
    "#Validation\n",
    "df_validation.sort_values(by=['dialog_id', 'turn_idx'])\n",
    "for i in range(1,(len(df_validation))):\n",
    "  if(i<(len(df_validation)) and  df_validation['dialog_id'][i] == df_validation['dialog_id'][i-1]):\n",
    "    df_validation.loc[i,'previous_transcript'] = df_validation['transcript'][i-1]\n",
    "    df_validation.loc[i,'previous_system_transcript'] = df_validation['system_transcript'][i-1]\n",
    "\n",
    "#Evaluation\n",
    "df_test.sort_values(by=['dialog_id', 'turn_idx'])\n",
    "for i in range(1,(len(df_test))):\n",
    "  if(i<(len(df_test)) and  df_test['dialog_id'][i] == df_test['dialog_id'][i-1]):\n",
    "    df_test.loc[i,'previous_transcript'] = df_test['transcript'][i-1]\n",
    "    df_test.loc[i,'previous_system_transcript'] = df_test['system_transcript'][i-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb106a56",
   "metadata": {},
   "source": [
    "### Estrazione vettori colonna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78177045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de95a8f0",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f65ef34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA:\n",
      " Original:  Is there a pattern on this one? It's hard to see in the image.\n",
      "Tokenized:  ['is', 'there', 'a', 'pattern', 'on', 'this', 'one', '?', 'it', \"'\", 's', 'hard', 'to', 'see', 'in', 'the', 'image', '.']\n",
      "Token IDs:  [2003, 2045, 1037, 5418, 2006, 2023, 2028, 1029, 2009, 1005, 1055, 2524, 2000, 2156, 1999, 1996, 3746, 1012]\n"
     ]
    }
   ],
   "source": [
    "transcripts_tr = df_training.transcript.values\n",
    "previous_transcript_tr = df_training.previous_transcript.values\n",
    "previous_system_transcript_tr = df_training.previous_system_transcript.values\n",
    "action_labels_tr = df_training.action.values\n",
    "attributes_labels_tr=df_training.attributes.values\n",
    "\n",
    "print (\"TRAINING DATA:\")\n",
    "# Print the original sentence.\n",
    "print(' Original: ', transcripts_tr[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(transcripts_tr[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(transcripts_tr[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b5da556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T: Is there a pattern on this one? It's hard to see in the image. | PT:  | PST: \n",
      "T: That's fancy. Do you have anything in warmer colors like yellow or red? | PT: Is there a pattern on this one? It's hard to see in the image. | PST: I don't have any information on the pattern, but it has pointelle embellishments.\n",
      "T: Yeah, that sounds good. | PT: That's fancy. Do you have anything in warmer colors like yellow or red? | PST: I have a crew neck sweater in red, would you like to see it?\n",
      "T: Oh, I love that. Please tell me you have a small. | PT: Yeah, that sounds good. | PST: This is $187 from Downtown Stylists with a 3.62 rating.\n",
      "T: Yes, please! Thank you for your help with this | PT: Oh, I love that. Please tell me you have a small. | PST: It does come in small, shall I put one in your cart?\n",
      "T: How nice! Does this come in other colors? | PT:  | PST: \n",
      "T: Oh well.  Can you show me a dress that comes in red? | PT: How nice! Does this come in other colors? | PST: No, I'm sorry, It comes only in blue.\n",
      "T: Cute! Do these come in Small? | PT: Oh well.  Can you show me a dress that comes in red? | PST: This dress comes in many colors, including a bright red and a pinkish-red. What do you think?\n",
      "T: Awesome. Would you add a red one in S to my cart please? | PT: Cute! Do these come in Small? | PST: Yes, they do!\n",
      "T: That's all. Thanks! | PT: Awesome. Would you add a red one in S to my cart please? | PST: The red one is in your cart. Is there anything else I can find for you?\n"
     ]
    }
   ],
   "source": [
    "for k in range(0,10):\n",
    "  print(f\"T: {transcripts_tr[k]} | PT: {previous_transcript_tr[k]} | PST: {previous_system_transcript_tr[k]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef35705",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcd4e529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION DATA:\n",
      " Original:  What's the price of this sweater compared to the other blue and gray one I looked at?\n",
      "Tokenized:  ['what', \"'\", 's', 'the', 'price', 'of', 'this', 'sweater', 'compared', 'to', 'the', 'other', 'blue', 'and', 'gray', 'one', 'i', 'looked', 'at', '?']\n",
      "Token IDs:  [2054, 1005, 1055, 1996, 3976, 1997, 2023, 14329, 4102, 2000, 1996, 2060, 2630, 1998, 3897, 2028, 1045, 2246, 2012, 1029]\n",
      "Dialog IDs: [4146 4146 4146 4146 4146 4146 4146 4260 4260 4260 4260 8022 8022 8022\n",
      " 8022 8022 8022 4992 4992 4992]\n",
      "Turn IDs: [0 1 2 3 4 5 6 0 1 2 3 0 1 2 3 4 5 0 1 2]\n"
     ]
    }
   ],
   "source": [
    "transcripts_vd = df_validation.transcript.values\n",
    "previous_transcript_vd = df_validation.previous_transcript.values\n",
    "previous_system_transcript_vd = df_validation.previous_system_transcript.values\n",
    "action_labels_vd = df_validation.action.values\n",
    "attributes_labels_vd=df_validation.attributes.values\n",
    "dialog_ids_vd = df_validation.dialog_id.values\n",
    "turn_idxs_vd = df_validation.turn_idx.values\n",
    "\n",
    "print (\"VALIDATION DATA:\")\n",
    "\n",
    "# Print the original sentence.\n",
    "print(' Original: ', transcripts_vd[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(transcripts_vd[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(transcripts_vd[0])))\n",
    "\n",
    "# Print the dialog ids.\n",
    "print(f\"Dialog IDs: {dialog_ids_vd[0:20]}\")\n",
    "\n",
    "# Print the turn idxs.\n",
    "print(f\"Turn IDs: {turn_idxs_vd[0:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba6e6ef",
   "metadata": {},
   "source": [
    "#### Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "886bcaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATION DATA:\n",
      " Original:  That looks a little too light for what I need, do you have something else with a high customer rating?\n",
      "Tokenized:  ['that', 'looks', 'a', 'little', 'too', 'light', 'for', 'what', 'i', 'need', ',', 'do', 'you', 'have', 'something', 'else', 'with', 'a', 'high', 'customer', 'rating', '?']\n",
      "Token IDs:  [2008, 3504, 1037, 2210, 2205, 2422, 2005, 2054, 1045, 2342, 1010, 2079, 2017, 2031, 2242, 2842, 2007, 1037, 2152, 8013, 5790, 1029]\n",
      "Dialog IDs: [2494 2494 2494 2494 2494 3731 3731 3731 3731 3731 8546 8546 8546 8546\n",
      " 8546 8546 5590 5590 5590 5590]\n",
      "Turn IDs: [0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 5 0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "transcripts_tst = df_test.transcript.values\n",
    "previous_transcript_tst = df_test.previous_transcript.values\n",
    "previous_system_transcript_tst = df_test.previous_system_transcript.values\n",
    "action_labels_tst = df_test.action.values\n",
    "attributes_labels_tst=df_test.attributes.values\n",
    "dialog_ids_tst = df_test.dialog_id.values\n",
    "turn_idxs_tst = df_test.turn_idx.values\n",
    "\n",
    "print (\"EVALUATION DATA:\")\n",
    "\n",
    "# Print the original sentence.\n",
    "print(' Original: ', transcripts_tst[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(transcripts_tst[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(transcripts_tst[0])))\n",
    "\n",
    "# Print the dialog ids.\n",
    "print(f\"Dialog IDs: {dialog_ids_tst[0:20]}\")\n",
    "\n",
    "# Print the turn idxs.\n",
    "print(f\"Turn IDs: {turn_idxs_tst[0:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c049bbf",
   "metadata": {},
   "source": [
    "## Calcolo dimensione massima\n",
    "\n",
    "The above code left out a few required formatting steps that we'll look at here.\n",
    "\n",
    "We are required to:\n",
    "1. Add special tokens to the start and end of each sentence.\n",
    "2. Pad & truncate all sentences to a single constant length.\n",
    "3. Explicitly differentiate real tokens from padding tokens with the \"attention mask\".\n",
    "\n",
    "\n",
    "The sentences in our dataset obviously have varying lengths, so how does BERT handle this?\n",
    "\n",
    "BERT has two constraints:\n",
    "\n",
    "\n",
    "1.   All sentences must be padded or truncated to a single, fixed length.\n",
    "2.   The maximum sentence length is 512 tokens.\n",
    "\n",
    "\n",
    "Padding is done with a special [PAD] token, which is at index 0 in the BERT vocabulary. The below illustration demonstrates padding out to a \"MAX_LEN\" of 8 tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c16396",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8e5132e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max transcript length for training:  177\n"
     ]
    }
   ],
   "source": [
    "max_len_tr = 0\n",
    "\n",
    "# For every sentence...\n",
    "for i in range(0,len(transcripts_tr)):\n",
    "    \n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "\n",
    "    if (previous_transcript_tr[i] != \"\" and use_next):\n",
    "      input_ids = tokenizer.encode(previous_transcript_tr[i]+ \" \" + previous_system_transcript_tr[i],transcripts_tr[i], add_special_tokens=True)\n",
    "    else:\n",
    "      input_ids = tokenizer.encode(transcripts_tr[i], add_special_tokens=True)\n",
    "        \n",
    "    # Update the maximum sentence length.\n",
    "    max_len_tr = max(max_len_tr, len(input_ids))\n",
    "\n",
    "print('Max transcript length for training: ', max_len_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17363e3c",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92914388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max transcript length for validation:  133\n"
     ]
    }
   ],
   "source": [
    "max_len_vd = 0\n",
    "\n",
    "# For every sentence...\n",
    "for i in range(0,len(transcripts_vd)):\n",
    "\n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    if (previous_transcript_vd[i] != \"\" and use_next):\n",
    "      input_ids = tokenizer.encode(previous_transcript_vd[i]+ \" \" + previous_system_transcript_vd[i],transcripts_vd[i], add_special_tokens=True)\n",
    "    else:\n",
    "      input_ids = tokenizer.encode(transcripts_vd[i], add_special_tokens=True)\n",
    "    \n",
    "    # Update the maximum sentence length.\n",
    "    max_len_vd = max(max_len_vd, len(input_ids))\n",
    "\n",
    "print('Max transcript length for validation: ', max_len_vd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3412aa8",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aab75df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max transcript length for evaluation:  150\n"
     ]
    }
   ],
   "source": [
    "max_len_tst = 0\n",
    "\n",
    "#non sono sicuro che il controllo della lunghezza vada fatto anche sul test set, dopo la performance non è determinata\n",
    "#dalla conoscenza del test set?\n",
    "#è anche vero che in teoria per far funzionare BERT bisogna dargli in pasto dei dati tokenizzati, quindi in un caso reale il nostro\n",
    "#model non potrebbe prendere in ingresso del testo non trattato. Nel dubbio ho controllato le dimensioni\n",
    "\n",
    "for i in range(0,len(transcripts_tst)):\n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    if (previous_transcript_tst[i] != \"\" and use_next):\n",
    "      input_ids = tokenizer.encode(previous_transcript_tst[i]+ \" \" + previous_system_transcript_tst[i],transcripts_tst[i], add_special_tokens=True)\n",
    "    else:\n",
    "      input_ids = tokenizer.encode(transcripts_tst[i], add_special_tokens=True)\n",
    "\n",
    "    # Update the maximum sentence length.\n",
    "    max_len_tst = max(max_len_tst, len(input_ids))\n",
    "\n",
    "print(\"Max transcript length for evaluation: \",max_len_tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c277f0",
   "metadata": {},
   "source": [
    "### Risultato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26bd8ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La massima lunghezza dei token da gestire è quindi  177\n"
     ]
    }
   ],
   "source": [
    "max_len = max(max_len_tr, max_len_vd, max_len_tst)\n",
    "\n",
    "# if (max_len_tr >= max_len_vd):\n",
    "#   max_len = max_len_tr\n",
    "# else:\n",
    "#   max_len = max_len_vd\n",
    "# if (max_len_tst >= max_len):\n",
    "#   max_len = max_len_tst\n",
    "\n",
    "print(\"La massima lunghezza dei token da gestire è quindi \",max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcefd1f1",
   "metadata": {},
   "source": [
    "## Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54bc7c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "[('availableSizes',)]\n",
      "['ageRange' 'amountInStock' 'availableSizes' 'brand' 'clothingCategory'\n",
      " 'clothingStyle' 'color' 'customerRating' 'dressStyle' 'embellishment'\n",
      " 'forGender' 'forOccasion' 'hasPart' 'hemLength' 'hemStyle' 'info'\n",
      " 'jacketStyle' 'madeIn' 'material' 'necklineStyle' 'pattern' 'price'\n",
      " 'sequential' 'size' 'skirtLength' 'skirtStyle' 'sleeveLength'\n",
      " 'sleeveStyle' 'soldBy' 'sweaterStyle' 'waistStyle' 'warmthRating'\n",
      " 'waterResistance']\n",
      "Totale: 30106, Training: 21196, Validation: 3513, Evaluation: 5397\n",
      "Training: 21196, Validation: 3513, Evaluation: 5397\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "attributes_labels_all = np.concatenate((attributes_labels_tr, attributes_labels_vd,attributes_labels_tst), axis=None)\n",
    "attr_yt = mlb.fit_transform(attributes_labels_all)\n",
    "print(attr_yt[0:15])\n",
    "print(mlb.inverse_transform(attr_yt[3].reshape(1, -1)))\n",
    "print(mlb.classes_)\n",
    "print(f\"Totale: {len(attr_yt)}, Training: {len(attributes_labels_tr)}, Validation: {len(attributes_labels_vd)}, Evaluation: {len(attributes_labels_tst)}\")\n",
    "attributes_labels_tr_vect = attr_yt[0:len(attributes_labels_tr)]\n",
    "attributes_labels_vd_vect = attr_yt[len(attributes_labels_tr):(len(attributes_labels_tr)+len(attributes_labels_vd))]\n",
    "attributes_labels_tst_vect = attr_yt[(len(attributes_labels_tr)+len(attributes_labels_vd)):]\n",
    "print(f\"Training: {len(attributes_labels_tr_vect)}, Validation: {len(attributes_labels_vd_vect)}, Evaluation: {len(attributes_labels_tst_vect)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63925873",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9505e37",
   "metadata": {},
   "source": [
    "Now we're ready to perform the real tokenization.\n",
    "\n",
    "The tokenizer.encode_plus function combines multiple steps for us:\n",
    "\n",
    "Split the sentence into tokens.\n",
    "Add the special [CLS] and [SEP] tokens.\n",
    "Map the tokens to their IDs.\n",
    "Pad or truncate all sentences to the same length.\n",
    "Create the attention masks which explicitly differentiate real tokens from [PAD] tokens.\n",
    "The first four features are in tokenizer.encode, but I'm using tokenizer.encode_plus to get the fifth item (attention masks). Documentation is here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aff8d187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "# backends cudnn for out memory not necessary (resolved by batch size)\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "# torch.backends.cudnn.enabled = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45855e8f",
   "metadata": {},
   "source": [
    "### Tokenize Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e32c330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21196 records to encode.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gian/anaconda3/envs/testcuda1/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2126: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING : \n",
      "Original:  Is there a pattern on this one? It's hard to see in the image.\n",
      "Token IDs: tensor([ 101, 2003, 2045, 1037, 5418, 2006, 2023, 2028, 1029, 2009, 1005, 1055,\n",
      "        2524, 2000, 2156, 1999, 1996, 3746, 1012,  102,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "\n",
    "#dobbiamo convertire le nostre lables da string a valori numerici, usiamo il metodo fornito da sklearn\n",
    "\n",
    "#TRAINING DATASET\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "action_labels_encoded_tr = le.fit_transform(action_labels_tr)\n",
    "\n",
    "input_ids_tr = []\n",
    "attention_masks_tr = []\n",
    "print(f\"{len(df_training)} records to encode.\")\n",
    "# For every sentence...\n",
    "for i in range(0,len(df_training)):\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "\n",
    "  if (previous_transcript_tr[i] != \"\" and use_next):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        previous_transcript_tr[i]+ \" \" + previous_system_transcript_tr[i],  # Sentence to encode.\n",
    "                        transcripts_tr[i], #next sentece to encode\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        truncation = True,\n",
    "                        max_length = max_len,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                    )\n",
    "  else:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        transcripts_tr[i],  # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        truncation = True,\n",
    "                        max_length = max_len,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                    )\n",
    "    \n",
    "\n",
    "    \n",
    "  # Add the encoded sentence to the list.    \n",
    "  input_ids_tr.append(encoded_dict['input_ids'])\n",
    "\n",
    "  # And its attention mask (simply differentiates padding from non-padding).\n",
    "  attention_masks_tr.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids_tr = torch.cat(input_ids_tr, dim=0)\n",
    "attention_masks_tr = torch.cat(attention_masks_tr, dim=0)\n",
    "labels_actions_tr = torch.tensor(action_labels_encoded_tr)\n",
    "labels_attributes_tr = torch.tensor(attributes_labels_tr_vect) \n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print (\"TRAINING : \")\n",
    "if (use_next):\n",
    "  print('Original: ', transcripts_tr[0])\n",
    "else:\n",
    "  print('Original: ', transcripts_tr[0])\n",
    "print('Token IDs:', input_ids_tr[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cda4541",
   "metadata": {},
   "source": [
    "### Tokenize Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5da13a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3513 records to encode.\n",
      "VALIDATION : \n",
      "Original:  What's the price of this sweater compared to the other blue and gray one I looked at?\n",
      "Token IDs: tensor([  101,  2054,  1005,  1055,  1996,  3976,  1997,  2023, 14329,  4102,\n",
      "         2000,  1996,  2060,  2630,  1998,  3897,  2028,  1045,  2246,  2012,\n",
      "         1029,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0])\n",
      "Dialog IDs: tensor([4146, 4146, 4146, 4146, 4146, 4146, 4146, 4260, 4260, 4260, 4260, 8022,\n",
      "        8022, 8022, 8022, 8022, 8022, 4992, 4992, 4992])\n",
      "Turn IDXs: tensor([0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 0, 1, 2, 3, 4, 5, 0, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "\n",
    "#dobbiamo convertire le nostre lables da string a valori numerici, usiamo il metodo fornito da sklearn\n",
    "\n",
    "#VALIDATION DATASET\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "action_labels_encoded_vd = le.fit_transform(action_labels_vd)\n",
    "\n",
    "input_ids_vd = []\n",
    "attention_masks_vd = []\n",
    "print(f\"{len(df_validation)} records to encode.\")\n",
    "# For every sentence...\n",
    "for i in range(0,len(df_validation)):\n",
    "  # `encode_plus` will:\n",
    "  #   (1) Tokenize the sentence.\n",
    "  #   (2) Prepend the `[CLS]` token to the start.\n",
    "  #   (3) Append the `[SEP]` token to the end.\n",
    "  #   (4) Map tokens to their IDs.\n",
    "  #   (5) Pad or truncate the sentence to `max_length`\n",
    "  #   (6) Create attention masks for [PAD] tokens.\n",
    "\n",
    "  if (previous_transcript_vd[i] != \"\" and use_next):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        previous_transcript_vd[i]+ \" \" + previous_system_transcript_vd[i],  # Sentence to encode.\n",
    "                        transcripts_vd[i], #next sentece to encode\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        truncation = True,\n",
    "                        max_length = max_len,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                    )\n",
    "  else:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        transcripts_vd[i],  # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        truncation = True,\n",
    "                        max_length = max_len,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                    )\n",
    "    \n",
    "  # Add the encoded sentence to the list.    \n",
    "  input_ids_vd.append(encoded_dict['input_ids'])\n",
    "  \n",
    "  # And its attention mask (simply differentiates padding from non-padding).\n",
    "  attention_masks_vd.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids_vd = torch.cat(input_ids_vd, dim=0)\n",
    "attention_masks_vd = torch.cat(attention_masks_vd, dim=0)\n",
    "labels_actions_vd = torch.tensor(action_labels_encoded_vd)\n",
    "labels_attributes_vd = torch.tensor(attributes_labels_vd_vect)\n",
    "# Check warning:\n",
    "# /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
    "dialog_ids_vd = torch.tensor(dialog_ids_vd)\n",
    "turn_idxs_vd = torch.tensor(turn_idxs_vd) \n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print (\"VALIDATION : \")\n",
    "if (use_next):\n",
    "  print('Original: ', transcripts_vd[0])\n",
    "else:\n",
    "  print('Original: ', transcripts_vd[0])\n",
    "print('Token IDs:', input_ids_vd[0])\n",
    "print(f\"Dialog IDs: {dialog_ids_vd[0:20]}\")\n",
    "print(f\"Turn IDXs: {turn_idxs_vd[0:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d364715",
   "metadata": {},
   "source": [
    "### Tokenize Evaluation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23888911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5397 records to encode.\n",
      "Evaluation : \n",
      "Original:  That looks a little too light for what I need, do you have something else with a high customer rating?\n",
      "Token IDs: tensor([ 101, 2008, 3504, 1037, 2210, 2205, 2422, 2005, 2054, 1045, 2342, 1010,\n",
      "        2079, 2017, 2031, 2242, 2842, 2007, 1037, 2152, 8013, 5790, 1029,  102,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0])\n",
      "Dialog IDs: tensor([2494, 2494, 2494, 2494, 2494, 3731, 3731, 3731, 3731, 3731, 8546, 8546,\n",
      "        8546, 8546, 8546, 8546, 5590, 5590, 5590, 5590])\n",
      "Turn IDXs: tensor([0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "\n",
    "#dobbiamo convertire le nostre lables da string a valori numerici, usiamo il metodo fornito da sklearn\n",
    "\n",
    "#EVALUATION DATASET\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "action_labels_encoded_tst = le.fit_transform(action_labels_tst)\n",
    "\n",
    "input_ids_tst = []\n",
    "attention_masks_tst = []\n",
    "print(f\"{len(df_test)} records to encode.\")\n",
    "# For every sentence...\n",
    "for i in range(0,len(df_test)):\n",
    "# for t in transcripts_tst:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "  \n",
    "  #Aggiungere \"and False\" PER UTILIZZARE sempre la tokenizzazione senza concatenazione\n",
    "  if (previous_transcript_tst[i] != \"\" and use_next):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                      previous_transcript_tst[i]+ \" \" + previous_system_transcript_tst[i],  # Sentence to encode.\n",
    "                      transcripts_tst[i], #next sentece to encode\n",
    "                      add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                      truncation = True,\n",
    "                      max_length = max_len,           # Pad & truncate all sentences.\n",
    "                      pad_to_max_length = True,\n",
    "                      return_attention_mask = True,   # Construct attn. masks.\n",
    "                      return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                  )\n",
    "  else:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                      transcripts_tst[i],  # Sentence to encode.\n",
    "                      add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                      truncation = True,\n",
    "                      max_length = max_len,           # Pad & truncate all sentences.\n",
    "                      pad_to_max_length = True,\n",
    "                      return_attention_mask = True,   # Construct attn. masks.\n",
    "                      return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                  )\n",
    "    \n",
    "  # Add the encoded sentence to the list.    \n",
    "  input_ids_tst.append(encoded_dict['input_ids'])\n",
    "  \n",
    "  # And its attention mask (simply differentiates padding from non-padding).\n",
    "  attention_masks_tst.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids_tst = torch.cat(input_ids_tst, dim=0)\n",
    "attention_masks_tst = torch.cat(attention_masks_tst, dim=0)\n",
    "labels_actions_tst = torch.tensor(action_labels_encoded_tst)\n",
    "labels_attributes_tst = torch.tensor(attributes_labels_tst_vect)\n",
    "# Check warning:\n",
    "# /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
    "dialog_ids_tst = torch.tensor(dialog_ids_tst)\n",
    "turn_idxs_tst = torch.tensor(turn_idxs_tst) \n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print (\"Evaluation : \")\n",
    "if (use_next):\n",
    "  print('Original: ', transcripts_tst[0])\n",
    "else:\n",
    "  print('Original: ', transcripts_tst[0])\n",
    "print('Token IDs:', input_ids_tst[0])\n",
    "print(f\"Dialog IDs: {dialog_ids_tst[0:20]}\")\n",
    "print(f\"Turn IDXs: {turn_idxs_tst[0:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af23bb7",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96157e27",
   "metadata": {},
   "source": [
    "# Data Split - AP4CA\n",
    "La nostra versione di split di dati per training e validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "680bdf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21,196 training samples\n",
      "3,513 validation samples\n",
      "5,397 evaluation samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "#labels_tr = {'actions': labels_actions_tr, 'attributes': labels_attributes_tr}\n",
    "#labels_vd = {'actions': labels_actions_vd, 'attributes': labels_attributes_vd}\n",
    "\n",
    "train_dataset = TensorDataset(input_ids_tr, attention_masks_tr, labels_actions_tr, labels_attributes_tr)\n",
    "val_dataset = TensorDataset(input_ids_vd, attention_masks_vd, labels_actions_vd, labels_attributes_vd, dialog_ids_vd, turn_idxs_vd)\n",
    "tst_dataset = TensorDataset(input_ids_tst, attention_masks_tst, labels_actions_tst, labels_attributes_tst, dialog_ids_tst, turn_idxs_tst)\n",
    "\n",
    "print('{:>5,} training samples'.format(len(train_dataset)))\n",
    "print('{:>5,} validation samples'.format(len(val_dataset)))\n",
    "print('{:>5,} evaluation samples'.format(len(tst_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed1196fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 101, 2008, 3504,  ...,    0,    0,    0],\n",
       "         [ 101, 2008, 3504,  ...,    0,    0,    0],\n",
       "         [ 101, 2040, 5617,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [ 101, 2821, 1045,  ...,    0,    0,    0],\n",
       "         [ 101, 4086, 1010,  ...,    0,    0,    0],\n",
       "         [ 101, 1045, 2066,  ...,    0,    0,    0]]),\n",
       " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " tensor([2, 4, 4, 0, 1, 2, 1, 2, 0, 1]),\n",
       " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " tensor([2494, 2494, 2494, 2494, 2494, 3731, 3731, 3731, 3731, 3731]),\n",
       " tensor([0, 1, 2, 3, 4, 0, 1, 2, 3, 4]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check evaluation TensorDataset content\n",
    "tst_dataset[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d01df19",
   "metadata": {},
   "source": [
    "## Check GPU for Training\n",
    "\n",
    "In questa versione la GPU è impostata fissa.\n",
    "Con una GPU in più a disposizione possiamo usare DataParallel e aumentare il batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31bf32c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2060\n"
     ]
    }
   ],
   "source": [
    "# Tell PyTorch to use the GPU.    \n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "print('We will use the GPU:', torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2045d72f",
   "metadata": {},
   "source": [
    "### Creazione Data Loaders per Training, Validation ed Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d9f42ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "# With size 32 GeForce RTX 2060 with 6GB run out of memory\n",
    "batch_size = exec_params['batch']\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )\n",
    "\n",
    "#ho controllato nel colab su cui ci basiamo, anche lui usa un Sequential Sampler per il dataset di evaluation\n",
    "evaluation_dataloader = DataLoader(\n",
    "            tst_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(tst_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040d27c5",
   "metadata": {},
   "source": [
    "## Train BERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc8111f",
   "metadata": {},
   "source": [
    "For this task, we first want to modify the pre-trained BERT model to give outputs for classification, and then we want to continue training the model on our dataset until that the entire model, end-to-end, is well-suited for our task. \n",
    "\n",
    "Thankfully, the huggingface pytorch implementation includes a set of interfaces designed for a variety of NLP tasks. Though these interfaces are all built on top of a trained BERT model, each has different top layers and output types designed to accomodate their specific NLP task.  \n",
    "\n",
    "Here is the current list of classes provided for fine-tuning:\n",
    "* BertModel\n",
    "* BertForPreTraining\n",
    "* BertForMaskedLM\n",
    "* BertForNextSentencePrediction\n",
    "* **BertForSequenceClassification** - The one we'll use.\n",
    "* BertForTokenClassification\n",
    "* BertForQuestionAnswering\n",
    "\n",
    "The documentation for these can be found under [here](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbd23ca",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We'll be using [BertForSequenceClassification](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#bertforsequenceclassification). This is the normal BERT model with an added single linear layer on top for classification that we will use as a sentence classifier. As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task. \n",
    "\n",
    "NB anche nell'articolo che sto leggendo sulla classificazione multi-label si parte da questo modello\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba0360b",
   "metadata": {},
   "source": [
    "OK, let's load BERT! There are a few different pre-trained BERT models available. \"bert-base-uncased\" means the version that has only lowercase letters (\"uncased\") and is the smaller version of the two (\"base\" vs \"large\").\n",
    "\n",
    "The documentation for `from_pretrained` can be found [here](https://huggingface.co/transformers/v2.2.0/main_classes/model.html#transformers.PreTrainedModel.from_pretrained), with the additional parameters defined [here](https://huggingface.co/transformers/v2.2.0/main_classes/configuration.html#transformers.PretrainedConfig)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "242aa137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DA SISTEMARE\n",
    "from transformers import BertModel\n",
    "from  torch import  nn\n",
    "\n",
    "class CustomBERTModel(nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "\n",
    "    super(CustomBERTModel, self).__init__()\n",
    "    self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "    ### New layers:\n",
    "    self.linear_intermedio = nn.Linear(768, exec_params['hidden_output_dim'])\n",
    "    #provare ad aggiungere ulteriori layer intermedi per ridurre le dimensioni fino ad arrivare all'output richiesto\n",
    "    self.linear_actions = nn.Linear(exec_params['hidden_output_dim'], 5) \n",
    "    self.linear_attributes = nn.Linear(exec_params['hidden_output_dim'], len(mlb.classes_)) #num attributi? \n",
    "\n",
    "  def forward(self, ids, mask):\n",
    "    #controllare che l'output non rappresenti solo lo stato interno dovuto al token CLS\n",
    "    output = self.bert(ids,attention_mask=mask)\n",
    "    # print(f\"Type output{type(output)}\")\n",
    "    # for p in output:\n",
    "    #   print(p)\n",
    "    #   print(type(output[p]))\n",
    "    #   print(output[p])\n",
    "\n",
    "    #prendiamo il campo last_hidden_state dall'oggetto output; last hidden state rappresenta il tensore\n",
    "    #in uscita dallo step di forward del BertModel\n",
    "    last_hidden_state_output = output[\"last_hidden_state\"]\n",
    "    # last_hidden_state has the following shape: (batch_size, sequence_length, 768)\n",
    "    #stiamo passando solo il token CLS ai layer successivi\n",
    "    linear_output_intermedio = self.linear_intermedio(last_hidden_state_output[:,0,:].view(-1,768)) \n",
    "    # linear_output_intermedio = self.linear_intermedio(pooled_output) \n",
    "    \n",
    "    linear_output_actions = self.linear_actions(linear_output_intermedio)\n",
    "    # linear_output_actions = self.sftmx(linear_output_actions)\n",
    "    # linear_output_actions = nn.functional.softmax(linear_output_actions)\n",
    "    # Test sigmoid for increasing perplexity performance\n",
    "    linear_output_actions = torch.sigmoid(linear_output_actions)\n",
    "    linear_output_attributes = self.linear_attributes(linear_output_intermedio)\n",
    "    # linear_output_attributes = self.sig(linear_output_attributes)\n",
    "    linear_output_attributes = torch.sigmoid(linear_output_attributes)\n",
    "\n",
    "    return {'actions': linear_output_actions, 'attributes': linear_output_attributes}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ceefd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomBERTModel(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (linear_intermedio): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (linear_actions): Linear(in_features=256, out_features=5, bias=True)\n",
       "  (linear_attributes): Linear(in_features=256, out_features=33, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test istanziazione del custom model\n",
    "model = CustomBERTModel()\n",
    "\n",
    "# model.bert.config\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cb0c4c",
   "metadata": {},
   "source": [
    "Just for curiosity's sake, we can browse all of the model's parameters by name here.\n",
    "\n",
    "In the below cell, I've printed out the names and dimensions of the weights for:\n",
    "\n",
    "1. The embedding layer.\n",
    "2. The first of the twelve transformers.\n",
    "3. The output layer.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c48662a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 205 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "linear_actions.weight                                       (5, 256)\n",
      "linear_actions.bias                                             (5,)\n",
      "linear_attributes.weight                                   (33, 256)\n",
      "linear_attributes.bias                                         (33,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655b5929",
   "metadata": {},
   "source": [
    "## 4.2. Optimizer & Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2ee817",
   "metadata": {},
   "source": [
    "Now that we have our model loaded we need to grab the training hyperparameters from within the stored model.\n",
    "\n",
    "For the purposes of fine-tuning, the authors recommend choosing from the following values (from Appendix A.3 of the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf)):\n",
    "\n",
    ">- **Batch size:** 16, 32  \n",
    "- **Learning rate (Adam):** 5e-5, 3e-5, 2e-5  \n",
    "- **Number of epochs:** 2, 3, 4 \n",
    "\n",
    "We chose:\n",
    "* Batch size: 32 (set when creating our DataLoaders)\n",
    "* Learning rate: 2e-5\n",
    "* Epochs: 4 (we'll see that this is probably too many...)\n",
    "\n",
    "The epsilon parameter `eps = 1e-8` is \"a very small number to prevent any division by zero in the implementation\" (from [here](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)).\n",
    "\n",
    "You can find the creation of the AdamW optimizer in `run_glue.py` [here](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "295fde1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 5e-5, # args.learning_rate - default is 5e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4faef5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = exec_params['epochs']\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eccdf3c",
   "metadata": {},
   "source": [
    "## 4.3. Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1141dfa",
   "metadata": {},
   "source": [
    "Below is our training loop. There's a lot going on, but fundamentally for each pass in our loop we have a trianing phase and a validation phase. \n",
    "\n",
    "> *Thank you to [Stas Bekman](https://ca.linkedin.com/in/stasbekman) for contributing the insights and code for using validation loss to detect over-fitting!*\n",
    "\n",
    "**Training:**\n",
    "- Unpack our data inputs and labels\n",
    "- Load data onto the GPU for acceleration\n",
    "- Clear out the gradients calculated in the previous pass. \n",
    "    - In pytorch the gradients accumulate by default (useful for things like RNNs) unless you explicitly clear them out.\n",
    "- Forward pass (feed input data through the network)\n",
    "- Backward pass (backpropagation)\n",
    "- Tell the network to update parameters with optimizer.step()\n",
    "- Track variables for monitoring progress\n",
    "\n",
    "**Evalution:**\n",
    "- Unpack our data inputs and labels\n",
    "- Load data onto the GPU for acceleration\n",
    "- Forward pass (feed input data through the network)\n",
    "- Compute loss on our validation data and track variables for monitoring progress\n",
    "\n",
    "Pytorch hides all of the detailed calculations from us, but we've commented the code to point out which of the above steps are happening on each line. \n",
    "\n",
    "> *PyTorch also has some [beginner tutorials](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py) which you may also find helpful.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d699904",
   "metadata": {},
   "source": [
    "Define a helper function for calculating accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df633469",
   "metadata": {},
   "source": [
    "### Flat accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef1a2d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy_actions(preds, labels):\n",
    "    #print(f\"[FA] preds: {preds} / labels: {labels}\")\n",
    "    #print(f\"[FA-Actions] {type(preds)} {type(labels)}\")\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()   \n",
    "    return {'matched': np.sum(pred_flat == labels_flat), 'counts': len(labels_flat)}\n",
    "\n",
    "def flat_accuracy_attributes(preds, labels):\n",
    "  #print(f\"[FA-Attributess] {type(preds)} {type(labels)}\")\n",
    "  tot_preds = preds.shape[0]\n",
    "  preds_int = np.rint(preds)\n",
    "  tot_eq = 0\n",
    "  for i in range(tot_preds):\n",
    "    comparison = preds_int[i] == labels[i]\n",
    "    if comparison.all():\n",
    "      tot_eq += 1\n",
    "  return {'matched': tot_eq, 'counts' : tot_preds}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc1a792",
   "metadata": {},
   "source": [
    "Helper function for formatting elapsed times as `hh:mm:ss`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "903c3769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdd0590",
   "metadata": {},
   "source": [
    "### Loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0629812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "# Loss function definition\n",
    "def MyBERT_loss(logits, actions_labels, attributes_labels):\n",
    "  actions_logits = logits['actions']\n",
    "  attributes_logits = logits['attributes']\n",
    "  loss_actions_fn = nn.CrossEntropyLoss()\n",
    "  loss_attributes_fn = nn.BCELoss()\n",
    "  loss_actions = loss_actions_fn(actions_logits, actions_labels)\n",
    "  loss_attributes = loss_attributes_fn(attributes_logits, attributes_labels.float())\n",
    "  return loss_actions + loss_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fea679",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We're ready to kick off the training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aab27b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 10 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  7% | 32% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  7% | 32% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:54.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 90% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:52.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 89% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:47.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 89% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:42.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 89% |\n",
      "End of epoch 0\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 89% |\n",
      "\n",
      "  Average training loss: 1.13\n",
      "  Training epcoh took: 0:08:31\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8423\n",
      "  Accuracy for multilabel-classification (attributes): 0.8804\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8423000284656988, 'action_perplexity': 1.998133700018065, 'attribute_accuracy': 0.686716383722839, 'confusion_matrix': array([[4.740e+02, 4.700e+01, 9.000e+00, 1.000e+00, 1.000e+01],\n",
      "       [8.000e+00, 6.450e+02, 1.400e+01, 6.000e+00, 1.500e+01],\n",
      "       [1.000e+01, 1.540e+02, 4.980e+02, 4.100e+01, 8.000e+00],\n",
      "       [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
      "       [0.000e+00, 6.200e+01, 1.030e+02, 6.600e+01, 1.342e+03]])}\n",
      "  Validation Loss: 1.0721\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "======== Epoch 2 / 10 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 98% | 89% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 98% | 89% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:57.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 90% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:52.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:50.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 89% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:47.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 88% |\n",
      "End of epoch 1\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "\n",
      "  Average training loss: 1.07\n",
      "  Training epcoh took: 0:08:37\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8446\n",
      "  Accuracy for multilabel-classification (attributes): 0.9163\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8445772843723314, 'action_perplexity': 2.2989174764455753, 'attribute_accuracy': 0.7285417858670012, 'confusion_matrix': array([[4.710e+02, 3.400e+01, 1.200e+01, 1.000e+00, 1.100e+01],\n",
      "       [1.200e+01, 6.770e+02, 4.500e+01, 7.000e+00, 1.600e+01],\n",
      "       [6.000e+00, 1.470e+02, 4.740e+02, 3.800e+01, 3.000e+00],\n",
      "       [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
      "       [3.000e+00, 5.000e+01, 9.300e+01, 6.800e+01, 1.345e+03]])}\n",
      "  Validation Loss: 1.0637\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "======== Epoch 3 / 10 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:56.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 89% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:51.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:46.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:42.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 89% |\n",
      "End of epoch 2\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 89% |\n",
      "\n",
      "  Average training loss: 1.06\n",
      "  Training epcoh took: 0:08:30\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8449\n",
      "  Accuracy for multilabel-classification (attributes): 0.9169\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8448619413606604, 'action_perplexity': 2.7610069112007585, 'attribute_accuracy': 0.7337956947907177, 'confusion_matrix': array([[ 443.,   21.,    4.,    0.,    8.],\n",
      "       [  37.,  704.,   63.,    9.,   28.],\n",
      "       [  10.,  142.,  502.,   54.,   20.],\n",
      "       [   0.,    0.,    0.,    0.,    0.],\n",
      "       [   2.,   41.,   55.,   51., 1319.]])}\n",
      "  Validation Loss: 1.0634\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "======== Epoch 4 / 10 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 89% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 79% | 89% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:55.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:50.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:44.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:39.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "End of epoch 3\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "\n",
      "  Average training loss: 1.05\n",
      "  Training epcoh took: 0:08:27\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8488\n",
      "  Accuracy for multilabel-classification (attributes): 0.9183\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8488471391972673, 'action_perplexity': 2.79762422513765, 'attribute_accuracy': 0.745661904570242, 'confusion_matrix': array([[ 475.,   35.,   15.,    0.,    7.],\n",
      "       [  11.,  689.,   58.,   12.,   12.],\n",
      "       [   2.,  128.,  475.,   44.,   13.],\n",
      "       [   0.,    0.,    0.,    0.,    0.],\n",
      "       [   4.,   56.,   76.,   58., 1343.]])}\n",
      "  Validation Loss: 1.0605\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "======== Epoch 5 / 10 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 87% | 88% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 87% | 88% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:55.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 88% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:51.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 89% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:48.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 90% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:43.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 90% |\n",
      "End of epoch 4\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 89% |\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epcoh took: 0:08:31\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8508\n",
      "  Accuracy for multilabel-classification (attributes): 0.9371\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8508397381155708, 'action_perplexity': 3.083283313080345, 'attribute_accuracy': 0.7665216520091027, 'confusion_matrix': array([[ 464.,   33.,    4.,    0.,    6.],\n",
      "       [  14.,  703.,   67.,    9.,   19.],\n",
      "       [  11.,  134.,  489.,   48.,   17.],\n",
      "       [   0.,    0.,    0.,    0.,    0.],\n",
      "       [   3.,   38.,   64.,   57., 1333.]])}\n",
      "  Validation Loss: 1.0579\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "======== Epoch 6 / 10 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 90% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 90% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:55.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 89% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:49.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 89% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:44.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 93% | 89% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:39.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "End of epoch 5\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "\n",
      "  Average training loss: 1.02\n",
      "  Training epcoh took: 0:08:27\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8500\n",
      "  Accuracy for multilabel-classification (attributes): 0.9374\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8499857671505835, 'action_perplexity': 3.1710858632224808, 'attribute_accuracy': 0.7807779568854851, 'confusion_matrix': array([[ 464.,   31.,    2.,    0.,    7.],\n",
      "       [  13.,  684.,   35.,    9.,   23.],\n",
      "       [  12.,  152.,  525.,   54.,   32.],\n",
      "       [   0.,    0.,    0.,    0.,    0.],\n",
      "       [   3.,   41.,   62.,   51., 1313.]])}\n",
      "  Validation Loss: 1.0590\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "======== Epoch 7 / 10 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 95% | 88% |\n",
      "GPU after train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 95% | 88% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:55.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 90% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:49.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 89% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:44.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 89% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:38.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 89% |\n",
      "End of epoch 6\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 89% |\n",
      "\n",
      "  Average training loss: 1.01\n",
      "  Training epcoh took: 0:08:25\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8477\n",
      "  Accuracy for multilabel-classification (attributes): 0.9397\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8477085112439511, 'action_perplexity': 3.933328343935887, 'attribute_accuracy': 0.7796939608556498, 'confusion_matrix': array([[ 463.,   30.,    2.,    0.,    4.],\n",
      "       [   9.,  694.,   66.,   10.,   18.],\n",
      "       [  12.,  136.,  490.,   50.,   22.],\n",
      "       [   0.,    0.,    0.,    0.,    0.],\n",
      "       [   8.,   48.,   66.,   54., 1331.]])}\n",
      "  Validation Loss: 1.0625\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "======== Epoch 8 / 10 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 89% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 89% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:54.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 89% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:48.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 89% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:43.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 89% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:37.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 88% |\n",
      "End of epoch 7\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "\n",
      "  Average training loss: 1.00\n",
      "  Training epcoh took: 0:08:25\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8525\n",
      "  Accuracy for multilabel-classification (attributes): 0.9436\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8525476800455452, 'action_perplexity': 4.420063574853818, 'attribute_accuracy': 0.7845090628719202, 'confusion_matrix': array([[ 463.,   27.,    5.,    0.,    5.],\n",
      "       [  16.,  707.,   64.,    9.,   20.],\n",
      "       [  10.,  125.,  497.,   53.,   22.],\n",
      "       [   0.,    0.,    0.,    0.,    0.],\n",
      "       [   3.,   49.,   58.,   52., 1328.]])}\n",
      "  Validation Loss: 1.0595\n",
      "  Validation took: 0:00:28\n",
      "\n",
      "======== Epoch 9 / 10 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:54.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 88% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:48.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:42.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 88% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:37.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "End of epoch 8\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 88% |\n",
      "\n",
      "  Average training loss: 1.00\n",
      "  Training epcoh took: 0:08:24\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8469\n",
      "  Accuracy for multilabel-classification (attributes): 0.9439\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8468545402789639, 'action_perplexity': 4.745156322970534, 'attribute_accuracy': 0.7753540944508626, 'confusion_matrix': array([[4.690e+02, 3.200e+01, 3.000e+00, 0.000e+00, 5.000e+00],\n",
      "       [1.200e+01, 7.050e+02, 8.500e+01, 1.000e+01, 2.000e+01],\n",
      "       [1.000e+01, 1.230e+02, 4.670e+02, 4.600e+01, 1.600e+01],\n",
      "       [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
      "       [1.000e+00, 4.800e+01, 6.900e+01, 5.800e+01, 1.334e+03]])}\n",
      "  Validation Loss: 1.0638\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "======== Epoch 10 / 10 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 88% | 88% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 88% | 88% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:54.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:48.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 88% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:42.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 88% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:36.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "End of epoch 9\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "\n",
      "  Average training loss: 0.99\n",
      "  Training epcoh took: 0:08:24\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8483\n",
      "  Accuracy for multilabel-classification (attributes): 0.9445\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8482778252206091, 'action_perplexity': 4.7607740051778, 'attribute_accuracy': 0.7742367142215908, 'confusion_matrix': array([[4.690e+02, 3.000e+01, 3.000e+00, 1.000e+00, 5.000e+00],\n",
      "       [1.200e+01, 7.090e+02, 8.200e+01, 1.000e+01, 2.000e+01],\n",
      "       [1.000e+01, 1.250e+02, 4.780e+02, 5.100e+01, 2.600e+01],\n",
      "       [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
      "       [1.000e+00, 4.400e+01, 6.100e+01, 5.200e+01, 1.324e+03]])}\n",
      "  Validation Loss: 1.0629\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "Training complete!\n",
      "Total training took 1:29:11 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import action_evaluation as evaluation\n",
    "import json\n",
    "from  GPUtil import showUtilization as gpu_usage\n",
    "with open('./extr_output/fashion_dev_dials_api_calls.json') as f:\n",
    "  dev_dials = json.load(f)\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 24\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "test_batch = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    print(\"GPU before train\")\n",
    "    gpu_usage()\n",
    "\n",
    "    model.train()\n",
    "    print(\"GPU after train\")\n",
    "    gpu_usage()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 400 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "            gpu_usage()\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: actions labels \n",
    "        #   [3]: attributes labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels_actions = batch[2].to(device)\n",
    "        b_labels_attributes = batch[3].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
    "        # function and pass down the arguments. The `forward` function is \n",
    "        # documented here: \n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
    "        # The results are returned in a results object, documented here:\n",
    "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
    "        # Specifically, we'll get the loss (because we provided labels) and the\n",
    "        # \"logits\"--the model outputs prior to activation.\n",
    "        result = model(b_input_ids, \n",
    "                       mask=b_input_mask)\n",
    "        \n",
    "        loss = MyBERT_loss(result, b_labels_actions, b_labels_attributes)\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.from transformers import BertModel, BertConfig\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    print(f\"End of epoch {epoch_i}\")\n",
    "    gpu_usage()\n",
    "    \n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.mlb.inverse_transform(attr_yt[3].reshape(1, -1))\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy_classification = { 'matched': 0, 'counts': 0}\n",
    "    total_eval_accuracy_multilabel = { 'matched': 0, 'counts': 0}\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    batch_number = 0\n",
    "\n",
    "    # Dictionary for action_evaluation\n",
    "    model_actions = {}\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        batch_number += 1\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels_actions = batch[2].to(device)\n",
    "        b_labels_attributes = batch[3].to(device)\n",
    "        b_dialog_ids = batch[4].to(device).detach().cpu().numpy()\n",
    "        b_turn_idxs = batch[5].to(device).detach().cpu().numpy()\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            result = model(b_input_ids, \n",
    "                       mask=b_input_mask)\n",
    "\n",
    "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
    "        # output values prior to applying an activation function like the \n",
    "        # softmax.\n",
    "        loss = MyBERT_loss(result, b_labels_actions, b_labels_attributes)\n",
    "            \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        # logits = logits.detach().cpu().numpy()\n",
    "        # label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        \n",
    "        actions_logits_foracc=result['actions'].detach().cpu().numpy()\n",
    "        attributes_logits_foracc=result['attributes'].detach().cpu().numpy()\n",
    "        actions_labels_foracc= b_labels_actions.to('cpu').numpy()\n",
    "        attributes_labels_foracc =b_labels_attributes.to('cpu').numpy()\n",
    "\n",
    "        #TODO: definire la nostra funzione di accuracy\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        accuracy_classification = flat_accuracy_actions(actions_logits_foracc, actions_labels_foracc)\n",
    "        accuracy_multilabel = flat_accuracy_attributes(attributes_logits_foracc, attributes_labels_foracc)\n",
    "        \n",
    "        total_eval_accuracy_classification['matched'] += accuracy_classification['matched']\n",
    "        total_eval_accuracy_classification['counts'] += accuracy_classification['counts']\n",
    "        total_eval_accuracy_multilabel['matched'] += accuracy_multilabel['matched']\n",
    "        total_eval_accuracy_multilabel['counts'] += accuracy_multilabel['counts']\n",
    "        # Salvo dati elaborazione batch per debug/analisi\n",
    "        test_batch.append({\n",
    "            'epoch' : epoch_i + 1,\n",
    "            'batchnum' : batch_number,\n",
    "            'actions_logits' : actions_logits_foracc,\n",
    "            'actions_labels' : actions_labels_foracc,\n",
    "            'attributes_logits' : attributes_logits_foracc,\n",
    "            'attributes_labels' : attributes_labels_foracc,\n",
    "            'accuracy_classification' : accuracy_classification,\n",
    "            'accuracy_multilabel' : accuracy_multilabel,\n",
    "        })\n",
    "\n",
    "        # Fill dictionary for action_evaluation\n",
    "        for el_i in range(len(actions_logits_foracc)):\n",
    "          dialog_id = b_dialog_ids[el_i]\n",
    "          action_log_prob = {}\n",
    "          for act_i in range(len(actions_logits_foracc[el_i])):\n",
    "            #todo: controllare che la probabilità predetta sia in scala logaritmica (?? potrebbe essere fonte di errori)\n",
    "            action_log_prob[le.classes_[act_i]] = np.log(actions_logits_foracc[el_i][act_i])\n",
    "          #attributes = {}\n",
    "          attributes = []\n",
    "          #attributes_list = np.rint(attributes_logits_foracc[el_i])\n",
    "          attributes_list = np.array(attributes_logits_foracc[el_i])\n",
    "          for attr in range(len(attributes_list)):\n",
    "            attribute = mlb.classes_[attr]\n",
    "            #attributes[mlb.classes_[attr]] = attributes_list[attr]\n",
    "            if attributes_list[attr] >= 0.5:\n",
    "              attributes.append(attribute)\n",
    "          prediction = {\n",
    "              'action': le.classes_[np.argmax(actions_logits_foracc[el_i])],\n",
    "              'action_log_prob': action_log_prob,\n",
    "              'attributes': {'attributes': attributes},\n",
    "              'turn_id': b_turn_idxs[el_i]\n",
    "          }\n",
    "          if dialog_id in model_actions:\n",
    "            model_actions[dialog_id]['predictions'].append(prediction)\n",
    "          else:\n",
    "            predictions = list()\n",
    "            predictions.append(prediction)\n",
    "            model_actions[dialog_id] = {\n",
    "                'dialog_id': dialog_id,\n",
    "                'predictions': predictions\n",
    "            }\n",
    "          \n",
    "\n",
    "    # Report the final accuracy for this validation \n",
    "\n",
    "    #avg_val_accuracy_classification = total_eval_accuracy_classification / len(validation_dataloader)\n",
    "    #avg_val_accuracy_multilabel = total_eval_accuracy_multilabel / len(validation_dataloader)\n",
    "    avg_val_accuracy_classification = total_eval_accuracy_classification['matched'] / total_eval_accuracy_classification['counts']\n",
    "    avg_val_accuracy_multilabel = total_eval_accuracy_multilabel['matched'] / total_eval_accuracy_multilabel['counts']\n",
    "    print(\"  Accuracy for classification (actions): {0:.4f}\".format(avg_val_accuracy_classification))\n",
    "    print(\"  Accuracy for multilabel-classification (attributes): {0:.4f}\".format(avg_val_accuracy_multilabel))\n",
    "\n",
    "    # Reference implementation: evaluation of action prediction along with attributes\n",
    "    metrics = evaluation.evaluate_action_prediction(dev_dials, model_actions.values())\n",
    "    # print(\"model_actions passed to the evaluator:\")\n",
    "    # for v in model_actions.values():\n",
    "    #   print(v)\n",
    "    print(\"***************************************\")\n",
    "    print(\"Reference evaluation metrics:\")\n",
    "    print(metrics)\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.4f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,  \n",
    "            'Valid. Accur. class.': avg_val_accuracy_classification,\n",
    "            'Valid. Accur. mult.label': avg_val_accuracy_multilabel,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time,\n",
    "            'metrics': metrics\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ac0f0f",
   "metadata": {},
   "source": [
    "## Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b6d29e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy for classification (actions): 0.8499\n",
      "  Accuracy for multilabel-classification (attributes): 0.9376\n",
      "#Instances evaluated API: 5397\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8499166203446359, 'action_perplexity': 4.9076304345682065, 'attribute_accuracy': 0.7681696875335761, 'confusion_matrix': array([[ 751.,   41.,   11.,    5.,   16.],\n",
      "       [  20., 1104.,  113.,   15.,   39.],\n",
      "       [  14.,  166.,  731.,  102.,   32.],\n",
      "       [   0.,    0.,    0.,    0.,    0.],\n",
      "       [   8.,   75.,   89.,   64., 2001.]])}\n"
     ]
    }
   ],
   "source": [
    "#Prediction on test set\n",
    "#quale modello gli viene passato? da controllare se BERT da solo riesce a tenere traccia del modello che ha dato l'epoca migliore\n",
    "\n",
    "\n",
    "with open('./extr_output/fashion_devtest_dials_api_calls.json') as f:\n",
    "  devtest_dials = json.load(f)\n",
    "\n",
    "# Tracking variables \n",
    "total_eval_accuracy_classification = { 'matched': 0, 'counts': 0}\n",
    "total_eval_accuracy_multilabel = { 'matched': 0, 'counts': 0}\n",
    "\n",
    "model_actions = {}\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "for batch in evaluation_dataloader:\n",
    "\n",
    "    # Unpack this training batch from our dataloader. \n",
    "    #\n",
    "    # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "    # the `to` method.\n",
    "    #\n",
    "    # `batch` contains three pytorch tensors:\n",
    "    #   [0]: input ids \n",
    "    #   [1]: attention masks\n",
    "    #   [2]: labels \n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels_actions = batch[2].to(device)\n",
    "    b_labels_attributes = batch[3].to(device)\n",
    "    b_dialog_ids = batch[4].to(device).detach().cpu().numpy()\n",
    "    b_turn_idxs = batch[5].to(device).detach().cpu().numpy()\n",
    "    \n",
    "    # Tell pytorch not to bother with constructing the compute graph during\n",
    "    # the forward pass, since this is only needed for backprop (training).\n",
    "    with torch.no_grad():        \n",
    "        # Forward pass, calculate logit predictions.\n",
    "        # token_type_ids is the same as the \"segment ids\", which \n",
    "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "        result = model(b_input_ids,mask=b_input_mask)\n",
    "\n",
    "    \n",
    "    actions_logits_foracc=result['actions'].detach().cpu().numpy()\n",
    "    attributes_logits_foracc=result['attributes'].detach().cpu().numpy()\n",
    "    actions_labels_foracc= b_labels_actions.to('cpu').numpy()\n",
    "    attributes_labels_foracc =b_labels_attributes.to('cpu').numpy()\n",
    "\n",
    "    # Calculate the accuracy for this batch of test sentences, and\n",
    "    # accumulate it over all batches.\n",
    "    accuracy_classification = flat_accuracy_actions(actions_logits_foracc, actions_labels_foracc)\n",
    "    accuracy_multilabel = flat_accuracy_attributes(attributes_logits_foracc, attributes_labels_foracc)\n",
    "    \n",
    "    total_eval_accuracy_classification['matched'] += accuracy_classification['matched']\n",
    "    total_eval_accuracy_classification['counts'] += accuracy_classification['counts']\n",
    "    total_eval_accuracy_multilabel['matched'] += accuracy_multilabel['matched']\n",
    "    total_eval_accuracy_multilabel['counts'] += accuracy_multilabel['counts']\n",
    "    \n",
    "\n",
    "    # Fill dictionary for action_evaluation\n",
    "    for el_i in range(len(actions_logits_foracc)):\n",
    "      dialog_id = b_dialog_ids[el_i]\n",
    "      action_log_prob = {}\n",
    "      for act_i in range(len(actions_logits_foracc[el_i])):\n",
    "        #todo: controllare che la probabilità predetta sia in scala logaritmica (?? potrebbe essere fonte di errori)\n",
    "        action_log_prob[le.classes_[act_i]] = np.log(actions_logits_foracc[el_i][act_i])\n",
    "      #attributes = {}\n",
    "      attributes = []\n",
    "      #attributes_list = np.rint(attributes_logits_foracc[el_i])\n",
    "      attributes_list = np.array(attributes_logits_foracc[el_i])\n",
    "      for attr in range(len(attributes_list)):\n",
    "        attribute = mlb.classes_[attr]\n",
    "        #attributes[mlb.classes_[attr]] = attributes_list[attr]\n",
    "        if attributes_list[attr] >= 0.5:\n",
    "          attributes.append(attribute)\n",
    "      prediction = {\n",
    "          'action': le.classes_[np.argmax(actions_logits_foracc[el_i])],\n",
    "          'action_log_prob': action_log_prob,\n",
    "          'attributes': {'attributes': attributes},\n",
    "          'turn_id': b_turn_idxs[el_i]\n",
    "      }\n",
    "      if dialog_id in model_actions:\n",
    "        model_actions[dialog_id]['predictions'].append(prediction)\n",
    "      else:\n",
    "        predictions = list()\n",
    "        predictions.append(prediction)\n",
    "        model_actions[dialog_id] = {\n",
    "            'dialog_id': dialog_id,\n",
    "            'predictions': predictions\n",
    "        }\n",
    "      \n",
    "\n",
    "# Report the final accuracy for this validation \n",
    "\n",
    "#avg_val_accuracy_classification = total_eval_accuracy_classification / len(validation_dataloader)\n",
    "#avg_val_accuracy_multilabel = total_eval_accuracy_multilabel / len(validation_dataloader)\n",
    "avg_val_accuracy_classification = total_eval_accuracy_classification['matched'] / total_eval_accuracy_classification['counts']\n",
    "avg_val_accuracy_multilabel = total_eval_accuracy_multilabel['matched'] / total_eval_accuracy_multilabel['counts']\n",
    "print(\"  Accuracy for classification (actions): {0:.4f}\".format(avg_val_accuracy_classification))\n",
    "print(\"  Accuracy for multilabel-classification (attributes): {0:.4f}\".format(avg_val_accuracy_multilabel))\n",
    "\n",
    "# Reference implementation: evaluation of action prediction along with attributes\n",
    "metrics = evaluation.evaluate_action_prediction(devtest_dials, model_actions.values())\n",
    "# print(\"model_actions passed to the evaluator:\")\n",
    "# for v in model_actions.values():\n",
    "#   print(v)\n",
    "print(\"***************************************\")\n",
    "print(\"Reference evaluation metrics:\")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a059e49",
   "metadata": {},
   "source": [
    "# OTHER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ca179f",
   "metadata": {},
   "source": [
    "Let's view the summary of the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "03bdf5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "401e879c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>batchnum</th>\n",
       "      <th>actions_logits</th>\n",
       "      <th>actions_labels</th>\n",
       "      <th>attributes_logits</th>\n",
       "      <th>attributes_labels</th>\n",
       "      <th>accuracy_classification</th>\n",
       "      <th>accuracy_multilabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.0004111114, 0.9999019, 0.0028128964, 0.000...</td>\n",
       "      <td>[1, 4, 2, 4, 0, 1, 1, 4, 4, 0, 1, 2]</td>\n",
       "      <td>[[0.0007370889, 0.0017997948, 0.0051518846, 0....</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>{'matched': 11, 'counts': 12}</td>\n",
       "      <td>{'matched': 11, 'counts': 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0.00012931021, 0.9998653, 0.0022472418, 0.00...</td>\n",
       "      <td>[1, 4, 2, 2, 0, 1, 2, 1, 1, 1, 1, 4]</td>\n",
       "      <td>[[0.0011436342, 0.0022213547, 0.0059215967, 0....</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>{'matched': 8, 'counts': 12}</td>\n",
       "      <td>{'matched': 10, 'counts': 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[[0.00018050394, 0.9984267, 0.034088146, 0.000...</td>\n",
       "      <td>[4, 1, 1, 1, 4, 2, 1, 2, 0, 1, 1, 1]</td>\n",
       "      <td>[[0.0011088823, 0.0020427345, 0.0491298, 0.001...</td>\n",
       "      <td>[[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>{'matched': 8, 'counts': 12}</td>\n",
       "      <td>{'matched': 10, 'counts': 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[[0.99976426, 0.0067516086, 0.00064552494, 0.0...</td>\n",
       "      <td>[0, 0, 1, 2, 0, 1, 4, 4, 0, 1, 1, 4]</td>\n",
       "      <td>[[0.00022466235, 0.00073125697, 0.005569735, 0...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>{'matched': 9, 'counts': 12}</td>\n",
       "      <td>{'matched': 11, 'counts': 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[[0.00027733576, 0.0014411556, 0.0009898278, 0...</td>\n",
       "      <td>[1, 4, 2, 4, 0, 3, 1, 1, 2, 4, 1, 1]</td>\n",
       "      <td>[[0.0002901426, 0.00037647187, 0.005853592, 0....</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>{'matched': 7, 'counts': 12}</td>\n",
       "      <td>{'matched': 10, 'counts': 12}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  batchnum                                     actions_logits  \\\n",
       "0      1         1  [[0.0004111114, 0.9999019, 0.0028128964, 0.000...   \n",
       "1      1         2  [[0.00012931021, 0.9998653, 0.0022472418, 0.00...   \n",
       "2      1         3  [[0.00018050394, 0.9984267, 0.034088146, 0.000...   \n",
       "3      1         4  [[0.99976426, 0.0067516086, 0.00064552494, 0.0...   \n",
       "4      1         5  [[0.00027733576, 0.0014411556, 0.0009898278, 0...   \n",
       "\n",
       "                         actions_labels  \\\n",
       "0  [1, 4, 2, 4, 0, 1, 1, 4, 4, 0, 1, 2]   \n",
       "1  [1, 4, 2, 2, 0, 1, 2, 1, 1, 1, 1, 4]   \n",
       "2  [4, 1, 1, 1, 4, 2, 1, 2, 0, 1, 1, 1]   \n",
       "3  [0, 0, 1, 2, 0, 1, 4, 4, 0, 1, 1, 4]   \n",
       "4  [1, 4, 2, 4, 0, 3, 1, 1, 2, 4, 1, 1]   \n",
       "\n",
       "                                   attributes_logits  \\\n",
       "0  [[0.0007370889, 0.0017997948, 0.0051518846, 0....   \n",
       "1  [[0.0011436342, 0.0022213547, 0.0059215967, 0....   \n",
       "2  [[0.0011088823, 0.0020427345, 0.0491298, 0.001...   \n",
       "3  [[0.00022466235, 0.00073125697, 0.005569735, 0...   \n",
       "4  [[0.0002901426, 0.00037647187, 0.005853592, 0....   \n",
       "\n",
       "                                   attributes_labels  \\\n",
       "0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "2  [[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "3  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "4  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "         accuracy_classification            accuracy_multilabel  \n",
       "0  {'matched': 11, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
       "1   {'matched': 8, 'counts': 12}  {'matched': 10, 'counts': 12}  \n",
       "2   {'matched': 8, 'counts': 12}  {'matched': 10, 'counts': 12}  \n",
       "3   {'matched': 9, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
       "4   {'matched': 7, 'counts': 12}  {'matched': 10, 'counts': 12}  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert test data to dataframe\n",
    "df_test = pd.DataFrame(data = test_batch)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dbd5290d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur. class.</th>\n",
       "      <th>Valid. Accur. mult.label</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "      <th>metrics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.13</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0:08:31</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8423000284656988, 'actio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.07</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0:08:37</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8445772843723314, 'actio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.06</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0:08:30</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8448619413606604, 'actio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.05</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0:08:27</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8488471391972673, 'actio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.03</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0:08:31</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8508397381155708, 'actio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.02</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0:08:27</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8499857671505835, 'actio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.01</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0:08:25</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8477085112439511, 'actio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0:08:25</td>\n",
       "      <td>0:00:28</td>\n",
       "      <td>{'action_accuracy': 0.8525476800455452, 'actio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0:08:24</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8468545402789639, 'actio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.99</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0:08:24</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8482778252206091, 'actio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. class.  \\\n",
       "epoch                                                     \n",
       "1               1.13         1.07                  0.84   \n",
       "2               1.07         1.06                  0.84   \n",
       "3               1.06         1.06                  0.84   \n",
       "4               1.05         1.06                  0.85   \n",
       "5               1.03         1.06                  0.85   \n",
       "6               1.02         1.06                  0.85   \n",
       "7               1.01         1.06                  0.85   \n",
       "8               1.00         1.06                  0.85   \n",
       "9               1.00         1.06                  0.85   \n",
       "10              0.99         1.06                  0.85   \n",
       "\n",
       "       Valid. Accur. mult.label Training Time Validation Time  \\\n",
       "epoch                                                           \n",
       "1                          0.88       0:08:31         0:00:27   \n",
       "2                          0.92       0:08:37         0:00:27   \n",
       "3                          0.92       0:08:30         0:00:27   \n",
       "4                          0.92       0:08:27         0:00:27   \n",
       "5                          0.94       0:08:31         0:00:27   \n",
       "6                          0.94       0:08:27         0:00:27   \n",
       "7                          0.94       0:08:25         0:00:27   \n",
       "8                          0.94       0:08:25         0:00:28   \n",
       "9                          0.94       0:08:24         0:00:27   \n",
       "10                         0.94       0:08:24         0:00:27   \n",
       "\n",
       "                                                 metrics  \n",
       "epoch                                                     \n",
       "1      {'action_accuracy': 0.8423000284656988, 'actio...  \n",
       "2      {'action_accuracy': 0.8445772843723314, 'actio...  \n",
       "3      {'action_accuracy': 0.8448619413606604, 'actio...  \n",
       "4      {'action_accuracy': 0.8488471391972673, 'actio...  \n",
       "5      {'action_accuracy': 0.8508397381155708, 'actio...  \n",
       "6      {'action_accuracy': 0.8499857671505835, 'actio...  \n",
       "7      {'action_accuracy': 0.8477085112439511, 'actio...  \n",
       "8      {'action_accuracy': 0.8525476800455452, 'actio...  \n",
       "9      {'action_accuracy': 0.8468545402789639, 'actio...  \n",
       "10     {'action_accuracy': 0.8482778252206091, 'actio...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display floats with two decimal places.\n",
    "pd.set_option('precision', 2)\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap.\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Display the table.\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "69386886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Objects serialization\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "testdata_filename = f\"testdata-{timestr}\"\n",
    "stats_filename = f\"stats-{timestr}\"\n",
    "#outtest = open(testdata_filename, \"wb\")\n",
    "#outstats = open(stats_filename, \"wb\")\n",
    "#pk.dump(obj=df_test, file=outtest)\n",
    "#outtest.close()\n",
    "#pk.dump(obj=df_stats, file=outstats)\n",
    "#outstats.close()\n",
    "df_test.to_pickle(testdata_filename)\n",
    "df_stats.to_pickle(stats_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb5a6cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testdata-20210731-212454\n",
      "       Training Loss  Valid. Loss  Valid. Accur. class.  \\\n",
      "epoch                                                     \n",
      "1               1.13         1.07                  0.84   \n",
      "2               1.07         1.06                  0.84   \n",
      "3               1.06         1.06                  0.84   \n",
      "4               1.05         1.06                  0.85   \n",
      "5               1.03         1.06                  0.85   \n",
      "\n",
      "       Valid. Accur. mult.label Training Time Validation Time  \\\n",
      "epoch                                                           \n",
      "1                          0.88       0:08:31         0:00:27   \n",
      "2                          0.92       0:08:37         0:00:27   \n",
      "3                          0.92       0:08:30         0:00:27   \n",
      "4                          0.92       0:08:27         0:00:27   \n",
      "5                          0.94       0:08:31         0:00:27   \n",
      "\n",
      "                                                 metrics  \n",
      "epoch                                                     \n",
      "1      {'action_accuracy': 0.8423000284656988, 'actio...  \n",
      "2      {'action_accuracy': 0.8445772843723314, 'actio...  \n",
      "3      {'action_accuracy': 0.8448619413606604, 'actio...  \n",
      "4      {'action_accuracy': 0.8488471391972673, 'actio...  \n",
      "5      {'action_accuracy': 0.8508397381155708, 'actio...  \n",
      "   epoch  batchnum                                     actions_logits  \\\n",
      "0      1         1  [[0.0004111114, 0.9999019, 0.0028128964, 0.000...   \n",
      "1      1         2  [[0.00012931021, 0.9998653, 0.0022472418, 0.00...   \n",
      "2      1         3  [[0.00018050394, 0.9984267, 0.034088146, 0.000...   \n",
      "3      1         4  [[0.99976426, 0.0067516086, 0.00064552494, 0.0...   \n",
      "4      1         5  [[0.00027733576, 0.0014411556, 0.0009898278, 0...   \n",
      "\n",
      "                         actions_labels  \\\n",
      "0  [1, 4, 2, 4, 0, 1, 1, 4, 4, 0, 1, 2]   \n",
      "1  [1, 4, 2, 2, 0, 1, 2, 1, 1, 1, 1, 4]   \n",
      "2  [4, 1, 1, 1, 4, 2, 1, 2, 0, 1, 1, 1]   \n",
      "3  [0, 0, 1, 2, 0, 1, 4, 4, 0, 1, 1, 4]   \n",
      "4  [1, 4, 2, 4, 0, 3, 1, 1, 2, 4, 1, 1]   \n",
      "\n",
      "                                   attributes_logits  \\\n",
      "0  [[0.0007370889, 0.0017997948, 0.0051518846, 0....   \n",
      "1  [[0.0011436342, 0.0022213547, 0.0059215967, 0....   \n",
      "2  [[0.0011088823, 0.0020427345, 0.0491298, 0.001...   \n",
      "3  [[0.00022466235, 0.00073125697, 0.005569735, 0...   \n",
      "4  [[0.0002901426, 0.00037647187, 0.005853592, 0....   \n",
      "\n",
      "                                   attributes_labels  \\\n",
      "0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
      "1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
      "2  [[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
      "3  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
      "4  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
      "\n",
      "         accuracy_classification            accuracy_multilabel  \n",
      "0  {'matched': 11, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
      "1   {'matched': 8, 'counts': 12}  {'matched': 10, 'counts': 12}  \n",
      "2   {'matched': 8, 'counts': 12}  {'matched': 10, 'counts': 12}  \n",
      "3   {'matched': 9, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
      "4   {'matched': 7, 'counts': 12}  {'matched': 10, 'counts': 12}  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Test reimport data\n",
    "df_stats_reload = pd.read_pickle(stats_filename)\n",
    "df_test_reload = pd.read_pickle(testdata_filename)\n",
    "\n",
    "print(testdata_filename)\n",
    "print(df_stats_reload.head())\n",
    "print(df_test_reload.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1af435",
   "metadata": {},
   "source": [
    "## Plot di training & validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2c4fe674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks([x+1 for x in range(exec_params['epochs'])])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d195fa2",
   "metadata": {},
   "source": [
    "## Plot accuracy and perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cb9c6926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "act_acc = [x['action_accuracy'] for x in df_stats.metrics]\n",
    "att_acc = [x['attribute_accuracy'] for x in df_stats.metrics]\n",
    "x_ticks = [x for x in range(len(act_acc))]\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(act_acc, 'b-o', label=\"Actions\")\n",
    "plt.plot(att_acc, 'g-o', label=\"Attributes\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Actions and attributes accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.xticks(ticks = x_ticks, labels = [str(x+1) for x in x_ticks])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "abed41bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "act_per = [x['action_perplexity'] for x in df_stats.metrics]\n",
    "x_ticks = [x for x in range(len(act_acc))]\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(act_per, 'b-o')\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Actions perplexity\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Perplexity\")\n",
    "plt.xticks(ticks = x_ticks, labels = [str(x+1) for x in x_ticks])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbd6990",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
