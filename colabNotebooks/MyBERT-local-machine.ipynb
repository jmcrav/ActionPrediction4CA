{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4e26663",
   "metadata": {},
   "source": [
    "# Download GitHub repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9f42ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gian/content\n",
      "Clone in 'ActionPrediction4CA' in corso...\n",
      "remote: Enumerating objects: 383, done.\u001b[K\n",
      "remote: Counting objects: 100% (383/383), done.\u001b[K\n",
      "remote: Compressing objects: 100% (294/294), done.\u001b[K\n",
      "remote: Total 383 (delta 195), reused 262 (delta 82), pack-reused 0\u001b[K\n",
      "Ricezione degli oggetti: 100% (383/383), 47.89 MiB | 10.26 MiB/s, fatto.\n",
      "Risoluzione dei delta: 100% (195/195), fatto.\n"
     ]
    }
   ],
   "source": [
    "%cd ~/content/\n",
    "%rm -rf ~/content/ActionPrediction4CA\n",
    "%rm -rf ~/content/ActionPredictionBERT\n",
    "!git clone  --branch colab_exe https://github.com/jmcrav/ActionPrediction4CA.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36cb4f3",
   "metadata": {},
   "source": [
    "# Elimino i file inutili al modello \n",
    "Per fare il fine tuning del modello, abbiamo bisogno solo dei dati grezzi.\n",
    "Il tutor ha puntualizzato di usare SOLO lo script `simmc/mm_action_prediction/tools/extract_actions_fashion.py`, che costruisce un json con le lables associate alle azioni e agli attributi (è lo step 1 del preprocessing).\n",
    "Questo credo sia necessario perchè credo che la loro implementazione sia di un livello molto più basso di quello a cui dovremo lavorare noi.\n",
    "BERT è un metodo per effettuare il  pre-trained di modelli per il NLP di cui dobbiamo solo fare un fine-tuning accettabile, mentre il SIMMC deve addestrare un intero modello da zero(o comunque credo che il loro obiettivo sia cercare di creare un modello che riesca a funzionare bene col linguaggio multimodale.Non ho capito perchè non sia statu usato BERT anche da loro onestamente -  il task finale è diviso in 3 sottotask, e la prima è un problema di classificazione multi-classe per il quale BERT dovrebbe poter funzionare - forse perchè quella fornita è solo un implementazione di partenza e i concorrenti alla challenge hanno fornito le loro implementazioni dei modelli?). Praticamente tutte le operazioni che fanno loro sui dati credo servano ai loro dettagli implementativi di bassissimo livello; con BERT noi dovremo usare solo i metodi forniti dalla classe.\n",
    "In pratica, partendo dai dati grezzi, dobbiamo solo darli in pasto ai metodi forniti da BERT e magari lavorare un po' per migliorare i risultati, senza che sia necessario scendere fino al livello dei transformers\n",
    "\n",
    "\n",
    "**DA TENERE**\n",
    "* Output dell'extract actions\n",
    "*  `fashion_train_dials.json`:  per il training\n",
    "*  `fashion_dev_dials.json` : per la validation\n",
    "*  `fashion_teststd_dials_public.json` :per il \"report dei risultati finali\" (forse per darlo in pasto allo script di evaluation?) \n",
    "*   `fashion_metadata.json`, `fashion_devtest_dials.json` : necessari per il funzionamento dello script `extract_actions_fashion.py `\n",
    "\n",
    "**DA VERIFICARE**:\n",
    "\n",
    " forse potrebbe convenire anche usare il vocabolario che loro si costruiscono (step 2 del preprocessing) per inizializzare il Tokenizer di Bert, come fanno loro nel data loader (in `loaders/loader_simmc.py`)\n",
    " ![linea codice loader.jpg](data:image/jpeg;base64,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)\n",
    "\n",
    " Questo comando istanzia il tokenizer con una versione default o definita dall'utente (devo capire bene cosa significa, l'ho letto su https://huggingface.co/transformers/quickstart.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cd41deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gian/content/ActionPrediction4CA/tools\n",
      "/home/gian/content/ActionPrediction4CA/data/simmc_fashion\n",
      "/home/gian/content\n"
     ]
    }
   ],
   "source": [
    "%mkdir ~/content/ActionPredictionBERT ActionPredictionBERT/input_data ActionPredictionBERT/extr_output\n",
    "%cd ~/content/ActionPrediction4CA/tools\n",
    "%mv extract_actions_fashion.py ~/content/ActionPredictionBERT\n",
    "%mv action_evaluation.py ~/content/ActionPredictionBERT\n",
    "\n",
    "%cd ~/content/ActionPrediction4CA/data/simmc_fashion/\n",
    "%mv fashion_train_dials.json fashion_dev_dials.json fashion_teststd_dials_public.json fashion_metadata.json fashion_devtest_dials.json ~/content/ActionPredictionBERT/input_data\n",
    "%cd ~/content/\n",
    "%rm -rf ./ActionPrediction4CA/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c76fc6c",
   "metadata": {},
   "source": [
    "# Extract_actions_fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86671584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gian/content/ActionPredictionBERT\n",
      "Reading: ./input_data/fashion_train_dials.json\n",
      "Dialogue task Id missing: 3406\n",
      "Dialogue task Id missing: 3969\n",
      "Dialogue task Id missing: 4847\n",
      "Dialogue task Id missing: 321\n",
      "Dialogue task Id missing: 3455\n",
      "Dialogue task Id missing: 3414\n",
      "Saving: ./extr_output/fashion_train_dials_api_calls.json\n",
      "Reading: ./input_data/fashion_dev_dials.json\n",
      "Dialogue task Id missing: 2117\n",
      "Saving: ./extr_output/fashion_dev_dials_api_calls.json\n",
      "Reading: ./input_data/fashion_devtest_dials.json\n",
      "Dialogue task Id missing: 9308\n",
      "Saving: ./extr_output/fashion_devtest_dials_api_calls.json\n"
     ]
    }
   ],
   "source": [
    "%cd ~/content/ActionPredictionBERT/\n",
    "!python extract_actions_fashion.py --json_path=\"./input_data/fashion_train_dials.json ./input_data/fashion_dev_dials.json ./input_data/fashion_devtest_dials.json\" --save_root=\"./extr_output\"  --metadata_path=\"./fashion_metadata.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98da7846",
   "metadata": {},
   "source": [
    "# Notebook originale\n",
    "Script copiato dal colab di Chris McCormick e Nick Ryan\n",
    "https://colab.research.google.com/drive/1pTuQhug6Dhl9XalKB0zUGf4FIdYFlpcX#scrollTo=nSU7yERLP_66"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34794cb2",
   "metadata": {},
   "source": [
    "## 1.2. Installing the Hugging Face Library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1b3c76",
   "metadata": {},
   "source": [
    "\n",
    "Next, let's install the [transformers](https://github.com/huggingface/transformers) package from Hugging Face which will give us a pytorch interface for working with BERT. (This library contains interfaces for other pretrained language models like OpenAI's GPT and GPT-2.) We've selected the pytorch interface because it strikes a nice balance between the high-level APIs (which are easy to use but don't provide insight into how things work) and tensorflow code (which contains lots of details but often sidetracks us into lessons about tensorflow, when the purpose here is BERT!).\n",
    "\n",
    "At the moment, the Hugging Face library seems to be the most widely accepted and powerful pytorch interface for working with BERT. In addition to supporting a variety of different pre-trained transformer models, the library also includes pre-built modifications of these models suited to your specific task. For example, in this tutorial we will use `BertForSequenceClassification`.\n",
    "\n",
    "The library also includes task-specific classes for token classification, question answering, next sentence prediciton, etc. Using these pre-built classes simplifies the process of modifying BERT for your purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a541709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install markdown\n",
    "#!pip install transformers\n",
    "#!pip install pandas\n",
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e9d8d0",
   "metadata": {},
   "source": [
    "# Impostazione parametri esecuzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2024f1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_params = {\n",
    "    'batch': 12,\n",
    "    'epochs': 10,\n",
    "    'hidden_output_dim': 256,\n",
    "    'seed': 193598,\n",
    "    'learning_rate': 5e-5,\n",
    "    'tolerance': 1e-8\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d9eda3",
   "metadata": {},
   "source": [
    "# Analisi Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4f4432",
   "metadata": {},
   "source": [
    "## train_dials\n",
    "\n",
    "Dati grezzi da preprocessare con lo script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7f4abad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "      <th>dialogue_idx</th>\n",
       "      <th>domains</th>\n",
       "      <th>dialogue_task_id</th>\n",
       "      <th>dialogue_coref_map.1426</th>\n",
       "      <th>dialogue_coref_map.1429</th>\n",
       "      <th>dialogue_coref_map.708</th>\n",
       "      <th>dialogue_coref_map.712</th>\n",
       "      <th>dialogue_coref_map.2401</th>\n",
       "      <th>dialogue_coref_map.2402</th>\n",
       "      <th>...</th>\n",
       "      <th>dialogue_coref_map.2335</th>\n",
       "      <th>dialogue_coref_map.713</th>\n",
       "      <th>dialogue_coref_map.1507</th>\n",
       "      <th>dialogue_coref_map.1509</th>\n",
       "      <th>dialogue_coref_map.949</th>\n",
       "      <th>dialogue_coref_map.1137</th>\n",
       "      <th>dialogue_coref_map.1872</th>\n",
       "      <th>dialogue_coref_map.1873</th>\n",
       "      <th>dialogue_coref_map.1753</th>\n",
       "      <th>dialogue_coref_map.834</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'belief_state': [{'act': 'DA:ASK:CHECK:CLOTH...</td>\n",
       "      <td>3094</td>\n",
       "      <td>[fashion]</td>\n",
       "      <td>1785.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'belief_state': [{'act': 'DA:INFORM:PREFER:C...</td>\n",
       "      <td>822</td>\n",
       "      <td>[fashion]</td>\n",
       "      <td>1720.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'belief_state': [{'act': 'DA:REQUEST:GET:CLO...</td>\n",
       "      <td>7411</td>\n",
       "      <td>[fashion]</td>\n",
       "      <td>2038.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'belief_state': [{'act': 'DA:INFORM:DISPREFE...</td>\n",
       "      <td>7029</td>\n",
       "      <td>[fashion]</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'belief_state': [{'act': 'DA:INFORM:DISPREFE...</td>\n",
       "      <td>1506</td>\n",
       "      <td>[fashion]</td>\n",
       "      <td>1686.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1648 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            dialogue  dialogue_idx    domains  \\\n",
       "0  [{'belief_state': [{'act': 'DA:ASK:CHECK:CLOTH...          3094  [fashion]   \n",
       "1  [{'belief_state': [{'act': 'DA:INFORM:PREFER:C...           822  [fashion]   \n",
       "2  [{'belief_state': [{'act': 'DA:REQUEST:GET:CLO...          7411  [fashion]   \n",
       "3  [{'belief_state': [{'act': 'DA:INFORM:DISPREFE...          7029  [fashion]   \n",
       "4  [{'belief_state': [{'act': 'DA:INFORM:DISPREFE...          1506  [fashion]   \n",
       "\n",
       "   dialogue_task_id  dialogue_coref_map.1426  dialogue_coref_map.1429  \\\n",
       "0            1785.0                      0.0                      1.0   \n",
       "1            1720.0                      NaN                      NaN   \n",
       "2            2038.0                      NaN                      NaN   \n",
       "3            2011.0                      NaN                      NaN   \n",
       "4            1686.0                      NaN                      NaN   \n",
       "\n",
       "   dialogue_coref_map.708  dialogue_coref_map.712  dialogue_coref_map.2401  \\\n",
       "0                     NaN                     NaN                      NaN   \n",
       "1                     0.0                     1.0                      NaN   \n",
       "2                     NaN                     NaN                      4.0   \n",
       "3                     NaN                     NaN                      NaN   \n",
       "4                     NaN                     NaN                      NaN   \n",
       "\n",
       "   dialogue_coref_map.2402  ...  dialogue_coref_map.2335  \\\n",
       "0                      NaN  ...                      NaN   \n",
       "1                      NaN  ...                      NaN   \n",
       "2                      0.0  ...                      NaN   \n",
       "3                      NaN  ...                      NaN   \n",
       "4                      NaN  ...                      NaN   \n",
       "\n",
       "   dialogue_coref_map.713  dialogue_coref_map.1507  dialogue_coref_map.1509  \\\n",
       "0                     NaN                      NaN                      NaN   \n",
       "1                     NaN                      NaN                      NaN   \n",
       "2                     NaN                      NaN                      NaN   \n",
       "3                     NaN                      NaN                      NaN   \n",
       "4                     NaN                      NaN                      NaN   \n",
       "\n",
       "   dialogue_coref_map.949  dialogue_coref_map.1137  dialogue_coref_map.1872  \\\n",
       "0                     NaN                      NaN                      NaN   \n",
       "1                     NaN                      NaN                      NaN   \n",
       "2                     NaN                      NaN                      NaN   \n",
       "3                     NaN                      NaN                      NaN   \n",
       "4                     NaN                      NaN                      NaN   \n",
       "\n",
       "   dialogue_coref_map.1873  dialogue_coref_map.1753  dialogue_coref_map.834  \n",
       "0                      NaN                      NaN                     NaN  \n",
       "1                      NaN                      NaN                     NaN  \n",
       "2                      NaN                      NaN                     NaN  \n",
       "3                      NaN                      NaN                     NaN  \n",
       "4                      NaN                      NaN                     NaN  \n",
       "\n",
       "[5 rows x 1648 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prima parte del fashion_train_dials\n",
    "import json \n",
    "import pandas as pd\n",
    "with open ('./input_data/fashion_train_dials.json',\"r\") as f:\n",
    "   data= json.load(f)\n",
    "\n",
    "result=[]\n",
    "row ={}\n",
    "for k in data:\n",
    "  row[k] = data[k]\n",
    "# []\n",
    "#prima parte del fashion_train_dials\n",
    "import json \n",
    "import pandas as pd\n",
    "with open ('./input_data/fashion_train_dials.json',\"r\") as f:\n",
    "   data= json.load(f)\n",
    "\n",
    "result=[]\n",
    "row ={}\n",
    "for k in data:\n",
    "  row[k] = data[k]\n",
    "# []\n",
    "\n",
    "dialogue_data = pd.json_normalize(row['dialogue_data'])\n",
    "type(dialogue_data)\n",
    "# dialogue = dialogue_data[\"dialogue\"]\n",
    "# for x in dialogue.head(1):\n",
    "#   display(x)\n",
    "# #dialogue.head(1)\n",
    "dialogue_data.head()\n",
    "\n",
    "\n",
    "\n",
    "dialogue_data = pd.json_normalize(row['dialogue_data'])\n",
    "type(dialogue_data)\n",
    "# dialogue = dialogue_data[\"dialogue\"]\n",
    "# for x in dialogue.head(1):\n",
    "#   display(x)\n",
    "# #dialogue.head(1)\n",
    "dialogue_data.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "625e5f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>image_ids</th>\n",
       "      <th>focus_image</th>\n",
       "      <th>memory_images</th>\n",
       "      <th>database_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2042</td>\n",
       "      <td>[2441, 2442, 2443, 2444, 2445, 2446, 2447, 244...</td>\n",
       "      <td>2441</td>\n",
       "      <td>[2442, 2443, 2444]</td>\n",
       "      <td>[2445, 2446, 2447, 2448, 2449, 2450]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2041</td>\n",
       "      <td>[2431, 2432, 2433, 2434, 2435, 2436, 2437, 243...</td>\n",
       "      <td>2431</td>\n",
       "      <td>[2432, 2433, 2434]</td>\n",
       "      <td>[2435, 2436, 2437, 2438, 2439, 2440]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2040</td>\n",
       "      <td>[2421, 2422, 2423, 2424, 2425, 2426, 2427, 242...</td>\n",
       "      <td>2421</td>\n",
       "      <td>[2422, 2423, 2424]</td>\n",
       "      <td>[2425, 2426, 2427, 2428, 2429, 2430]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2039</td>\n",
       "      <td>[2411, 2412, 2413, 2414, 2415, 2416, 2417, 241...</td>\n",
       "      <td>2411</td>\n",
       "      <td>[2412, 2413, 2414]</td>\n",
       "      <td>[2415, 2416, 2417, 2418, 2419, 2420]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2038</td>\n",
       "      <td>[2401, 2402, 2403, 2404, 2405, 2406, 2407, 240...</td>\n",
       "      <td>2401</td>\n",
       "      <td>[2402, 2403, 2404]</td>\n",
       "      <td>[2405, 2406, 2407, 2408, 2409, 2410]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   task_id                                          image_ids  focus_image  \\\n",
       "0     2042  [2441, 2442, 2443, 2444, 2445, 2446, 2447, 244...         2441   \n",
       "1     2041  [2431, 2432, 2433, 2434, 2435, 2436, 2437, 243...         2431   \n",
       "2     2040  [2421, 2422, 2423, 2424, 2425, 2426, 2427, 242...         2421   \n",
       "3     2039  [2411, 2412, 2413, 2414, 2415, 2416, 2417, 241...         2411   \n",
       "4     2038  [2401, 2402, 2403, 2404, 2405, 2406, 2407, 240...         2401   \n",
       "\n",
       "        memory_images                       database_images  \n",
       "0  [2442, 2443, 2444]  [2445, 2446, 2447, 2448, 2449, 2450]  \n",
       "1  [2432, 2433, 2434]  [2435, 2436, 2437, 2438, 2439, 2440]  \n",
       "2  [2422, 2423, 2424]  [2425, 2426, 2427, 2428, 2429, 2430]  \n",
       "3  [2412, 2413, 2414]  [2415, 2416, 2417, 2418, 2419, 2420]  \n",
       "4  [2402, 2403, 2404]  [2405, 2406, 2407, 2408, 2409, 2410]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#seconda parte del fashion_train_dials\n",
    "task_mapping = pd.json_normalize(row['task_mapping'])\n",
    "task_mapping.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9867cff",
   "metadata": {},
   "source": [
    "## dev_dials_api_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d5d29b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialog_id</th>\n",
       "      <th>actions</th>\n",
       "      <th>focus_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4146</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'None', 'action_sup...</td>\n",
       "      <td>[1646, 1646, 1646, 1649, 1649, 1649, 1649]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4260</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...</td>\n",
       "      <td>[2161, 2161, 2161, 2161]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8022</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SearchDatabase', '...</td>\n",
       "      <td>[1971, 1972, 1972, 1972, 1977, 1978]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4992</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'None', 'action_sup...</td>\n",
       "      <td>[1931, 1931, 1936, 1936, 1936]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5606</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'None', 'action_sup...</td>\n",
       "      <td>[1931, 1931, 1931, 1931, 1931]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dialog_id                                            actions  \\\n",
       "0       4146  [{'turn_idx': 0, 'action': 'None', 'action_sup...   \n",
       "1       4260  [{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...   \n",
       "2       8022  [{'turn_idx': 0, 'action': 'SearchDatabase', '...   \n",
       "3       4992  [{'turn_idx': 0, 'action': 'None', 'action_sup...   \n",
       "4       5606  [{'turn_idx': 0, 'action': 'None', 'action_sup...   \n",
       "\n",
       "                                 focus_images  \n",
       "0  [1646, 1646, 1646, 1649, 1649, 1649, 1649]  \n",
       "1                    [2161, 2161, 2161, 2161]  \n",
       "2        [1971, 1972, 1972, 1972, 1977, 1978]  \n",
       "3              [1931, 1931, 1936, 1936, 1936]  \n",
       "4              [1931, 1931, 1931, 1931, 1931]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dev_dials_api = pd.read_json('./extr_output/fashion_dev_dials_api_calls.json')\n",
    "dev_dials_api.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b899ff34",
   "metadata": {},
   "source": [
    "## devtest_dials_api_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f9c6435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialog_id</th>\n",
       "      <th>actions</th>\n",
       "      <th>focus_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2494</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SearchDatabase', '...</td>\n",
       "      <td>[1836, 1841, 1841, 1841, 1841]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3731</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SearchDatabase', '...</td>\n",
       "      <td>[1676, 1681, 1681, 1683, 1683]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8546</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...</td>\n",
       "      <td>[840, 840, 840, 849, 849, 843]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5590</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SearchDatabase', '...</td>\n",
       "      <td>[1616, 1618, 1618, 1618, 1618]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5452</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...</td>\n",
       "      <td>[2231, 2231, 2231, 2236, 2236]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dialog_id                                            actions  \\\n",
       "0       2494  [{'turn_idx': 0, 'action': 'SearchDatabase', '...   \n",
       "1       3731  [{'turn_idx': 0, 'action': 'SearchDatabase', '...   \n",
       "2       8546  [{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...   \n",
       "3       5590  [{'turn_idx': 0, 'action': 'SearchDatabase', '...   \n",
       "4       5452  [{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...   \n",
       "\n",
       "                     focus_images  \n",
       "0  [1836, 1841, 1841, 1841, 1841]  \n",
       "1  [1676, 1681, 1681, 1683, 1683]  \n",
       "2  [840, 840, 840, 849, 849, 843]  \n",
       "3  [1616, 1618, 1618, 1618, 1618]  \n",
       "4  [2231, 2231, 2231, 2236, 2236]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "devtest_dials_api = pd.read_json('./extr_output/fashion_devtest_dials_api_calls.json')\n",
    "devtest_dials_api.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3ba47e",
   "metadata": {},
   "source": [
    "## Funzione generazione dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe1973e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def createDataframe(json_file):\n",
    "  with open(json_file) as f:\n",
    "    dictftdac = json.load(f)\n",
    "\n",
    "  data = []\n",
    "\n",
    "  for e in dictftdac:\n",
    "    dialog_id = e['dialog_id']\n",
    "    actions = e['actions']\n",
    "    focus_images = e['focus_images']\n",
    "\n",
    "    for a in actions:\n",
    "      \n",
    "      turn_idx = a['turn_idx']\n",
    "      action = a['action']\n",
    "      action_supervision = a['action_supervision']\n",
    "      transcript = a['transcript']\n",
    "      transcript_annotated = a['transcript_annotated']\n",
    "      system_transcript = a['system_transcript']\n",
    "      system_transcript_annotated = a['system_transcript_annotated']\n",
    "\n",
    "      row = {\n",
    "          \"dialog_id\" : dialog_id,\n",
    "          'turn_idx' : turn_idx,\n",
    "          'action' : action,\n",
    "          'action_supervision' : action_supervision,\n",
    "          'focus_images' : focus_images,\n",
    "          'transcript': transcript,\n",
    "          'transcript_annotated': transcript_annotated,\n",
    "          'system_transcript': system_transcript,\n",
    "          'system_transcript_annotated':system_transcript_annotated,\n",
    "          'previous_transcript': \"\",\n",
    "          'previous_system_transcript': \"\"\n",
    "      }\n",
    "      if (action_supervision != None):\n",
    "        if 'focus' in action_supervision:\n",
    "          acsf = {'focus':action_supervision['focus']}\n",
    "        else:\n",
    "          acsf = {'focus':None}\n",
    "        \n",
    "        if 'attributes' in action_supervision:\n",
    "          acsa = {'attributes':action_supervision['attributes']}\n",
    "        else:\n",
    "          acsa = {'attributes':[]}\n",
    "      else:\n",
    "          acsf = {'focus':None}\n",
    "          acsa = {'attributes':[]}\n",
    "      \n",
    "        \n",
    "      row.update(acsf)\n",
    "      row.update(acsa)\n",
    "    \n",
    "      data.append(row)\n",
    "\n",
    "  # Conservo id turno e risposta sistema per provare a implementare una soluzione articolata\n",
    "  df = pd.DataFrame(data,columns=['dialog_id','turn_idx','transcript','action','attributes', 'system_transcript','transcript_annotated','system_transcript_annotated','previous_transcript','previous_system_transcript'])\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a30c6d",
   "metadata": {},
   "source": [
    "## train_dials_api_calls with transcript\n",
    "Dati per il training che usiamo ( per ora semplificati)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9d78e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  21196  elementi\n"
     ]
    }
   ],
   "source": [
    "df_training = createDataframe('./extr_output/fashion_train_dials_api_calls.json')\n",
    "print(\"Training: \",len(df_training),\" elementi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e542c9",
   "metadata": {},
   "source": [
    "## fashion_dev_dials_api_calls\n",
    "Dati per la validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d7d98f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:  3513  elementi\n"
     ]
    }
   ],
   "source": [
    "df_validation = createDataframe('./extr_output/fashion_dev_dials_api_calls.json')\n",
    "print(\"Validation: \",len(df_validation),\" elementi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f272d647",
   "metadata": {},
   "source": [
    "## fashion_devtest_dials_api_calls\n",
    "Dati per la valutazione delle performance del modello (test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8e22d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  5397  elementi\n"
     ]
    }
   ],
   "source": [
    "df_test = createDataframe('./extr_output/fashion_devtest_dials_api_calls.json')\n",
    "print(\"Test: \",len(df_test),\" elementi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc25d11d",
   "metadata": {},
   "source": [
    "# BERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4c901c",
   "metadata": {},
   "source": [
    "## Scelta tipo input\n",
    "\n",
    "Il valore di questa variabile determinerà se utilizzare i singoli transcript, o se concatenare ogni transcript a quello successivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef5cc083",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_next = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d30106",
   "metadata": {},
   "source": [
    "## Preparazione input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e090913a",
   "metadata": {},
   "source": [
    "### Generazione colonna previous_transcript\n",
    "\n",
    "Generazione della colonna contenente la frase del turno successivo del dialogo (se presente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fb54823",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "df_training.sort_values(by=['dialog_id', 'turn_idx'])\n",
    "for i in range(1,(len(df_training))):\n",
    "  if(i<(len(df_training)) and  df_training['dialog_id'][i] == df_training['dialog_id'][i-1]):\n",
    "    df_training.loc[i,'previous_transcript'] = df_training['transcript'][i-1]\n",
    "    df_training.loc[i,'previous_system_transcript'] = df_training['system_transcript'][i-1]\n",
    "\n",
    "#Validation\n",
    "df_validation.sort_values(by=['dialog_id', 'turn_idx'])\n",
    "for i in range(1,(len(df_validation))):\n",
    "  if(i<(len(df_validation)) and  df_validation['dialog_id'][i] == df_validation['dialog_id'][i-1]):\n",
    "    df_validation.loc[i,'previous_transcript'] = df_validation['transcript'][i-1]\n",
    "    df_validation.loc[i,'previous_system_transcript'] = df_validation['system_transcript'][i-1]\n",
    "\n",
    "#Evaluation\n",
    "df_test.sort_values(by=['dialog_id', 'turn_idx'])\n",
    "for i in range(1,(len(df_test))):\n",
    "  if(i<(len(df_test)) and  df_test['dialog_id'][i] == df_test['dialog_id'][i-1]):\n",
    "    df_test.loc[i,'previous_transcript'] = df_test['transcript'][i-1]\n",
    "    df_test.loc[i,'previous_system_transcript'] = df_test['system_transcript'][i-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb106a56",
   "metadata": {},
   "source": [
    "### Estrazione vettori colonna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78177045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de95a8f0",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f65ef34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA:\n",
      " Original:  Is there a pattern on this one? It's hard to see in the image.\n",
      "Tokenized:  ['is', 'there', 'a', 'pattern', 'on', 'this', 'one', '?', 'it', \"'\", 's', 'hard', 'to', 'see', 'in', 'the', 'image', '.']\n",
      "Token IDs:  [2003, 2045, 1037, 5418, 2006, 2023, 2028, 1029, 2009, 1005, 1055, 2524, 2000, 2156, 1999, 1996, 3746, 1012]\n"
     ]
    }
   ],
   "source": [
    "transcripts_tr = df_training.transcript.values\n",
    "previous_transcript_tr = df_training.previous_transcript.values\n",
    "previous_system_transcript_tr = df_training.previous_system_transcript.values\n",
    "action_labels_tr = df_training.action.values\n",
    "attributes_labels_tr=df_training.attributes.values\n",
    "\n",
    "print (\"TRAINING DATA:\")\n",
    "# Print the original sentence.\n",
    "print(' Original: ', transcripts_tr[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(transcripts_tr[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(transcripts_tr[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b5da556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T: Is there a pattern on this one? It's hard to see in the image. | PT:  | PST: \n",
      "T: That's fancy. Do you have anything in warmer colors like yellow or red? | PT: Is there a pattern on this one? It's hard to see in the image. | PST: I don't have any information on the pattern, but it has pointelle embellishments.\n",
      "T: Yeah, that sounds good. | PT: That's fancy. Do you have anything in warmer colors like yellow or red? | PST: I have a crew neck sweater in red, would you like to see it?\n",
      "T: Oh, I love that. Please tell me you have a small. | PT: Yeah, that sounds good. | PST: This is $187 from Downtown Stylists with a 3.62 rating.\n",
      "T: Yes, please! Thank you for your help with this | PT: Oh, I love that. Please tell me you have a small. | PST: It does come in small, shall I put one in your cart?\n",
      "T: How nice! Does this come in other colors? | PT:  | PST: \n",
      "T: Oh well.  Can you show me a dress that comes in red? | PT: How nice! Does this come in other colors? | PST: No, I'm sorry, It comes only in blue.\n",
      "T: Cute! Do these come in Small? | PT: Oh well.  Can you show me a dress that comes in red? | PST: This dress comes in many colors, including a bright red and a pinkish-red. What do you think?\n",
      "T: Awesome. Would you add a red one in S to my cart please? | PT: Cute! Do these come in Small? | PST: Yes, they do!\n",
      "T: That's all. Thanks! | PT: Awesome. Would you add a red one in S to my cart please? | PST: The red one is in your cart. Is there anything else I can find for you?\n"
     ]
    }
   ],
   "source": [
    "for k in range(0,10):\n",
    "  print(f\"T: {transcripts_tr[k]} | PT: {previous_transcript_tr[k]} | PST: {previous_system_transcript_tr[k]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef35705",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcd4e529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION DATA:\n",
      " Original:  What's the price of this sweater compared to the other blue and gray one I looked at?\n",
      "Tokenized:  ['what', \"'\", 's', 'the', 'price', 'of', 'this', 'sweater', 'compared', 'to', 'the', 'other', 'blue', 'and', 'gray', 'one', 'i', 'looked', 'at', '?']\n",
      "Token IDs:  [2054, 1005, 1055, 1996, 3976, 1997, 2023, 14329, 4102, 2000, 1996, 2060, 2630, 1998, 3897, 2028, 1045, 2246, 2012, 1029]\n",
      "Dialog IDs: [4146 4146 4146 4146 4146 4146 4146 4260 4260 4260 4260 8022 8022 8022\n",
      " 8022 8022 8022 4992 4992 4992]\n",
      "Turn IDs: [0 1 2 3 4 5 6 0 1 2 3 0 1 2 3 4 5 0 1 2]\n"
     ]
    }
   ],
   "source": [
    "transcripts_vd = df_validation.transcript.values\n",
    "previous_transcript_vd = df_validation.previous_transcript.values\n",
    "previous_system_transcript_vd = df_validation.previous_system_transcript.values\n",
    "action_labels_vd = df_validation.action.values\n",
    "attributes_labels_vd=df_validation.attributes.values\n",
    "dialog_ids_vd = df_validation.dialog_id.values\n",
    "turn_idxs_vd = df_validation.turn_idx.values\n",
    "\n",
    "print (\"VALIDATION DATA:\")\n",
    "\n",
    "# Print the original sentence.\n",
    "print(' Original: ', transcripts_vd[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(transcripts_vd[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(transcripts_vd[0])))\n",
    "\n",
    "# Print the dialog ids.\n",
    "print(f\"Dialog IDs: {dialog_ids_vd[0:20]}\")\n",
    "\n",
    "# Print the turn idxs.\n",
    "print(f\"Turn IDs: {turn_idxs_vd[0:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba6e6ef",
   "metadata": {},
   "source": [
    "#### Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "886bcaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATION DATA:\n",
      " Original:  That looks a little too light for what I need, do you have something else with a high customer rating?\n",
      "Tokenized:  ['that', 'looks', 'a', 'little', 'too', 'light', 'for', 'what', 'i', 'need', ',', 'do', 'you', 'have', 'something', 'else', 'with', 'a', 'high', 'customer', 'rating', '?']\n",
      "Token IDs:  [2008, 3504, 1037, 2210, 2205, 2422, 2005, 2054, 1045, 2342, 1010, 2079, 2017, 2031, 2242, 2842, 2007, 1037, 2152, 8013, 5790, 1029]\n",
      "Dialog IDs: [2494 2494 2494 2494 2494 3731 3731 3731 3731 3731 8546 8546 8546 8546\n",
      " 8546 8546 5590 5590 5590 5590]\n",
      "Turn IDs: [0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 5 0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "transcripts_tst = df_test.transcript.values\n",
    "previous_transcript_tst = df_test.previous_transcript.values\n",
    "previous_system_transcript_tst = df_test.previous_system_transcript.values\n",
    "action_labels_tst = df_test.action.values\n",
    "attributes_labels_tst=df_test.attributes.values\n",
    "dialog_ids_tst = df_test.dialog_id.values\n",
    "turn_idxs_tst = df_test.turn_idx.values\n",
    "\n",
    "print (\"EVALUATION DATA:\")\n",
    "\n",
    "# Print the original sentence.\n",
    "print(' Original: ', transcripts_tst[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(transcripts_tst[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(transcripts_tst[0])))\n",
    "\n",
    "# Print the dialog ids.\n",
    "print(f\"Dialog IDs: {dialog_ids_tst[0:20]}\")\n",
    "\n",
    "# Print the turn idxs.\n",
    "print(f\"Turn IDs: {turn_idxs_tst[0:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c049bbf",
   "metadata": {},
   "source": [
    "## Calcolo dimensione massima\n",
    "\n",
    "The above code left out a few required formatting steps that we'll look at here.\n",
    "\n",
    "We are required to:\n",
    "1. Add special tokens to the start and end of each sentence.\n",
    "2. Pad & truncate all sentences to a single constant length.\n",
    "3. Explicitly differentiate real tokens from padding tokens with the \"attention mask\".\n",
    "\n",
    "\n",
    "The sentences in our dataset obviously have varying lengths, so how does BERT handle this?\n",
    "\n",
    "BERT has two constraints:\n",
    "\n",
    "\n",
    "1.   All sentences must be padded or truncated to a single, fixed length.\n",
    "2.   The maximum sentence length is 512 tokens.\n",
    "\n",
    "\n",
    "Padding is done with a special [PAD] token, which is at index 0 in the BERT vocabulary. The below illustration demonstrates padding out to a \"MAX_LEN\" of 8 tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c16396",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8e5132e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max transcript length for training:  177\n"
     ]
    }
   ],
   "source": [
    "max_len_tr = 0\n",
    "\n",
    "# For every sentence...\n",
    "for i in range(0,len(transcripts_tr)):\n",
    "    \n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "\n",
    "    if (previous_transcript_tr[i] != \"\" and use_next):\n",
    "      input_ids = tokenizer.encode(previous_transcript_tr[i]+ \" \" + previous_system_transcript_tr[i],transcripts_tr[i], add_special_tokens=True)\n",
    "    else:\n",
    "      input_ids = tokenizer.encode(transcripts_tr[i], add_special_tokens=True)\n",
    "        \n",
    "    # Update the maximum sentence length.\n",
    "    max_len_tr = max(max_len_tr, len(input_ids))\n",
    "\n",
    "print('Max transcript length for training: ', max_len_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17363e3c",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92914388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max transcript length for validation:  133\n"
     ]
    }
   ],
   "source": [
    "max_len_vd = 0\n",
    "\n",
    "# For every sentence...\n",
    "for i in range(0,len(transcripts_vd)):\n",
    "\n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    if (previous_transcript_vd[i] != \"\" and use_next):\n",
    "      input_ids = tokenizer.encode(previous_transcript_vd[i]+ \" \" + previous_system_transcript_vd[i],transcripts_vd[i], add_special_tokens=True)\n",
    "    else:\n",
    "      input_ids = tokenizer.encode(transcripts_vd[i], add_special_tokens=True)\n",
    "    \n",
    "    # Update the maximum sentence length.\n",
    "    max_len_vd = max(max_len_vd, len(input_ids))\n",
    "\n",
    "print('Max transcript length for validation: ', max_len_vd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3412aa8",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aab75df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max transcript length for evaluation:  150\n"
     ]
    }
   ],
   "source": [
    "max_len_tst = 0\n",
    "\n",
    "#non sono sicuro che il controllo della lunghezza vada fatto anche sul test set, dopo la performance non è determinata\n",
    "#dalla conoscenza del test set?\n",
    "#è anche vero che in teoria per far funzionare BERT bisogna dargli in pasto dei dati tokenizzati, quindi in un caso reale il nostro\n",
    "#model non potrebbe prendere in ingresso del testo non trattato. Nel dubbio ho controllato le dimensioni\n",
    "\n",
    "for i in range(0,len(transcripts_tst)):\n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    if (previous_transcript_tst[i] != \"\" and use_next):\n",
    "      input_ids = tokenizer.encode(previous_transcript_tst[i]+ \" \" + previous_system_transcript_tst[i],transcripts_tst[i], add_special_tokens=True)\n",
    "    else:\n",
    "      input_ids = tokenizer.encode(transcripts_tst[i], add_special_tokens=True)\n",
    "\n",
    "    # Update the maximum sentence length.\n",
    "    max_len_tst = max(max_len_tst, len(input_ids))\n",
    "\n",
    "print(\"Max transcript length for evaluation: \",max_len_tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c277f0",
   "metadata": {},
   "source": [
    "### Risultato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26bd8ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La massima lunghezza dei token da gestire è quindi  177\n"
     ]
    }
   ],
   "source": [
    "max_len = max(max_len_tr, max_len_vd, max_len_tst)\n",
    "\n",
    "# if (max_len_tr >= max_len_vd):\n",
    "#   max_len = max_len_tr\n",
    "# else:\n",
    "#   max_len = max_len_vd\n",
    "# if (max_len_tst >= max_len):\n",
    "#   max_len = max_len_tst\n",
    "\n",
    "print(\"La massima lunghezza dei token da gestire è quindi \",max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcefd1f1",
   "metadata": {},
   "source": [
    "## Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54bc7c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "[('availableSizes',)]\n",
      "['ageRange' 'amountInStock' 'availableSizes' 'brand' 'clothingCategory'\n",
      " 'clothingStyle' 'color' 'customerRating' 'dressStyle' 'embellishment'\n",
      " 'forGender' 'forOccasion' 'hasPart' 'hemLength' 'hemStyle' 'info'\n",
      " 'jacketStyle' 'madeIn' 'material' 'necklineStyle' 'pattern' 'price'\n",
      " 'sequential' 'size' 'skirtLength' 'skirtStyle' 'sleeveLength'\n",
      " 'sleeveStyle' 'soldBy' 'sweaterStyle' 'waistStyle' 'warmthRating'\n",
      " 'waterResistance']\n",
      "Totale: 30106, Training: 21196, Validation: 3513, Evaluation: 5397\n",
      "Training: 21196, Validation: 3513, Evaluation: 5397\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "attributes_labels_all = np.concatenate((attributes_labels_tr, attributes_labels_vd,attributes_labels_tst), axis=None)\n",
    "attr_yt = mlb.fit_transform(attributes_labels_all)\n",
    "print(attr_yt[0:15])\n",
    "print(mlb.inverse_transform(attr_yt[3].reshape(1, -1)))\n",
    "print(mlb.classes_)\n",
    "print(f\"Totale: {len(attr_yt)}, Training: {len(attributes_labels_tr)}, Validation: {len(attributes_labels_vd)}, Evaluation: {len(attributes_labels_tst)}\")\n",
    "attributes_labels_tr_vect = attr_yt[0:len(attributes_labels_tr)]\n",
    "attributes_labels_vd_vect = attr_yt[len(attributes_labels_tr):(len(attributes_labels_tr)+len(attributes_labels_vd))]\n",
    "attributes_labels_tst_vect = attr_yt[(len(attributes_labels_tr)+len(attributes_labels_vd)):]\n",
    "print(f\"Training: {len(attributes_labels_tr_vect)}, Validation: {len(attributes_labels_vd_vect)}, Evaluation: {len(attributes_labels_tst_vect)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63925873",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9505e37",
   "metadata": {},
   "source": [
    "Now we're ready to perform the real tokenization.\n",
    "\n",
    "The tokenizer.encode_plus function combines multiple steps for us:\n",
    "\n",
    "Split the sentence into tokens.\n",
    "Add the special [CLS] and [SEP] tokens.\n",
    "Map the tokens to their IDs.\n",
    "Pad or truncate all sentences to the same length.\n",
    "Create the attention masks which explicitly differentiate real tokens from [PAD] tokens.\n",
    "The first four features are in tokenizer.encode, but I'm using tokenizer.encode_plus to get the fifth item (attention masks). Documentation is here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aff8d187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff7a6c74350>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "# backends cudnn for out memory not necessary (resolved by batch size)\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "# torch.backends.cudnn.enabled = True\n",
    "# Set torch seed for deterministic behaviour\n",
    "torch.manual_seed(exec_params['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45855e8f",
   "metadata": {},
   "source": [
    "### Tokenize Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e32c330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21196 records to encode.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gian/anaconda3/envs/testcuda1/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2126: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING : \n",
      "Original:  Is there a pattern on this one? It's hard to see in the image.\n",
      "Token IDs: tensor([ 101, 2003, 2045, 1037, 5418, 2006, 2023, 2028, 1029, 2009, 1005, 1055,\n",
      "        2524, 2000, 2156, 1999, 1996, 3746, 1012,  102,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "\n",
    "#dobbiamo convertire le nostre lables da string a valori numerici, usiamo il metodo fornito da sklearn\n",
    "\n",
    "#TRAINING DATASET\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "action_labels_encoded_tr = le.fit_transform(action_labels_tr)\n",
    "\n",
    "input_ids_tr = []\n",
    "attention_masks_tr = []\n",
    "print(f\"{len(df_training)} records to encode.\")\n",
    "# For every sentence...\n",
    "for i in range(0,len(df_training)):\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "\n",
    "  if (previous_transcript_tr[i] != \"\" and use_next):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        previous_transcript_tr[i]+ \" \" + previous_system_transcript_tr[i],  # Sentence to encode.\n",
    "                        transcripts_tr[i], #next sentece to encode\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        truncation = True,\n",
    "                        max_length = max_len,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                    )\n",
    "  else:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        transcripts_tr[i],  # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        truncation = True,\n",
    "                        max_length = max_len,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                    )\n",
    "    \n",
    "\n",
    "    \n",
    "  # Add the encoded sentence to the list.    \n",
    "  input_ids_tr.append(encoded_dict['input_ids'])\n",
    "\n",
    "  # And its attention mask (simply differentiates padding from non-padding).\n",
    "  attention_masks_tr.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids_tr = torch.cat(input_ids_tr, dim=0)\n",
    "attention_masks_tr = torch.cat(attention_masks_tr, dim=0)\n",
    "labels_actions_tr = torch.tensor(action_labels_encoded_tr)\n",
    "labels_attributes_tr = torch.tensor(attributes_labels_tr_vect) \n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print (\"TRAINING : \")\n",
    "if (use_next):\n",
    "  print('Original: ', transcripts_tr[0])\n",
    "else:\n",
    "  print('Original: ', transcripts_tr[0])\n",
    "print('Token IDs:', input_ids_tr[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cda4541",
   "metadata": {},
   "source": [
    "### Tokenize Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5da13a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3513 records to encode.\n",
      "VALIDATION : \n",
      "Original:  What's the price of this sweater compared to the other blue and gray one I looked at?\n",
      "Token IDs: tensor([  101,  2054,  1005,  1055,  1996,  3976,  1997,  2023, 14329,  4102,\n",
      "         2000,  1996,  2060,  2630,  1998,  3897,  2028,  1045,  2246,  2012,\n",
      "         1029,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0])\n",
      "Dialog IDs: tensor([4146, 4146, 4146, 4146, 4146, 4146, 4146, 4260, 4260, 4260, 4260, 8022,\n",
      "        8022, 8022, 8022, 8022, 8022, 4992, 4992, 4992])\n",
      "Turn IDXs: tensor([0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 0, 1, 2, 3, 4, 5, 0, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "\n",
    "#dobbiamo convertire le nostre lables da string a valori numerici, usiamo il metodo fornito da sklearn\n",
    "\n",
    "#VALIDATION DATASET\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "action_labels_encoded_vd = le.fit_transform(action_labels_vd)\n",
    "\n",
    "input_ids_vd = []\n",
    "attention_masks_vd = []\n",
    "print(f\"{len(df_validation)} records to encode.\")\n",
    "# For every sentence...\n",
    "for i in range(0,len(df_validation)):\n",
    "  # `encode_plus` will:\n",
    "  #   (1) Tokenize the sentence.\n",
    "  #   (2) Prepend the `[CLS]` token to the start.\n",
    "  #   (3) Append the `[SEP]` token to the end.\n",
    "  #   (4) Map tokens to their IDs.\n",
    "  #   (5) Pad or truncate the sentence to `max_length`\n",
    "  #   (6) Create attention masks for [PAD] tokens.\n",
    "\n",
    "  if (previous_transcript_vd[i] != \"\" and use_next):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        previous_transcript_vd[i]+ \" \" + previous_system_transcript_vd[i],  # Sentence to encode.\n",
    "                        transcripts_vd[i], #next sentece to encode\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        truncation = True,\n",
    "                        max_length = max_len,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                    )\n",
    "  else:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        transcripts_vd[i],  # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        truncation = True,\n",
    "                        max_length = max_len,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                    )\n",
    "    \n",
    "  # Add the encoded sentence to the list.    \n",
    "  input_ids_vd.append(encoded_dict['input_ids'])\n",
    "  \n",
    "  # And its attention mask (simply differentiates padding from non-padding).\n",
    "  attention_masks_vd.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids_vd = torch.cat(input_ids_vd, dim=0)\n",
    "attention_masks_vd = torch.cat(attention_masks_vd, dim=0)\n",
    "labels_actions_vd = torch.tensor(action_labels_encoded_vd)\n",
    "labels_attributes_vd = torch.tensor(attributes_labels_vd_vect)\n",
    "# Check warning:\n",
    "# /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
    "dialog_ids_vd = torch.tensor(dialog_ids_vd)\n",
    "turn_idxs_vd = torch.tensor(turn_idxs_vd) \n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print (\"VALIDATION : \")\n",
    "if (use_next):\n",
    "  print('Original: ', transcripts_vd[0])\n",
    "else:\n",
    "  print('Original: ', transcripts_vd[0])\n",
    "print('Token IDs:', input_ids_vd[0])\n",
    "print(f\"Dialog IDs: {dialog_ids_vd[0:20]}\")\n",
    "print(f\"Turn IDXs: {turn_idxs_vd[0:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d364715",
   "metadata": {},
   "source": [
    "### Tokenize Evaluation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23888911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5397 records to encode.\n",
      "Evaluation : \n",
      "Original:  That looks a little too light for what I need, do you have something else with a high customer rating?\n",
      "Token IDs: tensor([ 101, 2008, 3504, 1037, 2210, 2205, 2422, 2005, 2054, 1045, 2342, 1010,\n",
      "        2079, 2017, 2031, 2242, 2842, 2007, 1037, 2152, 8013, 5790, 1029,  102,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0])\n",
      "Dialog IDs: tensor([2494, 2494, 2494, 2494, 2494, 3731, 3731, 3731, 3731, 3731, 8546, 8546,\n",
      "        8546, 8546, 8546, 8546, 5590, 5590, 5590, 5590])\n",
      "Turn IDXs: tensor([0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "\n",
    "#dobbiamo convertire le nostre lables da string a valori numerici, usiamo il metodo fornito da sklearn\n",
    "\n",
    "#EVALUATION DATASET\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "action_labels_encoded_tst = le.fit_transform(action_labels_tst)\n",
    "\n",
    "input_ids_tst = []\n",
    "attention_masks_tst = []\n",
    "print(f\"{len(df_test)} records to encode.\")\n",
    "# For every sentence...\n",
    "for i in range(0,len(df_test)):\n",
    "# for t in transcripts_tst:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "  \n",
    "  #Aggiungere \"and False\" PER UTILIZZARE sempre la tokenizzazione senza concatenazione\n",
    "  if (previous_transcript_tst[i] != \"\" and use_next):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                      previous_transcript_tst[i]+ \" \" + previous_system_transcript_tst[i],  # Sentence to encode.\n",
    "                      transcripts_tst[i], #next sentece to encode\n",
    "                      add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                      truncation = True,\n",
    "                      max_length = max_len,           # Pad & truncate all sentences.\n",
    "                      pad_to_max_length = True,\n",
    "                      return_attention_mask = True,   # Construct attn. masks.\n",
    "                      return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                  )\n",
    "  else:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                      transcripts_tst[i],  # Sentence to encode.\n",
    "                      add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                      truncation = True,\n",
    "                      max_length = max_len,           # Pad & truncate all sentences.\n",
    "                      pad_to_max_length = True,\n",
    "                      return_attention_mask = True,   # Construct attn. masks.\n",
    "                      return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                  )\n",
    "    \n",
    "  # Add the encoded sentence to the list.    \n",
    "  input_ids_tst.append(encoded_dict['input_ids'])\n",
    "  \n",
    "  # And its attention mask (simply differentiates padding from non-padding).\n",
    "  attention_masks_tst.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids_tst = torch.cat(input_ids_tst, dim=0)\n",
    "attention_masks_tst = torch.cat(attention_masks_tst, dim=0)\n",
    "labels_actions_tst = torch.tensor(action_labels_encoded_tst)\n",
    "labels_attributes_tst = torch.tensor(attributes_labels_tst_vect)\n",
    "# Check warning:\n",
    "# /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
    "dialog_ids_tst = torch.tensor(dialog_ids_tst)\n",
    "turn_idxs_tst = torch.tensor(turn_idxs_tst) \n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print (\"Evaluation : \")\n",
    "if (use_next):\n",
    "  print('Original: ', transcripts_tst[0])\n",
    "else:\n",
    "  print('Original: ', transcripts_tst[0])\n",
    "print('Token IDs:', input_ids_tst[0])\n",
    "print(f\"Dialog IDs: {dialog_ids_tst[0:20]}\")\n",
    "print(f\"Turn IDXs: {turn_idxs_tst[0:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af23bb7",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96157e27",
   "metadata": {},
   "source": [
    "# Data Split - AP4CA\n",
    "La nostra versione di split di dati per training e validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "680bdf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21,196 training samples\n",
      "3,513 validation samples\n",
      "5,397 evaluation samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "#labels_tr = {'actions': labels_actions_tr, 'attributes': labels_attributes_tr}\n",
    "#labels_vd = {'actions': labels_actions_vd, 'attributes': labels_attributes_vd}\n",
    "\n",
    "train_dataset = TensorDataset(input_ids_tr, attention_masks_tr, labels_actions_tr, labels_attributes_tr)\n",
    "val_dataset = TensorDataset(input_ids_vd, attention_masks_vd, labels_actions_vd, labels_attributes_vd, dialog_ids_vd, turn_idxs_vd)\n",
    "tst_dataset = TensorDataset(input_ids_tst, attention_masks_tst, labels_actions_tst, labels_attributes_tst, dialog_ids_tst, turn_idxs_tst)\n",
    "\n",
    "print('{:>5,} training samples'.format(len(train_dataset)))\n",
    "print('{:>5,} validation samples'.format(len(val_dataset)))\n",
    "print('{:>5,} evaluation samples'.format(len(tst_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed1196fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 101, 2008, 3504,  ...,    0,    0,    0],\n",
       "         [ 101, 2008, 3504,  ...,    0,    0,    0],\n",
       "         [ 101, 2040, 5617,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [ 101, 2821, 1045,  ...,    0,    0,    0],\n",
       "         [ 101, 4086, 1010,  ...,    0,    0,    0],\n",
       "         [ 101, 1045, 2066,  ...,    0,    0,    0]]),\n",
       " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " tensor([2, 4, 4, 0, 1, 2, 1, 2, 0, 1]),\n",
       " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " tensor([2494, 2494, 2494, 2494, 2494, 3731, 3731, 3731, 3731, 3731]),\n",
       " tensor([0, 1, 2, 3, 4, 0, 1, 2, 3, 4]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check evaluation TensorDataset content\n",
    "tst_dataset[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d01df19",
   "metadata": {},
   "source": [
    "## Check GPU for Training\n",
    "\n",
    "In questa versione la GPU è impostata fissa.\n",
    "Con una GPU in più a disposizione possiamo usare DataParallel e aumentare il batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31bf32c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2060\n"
     ]
    }
   ],
   "source": [
    "# Tell PyTorch to use the GPU.    \n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "print('We will use the GPU:', torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2045d72f",
   "metadata": {},
   "source": [
    "### Creazione Data Loaders per Training, Validation ed Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d9f42ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "# With size 32 GeForce RTX 2060 with 6GB run out of memory\n",
    "batch_size = exec_params['batch']\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )\n",
    "\n",
    "#ho controllato nel colab su cui ci basiamo, anche lui usa un Sequential Sampler per il dataset di evaluation\n",
    "evaluation_dataloader = DataLoader(\n",
    "            tst_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(tst_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040d27c5",
   "metadata": {},
   "source": [
    "## Train BERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc8111f",
   "metadata": {},
   "source": [
    "For this task, we first want to modify the pre-trained BERT model to give outputs for classification, and then we want to continue training the model on our dataset until that the entire model, end-to-end, is well-suited for our task. \n",
    "\n",
    "Thankfully, the huggingface pytorch implementation includes a set of interfaces designed for a variety of NLP tasks. Though these interfaces are all built on top of a trained BERT model, each has different top layers and output types designed to accomodate their specific NLP task.  \n",
    "\n",
    "Here is the current list of classes provided for fine-tuning:\n",
    "* BertModel\n",
    "* BertForPreTraining\n",
    "* BertForMaskedLM\n",
    "* BertForNextSentencePrediction\n",
    "* **BertForSequenceClassification** - The one we'll use.\n",
    "* BertForTokenClassification\n",
    "* BertForQuestionAnswering\n",
    "\n",
    "The documentation for these can be found under [here](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbd23ca",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We'll be using [BertForSequenceClassification](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#bertforsequenceclassification). This is the normal BERT model with an added single linear layer on top for classification that we will use as a sentence classifier. As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task. \n",
    "\n",
    "NB anche nell'articolo che sto leggendo sulla classificazione multi-label si parte da questo modello\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba0360b",
   "metadata": {},
   "source": [
    "OK, let's load BERT! There are a few different pre-trained BERT models available. \"bert-base-uncased\" means the version that has only lowercase letters (\"uncased\") and is the smaller version of the two (\"base\" vs \"large\").\n",
    "\n",
    "The documentation for `from_pretrained` can be found [here](https://huggingface.co/transformers/v2.2.0/main_classes/model.html#transformers.PreTrainedModel.from_pretrained), with the additional parameters defined [here](https://huggingface.co/transformers/v2.2.0/main_classes/configuration.html#transformers.PretrainedConfig)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "242aa137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DA SISTEMARE\n",
    "from transformers import BertModel\n",
    "from  torch import  nn\n",
    "\n",
    "class CustomBERTModel(nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "\n",
    "    super(CustomBERTModel, self).__init__()\n",
    "    self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "    ### New layers:\n",
    "    self.linear_intermedio = nn.Linear(768, exec_params['hidden_output_dim'])\n",
    "    #provare ad aggiungere ulteriori layer intermedi per ridurre le dimensioni fino ad arrivare all'output richiesto\n",
    "    self.linear_actions = nn.Linear(exec_params['hidden_output_dim'], 5) \n",
    "    self.linear_attributes = nn.Linear(exec_params['hidden_output_dim'], len(mlb.classes_)) #num attributi? \n",
    "\n",
    "  def forward(self, ids, mask):\n",
    "    #controllare che l'output non rappresenti solo lo stato interno dovuto al token CLS\n",
    "    output = self.bert(ids,attention_mask=mask)\n",
    "    # print(f\"Type output{type(output)}\")\n",
    "    # for p in output:\n",
    "    #   print(p)\n",
    "    #   print(type(output[p]))\n",
    "    #   print(output[p])\n",
    "\n",
    "    #prendiamo il campo last_hidden_state dall'oggetto output; last hidden state rappresenta il tensore\n",
    "    #in uscita dallo step di forward del BertModel\n",
    "    last_hidden_state_output = output[\"last_hidden_state\"]\n",
    "    # last_hidden_state has the following shape: (batch_size, sequence_length, 768)\n",
    "    #stiamo passando solo il token CLS ai layer successivi\n",
    "    linear_output_intermedio = self.linear_intermedio(last_hidden_state_output[:,0,:].view(-1,768)) \n",
    "    # linear_output_intermedio = self.linear_intermedio(pooled_output) \n",
    "    \n",
    "    linear_output_actions = self.linear_actions(linear_output_intermedio)\n",
    "    # linear_output_actions = self.sftmx(linear_output_actions)\n",
    "    # linear_output_actions = nn.functional.softmax(linear_output_actions)\n",
    "    # Test sigmoid for increasing perplexity performance\n",
    "    linear_output_actions = torch.sigmoid(linear_output_actions)\n",
    "    linear_output_attributes = self.linear_attributes(linear_output_intermedio)\n",
    "    # linear_output_attributes = self.sig(linear_output_attributes)\n",
    "    linear_output_attributes = torch.sigmoid(linear_output_attributes)\n",
    "\n",
    "    return {'actions': linear_output_actions, 'attributes': linear_output_attributes}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ceefd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomBERTModel(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (linear_intermedio): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (linear_actions): Linear(in_features=256, out_features=5, bias=True)\n",
       "  (linear_attributes): Linear(in_features=256, out_features=33, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test istanziazione del custom model\n",
    "model = CustomBERTModel()\n",
    "\n",
    "# model.bert.config\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cb0c4c",
   "metadata": {},
   "source": [
    "Just for curiosity's sake, we can browse all of the model's parameters by name here.\n",
    "\n",
    "In the below cell, I've printed out the names and dimensions of the weights for:\n",
    "\n",
    "1. The embedding layer.\n",
    "2. The first of the twelve transformers.\n",
    "3. The output layer.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c48662a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 205 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "linear_actions.weight                                       (5, 256)\n",
      "linear_actions.bias                                             (5,)\n",
      "linear_attributes.weight                                   (33, 256)\n",
      "linear_attributes.bias                                         (33,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655b5929",
   "metadata": {},
   "source": [
    "## 4.2. Optimizer & Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2ee817",
   "metadata": {},
   "source": [
    "Now that we have our model loaded we need to grab the training hyperparameters from within the stored model.\n",
    "\n",
    "For the purposes of fine-tuning, the authors recommend choosing from the following values (from Appendix A.3 of the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf)):\n",
    "\n",
    ">- **Batch size:** 16, 32  \n",
    "- **Learning rate (Adam):** 5e-5, 3e-5, 2e-5  \n",
    "- **Number of epochs:** 2, 3, 4 \n",
    "\n",
    "We chose:\n",
    "* Batch size: 32 (set when creating our DataLoaders)\n",
    "* Learning rate: 2e-5\n",
    "* Epochs: 4 (we'll see that this is probably too many...)\n",
    "\n",
    "The epsilon parameter `eps = 1e-8` is \"a very small number to prevent any division by zero in the implementation\" (from [here](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)).\n",
    "\n",
    "You can find the creation of the AdamW optimizer in `run_glue.py` [here](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "295fde1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = exec_params['learning_rate'], # args.learning_rate - default is 5e-5\n",
    "                  eps = exec_params['tolerance'] # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4faef5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = exec_params['epochs']\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eccdf3c",
   "metadata": {},
   "source": [
    "## 4.3. Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1141dfa",
   "metadata": {},
   "source": [
    "Below is our training loop. There's a lot going on, but fundamentally for each pass in our loop we have a trianing phase and a validation phase. \n",
    "\n",
    "> *Thank you to [Stas Bekman](https://ca.linkedin.com/in/stasbekman) for contributing the insights and code for using validation loss to detect over-fitting!*\n",
    "\n",
    "**Training:**\n",
    "- Unpack our data inputs and labels\n",
    "- Load data onto the GPU for acceleration\n",
    "- Clear out the gradients calculated in the previous pass. \n",
    "    - In pytorch the gradients accumulate by default (useful for things like RNNs) unless you explicitly clear them out.\n",
    "- Forward pass (feed input data through the network)\n",
    "- Backward pass (backpropagation)\n",
    "- Tell the network to update parameters with optimizer.step()\n",
    "- Track variables for monitoring progress\n",
    "\n",
    "**Evalution:**\n",
    "- Unpack our data inputs and labels\n",
    "- Load data onto the GPU for acceleration\n",
    "- Forward pass (feed input data through the network)\n",
    "- Compute loss on our validation data and track variables for monitoring progress\n",
    "\n",
    "Pytorch hides all of the detailed calculations from us, but we've commented the code to point out which of the above steps are happening on each line. \n",
    "\n",
    "> *PyTorch also has some [beginner tutorials](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py) which you may also find helpful.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d699904",
   "metadata": {},
   "source": [
    "Define a helper function for calculating accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df633469",
   "metadata": {},
   "source": [
    "### Flat accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef1a2d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy_actions(preds, labels):\n",
    "    #print(f\"[FA] preds: {preds} / labels: {labels}\")\n",
    "    #print(f\"[FA-Actions] {type(preds)} {type(labels)}\")\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()   \n",
    "    return {'matched': np.sum(pred_flat == labels_flat), 'counts': len(labels_flat)}\n",
    "\n",
    "def flat_accuracy_attributes(preds, labels):\n",
    "  #print(f\"[FA-Attributess] {type(preds)} {type(labels)}\")\n",
    "  tot_preds = preds.shape[0]\n",
    "  preds_int = np.rint(preds)\n",
    "  tot_eq = 0\n",
    "  for i in range(tot_preds):\n",
    "    comparison = preds_int[i] == labels[i]\n",
    "    if comparison.all():\n",
    "      tot_eq += 1\n",
    "  return {'matched': tot_eq, 'counts' : tot_preds}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc1a792",
   "metadata": {},
   "source": [
    "Helper function for formatting elapsed times as `hh:mm:ss`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "903c3769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdd0590",
   "metadata": {},
   "source": [
    "### Loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0629812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "# Loss function definition\n",
    "def MyBERT_loss(logits, actions_labels, attributes_labels):\n",
    "  actions_logits = logits['actions']\n",
    "  attributes_logits = logits['attributes']\n",
    "  loss_actions_fn = nn.CrossEntropyLoss()\n",
    "  loss_attributes_fn = nn.BCELoss()\n",
    "  loss_actions = loss_actions_fn(actions_logits, actions_labels)\n",
    "  loss_attributes = loss_attributes_fn(attributes_logits, attributes_labels.float())\n",
    "  return loss_actions + loss_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fea679",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We're ready to kick off the training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aab27b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 10 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  4% | 33% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  4% | 33% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:54.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:49.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 94% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:47.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 98% | 92% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:45.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 92% |\n",
      "End of epoch 0\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 92% |\n",
      "\n",
      "  Average training loss: 1.13\n",
      "  Training epcoh took: 0:08:33\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8457\n",
      "  Accuracy for multilabel-classification (attributes): 0.8782\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8457159123256476, 'action_perplexity': 2.50158322385372, 'attribute_accuracy': 0.6964013023834549, 'confusion_matrix': array([[ 451.,   29.,    3.,    0.,    8.],\n",
      "       [  20.,  666.,   17.,    4.,   20.],\n",
      "       [  16.,  170.,  547.,   67.,   40.],\n",
      "       [   0.,    0.,    0.,    0.,    0.],\n",
      "       [   5.,   43.,   57.,   43., 1307.]])}\n",
      "  Validation Loss: 1.0741\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "======== Epoch 2 / 10 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 92% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 92% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:55.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 92% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:51.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:47.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 93% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:42.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 93% |\n",
      "End of epoch 1\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 93% |\n",
      "\n",
      "  Average training loss: 1.07\n",
      "  Training epcoh took: 0:08:30\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8434\n",
      "  Accuracy for multilabel-classification (attributes): 0.9132\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.843438656419015, 'action_perplexity': 2.8493353655787006, 'attribute_accuracy': 0.7207040424457031, 'confusion_matrix': array([[ 475.,   54.,   17.,    3.,   19.],\n",
      "       [   8.,  679.,   49.,   10.,   16.],\n",
      "       [   9.,  131.,  472.,   36.,    3.],\n",
      "       [   0.,    0.,    0.,    0.,    0.],\n",
      "       [   0.,   44.,   86.,   65., 1337.]])}\n",
      "  Validation Loss: 1.0668\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "======== Epoch 3 / 10 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 93% | 92% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 93% | 92% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:56.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 92% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:50.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 92% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:45.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:39.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "End of epoch 2\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "\n",
      "  Average training loss: 1.06\n",
      "  Training epcoh took: 0:08:27\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8517\n",
      "  Accuracy for multilabel-classification (attributes): 0.9137\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.851693709080558, 'action_perplexity': 2.6842860173653165, 'attribute_accuracy': 0.7437258234700955, 'confusion_matrix': array([[ 465.,   32.,   10.,    0.,    8.],\n",
      "       [  12.,  689.,   40.,    8.,   20.],\n",
      "       [   9.,  146.,  520.,   51.,   29.],\n",
      "       [   0.,    0.,    0.,    0.,    0.],\n",
      "       [   6.,   41.,   54.,   55., 1318.]])}\n",
      "  Validation Loss: 1.0581\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "======== Epoch 4 / 10 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:55.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:49.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 91% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:44.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 92% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:38.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 91% |\n",
      "End of epoch 3\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "\n",
      "  Average training loss: 1.05\n",
      "  Training epcoh took: 0:08:26\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8500\n",
      "  Accuracy for multilabel-classification (attributes): 0.9325\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8499857671505835, 'action_perplexity': 3.1358842626205785, 'attribute_accuracy': 0.7669489279369275, 'confusion_matrix': array([[ 461.,   30.,    8.,    0.,    8.],\n",
      "       [  14.,  690.,   36.,   11.,   22.],\n",
      "       [  11.,  147.,  504.,   46.,   14.],\n",
      "       [   0.,    0.,    0.,    0.,    0.],\n",
      "       [   6.,   41.,   76.,   57., 1331.]])}\n",
      "  Validation Loss: 1.0615\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "======== Epoch 5 / 10 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:54.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 92% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:48.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 91% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:42.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 91% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:36.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 90% |\n",
      "End of epoch 4\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 90% |\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epcoh took: 0:08:24\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8486\n",
      "  Accuracy for multilabel-classification (attributes): 0.9337\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8485624822089383, 'action_perplexity': 3.378606191026973, 'attribute_accuracy': 0.7607234454233412, 'confusion_matrix': array([[ 468.,   33.,    6.,    0.,    7.],\n",
      "       [  11.,  698.,   57.,   11.,   18.],\n",
      "       [   9.,  133.,  499.,   55.,   34.],\n",
      "       [   0.,    0.,    0.,    0.,    0.],\n",
      "       [   4.,   44.,   62.,   48., 1316.]])}\n",
      "  Validation Loss: 1.0615\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "======== Epoch 6 / 10 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 90% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 90% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:55.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 91% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:49.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:43.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:37.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "End of epoch 5\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "\n",
      "  Average training loss: 1.02\n",
      "  Training epcoh took: 0:08:24\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8548\n",
      "  Accuracy for multilabel-classification (attributes): 0.9357\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8548249359521777, 'action_perplexity': 3.5247465759922076, 'attribute_accuracy': 0.7831962185953601, 'confusion_matrix': array([[ 466.,   34.,    4.,    0.,    7.],\n",
      "       [  12.,  693.,   34.,   12.,   18.],\n",
      "       [  11.,  139.,  515.,   40.,   21.],\n",
      "       [   0.,    0.,    0.,    0.,    0.],\n",
      "       [   3.,   42.,   71.,   62., 1329.]])}\n",
      "  Validation Loss: 1.0567\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "======== Epoch 7 / 10 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "GPU after train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:54.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 91% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:48.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:42.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 91% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:36.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 91% |\n",
      "End of epoch 6\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "\n",
      "  Average training loss: 1.01\n",
      "  Training epcoh took: 0:08:24\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8497\n",
      "  Accuracy for multilabel-classification (attributes): 0.9425\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8497011101622545, 'action_perplexity': 3.7081396355457987, 'attribute_accuracy': 0.7787289358584158, 'confusion_matrix': array([[4.660e+02, 2.800e+01, 5.000e+00, 1.000e+00, 8.000e+00],\n",
      "       [1.100e+01, 7.090e+02, 6.700e+01, 2.200e+01, 2.500e+01],\n",
      "       [9.000e+00, 1.360e+02, 4.960e+02, 5.000e+01, 2.800e+01],\n",
      "       [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
      "       [6.000e+00, 3.500e+01, 5.600e+01, 4.100e+01, 1.314e+03]])}\n",
      "  Validation Loss: 1.0599\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "======== Epoch 8 / 10 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:54.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 91% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:48.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:42.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 91% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:36.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 91% |\n",
      "End of epoch 7\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 91% |\n",
      "\n",
      "  Average training loss: 1.01\n",
      "  Training epcoh took: 0:08:24\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8503\n",
      "  Accuracy for multilabel-classification (attributes): 0.9439\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8502704241389126, 'action_perplexity': 4.123066274416645, 'attribute_accuracy': 0.7824265821020236, 'confusion_matrix': array([[ 464.,   27.,   12.,   13.,    9.],\n",
      "       [  15.,  701.,   50.,   11.,   19.],\n",
      "       [   9.,  139.,  507.,   44.,   32.],\n",
      "       [   0.,    0.,    0.,    0.,    0.],\n",
      "       [   4.,   41.,   55.,   46., 1315.]])}\n",
      "  Validation Loss: 1.0580\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "======== Epoch 9 / 10 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 90% | 91% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 90% | 91% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:54.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:48.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:42.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:36.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "End of epoch 8\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "\n",
      "  Average training loss: 1.00\n",
      "  Training epcoh took: 0:08:23\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8523\n",
      "  Accuracy for multilabel-classification (attributes): 0.9436\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.852263023057216, 'action_perplexity': 4.440321699115397, 'attribute_accuracy': 0.7828641845398153, 'confusion_matrix': array([[ 466.,   28.,    9.,    2.,    8.],\n",
      "       [  12.,  704.,   57.,   11.,   20.],\n",
      "       [   9.,  137.,  501.,   48.,   24.],\n",
      "       [   0.,    0.,    0.,    0.,    0.],\n",
      "       [   5.,   39.,   57.,   53., 1323.]])}\n",
      "  Validation Loss: 1.0565\n",
      "  Validation took: 0:00:28\n",
      "\n",
      "======== Epoch 10 / 10 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:54.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 90% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:48.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 91% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:42.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:36.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "End of epoch 9\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "\n",
      "  Average training loss: 0.99\n",
      "  Training epcoh took: 0:08:23\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8525\n",
      "  Accuracy for multilabel-classification (attributes): 0.9445\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8525476800455452, 'action_perplexity': 4.567035892337402, 'attribute_accuracy': 0.7847931454536415, 'confusion_matrix': array([[ 465.,   27.,    7.,    2.,    7.],\n",
      "       [  13.,  705.,   58.,   13.,   18.],\n",
      "       [   9.,  135.,  498.,   46.,   23.],\n",
      "       [   0.,    0.,    0.,    0.,    0.],\n",
      "       [   5.,   41.,   61.,   53., 1327.]])}\n",
      "  Validation Loss: 1.0587\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "Training complete!\n",
      "Total training took 1:28:46 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import action_evaluation as evaluation\n",
    "import json\n",
    "from  GPUtil import showUtilization as gpu_usage\n",
    "with open('./extr_output/fashion_dev_dials_api_calls.json') as f:\n",
    "  dev_dials = json.load(f)\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = exec_params['seed']\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "#torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "test_batch = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    print(\"GPU before train\")\n",
    "    gpu_usage()\n",
    "\n",
    "    model.train()\n",
    "    print(\"GPU after train\")\n",
    "    gpu_usage()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 400 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "            gpu_usage()\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: actions labels \n",
    "        #   [3]: attributes labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels_actions = batch[2].to(device)\n",
    "        b_labels_attributes = batch[3].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
    "        # function and pass down the arguments. The `forward` function is \n",
    "        # documented here: \n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
    "        # The results are returned in a results object, documented here:\n",
    "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
    "        # Specifically, we'll get the loss (because we provided labels) and the\n",
    "        # \"logits\"--the model outputs prior to activation.\n",
    "        result = model(b_input_ids, \n",
    "                       mask=b_input_mask)\n",
    "        \n",
    "        loss = MyBERT_loss(result, b_labels_actions, b_labels_attributes)\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.from transformers import BertModel, BertConfig\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    print(f\"End of epoch {epoch_i}\")\n",
    "    gpu_usage()\n",
    "    \n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.mlb.inverse_transform(attr_yt[3].reshape(1, -1))\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy_classification = { 'matched': 0, 'counts': 0}\n",
    "    total_eval_accuracy_multilabel = { 'matched': 0, 'counts': 0}\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    batch_number = 0\n",
    "\n",
    "    # Dictionary for action_evaluation\n",
    "    model_actions = {}\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        batch_number += 1\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels_actions = batch[2].to(device)\n",
    "        b_labels_attributes = batch[3].to(device)\n",
    "        b_dialog_ids = batch[4].to(device).detach().cpu().numpy()\n",
    "        b_turn_idxs = batch[5].to(device).detach().cpu().numpy()\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            result = model(b_input_ids, \n",
    "                       mask=b_input_mask)\n",
    "\n",
    "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
    "        # output values prior to applying an activation function like the \n",
    "        # softmax.\n",
    "        loss = MyBERT_loss(result, b_labels_actions, b_labels_attributes)\n",
    "            \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        # logits = logits.detach().cpu().numpy()\n",
    "        # label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        \n",
    "        actions_logits_foracc=result['actions'].detach().cpu().numpy()\n",
    "        attributes_logits_foracc=result['attributes'].detach().cpu().numpy()\n",
    "        actions_labels_foracc= b_labels_actions.to('cpu').numpy()\n",
    "        attributes_labels_foracc =b_labels_attributes.to('cpu').numpy()\n",
    "\n",
    "        #TODO: definire la nostra funzione di accuracy\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        accuracy_classification = flat_accuracy_actions(actions_logits_foracc, actions_labels_foracc)\n",
    "        accuracy_multilabel = flat_accuracy_attributes(attributes_logits_foracc, attributes_labels_foracc)\n",
    "        \n",
    "        total_eval_accuracy_classification['matched'] += accuracy_classification['matched']\n",
    "        total_eval_accuracy_classification['counts'] += accuracy_classification['counts']\n",
    "        total_eval_accuracy_multilabel['matched'] += accuracy_multilabel['matched']\n",
    "        total_eval_accuracy_multilabel['counts'] += accuracy_multilabel['counts']\n",
    "        # Salvo dati elaborazione batch per debug/analisi\n",
    "        test_batch.append({\n",
    "            'epoch' : epoch_i + 1,\n",
    "            'batchnum' : batch_number,\n",
    "            'actions_logits' : actions_logits_foracc,\n",
    "            'actions_labels' : actions_labels_foracc,\n",
    "            'attributes_logits' : attributes_logits_foracc,\n",
    "            'attributes_labels' : attributes_labels_foracc,\n",
    "            'accuracy_classification' : accuracy_classification,\n",
    "            'accuracy_multilabel' : accuracy_multilabel,\n",
    "        })\n",
    "\n",
    "        # Fill dictionary for action_evaluation\n",
    "        for el_i in range(len(actions_logits_foracc)):\n",
    "          dialog_id = b_dialog_ids[el_i]\n",
    "          action_log_prob = {}\n",
    "          for act_i in range(len(actions_logits_foracc[el_i])):\n",
    "            #todo: controllare che la probabilità predetta sia in scala logaritmica (?? potrebbe essere fonte di errori)\n",
    "            action_log_prob[le.classes_[act_i]] = np.log(actions_logits_foracc[el_i][act_i])\n",
    "          #attributes = {}\n",
    "          attributes = []\n",
    "          #attributes_list = np.rint(attributes_logits_foracc[el_i])\n",
    "          attributes_list = np.array(attributes_logits_foracc[el_i])\n",
    "          for attr in range(len(attributes_list)):\n",
    "            attribute = mlb.classes_[attr]\n",
    "            #attributes[mlb.classes_[attr]] = attributes_list[attr]\n",
    "            if attributes_list[attr] >= 0.5:\n",
    "              attributes.append(attribute)\n",
    "          prediction = {\n",
    "              'action': le.classes_[np.argmax(actions_logits_foracc[el_i])],\n",
    "              'action_log_prob': action_log_prob,\n",
    "              'attributes': {'attributes': attributes},\n",
    "              'turn_id': b_turn_idxs[el_i]\n",
    "          }\n",
    "          if dialog_id in model_actions:\n",
    "            model_actions[dialog_id]['predictions'].append(prediction)\n",
    "          else:\n",
    "            predictions = list()\n",
    "            predictions.append(prediction)\n",
    "            model_actions[dialog_id] = {\n",
    "                'dialog_id': dialog_id,\n",
    "                'predictions': predictions\n",
    "            }\n",
    "          \n",
    "\n",
    "    # Report the final accuracy for this validation \n",
    "\n",
    "    #avg_val_accuracy_classification = total_eval_accuracy_classification / len(validation_dataloader)\n",
    "    #avg_val_accuracy_multilabel = total_eval_accuracy_multilabel / len(validation_dataloader)\n",
    "    avg_val_accuracy_classification = total_eval_accuracy_classification['matched'] / total_eval_accuracy_classification['counts']\n",
    "    avg_val_accuracy_multilabel = total_eval_accuracy_multilabel['matched'] / total_eval_accuracy_multilabel['counts']\n",
    "    print(\"  Accuracy for classification (actions): {0:.4f}\".format(avg_val_accuracy_classification))\n",
    "    print(\"  Accuracy for multilabel-classification (attributes): {0:.4f}\".format(avg_val_accuracy_multilabel))\n",
    "\n",
    "    # Reference implementation: evaluation of action prediction along with attributes\n",
    "    metrics = evaluation.evaluate_action_prediction(dev_dials, model_actions.values())\n",
    "    # print(\"model_actions passed to the evaluator:\")\n",
    "    # for v in model_actions.values():\n",
    "    #   print(v)\n",
    "    print(\"***************************************\")\n",
    "    print(\"Reference evaluation metrics:\")\n",
    "    print(metrics)\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.4f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,  \n",
    "            'Valid. Accur. class.': avg_val_accuracy_classification,\n",
    "            'Valid. Accur. mult.label': avg_val_accuracy_multilabel,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time,\n",
    "            'metrics': metrics\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ac0f0f",
   "metadata": {},
   "source": [
    "## Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b6d29e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy for classification (actions): 0.8466\n",
      "  Accuracy for multilabel-classification (attributes): 0.9385\n",
      "#Instances evaluated API: 5397\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8465814341300723, 'action_perplexity': 4.8805655595048, 'attribute_accuracy': 0.7716289557452825, 'confusion_matrix': array([[ 739.,   44.,   11.,   10.,    9.],\n",
      "       [  32., 1084.,   91.,   15.,   43.],\n",
      "       [  12.,  186.,  742.,   90.,   32.],\n",
      "       [   0.,    0.,    0.,    0.,    0.],\n",
      "       [  10.,   72.,  100.,   71., 2004.]])}\n"
     ]
    }
   ],
   "source": [
    "#Prediction on test set\n",
    "#quale modello gli viene passato? da controllare se BERT da solo riesce a tenere traccia del modello che ha dato l'epoca migliore\n",
    "\n",
    "\n",
    "with open('./extr_output/fashion_devtest_dials_api_calls.json') as f:\n",
    "  devtest_dials = json.load(f)\n",
    "\n",
    "# Tracking variables \n",
    "total_eval_accuracy_classification = { 'matched': 0, 'counts': 0}\n",
    "total_eval_accuracy_multilabel = { 'matched': 0, 'counts': 0}\n",
    "\n",
    "model_actions = {}\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "for batch in evaluation_dataloader:\n",
    "\n",
    "    # Unpack this training batch from our dataloader. \n",
    "    #\n",
    "    # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "    # the `to` method.\n",
    "    #\n",
    "    # `batch` contains three pytorch tensors:\n",
    "    #   [0]: input ids \n",
    "    #   [1]: attention masks\n",
    "    #   [2]: labels \n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels_actions = batch[2].to(device)\n",
    "    b_labels_attributes = batch[3].to(device)\n",
    "    b_dialog_ids = batch[4].to(device).detach().cpu().numpy()\n",
    "    b_turn_idxs = batch[5].to(device).detach().cpu().numpy()\n",
    "    \n",
    "    # Tell pytorch not to bother with constructing the compute graph during\n",
    "    # the forward pass, since this is only needed for backprop (training).\n",
    "    with torch.no_grad():        \n",
    "        # Forward pass, calculate logit predictions.\n",
    "        # token_type_ids is the same as the \"segment ids\", which \n",
    "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "        result = model(b_input_ids,mask=b_input_mask)\n",
    "\n",
    "    \n",
    "    actions_logits_foracc=result['actions'].detach().cpu().numpy()\n",
    "    attributes_logits_foracc=result['attributes'].detach().cpu().numpy()\n",
    "    actions_labels_foracc= b_labels_actions.to('cpu').numpy()\n",
    "    attributes_labels_foracc =b_labels_attributes.to('cpu').numpy()\n",
    "\n",
    "    # Calculate the accuracy for this batch of test sentences, and\n",
    "    # accumulate it over all batches.\n",
    "    accuracy_classification = flat_accuracy_actions(actions_logits_foracc, actions_labels_foracc)\n",
    "    accuracy_multilabel = flat_accuracy_attributes(attributes_logits_foracc, attributes_labels_foracc)\n",
    "    \n",
    "    total_eval_accuracy_classification['matched'] += accuracy_classification['matched']\n",
    "    total_eval_accuracy_classification['counts'] += accuracy_classification['counts']\n",
    "    total_eval_accuracy_multilabel['matched'] += accuracy_multilabel['matched']\n",
    "    total_eval_accuracy_multilabel['counts'] += accuracy_multilabel['counts']\n",
    "    \n",
    "\n",
    "    # Fill dictionary for action_evaluation\n",
    "    for el_i in range(len(actions_logits_foracc)):\n",
    "      dialog_id = b_dialog_ids[el_i]\n",
    "      action_log_prob = {}\n",
    "      for act_i in range(len(actions_logits_foracc[el_i])):\n",
    "        #todo: controllare che la probabilità predetta sia in scala logaritmica (?? potrebbe essere fonte di errori)\n",
    "        action_log_prob[le.classes_[act_i]] = np.log(actions_logits_foracc[el_i][act_i])\n",
    "      #attributes = {}\n",
    "      attributes = []\n",
    "      #attributes_list = np.rint(attributes_logits_foracc[el_i])\n",
    "      attributes_list = np.array(attributes_logits_foracc[el_i])\n",
    "      for attr in range(len(attributes_list)):\n",
    "        attribute = mlb.classes_[attr]\n",
    "        #attributes[mlb.classes_[attr]] = attributes_list[attr]\n",
    "        if attributes_list[attr] >= 0.5:\n",
    "          attributes.append(attribute)\n",
    "      prediction = {\n",
    "          'action': le.classes_[np.argmax(actions_logits_foracc[el_i])],\n",
    "          'action_log_prob': action_log_prob,\n",
    "          'attributes': {'attributes': attributes},\n",
    "          'turn_id': b_turn_idxs[el_i]\n",
    "      }\n",
    "      if dialog_id in model_actions:\n",
    "        model_actions[dialog_id]['predictions'].append(prediction)\n",
    "      else:\n",
    "        predictions = list()\n",
    "        predictions.append(prediction)\n",
    "        model_actions[dialog_id] = {\n",
    "            'dialog_id': dialog_id,\n",
    "            'predictions': predictions\n",
    "        }\n",
    "      \n",
    "\n",
    "# Report the final accuracy for this validation \n",
    "\n",
    "#avg_val_accuracy_classification = total_eval_accuracy_classification / len(validation_dataloader)\n",
    "#avg_val_accuracy_multilabel = total_eval_accuracy_multilabel / len(validation_dataloader)\n",
    "avg_val_accuracy_classification = total_eval_accuracy_classification['matched'] / total_eval_accuracy_classification['counts']\n",
    "avg_val_accuracy_multilabel = total_eval_accuracy_multilabel['matched'] / total_eval_accuracy_multilabel['counts']\n",
    "print(\"  Accuracy for classification (actions): {0:.4f}\".format(avg_val_accuracy_classification))\n",
    "print(\"  Accuracy for multilabel-classification (attributes): {0:.4f}\".format(avg_val_accuracy_multilabel))\n",
    "\n",
    "# Reference implementation: evaluation of action prediction along with attributes\n",
    "metrics = evaluation.evaluate_action_prediction(devtest_dials, model_actions.values())\n",
    "# print(\"model_actions passed to the evaluator:\")\n",
    "# for v in model_actions.values():\n",
    "#   print(v)\n",
    "print(\"***************************************\")\n",
    "print(\"Reference evaluation metrics:\")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a059e49",
   "metadata": {},
   "source": [
    "# OTHER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ca179f",
   "metadata": {},
   "source": [
    "Let's view the summary of the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "03bdf5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "401e879c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>batchnum</th>\n",
       "      <th>actions_logits</th>\n",
       "      <th>actions_labels</th>\n",
       "      <th>attributes_logits</th>\n",
       "      <th>attributes_labels</th>\n",
       "      <th>accuracy_classification</th>\n",
       "      <th>accuracy_multilabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.0018640875, 0.98465234, 0.00039248625, 6.2...</td>\n",
       "      <td>[1, 4, 2, 4, 0, 1, 1, 4, 4, 0, 1, 2]</td>\n",
       "      <td>[[0.00037661457, 0.00014894667, 0.00464106, 0....</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>{'matched': 11, 'counts': 12}</td>\n",
       "      <td>{'matched': 11, 'counts': 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0.0018100431, 0.99977607, 0.001135715, 4.966...</td>\n",
       "      <td>[1, 4, 2, 2, 0, 1, 2, 1, 1, 1, 1, 4]</td>\n",
       "      <td>[[0.0004687756, 0.0002263966, 0.0032983879, 0....</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>{'matched': 9, 'counts': 12}</td>\n",
       "      <td>{'matched': 11, 'counts': 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[[0.5982404, 0.00034867405, 0.004634232, 8.834...</td>\n",
       "      <td>[4, 1, 1, 1, 4, 2, 1, 2, 0, 1, 1, 1]</td>\n",
       "      <td>[[0.0001970854, 4.689077e-05, 0.1681338, 0.000...</td>\n",
       "      <td>[[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>{'matched': 8, 'counts': 12}</td>\n",
       "      <td>{'matched': 10, 'counts': 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[[0.9989441, 0.0005558613, 0.0016913917, 0.000...</td>\n",
       "      <td>[0, 0, 1, 2, 0, 1, 4, 4, 0, 1, 1, 4]</td>\n",
       "      <td>[[0.0005334459, 8.784159e-05, 0.006505481, 0.0...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>{'matched': 10, 'counts': 12}</td>\n",
       "      <td>{'matched': 11, 'counts': 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[[0.00033772367, 0.005396742, 0.00034234027, 0...</td>\n",
       "      <td>[1, 4, 2, 4, 0, 3, 1, 1, 2, 4, 1, 1]</td>\n",
       "      <td>[[0.0005176705, 0.00083357736, 0.020055825, 0....</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>{'matched': 9, 'counts': 12}</td>\n",
       "      <td>{'matched': 10, 'counts': 12}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  batchnum                                     actions_logits  \\\n",
       "0      1         1  [[0.0018640875, 0.98465234, 0.00039248625, 6.2...   \n",
       "1      1         2  [[0.0018100431, 0.99977607, 0.001135715, 4.966...   \n",
       "2      1         3  [[0.5982404, 0.00034867405, 0.004634232, 8.834...   \n",
       "3      1         4  [[0.9989441, 0.0005558613, 0.0016913917, 0.000...   \n",
       "4      1         5  [[0.00033772367, 0.005396742, 0.00034234027, 0...   \n",
       "\n",
       "                         actions_labels  \\\n",
       "0  [1, 4, 2, 4, 0, 1, 1, 4, 4, 0, 1, 2]   \n",
       "1  [1, 4, 2, 2, 0, 1, 2, 1, 1, 1, 1, 4]   \n",
       "2  [4, 1, 1, 1, 4, 2, 1, 2, 0, 1, 1, 1]   \n",
       "3  [0, 0, 1, 2, 0, 1, 4, 4, 0, 1, 1, 4]   \n",
       "4  [1, 4, 2, 4, 0, 3, 1, 1, 2, 4, 1, 1]   \n",
       "\n",
       "                                   attributes_logits  \\\n",
       "0  [[0.00037661457, 0.00014894667, 0.00464106, 0....   \n",
       "1  [[0.0004687756, 0.0002263966, 0.0032983879, 0....   \n",
       "2  [[0.0001970854, 4.689077e-05, 0.1681338, 0.000...   \n",
       "3  [[0.0005334459, 8.784159e-05, 0.006505481, 0.0...   \n",
       "4  [[0.0005176705, 0.00083357736, 0.020055825, 0....   \n",
       "\n",
       "                                   attributes_labels  \\\n",
       "0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "2  [[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "3  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "4  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "         accuracy_classification            accuracy_multilabel  \n",
       "0  {'matched': 11, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
       "1   {'matched': 9, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
       "2   {'matched': 8, 'counts': 12}  {'matched': 10, 'counts': 12}  \n",
       "3  {'matched': 10, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
       "4   {'matched': 9, 'counts': 12}  {'matched': 10, 'counts': 12}  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert test data to dataframe\n",
    "df_test = pd.DataFrame(data = test_batch)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dbd5290d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur. class.</th>\n",
       "      <th>Valid. Accur. mult.label</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "      <th>metrics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.13</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0:08:33</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8457159123256476, 'actio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.07</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0:08:30</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.843438656419015, 'action...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.06</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0:08:27</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.851693709080558, 'action...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.05</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0:08:26</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8499857671505835, 'actio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.03</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0:08:24</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8485624822089383, 'actio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.02</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0:08:24</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8548249359521777, 'actio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.01</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0:08:24</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8497011101622545, 'actio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.01</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0:08:24</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8502704241389126, 'actio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0:08:23</td>\n",
       "      <td>0:00:28</td>\n",
       "      <td>{'action_accuracy': 0.852263023057216, 'action...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.99</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0:08:23</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8525476800455452, 'actio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. class.  \\\n",
       "epoch                                                     \n",
       "1               1.13         1.07                  0.85   \n",
       "2               1.07         1.07                  0.84   \n",
       "3               1.06         1.06                  0.85   \n",
       "4               1.05         1.06                  0.85   \n",
       "5               1.03         1.06                  0.85   \n",
       "6               1.02         1.06                  0.85   \n",
       "7               1.01         1.06                  0.85   \n",
       "8               1.01         1.06                  0.85   \n",
       "9               1.00         1.06                  0.85   \n",
       "10              0.99         1.06                  0.85   \n",
       "\n",
       "       Valid. Accur. mult.label Training Time Validation Time  \\\n",
       "epoch                                                           \n",
       "1                          0.88       0:08:33         0:00:27   \n",
       "2                          0.91       0:08:30         0:00:27   \n",
       "3                          0.91       0:08:27         0:00:27   \n",
       "4                          0.93       0:08:26         0:00:27   \n",
       "5                          0.93       0:08:24         0:00:27   \n",
       "6                          0.94       0:08:24         0:00:27   \n",
       "7                          0.94       0:08:24         0:00:27   \n",
       "8                          0.94       0:08:24         0:00:27   \n",
       "9                          0.94       0:08:23         0:00:28   \n",
       "10                         0.94       0:08:23         0:00:27   \n",
       "\n",
       "                                                 metrics  \n",
       "epoch                                                     \n",
       "1      {'action_accuracy': 0.8457159123256476, 'actio...  \n",
       "2      {'action_accuracy': 0.843438656419015, 'action...  \n",
       "3      {'action_accuracy': 0.851693709080558, 'action...  \n",
       "4      {'action_accuracy': 0.8499857671505835, 'actio...  \n",
       "5      {'action_accuracy': 0.8485624822089383, 'actio...  \n",
       "6      {'action_accuracy': 0.8548249359521777, 'actio...  \n",
       "7      {'action_accuracy': 0.8497011101622545, 'actio...  \n",
       "8      {'action_accuracy': 0.8502704241389126, 'actio...  \n",
       "9      {'action_accuracy': 0.852263023057216, 'action...  \n",
       "10     {'action_accuracy': 0.8525476800455452, 'actio...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display floats with two decimal places.\n",
    "pd.set_option('precision', 2)\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap.\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Display the table.\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "69386886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Objects serialization\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "testdata_filename = f\"testdata-{timestr}\"\n",
    "stats_filename = f\"stats-{timestr}\"\n",
    "#outtest = open(testdata_filename, \"wb\")\n",
    "#outstats = open(stats_filename, \"wb\")\n",
    "#pk.dump(obj=df_test, file=outtest)\n",
    "#outtest.close()\n",
    "#pk.dump(obj=df_stats, file=outstats)\n",
    "#outstats.close()\n",
    "df_test.to_pickle(testdata_filename)\n",
    "df_stats.to_pickle(stats_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb5a6cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testdata-20210801-031312\n",
      "       Training Loss  Valid. Loss  Valid. Accur. class.  \\\n",
      "epoch                                                     \n",
      "1               1.13         1.07                  0.85   \n",
      "2               1.07         1.07                  0.84   \n",
      "3               1.06         1.06                  0.85   \n",
      "4               1.05         1.06                  0.85   \n",
      "5               1.03         1.06                  0.85   \n",
      "\n",
      "       Valid. Accur. mult.label Training Time Validation Time  \\\n",
      "epoch                                                           \n",
      "1                          0.88       0:08:33         0:00:27   \n",
      "2                          0.91       0:08:30         0:00:27   \n",
      "3                          0.91       0:08:27         0:00:27   \n",
      "4                          0.93       0:08:26         0:00:27   \n",
      "5                          0.93       0:08:24         0:00:27   \n",
      "\n",
      "                                                 metrics  \n",
      "epoch                                                     \n",
      "1      {'action_accuracy': 0.8457159123256476, 'actio...  \n",
      "2      {'action_accuracy': 0.843438656419015, 'action...  \n",
      "3      {'action_accuracy': 0.851693709080558, 'action...  \n",
      "4      {'action_accuracy': 0.8499857671505835, 'actio...  \n",
      "5      {'action_accuracy': 0.8485624822089383, 'actio...  \n",
      "   epoch  batchnum                                     actions_logits  \\\n",
      "0      1         1  [[0.0018640875, 0.98465234, 0.00039248625, 6.2...   \n",
      "1      1         2  [[0.0018100431, 0.99977607, 0.001135715, 4.966...   \n",
      "2      1         3  [[0.5982404, 0.00034867405, 0.004634232, 8.834...   \n",
      "3      1         4  [[0.9989441, 0.0005558613, 0.0016913917, 0.000...   \n",
      "4      1         5  [[0.00033772367, 0.005396742, 0.00034234027, 0...   \n",
      "\n",
      "                         actions_labels  \\\n",
      "0  [1, 4, 2, 4, 0, 1, 1, 4, 4, 0, 1, 2]   \n",
      "1  [1, 4, 2, 2, 0, 1, 2, 1, 1, 1, 1, 4]   \n",
      "2  [4, 1, 1, 1, 4, 2, 1, 2, 0, 1, 1, 1]   \n",
      "3  [0, 0, 1, 2, 0, 1, 4, 4, 0, 1, 1, 4]   \n",
      "4  [1, 4, 2, 4, 0, 3, 1, 1, 2, 4, 1, 1]   \n",
      "\n",
      "                                   attributes_logits  \\\n",
      "0  [[0.00037661457, 0.00014894667, 0.00464106, 0....   \n",
      "1  [[0.0004687756, 0.0002263966, 0.0032983879, 0....   \n",
      "2  [[0.0001970854, 4.689077e-05, 0.1681338, 0.000...   \n",
      "3  [[0.0005334459, 8.784159e-05, 0.006505481, 0.0...   \n",
      "4  [[0.0005176705, 0.00083357736, 0.020055825, 0....   \n",
      "\n",
      "                                   attributes_labels  \\\n",
      "0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
      "1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
      "2  [[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
      "3  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
      "4  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
      "\n",
      "         accuracy_classification            accuracy_multilabel  \n",
      "0  {'matched': 11, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
      "1   {'matched': 9, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
      "2   {'matched': 8, 'counts': 12}  {'matched': 10, 'counts': 12}  \n",
      "3  {'matched': 10, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
      "4   {'matched': 9, 'counts': 12}  {'matched': 10, 'counts': 12}  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Test reimport data\n",
    "df_stats_reload = pd.read_pickle(stats_filename)\n",
    "df_test_reload = pd.read_pickle(testdata_filename)\n",
    "\n",
    "print(testdata_filename)\n",
    "print(df_stats_reload.head())\n",
    "print(df_test_reload.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1af435",
   "metadata": {},
   "source": [
    "## Plot di training & validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2c4fe674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks([x+1 for x in range(exec_params['epochs'])])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aad9f80",
   "metadata": {},
   "source": [
    "## Plot accuracy and perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2a533123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "act_acc = [x['action_accuracy'] for x in df_stats.metrics]\n",
    "att_acc = [x['attribute_accuracy'] for x in df_stats.metrics]\n",
    "x_ticks = [x for x in range(len(act_acc))]\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(act_acc, 'b-o', label=\"Actions\")\n",
    "plt.plot(att_acc, 'g-o', label=\"Attributes\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Actions and attributes accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.xticks(ticks = x_ticks, labels = [str(x+1) for x in x_ticks])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9e098406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "act_per = [x['action_perplexity'] for x in df_stats.metrics]\n",
    "x_ticks = [x for x in range(len(act_acc))]\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(act_per, 'b-o')\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Actions perplexity\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Perplexity\")\n",
    "plt.xticks(ticks = x_ticks, labels = [str(x+1) for x in x_ticks])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8bc888",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
