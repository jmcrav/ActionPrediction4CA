{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4e26663",
   "metadata": {},
   "source": [
    "# Download GitHub repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9f42ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gian/content\n",
      "Clone in 'ActionPrediction4CA' in corso...\n",
      "remote: Enumerating objects: 388, done.\u001b[K\n",
      "remote: Counting objects: 100% (388/388), done.\u001b[K\n",
      "remote: Compressing objects: 100% (299/299), done.\u001b[K\n",
      "remote: Total 388 (delta 197), reused 265 (delta 82), pack-reused 0\u001b[K\n",
      "Ricezione degli oggetti: 100% (388/388), 48.25 MiB | 10.39 MiB/s, fatto.\n",
      "Risoluzione dei delta: 100% (197/197), fatto.\n"
     ]
    }
   ],
   "source": [
    "%cd ~/content/\n",
    "%rm -rf ~/content/ActionPrediction4CA\n",
    "%rm -rf ~/content/ActionPredictionBERT\n",
    "!git clone  --branch colab_exe https://github.com/jmcrav/ActionPrediction4CA.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36cb4f3",
   "metadata": {},
   "source": [
    "# Elimino i file inutili al modello \n",
    "Per fare il fine tuning del modello, abbiamo bisogno solo dei dati grezzi.\n",
    "Il tutor ha puntualizzato di usare SOLO lo script `simmc/mm_action_prediction/tools/extract_actions_fashion.py`, che costruisce un json con le lables associate alle azioni e agli attributi (è lo step 1 del preprocessing).\n",
    "Questo credo sia necessario perchè credo che la loro implementazione sia di un livello molto più basso di quello a cui dovremo lavorare noi.\n",
    "BERT è un metodo per effettuare il  pre-trained di modelli per il NLP di cui dobbiamo solo fare un fine-tuning accettabile, mentre il SIMMC deve addestrare un intero modello da zero(o comunque credo che il loro obiettivo sia cercare di creare un modello che riesca a funzionare bene col linguaggio multimodale.Non ho capito perchè non sia statu usato BERT anche da loro onestamente -  il task finale è diviso in 3 sottotask, e la prima è un problema di classificazione multi-classe per il quale BERT dovrebbe poter funzionare - forse perchè quella fornita è solo un implementazione di partenza e i concorrenti alla challenge hanno fornito le loro implementazioni dei modelli?). Praticamente tutte le operazioni che fanno loro sui dati credo servano ai loro dettagli implementativi di bassissimo livello; con BERT noi dovremo usare solo i metodi forniti dalla classe.\n",
    "In pratica, partendo dai dati grezzi, dobbiamo solo darli in pasto ai metodi forniti da BERT e magari lavorare un po' per migliorare i risultati, senza che sia necessario scendere fino al livello dei transformers\n",
    "\n",
    "\n",
    "**DA TENERE**\n",
    "* Output dell'extract actions\n",
    "*  `fashion_train_dials.json`:  per il training\n",
    "*  `fashion_dev_dials.json` : per la validation\n",
    "*  `fashion_teststd_dials_public.json` :per il \"report dei risultati finali\" (forse per darlo in pasto allo script di evaluation?) \n",
    "*   `fashion_metadata.json`, `fashion_devtest_dials.json` : necessari per il funzionamento dello script `extract_actions_fashion.py `\n",
    "\n",
    "**DA VERIFICARE**:\n",
    "\n",
    " forse potrebbe convenire anche usare il vocabolario che loro si costruiscono (step 2 del preprocessing) per inizializzare il Tokenizer di Bert, come fanno loro nel data loader (in `loaders/loader_simmc.py`)\n",
    " ![linea codice loader.jpg](data:image/jpeg;base64,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)\n",
    "\n",
    " Questo comando istanzia il tokenizer con una versione default o definita dall'utente (devo capire bene cosa significa, l'ho letto su https://huggingface.co/transformers/quickstart.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cd41deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gian/content/ActionPrediction4CA/tools\n",
      "/home/gian/content/ActionPrediction4CA/data/simmc_fashion\n",
      "/home/gian/content\n"
     ]
    }
   ],
   "source": [
    "%mkdir ~/content/ActionPredictionBERT ActionPredictionBERT/input_data ActionPredictionBERT/extr_output\n",
    "%cd ~/content/ActionPrediction4CA/tools\n",
    "%mv extract_actions_fashion.py ~/content/ActionPredictionBERT\n",
    "%mv action_evaluation.py ~/content/ActionPredictionBERT\n",
    "\n",
    "%cd ~/content/ActionPrediction4CA/data/simmc_fashion/\n",
    "%mv fashion_train_dials.json fashion_dev_dials.json fashion_teststd_dials_public.json fashion_metadata.json fashion_devtest_dials.json ~/content/ActionPredictionBERT/input_data\n",
    "%cd ~/content/\n",
    "%rm -rf ./ActionPrediction4CA/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c76fc6c",
   "metadata": {},
   "source": [
    "# Extract_actions_fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86671584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gian/content/ActionPredictionBERT\n",
      "Reading: ./input_data/fashion_train_dials.json\n",
      "Dialogue task Id missing: 3406\n",
      "Dialogue task Id missing: 3969\n",
      "Dialogue task Id missing: 4847\n",
      "Dialogue task Id missing: 321\n",
      "Dialogue task Id missing: 3455\n",
      "Dialogue task Id missing: 3414\n",
      "Saving: ./extr_output/fashion_train_dials_api_calls.json\n",
      "Reading: ./input_data/fashion_dev_dials.json\n",
      "Dialogue task Id missing: 2117\n",
      "Saving: ./extr_output/fashion_dev_dials_api_calls.json\n",
      "Reading: ./input_data/fashion_devtest_dials.json\n",
      "Dialogue task Id missing: 9308\n",
      "Saving: ./extr_output/fashion_devtest_dials_api_calls.json\n"
     ]
    }
   ],
   "source": [
    "%cd ~/content/ActionPredictionBERT/\n",
    "!python extract_actions_fashion.py --json_path=\"./input_data/fashion_train_dials.json ./input_data/fashion_dev_dials.json ./input_data/fashion_devtest_dials.json\" --save_root=\"./extr_output\"  --metadata_path=\"./fashion_metadata.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98da7846",
   "metadata": {},
   "source": [
    "# Notebook originale\n",
    "Script copiato dal colab di Chris McCormick e Nick Ryan\n",
    "https://colab.research.google.com/drive/1pTuQhug6Dhl9XalKB0zUGf4FIdYFlpcX#scrollTo=nSU7yERLP_66"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34794cb2",
   "metadata": {},
   "source": [
    "## 1.2. Installing the Hugging Face Library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1b3c76",
   "metadata": {},
   "source": [
    "\n",
    "Next, let's install the [transformers](https://github.com/huggingface/transformers) package from Hugging Face which will give us a pytorch interface for working with BERT. (This library contains interfaces for other pretrained language models like OpenAI's GPT and GPT-2.) We've selected the pytorch interface because it strikes a nice balance between the high-level APIs (which are easy to use but don't provide insight into how things work) and tensorflow code (which contains lots of details but often sidetracks us into lessons about tensorflow, when the purpose here is BERT!).\n",
    "\n",
    "At the moment, the Hugging Face library seems to be the most widely accepted and powerful pytorch interface for working with BERT. In addition to supporting a variety of different pre-trained transformer models, the library also includes pre-built modifications of these models suited to your specific task. For example, in this tutorial we will use `BertForSequenceClassification`.\n",
    "\n",
    "The library also includes task-specific classes for token classification, question answering, next sentence prediciton, etc. Using these pre-built classes simplifies the process of modifying BERT for your purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0788d925",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install markdown\n",
    "#!pip install transformers\n",
    "#!pip install pandas\n",
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d22457e",
   "metadata": {},
   "source": [
    "# Impostazione parametri esecuzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b814a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_params = {\n",
    "    'batch': 12,\n",
    "    'epochs': 6,\n",
    "    'hidden_output_dim': 256,\n",
    "    'seed': 193598,\n",
    "    'learning_rate': 5e-5,\n",
    "    'tolerance': 1e-8\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d9eda3",
   "metadata": {},
   "source": [
    "# Analisi Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4f4432",
   "metadata": {},
   "source": [
    "## train_dials\n",
    "\n",
    "Dati grezzi da preprocessare con lo script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7f4abad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "      <th>dialogue_idx</th>\n",
       "      <th>domains</th>\n",
       "      <th>dialogue_task_id</th>\n",
       "      <th>dialogue_coref_map.1426</th>\n",
       "      <th>dialogue_coref_map.1429</th>\n",
       "      <th>dialogue_coref_map.708</th>\n",
       "      <th>dialogue_coref_map.712</th>\n",
       "      <th>dialogue_coref_map.2401</th>\n",
       "      <th>dialogue_coref_map.2402</th>\n",
       "      <th>...</th>\n",
       "      <th>dialogue_coref_map.2335</th>\n",
       "      <th>dialogue_coref_map.713</th>\n",
       "      <th>dialogue_coref_map.1507</th>\n",
       "      <th>dialogue_coref_map.1509</th>\n",
       "      <th>dialogue_coref_map.949</th>\n",
       "      <th>dialogue_coref_map.1137</th>\n",
       "      <th>dialogue_coref_map.1872</th>\n",
       "      <th>dialogue_coref_map.1873</th>\n",
       "      <th>dialogue_coref_map.1753</th>\n",
       "      <th>dialogue_coref_map.834</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'belief_state': [{'act': 'DA:ASK:CHECK:CLOTH...</td>\n",
       "      <td>3094</td>\n",
       "      <td>[fashion]</td>\n",
       "      <td>1785.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'belief_state': [{'act': 'DA:INFORM:PREFER:C...</td>\n",
       "      <td>822</td>\n",
       "      <td>[fashion]</td>\n",
       "      <td>1720.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'belief_state': [{'act': 'DA:REQUEST:GET:CLO...</td>\n",
       "      <td>7411</td>\n",
       "      <td>[fashion]</td>\n",
       "      <td>2038.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'belief_state': [{'act': 'DA:INFORM:DISPREFE...</td>\n",
       "      <td>7029</td>\n",
       "      <td>[fashion]</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'belief_state': [{'act': 'DA:INFORM:DISPREFE...</td>\n",
       "      <td>1506</td>\n",
       "      <td>[fashion]</td>\n",
       "      <td>1686.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1648 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            dialogue  dialogue_idx    domains  \\\n",
       "0  [{'belief_state': [{'act': 'DA:ASK:CHECK:CLOTH...          3094  [fashion]   \n",
       "1  [{'belief_state': [{'act': 'DA:INFORM:PREFER:C...           822  [fashion]   \n",
       "2  [{'belief_state': [{'act': 'DA:REQUEST:GET:CLO...          7411  [fashion]   \n",
       "3  [{'belief_state': [{'act': 'DA:INFORM:DISPREFE...          7029  [fashion]   \n",
       "4  [{'belief_state': [{'act': 'DA:INFORM:DISPREFE...          1506  [fashion]   \n",
       "\n",
       "   dialogue_task_id  dialogue_coref_map.1426  dialogue_coref_map.1429  \\\n",
       "0            1785.0                      0.0                      1.0   \n",
       "1            1720.0                      NaN                      NaN   \n",
       "2            2038.0                      NaN                      NaN   \n",
       "3            2011.0                      NaN                      NaN   \n",
       "4            1686.0                      NaN                      NaN   \n",
       "\n",
       "   dialogue_coref_map.708  dialogue_coref_map.712  dialogue_coref_map.2401  \\\n",
       "0                     NaN                     NaN                      NaN   \n",
       "1                     0.0                     1.0                      NaN   \n",
       "2                     NaN                     NaN                      4.0   \n",
       "3                     NaN                     NaN                      NaN   \n",
       "4                     NaN                     NaN                      NaN   \n",
       "\n",
       "   dialogue_coref_map.2402  ...  dialogue_coref_map.2335  \\\n",
       "0                      NaN  ...                      NaN   \n",
       "1                      NaN  ...                      NaN   \n",
       "2                      0.0  ...                      NaN   \n",
       "3                      NaN  ...                      NaN   \n",
       "4                      NaN  ...                      NaN   \n",
       "\n",
       "   dialogue_coref_map.713  dialogue_coref_map.1507  dialogue_coref_map.1509  \\\n",
       "0                     NaN                      NaN                      NaN   \n",
       "1                     NaN                      NaN                      NaN   \n",
       "2                     NaN                      NaN                      NaN   \n",
       "3                     NaN                      NaN                      NaN   \n",
       "4                     NaN                      NaN                      NaN   \n",
       "\n",
       "   dialogue_coref_map.949  dialogue_coref_map.1137  dialogue_coref_map.1872  \\\n",
       "0                     NaN                      NaN                      NaN   \n",
       "1                     NaN                      NaN                      NaN   \n",
       "2                     NaN                      NaN                      NaN   \n",
       "3                     NaN                      NaN                      NaN   \n",
       "4                     NaN                      NaN                      NaN   \n",
       "\n",
       "   dialogue_coref_map.1873  dialogue_coref_map.1753  dialogue_coref_map.834  \n",
       "0                      NaN                      NaN                     NaN  \n",
       "1                      NaN                      NaN                     NaN  \n",
       "2                      NaN                      NaN                     NaN  \n",
       "3                      NaN                      NaN                     NaN  \n",
       "4                      NaN                      NaN                     NaN  \n",
       "\n",
       "[5 rows x 1648 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prima parte del fashion_train_dials\n",
    "import json \n",
    "import pandas as pd\n",
    "with open ('./input_data/fashion_train_dials.json',\"r\") as f:\n",
    "   data= json.load(f)\n",
    "\n",
    "result=[]\n",
    "row ={}\n",
    "for k in data:\n",
    "  row[k] = data[k]\n",
    "# []\n",
    "#prima parte del fashion_train_dials\n",
    "import json \n",
    "import pandas as pd\n",
    "with open ('./input_data/fashion_train_dials.json',\"r\") as f:\n",
    "   data= json.load(f)\n",
    "\n",
    "result=[]\n",
    "row ={}\n",
    "for k in data:\n",
    "  row[k] = data[k]\n",
    "# []\n",
    "\n",
    "dialogue_data = pd.json_normalize(row['dialogue_data'])\n",
    "type(dialogue_data)\n",
    "# dialogue = dialogue_data[\"dialogue\"]\n",
    "# for x in dialogue.head(1):\n",
    "#   display(x)\n",
    "# #dialogue.head(1)\n",
    "dialogue_data.head()\n",
    "\n",
    "\n",
    "\n",
    "dialogue_data = pd.json_normalize(row['dialogue_data'])\n",
    "type(dialogue_data)\n",
    "# dialogue = dialogue_data[\"dialogue\"]\n",
    "# for x in dialogue.head(1):\n",
    "#   display(x)\n",
    "# #dialogue.head(1)\n",
    "dialogue_data.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "625e5f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>image_ids</th>\n",
       "      <th>focus_image</th>\n",
       "      <th>memory_images</th>\n",
       "      <th>database_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2042</td>\n",
       "      <td>[2441, 2442, 2443, 2444, 2445, 2446, 2447, 244...</td>\n",
       "      <td>2441</td>\n",
       "      <td>[2442, 2443, 2444]</td>\n",
       "      <td>[2445, 2446, 2447, 2448, 2449, 2450]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2041</td>\n",
       "      <td>[2431, 2432, 2433, 2434, 2435, 2436, 2437, 243...</td>\n",
       "      <td>2431</td>\n",
       "      <td>[2432, 2433, 2434]</td>\n",
       "      <td>[2435, 2436, 2437, 2438, 2439, 2440]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2040</td>\n",
       "      <td>[2421, 2422, 2423, 2424, 2425, 2426, 2427, 242...</td>\n",
       "      <td>2421</td>\n",
       "      <td>[2422, 2423, 2424]</td>\n",
       "      <td>[2425, 2426, 2427, 2428, 2429, 2430]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2039</td>\n",
       "      <td>[2411, 2412, 2413, 2414, 2415, 2416, 2417, 241...</td>\n",
       "      <td>2411</td>\n",
       "      <td>[2412, 2413, 2414]</td>\n",
       "      <td>[2415, 2416, 2417, 2418, 2419, 2420]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2038</td>\n",
       "      <td>[2401, 2402, 2403, 2404, 2405, 2406, 2407, 240...</td>\n",
       "      <td>2401</td>\n",
       "      <td>[2402, 2403, 2404]</td>\n",
       "      <td>[2405, 2406, 2407, 2408, 2409, 2410]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   task_id                                          image_ids  focus_image  \\\n",
       "0     2042  [2441, 2442, 2443, 2444, 2445, 2446, 2447, 244...         2441   \n",
       "1     2041  [2431, 2432, 2433, 2434, 2435, 2436, 2437, 243...         2431   \n",
       "2     2040  [2421, 2422, 2423, 2424, 2425, 2426, 2427, 242...         2421   \n",
       "3     2039  [2411, 2412, 2413, 2414, 2415, 2416, 2417, 241...         2411   \n",
       "4     2038  [2401, 2402, 2403, 2404, 2405, 2406, 2407, 240...         2401   \n",
       "\n",
       "        memory_images                       database_images  \n",
       "0  [2442, 2443, 2444]  [2445, 2446, 2447, 2448, 2449, 2450]  \n",
       "1  [2432, 2433, 2434]  [2435, 2436, 2437, 2438, 2439, 2440]  \n",
       "2  [2422, 2423, 2424]  [2425, 2426, 2427, 2428, 2429, 2430]  \n",
       "3  [2412, 2413, 2414]  [2415, 2416, 2417, 2418, 2419, 2420]  \n",
       "4  [2402, 2403, 2404]  [2405, 2406, 2407, 2408, 2409, 2410]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#seconda parte del fashion_train_dials\n",
    "task_mapping = pd.json_normalize(row['task_mapping'])\n",
    "task_mapping.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9867cff",
   "metadata": {},
   "source": [
    "## dev_dials_api_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d5d29b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialog_id</th>\n",
       "      <th>actions</th>\n",
       "      <th>focus_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4146</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'None', 'action_sup...</td>\n",
       "      <td>[1646, 1646, 1646, 1649, 1649, 1649, 1649]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4260</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...</td>\n",
       "      <td>[2161, 2161, 2161, 2161]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8022</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SearchDatabase', '...</td>\n",
       "      <td>[1971, 1972, 1972, 1972, 1977, 1978]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4992</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'None', 'action_sup...</td>\n",
       "      <td>[1931, 1931, 1936, 1936, 1936]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5606</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'None', 'action_sup...</td>\n",
       "      <td>[1931, 1931, 1931, 1931, 1931]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dialog_id                                            actions  \\\n",
       "0       4146  [{'turn_idx': 0, 'action': 'None', 'action_sup...   \n",
       "1       4260  [{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...   \n",
       "2       8022  [{'turn_idx': 0, 'action': 'SearchDatabase', '...   \n",
       "3       4992  [{'turn_idx': 0, 'action': 'None', 'action_sup...   \n",
       "4       5606  [{'turn_idx': 0, 'action': 'None', 'action_sup...   \n",
       "\n",
       "                                 focus_images  \n",
       "0  [1646, 1646, 1646, 1649, 1649, 1649, 1649]  \n",
       "1                    [2161, 2161, 2161, 2161]  \n",
       "2        [1971, 1972, 1972, 1972, 1977, 1978]  \n",
       "3              [1931, 1931, 1936, 1936, 1936]  \n",
       "4              [1931, 1931, 1931, 1931, 1931]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dev_dials_api = pd.read_json('./extr_output/fashion_dev_dials_api_calls.json')\n",
    "dev_dials_api.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b899ff34",
   "metadata": {},
   "source": [
    "## devtest_dials_api_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f9c6435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialog_id</th>\n",
       "      <th>actions</th>\n",
       "      <th>focus_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2494</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SearchDatabase', '...</td>\n",
       "      <td>[1836, 1841, 1841, 1841, 1841]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3731</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SearchDatabase', '...</td>\n",
       "      <td>[1676, 1681, 1681, 1683, 1683]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8546</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...</td>\n",
       "      <td>[840, 840, 840, 849, 849, 843]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5590</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SearchDatabase', '...</td>\n",
       "      <td>[1616, 1618, 1618, 1618, 1618]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5452</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...</td>\n",
       "      <td>[2231, 2231, 2231, 2236, 2236]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dialog_id                                            actions  \\\n",
       "0       2494  [{'turn_idx': 0, 'action': 'SearchDatabase', '...   \n",
       "1       3731  [{'turn_idx': 0, 'action': 'SearchDatabase', '...   \n",
       "2       8546  [{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...   \n",
       "3       5590  [{'turn_idx': 0, 'action': 'SearchDatabase', '...   \n",
       "4       5452  [{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...   \n",
       "\n",
       "                     focus_images  \n",
       "0  [1836, 1841, 1841, 1841, 1841]  \n",
       "1  [1676, 1681, 1681, 1683, 1683]  \n",
       "2  [840, 840, 840, 849, 849, 843]  \n",
       "3  [1616, 1618, 1618, 1618, 1618]  \n",
       "4  [2231, 2231, 2231, 2236, 2236]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "devtest_dials_api = pd.read_json('./extr_output/fashion_devtest_dials_api_calls.json')\n",
    "devtest_dials_api.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3ba47e",
   "metadata": {},
   "source": [
    "## Funzione generazione dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe1973e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def createDataframe(json_file):\n",
    "  with open(json_file) as f:\n",
    "    dictftdac = json.load(f)\n",
    "\n",
    "  data = []\n",
    "\n",
    "  for e in dictftdac:\n",
    "    dialog_id = e['dialog_id']\n",
    "    actions = e['actions']\n",
    "    focus_images = e['focus_images']\n",
    "\n",
    "    for a in actions:\n",
    "      \n",
    "      turn_idx = a['turn_idx']\n",
    "      action = a['action']\n",
    "      action_supervision = a['action_supervision']\n",
    "      transcript = a['transcript']\n",
    "      transcript_annotated = a['transcript_annotated']\n",
    "      system_transcript = a['system_transcript']\n",
    "      system_transcript_annotated = a['system_transcript_annotated']\n",
    "\n",
    "      row = {\n",
    "          \"dialog_id\" : dialog_id,\n",
    "          'turn_idx' : turn_idx,\n",
    "          'action' : action,\n",
    "          'action_supervision' : action_supervision,\n",
    "          'focus_images' : focus_images,\n",
    "          'transcript': transcript,\n",
    "          'transcript_annotated': transcript_annotated,\n",
    "          'system_transcript': system_transcript,\n",
    "          'system_transcript_annotated':system_transcript_annotated,\n",
    "          'previous_transcript': \"\",\n",
    "          'previous_system_transcript': \"\"\n",
    "      }\n",
    "      if (action_supervision != None):\n",
    "        if 'focus' in action_supervision:\n",
    "          acsf = {'focus':action_supervision['focus']}\n",
    "        else:\n",
    "          acsf = {'focus':None}\n",
    "        \n",
    "        if 'attributes' in action_supervision:\n",
    "          acsa = {'attributes':action_supervision['attributes']}\n",
    "        else:\n",
    "          acsa = {'attributes':[]}\n",
    "      else:\n",
    "          acsf = {'focus':None}\n",
    "          acsa = {'attributes':[]}\n",
    "      \n",
    "        \n",
    "      row.update(acsf)\n",
    "      row.update(acsa)\n",
    "    \n",
    "      data.append(row)\n",
    "\n",
    "  # Conservo id turno e risposta sistema per provare a implementare una soluzione articolata\n",
    "  df = pd.DataFrame(data,columns=['dialog_id','turn_idx','transcript','action','attributes', 'system_transcript','transcript_annotated','system_transcript_annotated','previous_transcript','previous_system_transcript'])\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a30c6d",
   "metadata": {},
   "source": [
    "## train_dials_api_calls with transcript\n",
    "Dati per il training che usiamo ( per ora semplificati)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9d78e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  21196  elementi\n"
     ]
    }
   ],
   "source": [
    "df_training = createDataframe('./extr_output/fashion_train_dials_api_calls.json')\n",
    "print(\"Training: \",len(df_training),\" elementi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e542c9",
   "metadata": {},
   "source": [
    "## fashion_dev_dials_api_calls\n",
    "Dati per la validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d7d98f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:  3513  elementi\n"
     ]
    }
   ],
   "source": [
    "df_validation = createDataframe('./extr_output/fashion_dev_dials_api_calls.json')\n",
    "print(\"Validation: \",len(df_validation),\" elementi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f272d647",
   "metadata": {},
   "source": [
    "## fashion_devtest_dials_api_calls\n",
    "Dati per la valutazione delle performance del modello (test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8e22d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  5397  elementi\n"
     ]
    }
   ],
   "source": [
    "df_test = createDataframe('./extr_output/fashion_devtest_dials_api_calls.json')\n",
    "print(\"Test: \",len(df_test),\" elementi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc25d11d",
   "metadata": {},
   "source": [
    "# BERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4c901c",
   "metadata": {},
   "source": [
    "## Scelta tipo input\n",
    "\n",
    "Il valore di questa variabile determinerà se utilizzare i singoli transcript, o se concatenare ogni transcript a quello successivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef5cc083",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_next = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d30106",
   "metadata": {},
   "source": [
    "## Preparazione input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e090913a",
   "metadata": {},
   "source": [
    "### Generazione colonna previous_transcript\n",
    "\n",
    "Generazione della colonna contenente la frase del turno successivo del dialogo (se presente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fb54823",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "df_training.sort_values(by=['dialog_id', 'turn_idx'])\n",
    "for i in range(1,(len(df_training))):\n",
    "  if(i<(len(df_training)) and  df_training['dialog_id'][i] == df_training['dialog_id'][i-1]):\n",
    "    df_training.loc[i,'previous_transcript'] = df_training['transcript'][i-1]\n",
    "    df_training.loc[i,'previous_system_transcript'] = df_training['system_transcript'][i-1]\n",
    "\n",
    "#Validation\n",
    "df_validation.sort_values(by=['dialog_id', 'turn_idx'])\n",
    "for i in range(1,(len(df_validation))):\n",
    "  if(i<(len(df_validation)) and  df_validation['dialog_id'][i] == df_validation['dialog_id'][i-1]):\n",
    "    df_validation.loc[i,'previous_transcript'] = df_validation['transcript'][i-1]\n",
    "    df_validation.loc[i,'previous_system_transcript'] = df_validation['system_transcript'][i-1]\n",
    "\n",
    "#Evaluation\n",
    "df_test.sort_values(by=['dialog_id', 'turn_idx'])\n",
    "for i in range(1,(len(df_test))):\n",
    "  if(i<(len(df_test)) and  df_test['dialog_id'][i] == df_test['dialog_id'][i-1]):\n",
    "    df_test.loc[i,'previous_transcript'] = df_test['transcript'][i-1]\n",
    "    df_test.loc[i,'previous_system_transcript'] = df_test['system_transcript'][i-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb106a56",
   "metadata": {},
   "source": [
    "### Estrazione vettori colonna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78177045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de95a8f0",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f65ef34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA:\n",
      " Original:  Is there a pattern on this one? It's hard to see in the image.\n",
      "Tokenized:  ['is', 'there', 'a', 'pattern', 'on', 'this', 'one', '?', 'it', \"'\", 's', 'hard', 'to', 'see', 'in', 'the', 'image', '.']\n",
      "Token IDs:  [2003, 2045, 1037, 5418, 2006, 2023, 2028, 1029, 2009, 1005, 1055, 2524, 2000, 2156, 1999, 1996, 3746, 1012]\n"
     ]
    }
   ],
   "source": [
    "transcripts_tr = df_training.transcript.values\n",
    "previous_transcript_tr = df_training.previous_transcript.values\n",
    "previous_system_transcript_tr = df_training.previous_system_transcript.values\n",
    "action_labels_tr = df_training.action.values\n",
    "attributes_labels_tr=df_training.attributes.values\n",
    "\n",
    "print (\"TRAINING DATA:\")\n",
    "# Print the original sentence.\n",
    "print(' Original: ', transcripts_tr[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(transcripts_tr[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(transcripts_tr[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b5da556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T: Is there a pattern on this one? It's hard to see in the image. | PT:  | PST: \n",
      "T: That's fancy. Do you have anything in warmer colors like yellow or red? | PT: Is there a pattern on this one? It's hard to see in the image. | PST: I don't have any information on the pattern, but it has pointelle embellishments.\n",
      "T: Yeah, that sounds good. | PT: That's fancy. Do you have anything in warmer colors like yellow or red? | PST: I have a crew neck sweater in red, would you like to see it?\n",
      "T: Oh, I love that. Please tell me you have a small. | PT: Yeah, that sounds good. | PST: This is $187 from Downtown Stylists with a 3.62 rating.\n",
      "T: Yes, please! Thank you for your help with this | PT: Oh, I love that. Please tell me you have a small. | PST: It does come in small, shall I put one in your cart?\n",
      "T: How nice! Does this come in other colors? | PT:  | PST: \n",
      "T: Oh well.  Can you show me a dress that comes in red? | PT: How nice! Does this come in other colors? | PST: No, I'm sorry, It comes only in blue.\n",
      "T: Cute! Do these come in Small? | PT: Oh well.  Can you show me a dress that comes in red? | PST: This dress comes in many colors, including a bright red and a pinkish-red. What do you think?\n",
      "T: Awesome. Would you add a red one in S to my cart please? | PT: Cute! Do these come in Small? | PST: Yes, they do!\n",
      "T: That's all. Thanks! | PT: Awesome. Would you add a red one in S to my cart please? | PST: The red one is in your cart. Is there anything else I can find for you?\n"
     ]
    }
   ],
   "source": [
    "for k in range(0,10):\n",
    "  print(f\"T: {transcripts_tr[k]} | PT: {previous_transcript_tr[k]} | PST: {previous_system_transcript_tr[k]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef35705",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcd4e529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION DATA:\n",
      " Original:  What's the price of this sweater compared to the other blue and gray one I looked at?\n",
      "Tokenized:  ['what', \"'\", 's', 'the', 'price', 'of', 'this', 'sweater', 'compared', 'to', 'the', 'other', 'blue', 'and', 'gray', 'one', 'i', 'looked', 'at', '?']\n",
      "Token IDs:  [2054, 1005, 1055, 1996, 3976, 1997, 2023, 14329, 4102, 2000, 1996, 2060, 2630, 1998, 3897, 2028, 1045, 2246, 2012, 1029]\n",
      "Dialog IDs: [4146 4146 4146 4146 4146 4146 4146 4260 4260 4260 4260 8022 8022 8022\n",
      " 8022 8022 8022 4992 4992 4992]\n",
      "Turn IDs: [0 1 2 3 4 5 6 0 1 2 3 0 1 2 3 4 5 0 1 2]\n"
     ]
    }
   ],
   "source": [
    "transcripts_vd = df_validation.transcript.values\n",
    "previous_transcript_vd = df_validation.previous_transcript.values\n",
    "previous_system_transcript_vd = df_validation.previous_system_transcript.values\n",
    "action_labels_vd = df_validation.action.values\n",
    "attributes_labels_vd=df_validation.attributes.values\n",
    "dialog_ids_vd = df_validation.dialog_id.values\n",
    "turn_idxs_vd = df_validation.turn_idx.values\n",
    "\n",
    "print (\"VALIDATION DATA:\")\n",
    "\n",
    "# Print the original sentence.\n",
    "print(' Original: ', transcripts_vd[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(transcripts_vd[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(transcripts_vd[0])))\n",
    "\n",
    "# Print the dialog ids.\n",
    "print(f\"Dialog IDs: {dialog_ids_vd[0:20]}\")\n",
    "\n",
    "# Print the turn idxs.\n",
    "print(f\"Turn IDs: {turn_idxs_vd[0:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba6e6ef",
   "metadata": {},
   "source": [
    "#### Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "886bcaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATION DATA:\n",
      " Original:  That looks a little too light for what I need, do you have something else with a high customer rating?\n",
      "Tokenized:  ['that', 'looks', 'a', 'little', 'too', 'light', 'for', 'what', 'i', 'need', ',', 'do', 'you', 'have', 'something', 'else', 'with', 'a', 'high', 'customer', 'rating', '?']\n",
      "Token IDs:  [2008, 3504, 1037, 2210, 2205, 2422, 2005, 2054, 1045, 2342, 1010, 2079, 2017, 2031, 2242, 2842, 2007, 1037, 2152, 8013, 5790, 1029]\n",
      "Dialog IDs: [2494 2494 2494 2494 2494 3731 3731 3731 3731 3731 8546 8546 8546 8546\n",
      " 8546 8546 5590 5590 5590 5590]\n",
      "Turn IDs: [0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 5 0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "transcripts_tst = df_test.transcript.values\n",
    "previous_transcript_tst = df_test.previous_transcript.values\n",
    "previous_system_transcript_tst = df_test.previous_system_transcript.values\n",
    "action_labels_tst = df_test.action.values\n",
    "attributes_labels_tst=df_test.attributes.values\n",
    "dialog_ids_tst = df_test.dialog_id.values\n",
    "turn_idxs_tst = df_test.turn_idx.values\n",
    "\n",
    "print (\"EVALUATION DATA:\")\n",
    "\n",
    "# Print the original sentence.\n",
    "print(' Original: ', transcripts_tst[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(transcripts_tst[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(transcripts_tst[0])))\n",
    "\n",
    "# Print the dialog ids.\n",
    "print(f\"Dialog IDs: {dialog_ids_tst[0:20]}\")\n",
    "\n",
    "# Print the turn idxs.\n",
    "print(f\"Turn IDs: {turn_idxs_tst[0:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c049bbf",
   "metadata": {},
   "source": [
    "## Calcolo dimensione massima\n",
    "\n",
    "The above code left out a few required formatting steps that we'll look at here.\n",
    "\n",
    "We are required to:\n",
    "1. Add special tokens to the start and end of each sentence.\n",
    "2. Pad & truncate all sentences to a single constant length.\n",
    "3. Explicitly differentiate real tokens from padding tokens with the \"attention mask\".\n",
    "\n",
    "\n",
    "The sentences in our dataset obviously have varying lengths, so how does BERT handle this?\n",
    "\n",
    "BERT has two constraints:\n",
    "\n",
    "\n",
    "1.   All sentences must be padded or truncated to a single, fixed length.\n",
    "2.   The maximum sentence length is 512 tokens.\n",
    "\n",
    "\n",
    "Padding is done with a special [PAD] token, which is at index 0 in the BERT vocabulary. The below illustration demonstrates padding out to a \"MAX_LEN\" of 8 tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c16396",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8e5132e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max transcript length for training:  177\n"
     ]
    }
   ],
   "source": [
    "max_len_tr = 0\n",
    "\n",
    "# For every sentence...\n",
    "for i in range(0,len(transcripts_tr)):\n",
    "    \n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "\n",
    "    if (previous_transcript_tr[i] != \"\" and use_next):\n",
    "      input_ids = tokenizer.encode(previous_transcript_tr[i]+ \" \" + previous_system_transcript_tr[i],transcripts_tr[i], add_special_tokens=True)\n",
    "    else:\n",
    "      input_ids = tokenizer.encode(transcripts_tr[i], add_special_tokens=True)\n",
    "        \n",
    "    # Update the maximum sentence length.\n",
    "    max_len_tr = max(max_len_tr, len(input_ids))\n",
    "\n",
    "print('Max transcript length for training: ', max_len_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17363e3c",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92914388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max transcript length for validation:  133\n"
     ]
    }
   ],
   "source": [
    "max_len_vd = 0\n",
    "\n",
    "# For every sentence...\n",
    "for i in range(0,len(transcripts_vd)):\n",
    "\n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    if (previous_transcript_vd[i] != \"\" and use_next):\n",
    "      input_ids = tokenizer.encode(previous_transcript_vd[i]+ \" \" + previous_system_transcript_vd[i],transcripts_vd[i], add_special_tokens=True)\n",
    "    else:\n",
    "      input_ids = tokenizer.encode(transcripts_vd[i], add_special_tokens=True)\n",
    "    \n",
    "    # Update the maximum sentence length.\n",
    "    max_len_vd = max(max_len_vd, len(input_ids))\n",
    "\n",
    "print('Max transcript length for validation: ', max_len_vd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3412aa8",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aab75df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max transcript length for evaluation:  150\n"
     ]
    }
   ],
   "source": [
    "max_len_tst = 0\n",
    "\n",
    "#non sono sicuro che il controllo della lunghezza vada fatto anche sul test set, dopo la performance non è determinata\n",
    "#dalla conoscenza del test set?\n",
    "#è anche vero che in teoria per far funzionare BERT bisogna dargli in pasto dei dati tokenizzati, quindi in un caso reale il nostro\n",
    "#model non potrebbe prendere in ingresso del testo non trattato. Nel dubbio ho controllato le dimensioni\n",
    "\n",
    "for i in range(0,len(transcripts_tst)):\n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    if (previous_transcript_tst[i] != \"\" and use_next):\n",
    "      input_ids = tokenizer.encode(previous_transcript_tst[i]+ \" \" + previous_system_transcript_tst[i],transcripts_tst[i], add_special_tokens=True)\n",
    "    else:\n",
    "      input_ids = tokenizer.encode(transcripts_tst[i], add_special_tokens=True)\n",
    "\n",
    "    # Update the maximum sentence length.\n",
    "    max_len_tst = max(max_len_tst, len(input_ids))\n",
    "\n",
    "print(\"Max transcript length for evaluation: \",max_len_tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c277f0",
   "metadata": {},
   "source": [
    "### Risultato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26bd8ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La massima lunghezza dei token da gestire è quindi  177\n"
     ]
    }
   ],
   "source": [
    "max_len = max(max_len_tr, max_len_vd, max_len_tst)\n",
    "\n",
    "# if (max_len_tr >= max_len_vd):\n",
    "#   max_len = max_len_tr\n",
    "# else:\n",
    "#   max_len = max_len_vd\n",
    "# if (max_len_tst >= max_len):\n",
    "#   max_len = max_len_tst\n",
    "\n",
    "print(\"La massima lunghezza dei token da gestire è quindi \",max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcefd1f1",
   "metadata": {},
   "source": [
    "## Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54bc7c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "[('availableSizes',)]\n",
      "['ageRange' 'amountInStock' 'availableSizes' 'brand' 'clothingCategory'\n",
      " 'clothingStyle' 'color' 'customerRating' 'dressStyle' 'embellishment'\n",
      " 'forGender' 'forOccasion' 'hasPart' 'hemLength' 'hemStyle' 'info'\n",
      " 'jacketStyle' 'madeIn' 'material' 'necklineStyle' 'pattern' 'price'\n",
      " 'sequential' 'size' 'skirtLength' 'skirtStyle' 'sleeveLength'\n",
      " 'sleeveStyle' 'soldBy' 'sweaterStyle' 'waistStyle' 'warmthRating'\n",
      " 'waterResistance']\n",
      "Totale: 30106, Training: 21196, Validation: 3513, Evaluation: 5397\n",
      "Training: 21196, Validation: 3513, Evaluation: 5397\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "attributes_labels_all = np.concatenate((attributes_labels_tr, attributes_labels_vd,attributes_labels_tst), axis=None)\n",
    "attr_yt = mlb.fit_transform(attributes_labels_all)\n",
    "print(attr_yt[0:15])\n",
    "print(mlb.inverse_transform(attr_yt[3].reshape(1, -1)))\n",
    "print(mlb.classes_)\n",
    "print(f\"Totale: {len(attr_yt)}, Training: {len(attributes_labels_tr)}, Validation: {len(attributes_labels_vd)}, Evaluation: {len(attributes_labels_tst)}\")\n",
    "attributes_labels_tr_vect = attr_yt[0:len(attributes_labels_tr)]\n",
    "attributes_labels_vd_vect = attr_yt[len(attributes_labels_tr):(len(attributes_labels_tr)+len(attributes_labels_vd))]\n",
    "attributes_labels_tst_vect = attr_yt[(len(attributes_labels_tr)+len(attributes_labels_vd)):]\n",
    "print(f\"Training: {len(attributes_labels_tr_vect)}, Validation: {len(attributes_labels_vd_vect)}, Evaluation: {len(attributes_labels_tst_vect)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63925873",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9505e37",
   "metadata": {},
   "source": [
    "Now we're ready to perform the real tokenization.\n",
    "\n",
    "The tokenizer.encode_plus function combines multiple steps for us:\n",
    "\n",
    "Split the sentence into tokens.\n",
    "Add the special [CLS] and [SEP] tokens.\n",
    "Map the tokens to their IDs.\n",
    "Pad or truncate all sentences to the same length.\n",
    "Create the attention masks which explicitly differentiate real tokens from [PAD] tokens.\n",
    "The first four features are in tokenizer.encode, but I'm using tokenizer.encode_plus to get the fifth item (attention masks). Documentation is here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aff8d187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f78409fe350>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "# backends cudnn for out memory not necessary (resolved by batch size)\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "# torch.backends.cudnn.enabled = True\n",
    "# Set torch seed for deterministic behaviour\n",
    "torch.manual_seed(exec_params['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45855e8f",
   "metadata": {},
   "source": [
    "### Tokenize Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e32c330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21196 records to encode.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gian/anaconda3/envs/testcuda1/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2126: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING : \n",
      "Original:  Is there a pattern on this one? It's hard to see in the image.\n",
      "Token IDs: tensor([ 101, 2003, 2045, 1037, 5418, 2006, 2023, 2028, 1029, 2009, 1005, 1055,\n",
      "        2524, 2000, 2156, 1999, 1996, 3746, 1012,  102,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "\n",
    "#dobbiamo convertire le nostre lables da string a valori numerici, usiamo il metodo fornito da sklearn\n",
    "\n",
    "#TRAINING DATASET\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "action_labels_encoded_tr = le.fit_transform(action_labels_tr)\n",
    "\n",
    "input_ids_tr = []\n",
    "attention_masks_tr = []\n",
    "print(f\"{len(df_training)} records to encode.\")\n",
    "# For every sentence...\n",
    "for i in range(0,len(df_training)):\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "\n",
    "  if (previous_transcript_tr[i] != \"\" and use_next):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        previous_transcript_tr[i]+ \" \" + previous_system_transcript_tr[i],  # Sentence to encode.\n",
    "                        transcripts_tr[i], #next sentece to encode\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        truncation = True,\n",
    "                        max_length = max_len,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                    )\n",
    "  else:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        transcripts_tr[i],  # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        truncation = True,\n",
    "                        max_length = max_len,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                    )\n",
    "    \n",
    "\n",
    "    \n",
    "  # Add the encoded sentence to the list.    \n",
    "  input_ids_tr.append(encoded_dict['input_ids'])\n",
    "\n",
    "  # And its attention mask (simply differentiates padding from non-padding).\n",
    "  attention_masks_tr.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids_tr = torch.cat(input_ids_tr, dim=0)\n",
    "attention_masks_tr = torch.cat(attention_masks_tr, dim=0)\n",
    "labels_actions_tr = torch.tensor(action_labels_encoded_tr)\n",
    "labels_attributes_tr = torch.tensor(attributes_labels_tr_vect) \n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print (\"TRAINING : \")\n",
    "if (use_next):\n",
    "  print('Original: ', transcripts_tr[0])\n",
    "else:\n",
    "  print('Original: ', transcripts_tr[0])\n",
    "print('Token IDs:', input_ids_tr[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cda4541",
   "metadata": {},
   "source": [
    "### Tokenize Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5da13a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3513 records to encode.\n",
      "VALIDATION : \n",
      "Original:  What's the price of this sweater compared to the other blue and gray one I looked at?\n",
      "Token IDs: tensor([  101,  2054,  1005,  1055,  1996,  3976,  1997,  2023, 14329,  4102,\n",
      "         2000,  1996,  2060,  2630,  1998,  3897,  2028,  1045,  2246,  2012,\n",
      "         1029,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0])\n",
      "Dialog IDs: tensor([4146, 4146, 4146, 4146, 4146, 4146, 4146, 4260, 4260, 4260, 4260, 8022,\n",
      "        8022, 8022, 8022, 8022, 8022, 4992, 4992, 4992])\n",
      "Turn IDXs: tensor([0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 0, 1, 2, 3, 4, 5, 0, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "\n",
    "#dobbiamo convertire le nostre lables da string a valori numerici, usiamo il metodo fornito da sklearn\n",
    "\n",
    "#VALIDATION DATASET\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "action_labels_encoded_vd = le.fit_transform(action_labels_vd)\n",
    "\n",
    "input_ids_vd = []\n",
    "attention_masks_vd = []\n",
    "print(f\"{len(df_validation)} records to encode.\")\n",
    "# For every sentence...\n",
    "for i in range(0,len(df_validation)):\n",
    "  # `encode_plus` will:\n",
    "  #   (1) Tokenize the sentence.\n",
    "  #   (2) Prepend the `[CLS]` token to the start.\n",
    "  #   (3) Append the `[SEP]` token to the end.\n",
    "  #   (4) Map tokens to their IDs.\n",
    "  #   (5) Pad or truncate the sentence to `max_length`\n",
    "  #   (6) Create attention masks for [PAD] tokens.\n",
    "\n",
    "  if (previous_transcript_vd[i] != \"\" and use_next):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        previous_transcript_vd[i]+ \" \" + previous_system_transcript_vd[i],  # Sentence to encode.\n",
    "                        transcripts_vd[i], #next sentece to encode\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        truncation = True,\n",
    "                        max_length = max_len,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                    )\n",
    "  else:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        transcripts_vd[i],  # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        truncation = True,\n",
    "                        max_length = max_len,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                    )\n",
    "    \n",
    "  # Add the encoded sentence to the list.    \n",
    "  input_ids_vd.append(encoded_dict['input_ids'])\n",
    "  \n",
    "  # And its attention mask (simply differentiates padding from non-padding).\n",
    "  attention_masks_vd.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids_vd = torch.cat(input_ids_vd, dim=0)\n",
    "attention_masks_vd = torch.cat(attention_masks_vd, dim=0)\n",
    "labels_actions_vd = torch.tensor(action_labels_encoded_vd)\n",
    "labels_attributes_vd = torch.tensor(attributes_labels_vd_vect)\n",
    "# Check warning:\n",
    "# /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
    "dialog_ids_vd = torch.tensor(dialog_ids_vd)\n",
    "turn_idxs_vd = torch.tensor(turn_idxs_vd) \n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print (\"VALIDATION : \")\n",
    "if (use_next):\n",
    "  print('Original: ', transcripts_vd[0])\n",
    "else:\n",
    "  print('Original: ', transcripts_vd[0])\n",
    "print('Token IDs:', input_ids_vd[0])\n",
    "print(f\"Dialog IDs: {dialog_ids_vd[0:20]}\")\n",
    "print(f\"Turn IDXs: {turn_idxs_vd[0:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d364715",
   "metadata": {},
   "source": [
    "### Tokenize Evaluation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23888911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5397 records to encode.\n",
      "Evaluation : \n",
      "Original:  That looks a little too light for what I need, do you have something else with a high customer rating?\n",
      "Token IDs: tensor([ 101, 2008, 3504, 1037, 2210, 2205, 2422, 2005, 2054, 1045, 2342, 1010,\n",
      "        2079, 2017, 2031, 2242, 2842, 2007, 1037, 2152, 8013, 5790, 1029,  102,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0])\n",
      "Dialog IDs: tensor([2494, 2494, 2494, 2494, 2494, 3731, 3731, 3731, 3731, 3731, 8546, 8546,\n",
      "        8546, 8546, 8546, 8546, 5590, 5590, 5590, 5590])\n",
      "Turn IDXs: tensor([0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "\n",
    "#dobbiamo convertire le nostre lables da string a valori numerici, usiamo il metodo fornito da sklearn\n",
    "\n",
    "#EVALUATION DATASET\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "action_labels_encoded_tst = le.fit_transform(action_labels_tst)\n",
    "\n",
    "input_ids_tst = []\n",
    "attention_masks_tst = []\n",
    "print(f\"{len(df_test)} records to encode.\")\n",
    "# For every sentence...\n",
    "for i in range(0,len(df_test)):\n",
    "# for t in transcripts_tst:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "  \n",
    "  #Aggiungere \"and False\" PER UTILIZZARE sempre la tokenizzazione senza concatenazione\n",
    "  if (previous_transcript_tst[i] != \"\" and use_next):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                      previous_transcript_tst[i]+ \" \" + previous_system_transcript_tst[i],  # Sentence to encode.\n",
    "                      transcripts_tst[i], #next sentece to encode\n",
    "                      add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                      truncation = True,\n",
    "                      max_length = max_len,           # Pad & truncate all sentences.\n",
    "                      pad_to_max_length = True,\n",
    "                      return_attention_mask = True,   # Construct attn. masks.\n",
    "                      return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                  )\n",
    "  else:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                      transcripts_tst[i],  # Sentence to encode.\n",
    "                      add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                      truncation = True,\n",
    "                      max_length = max_len,           # Pad & truncate all sentences.\n",
    "                      pad_to_max_length = True,\n",
    "                      return_attention_mask = True,   # Construct attn. masks.\n",
    "                      return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                  )\n",
    "    \n",
    "  # Add the encoded sentence to the list.    \n",
    "  input_ids_tst.append(encoded_dict['input_ids'])\n",
    "  \n",
    "  # And its attention mask (simply differentiates padding from non-padding).\n",
    "  attention_masks_tst.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids_tst = torch.cat(input_ids_tst, dim=0)\n",
    "attention_masks_tst = torch.cat(attention_masks_tst, dim=0)\n",
    "labels_actions_tst = torch.tensor(action_labels_encoded_tst)\n",
    "labels_attributes_tst = torch.tensor(attributes_labels_tst_vect)\n",
    "# Check warning:\n",
    "# /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
    "dialog_ids_tst = torch.tensor(dialog_ids_tst)\n",
    "turn_idxs_tst = torch.tensor(turn_idxs_tst) \n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print (\"Evaluation : \")\n",
    "if (use_next):\n",
    "  print('Original: ', transcripts_tst[0])\n",
    "else:\n",
    "  print('Original: ', transcripts_tst[0])\n",
    "print('Token IDs:', input_ids_tst[0])\n",
    "print(f\"Dialog IDs: {dialog_ids_tst[0:20]}\")\n",
    "print(f\"Turn IDXs: {turn_idxs_tst[0:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af23bb7",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96157e27",
   "metadata": {},
   "source": [
    "# Data Split - AP4CA\n",
    "La nostra versione di split di dati per training e validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "680bdf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21,196 training samples\n",
      "3,513 validation samples\n",
      "5,397 evaluation samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "#labels_tr = {'actions': labels_actions_tr, 'attributes': labels_attributes_tr}\n",
    "#labels_vd = {'actions': labels_actions_vd, 'attributes': labels_attributes_vd}\n",
    "\n",
    "train_dataset = TensorDataset(input_ids_tr, attention_masks_tr, labels_actions_tr, labels_attributes_tr)\n",
    "val_dataset = TensorDataset(input_ids_vd, attention_masks_vd, labels_actions_vd, labels_attributes_vd, dialog_ids_vd, turn_idxs_vd)\n",
    "tst_dataset = TensorDataset(input_ids_tst, attention_masks_tst, labels_actions_tst, labels_attributes_tst, dialog_ids_tst, turn_idxs_tst)\n",
    "\n",
    "print('{:>5,} training samples'.format(len(train_dataset)))\n",
    "print('{:>5,} validation samples'.format(len(val_dataset)))\n",
    "print('{:>5,} evaluation samples'.format(len(tst_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed1196fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 101, 2008, 3504,  ...,    0,    0,    0],\n",
       "         [ 101, 2008, 3504,  ...,    0,    0,    0],\n",
       "         [ 101, 2040, 5617,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [ 101, 2821, 1045,  ...,    0,    0,    0],\n",
       "         [ 101, 4086, 1010,  ...,    0,    0,    0],\n",
       "         [ 101, 1045, 2066,  ...,    0,    0,    0]]),\n",
       " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " tensor([2, 4, 4, 0, 1, 2, 1, 2, 0, 1]),\n",
       " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " tensor([2494, 2494, 2494, 2494, 2494, 3731, 3731, 3731, 3731, 3731]),\n",
       " tensor([0, 1, 2, 3, 4, 0, 1, 2, 3, 4]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check evaluation TensorDataset content\n",
    "tst_dataset[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d01df19",
   "metadata": {},
   "source": [
    "## Check GPU for Training\n",
    "\n",
    "In questa versione la GPU è impostata fissa.\n",
    "Con una GPU in più a disposizione possiamo usare DataParallel e aumentare il batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31bf32c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2060\n"
     ]
    }
   ],
   "source": [
    "# Tell PyTorch to use the GPU.    \n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "print('We will use the GPU:', torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2045d72f",
   "metadata": {},
   "source": [
    "### Creazione Data Loaders per Training, Validation ed Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d9f42ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "# With size 32 GeForce RTX 2060 with 6GB run out of memory\n",
    "batch_size = exec_params['batch']\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )\n",
    "\n",
    "#ho controllato nel colab su cui ci basiamo, anche lui usa un Sequential Sampler per il dataset di evaluation\n",
    "evaluation_dataloader = DataLoader(\n",
    "            tst_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(tst_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040d27c5",
   "metadata": {},
   "source": [
    "## Train BERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc8111f",
   "metadata": {},
   "source": [
    "For this task, we first want to modify the pre-trained BERT model to give outputs for classification, and then we want to continue training the model on our dataset until that the entire model, end-to-end, is well-suited for our task. \n",
    "\n",
    "Thankfully, the huggingface pytorch implementation includes a set of interfaces designed for a variety of NLP tasks. Though these interfaces are all built on top of a trained BERT model, each has different top layers and output types designed to accomodate their specific NLP task.  \n",
    "\n",
    "Here is the current list of classes provided for fine-tuning:\n",
    "* BertModel\n",
    "* BertForPreTraining\n",
    "* BertForMaskedLM\n",
    "* BertForNextSentencePrediction\n",
    "* **BertForSequenceClassification** - The one we'll use.\n",
    "* BertForTokenClassification\n",
    "* BertForQuestionAnswering\n",
    "\n",
    "The documentation for these can be found under [here](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbd23ca",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We'll be using [BertForSequenceClassification](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#bertforsequenceclassification). This is the normal BERT model with an added single linear layer on top for classification that we will use as a sentence classifier. As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task. \n",
    "\n",
    "NB anche nell'articolo che sto leggendo sulla classificazione multi-label si parte da questo modello\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba0360b",
   "metadata": {},
   "source": [
    "OK, let's load BERT! There are a few different pre-trained BERT models available. \"bert-base-uncased\" means the version that has only lowercase letters (\"uncased\") and is the smaller version of the two (\"base\" vs \"large\").\n",
    "\n",
    "The documentation for `from_pretrained` can be found [here](https://huggingface.co/transformers/v2.2.0/main_classes/model.html#transformers.PreTrainedModel.from_pretrained), with the additional parameters defined [here](https://huggingface.co/transformers/v2.2.0/main_classes/configuration.html#transformers.PretrainedConfig)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "242aa137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DA SISTEMARE\n",
    "from transformers import BertModel\n",
    "from  torch import  nn\n",
    "\n",
    "class CustomBERTModel(nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "\n",
    "    super(CustomBERTModel, self).__init__()\n",
    "    self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "    ### New layers:\n",
    "    self.linear_intermedio = nn.Linear(768, exec_params['hidden_output_dim'])\n",
    "    #provare ad aggiungere ulteriori layer intermedi per ridurre le dimensioni fino ad arrivare all'output richiesto\n",
    "    self.linear_actions = nn.Linear(exec_params['hidden_output_dim'], 5) \n",
    "    self.linear_attributes = nn.Linear(exec_params['hidden_output_dim'], len(mlb.classes_)) #num attributi? \n",
    "\n",
    "  def forward(self, ids, mask):\n",
    "    #controllare che l'output non rappresenti solo lo stato interno dovuto al token CLS\n",
    "    output = self.bert(ids,attention_mask=mask)\n",
    "    # print(f\"Type output{type(output)}\")\n",
    "    # for p in output:\n",
    "    #   print(p)\n",
    "    #   print(type(output[p]))\n",
    "    #   print(output[p])\n",
    "\n",
    "    #prendiamo il campo last_hidden_state dall'oggetto output; last hidden state rappresenta il tensore\n",
    "    #in uscita dallo step di forward del BertModel\n",
    "    last_hidden_state_output = output[\"last_hidden_state\"]\n",
    "    # last_hidden_state has the following shape: (batch_size, sequence_length, 768)\n",
    "    #stiamo passando solo il token CLS ai layer successivi\n",
    "    linear_output_intermedio = self.linear_intermedio(last_hidden_state_output[:,0,:].view(-1,768)) \n",
    "    # linear_output_intermedio = self.linear_intermedio(pooled_output) \n",
    "    \n",
    "    linear_output_actions = self.linear_actions(linear_output_intermedio)\n",
    "    # linear_output_actions = self.sftmx(linear_output_actions)\n",
    "    # linear_output_actions = nn.functional.softmax(linear_output_actions)\n",
    "    # Test sigmoid for increasing perplexity performance\n",
    "    linear_output_actions = torch.sigmoid(linear_output_actions)\n",
    "    linear_output_attributes = self.linear_attributes(linear_output_intermedio)\n",
    "    # linear_output_attributes = self.sig(linear_output_attributes)\n",
    "    linear_output_attributes = torch.sigmoid(linear_output_attributes)\n",
    "\n",
    "    return {'actions': linear_output_actions, 'attributes': linear_output_attributes}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ceefd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomBERTModel(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (linear_intermedio): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (linear_actions): Linear(in_features=256, out_features=5, bias=True)\n",
       "  (linear_attributes): Linear(in_features=256, out_features=33, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test istanziazione del custom model\n",
    "model = CustomBERTModel()\n",
    "\n",
    "# model.bert.config\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cb0c4c",
   "metadata": {},
   "source": [
    "Just for curiosity's sake, we can browse all of the model's parameters by name here.\n",
    "\n",
    "In the below cell, I've printed out the names and dimensions of the weights for:\n",
    "\n",
    "1. The embedding layer.\n",
    "2. The first of the twelve transformers.\n",
    "3. The output layer.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c48662a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 205 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "linear_actions.weight                                       (5, 256)\n",
      "linear_actions.bias                                             (5,)\n",
      "linear_attributes.weight                                   (33, 256)\n",
      "linear_attributes.bias                                         (33,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655b5929",
   "metadata": {},
   "source": [
    "## 4.2. Optimizer & Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2ee817",
   "metadata": {},
   "source": [
    "Now that we have our model loaded we need to grab the training hyperparameters from within the stored model.\n",
    "\n",
    "For the purposes of fine-tuning, the authors recommend choosing from the following values (from Appendix A.3 of the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf)):\n",
    "\n",
    ">- **Batch size:** 16, 32  \n",
    "- **Learning rate (Adam):** 5e-5, 3e-5, 2e-5  \n",
    "- **Number of epochs:** 2, 3, 4 \n",
    "\n",
    "We chose:\n",
    "* Batch size: 32 (set when creating our DataLoaders)\n",
    "* Learning rate: 2e-5\n",
    "* Epochs: 4 (we'll see that this is probably too many...)\n",
    "\n",
    "The epsilon parameter `eps = 1e-8` is \"a very small number to prevent any division by zero in the implementation\" (from [here](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)).\n",
    "\n",
    "You can find the creation of the AdamW optimizer in `run_glue.py` [here](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "295fde1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = exec_params['learning_rate'], # args.learning_rate - default is 5e-5\n",
    "                  eps = exec_params['tolerance'] # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4faef5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = exec_params['epochs']\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eccdf3c",
   "metadata": {},
   "source": [
    "## 4.3. Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1141dfa",
   "metadata": {},
   "source": [
    "Below is our training loop. There's a lot going on, but fundamentally for each pass in our loop we have a trianing phase and a validation phase. \n",
    "\n",
    "> *Thank you to [Stas Bekman](https://ca.linkedin.com/in/stasbekman) for contributing the insights and code for using validation loss to detect over-fitting!*\n",
    "\n",
    "**Training:**\n",
    "- Unpack our data inputs and labels\n",
    "- Load data onto the GPU for acceleration\n",
    "- Clear out the gradients calculated in the previous pass. \n",
    "    - In pytorch the gradients accumulate by default (useful for things like RNNs) unless you explicitly clear them out.\n",
    "- Forward pass (feed input data through the network)\n",
    "- Backward pass (backpropagation)\n",
    "- Tell the network to update parameters with optimizer.step()\n",
    "- Track variables for monitoring progress\n",
    "\n",
    "**Evalution:**\n",
    "- Unpack our data inputs and labels\n",
    "- Load data onto the GPU for acceleration\n",
    "- Forward pass (feed input data through the network)\n",
    "- Compute loss on our validation data and track variables for monitoring progress\n",
    "\n",
    "Pytorch hides all of the detailed calculations from us, but we've commented the code to point out which of the above steps are happening on each line. \n",
    "\n",
    "> *PyTorch also has some [beginner tutorials](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py) which you may also find helpful.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d699904",
   "metadata": {},
   "source": [
    "Define a helper function for calculating accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df633469",
   "metadata": {},
   "source": [
    "### Flat accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef1a2d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy_actions(preds, labels):\n",
    "    #print(f\"[FA] preds: {preds} / labels: {labels}\")\n",
    "    #print(f\"[FA-Actions] {type(preds)} {type(labels)}\")\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()   \n",
    "    return {'matched': np.sum(pred_flat == labels_flat), 'counts': len(labels_flat)}\n",
    "\n",
    "def flat_accuracy_attributes(preds, labels):\n",
    "  #print(f\"[FA-Attributess] {type(preds)} {type(labels)}\")\n",
    "  tot_preds = preds.shape[0]\n",
    "  preds_int = np.rint(preds)\n",
    "  tot_eq = 0\n",
    "  for i in range(tot_preds):\n",
    "    comparison = preds_int[i] == labels[i]\n",
    "    if comparison.all():\n",
    "      tot_eq += 1\n",
    "  return {'matched': tot_eq, 'counts' : tot_preds}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc1a792",
   "metadata": {},
   "source": [
    "Helper function for formatting elapsed times as `hh:mm:ss`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "903c3769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdd0590",
   "metadata": {},
   "source": [
    "### Loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0629812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "# Loss function definition\n",
    "def MyBERT_loss(logits, actions_labels, attributes_labels):\n",
    "  actions_logits = logits['actions']\n",
    "  attributes_logits = logits['attributes']\n",
    "  loss_actions_fn = nn.CrossEntropyLoss()\n",
    "  loss_attributes_fn = nn.BCELoss()\n",
    "  loss_actions = loss_actions_fn(actions_logits, actions_labels)\n",
    "  loss_attributes = loss_attributes_fn(attributes_logits, attributes_labels.float())\n",
    "  return loss_actions + loss_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fea679",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We're ready to kick off the training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aab27b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 6 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 12% | 31% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 16% | 31% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:54.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:48.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:45.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:41.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 91% | 88% |\n",
      "End of epoch 0\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "\n",
      "  Average training loss: 1.13\n",
      "  Training epcoh took: 0:08:29\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8377\n",
      "  Accuracy for multilabel-classification (attributes): 0.8748\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8377455166524338, 'action_perplexity': 2.118447578327549, 'attribute_accuracy': 0.6618928513777053, 'confusion_matrix': array([[4.640e+02, 3.200e+01, 2.100e+01, 0.000e+00, 1.000e+01],\n",
      "       [2.400e+01, 6.790e+02, 5.300e+01, 8.000e+00, 1.500e+01],\n",
      "       [1.000e+00, 1.380e+02, 4.620e+02, 4.500e+01, 1.200e+01],\n",
      "       [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
      "       [3.000e+00, 5.900e+01, 8.800e+01, 6.100e+01, 1.338e+03]])}\n",
      "  Validation Loss: 1.0744\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "======== Epoch 2 / 6 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 97% | 89% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 97% | 89% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:55.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 89% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:49.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 88% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:44.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 88% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:38.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "End of epoch 1\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "\n",
      "  Average training loss: 1.06\n",
      "  Training epcoh took: 0:08:26\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8429\n",
      "  Accuracy for multilabel-classification (attributes): 0.9061\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.842869342442357, 'action_perplexity': 2.5957289320680412, 'attribute_accuracy': 0.7337424283985002, 'confusion_matrix': array([[4.800e+02, 7.800e+01, 3.000e+00, 1.000e+00, 8.000e+00],\n",
      "       [3.000e+00, 6.240e+02, 2.000e+01, 7.000e+00, 1.800e+01],\n",
      "       [7.000e+00, 1.540e+02, 5.260e+02, 4.600e+01, 1.800e+01],\n",
      "       [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
      "       [2.000e+00, 5.200e+01, 7.500e+01, 6.000e+01, 1.331e+03]])}\n",
      "  Validation Loss: 1.0699\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "======== Epoch 3 / 6 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:55.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 88% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:50.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:45.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 88% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:39.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 87% |\n",
      "End of epoch 2\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 87% |\n",
      "\n",
      "  Average training loss: 1.05\n",
      "  Training epcoh took: 0:08:27\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8483\n",
      "  Accuracy for multilabel-classification (attributes): 0.9155\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8482778252206091, 'action_perplexity': 2.415121293186072, 'attribute_accuracy': 0.7513381496367191, 'confusion_matrix': array([[4.410e+02, 2.500e+01, 3.000e+00, 0.000e+00, 3.000e+00],\n",
      "       [4.100e+01, 6.910e+02, 3.700e+01, 1.000e+01, 1.700e+01],\n",
      "       [9.000e+00, 1.410e+02, 5.130e+02, 4.100e+01, 2.000e+01],\n",
      "       [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
      "       [1.000e+00, 5.100e+01, 7.100e+01, 6.300e+01, 1.335e+03]])}\n",
      "  Validation Loss: 1.0600\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "======== Epoch 4 / 6 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 87% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 87% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:55.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 89% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:50.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 89% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:44.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 89% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:39.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 89% |\n",
      "End of epoch 3\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 87% |\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epcoh took: 0:08:27\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8531\n",
      "  Accuracy for multilabel-classification (attributes): 0.9132\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8531169940222032, 'action_perplexity': 2.5129833728618474, 'attribute_accuracy': 0.7386219200940045, 'confusion_matrix': array([[4.710e+02, 3.600e+01, 5.000e+00, 0.000e+00, 8.000e+00],\n",
      "       [9.000e+00, 6.860e+02, 3.600e+01, 9.000e+00, 2.100e+01],\n",
      "       [7.000e+00, 1.470e+02, 5.350e+02, 6.100e+01, 4.200e+01],\n",
      "       [0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00],\n",
      "       [5.000e+00, 3.900e+01, 4.800e+01, 4.300e+01, 1.304e+03]])}\n",
      "  Validation Loss: 1.0565\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "======== Epoch 5 / 6 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 87% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 87% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:55.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 88% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:51.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 93% | 89% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:47.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 90% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:42.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 90% |\n",
      "End of epoch 4\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 89% |\n",
      "\n",
      "  Average training loss: 1.01\n",
      "  Training epcoh took: 0:08:30\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8514\n",
      "  Accuracy for multilabel-classification (attributes): 0.9320\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8514090520922288, 'action_perplexity': 2.5958760725816434, 'attribute_accuracy': 0.7511113194966271, 'confusion_matrix': array([[ 468.,   34.,    4.,    0.,    3.],\n",
      "       [  12.,  717.,   88.,   12.,   17.],\n",
      "       [   7.,  116.,  469.,   40.,   26.],\n",
      "       [   0.,    0.,    5.,   14.,    6.],\n",
      "       [   5.,   41.,   58.,   48., 1323.]])}\n",
      "  Validation Loss: 1.0580\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "======== Epoch 6 / 6 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 98% | 89% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 98% | 89% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:55.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 89% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:51.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 89% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:48.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 90% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:43.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 90% |\n",
      "End of epoch 5\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 90% |\n",
      "\n",
      "  Average training loss: 1.00\n",
      "  Training epcoh took: 0:08:32\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8525\n",
      "  Accuracy for multilabel-classification (attributes): 0.9362\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8525476800455452, 'action_perplexity': 2.57779704806192, 'attribute_accuracy': 0.7608893591723118, 'confusion_matrix': array([[4.700e+02, 3.500e+01, 1.000e+00, 0.000e+00, 2.000e+00],\n",
      "       [9.000e+00, 7.070e+02, 7.300e+01, 1.000e+01, 2.000e+01],\n",
      "       [8.000e+00, 1.270e+02, 4.820e+02, 3.800e+01, 3.100e+01],\n",
      "       [0.000e+00, 1.000e+00, 1.300e+01, 2.100e+01, 7.000e+00],\n",
      "       [5.000e+00, 3.800e+01, 5.500e+01, 4.500e+01, 1.315e+03]])}\n",
      "  Validation Loss: 1.0547\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:53:32 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import action_evaluation as evaluation\n",
    "import json\n",
    "from  GPUtil import showUtilization as gpu_usage\n",
    "with open('./extr_output/fashion_dev_dials_api_calls.json') as f:\n",
    "  dev_dials = json.load(f)\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = exec_params['seed']\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "#torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "test_batch = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    print(\"GPU before train\")\n",
    "    gpu_usage()\n",
    "\n",
    "    model.train()\n",
    "    print(\"GPU after train\")\n",
    "    gpu_usage()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 400 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "            gpu_usage()\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: actions labels \n",
    "        #   [3]: attributes labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels_actions = batch[2].to(device)\n",
    "        b_labels_attributes = batch[3].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
    "        # function and pass down the arguments. The `forward` function is \n",
    "        # documented here: \n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
    "        # The results are returned in a results object, documented here:\n",
    "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
    "        # Specifically, we'll get the loss (because we provided labels) and the\n",
    "        # \"logits\"--the model outputs prior to activation.\n",
    "        result = model(b_input_ids, \n",
    "                       mask=b_input_mask)\n",
    "        \n",
    "        loss = MyBERT_loss(result, b_labels_actions, b_labels_attributes)\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.from transformers import BertModel, BertConfig\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    print(f\"End of epoch {epoch_i}\")\n",
    "    gpu_usage()\n",
    "    \n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.mlb.inverse_transform(attr_yt[3].reshape(1, -1))\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy_classification = { 'matched': 0, 'counts': 0}\n",
    "    total_eval_accuracy_multilabel = { 'matched': 0, 'counts': 0}\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    batch_number = 0\n",
    "\n",
    "    # Dictionary for action_evaluation\n",
    "    model_actions = {}\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        batch_number += 1\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels_actions = batch[2].to(device)\n",
    "        b_labels_attributes = batch[3].to(device)\n",
    "        b_dialog_ids = batch[4].to(device).detach().cpu().numpy()\n",
    "        b_turn_idxs = batch[5].to(device).detach().cpu().numpy()\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            result = model(b_input_ids, \n",
    "                       mask=b_input_mask)\n",
    "\n",
    "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
    "        # output values prior to applying an activation function like the \n",
    "        # softmax.\n",
    "        loss = MyBERT_loss(result, b_labels_actions, b_labels_attributes)\n",
    "            \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        # logits = logits.detach().cpu().numpy()\n",
    "        # label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        \n",
    "        actions_logits_foracc=result['actions'].detach().cpu().numpy()\n",
    "        attributes_logits_foracc=result['attributes'].detach().cpu().numpy()\n",
    "        actions_labels_foracc= b_labels_actions.to('cpu').numpy()\n",
    "        attributes_labels_foracc =b_labels_attributes.to('cpu').numpy()\n",
    "\n",
    "        #TODO: definire la nostra funzione di accuracy\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        accuracy_classification = flat_accuracy_actions(actions_logits_foracc, actions_labels_foracc)\n",
    "        accuracy_multilabel = flat_accuracy_attributes(attributes_logits_foracc, attributes_labels_foracc)\n",
    "        \n",
    "        total_eval_accuracy_classification['matched'] += accuracy_classification['matched']\n",
    "        total_eval_accuracy_classification['counts'] += accuracy_classification['counts']\n",
    "        total_eval_accuracy_multilabel['matched'] += accuracy_multilabel['matched']\n",
    "        total_eval_accuracy_multilabel['counts'] += accuracy_multilabel['counts']\n",
    "        # Salvo dati elaborazione batch per debug/analisi\n",
    "        test_batch.append({\n",
    "            'epoch' : epoch_i + 1,\n",
    "            'batchnum' : batch_number,\n",
    "            'actions_logits' : actions_logits_foracc,\n",
    "            'actions_labels' : actions_labels_foracc,\n",
    "            'attributes_logits' : attributes_logits_foracc,\n",
    "            'attributes_labels' : attributes_labels_foracc,\n",
    "            'accuracy_classification' : accuracy_classification,\n",
    "            'accuracy_multilabel' : accuracy_multilabel,\n",
    "        })\n",
    "\n",
    "        # Fill dictionary for action_evaluation\n",
    "        for el_i in range(len(actions_logits_foracc)):\n",
    "          dialog_id = b_dialog_ids[el_i]\n",
    "          action_log_prob = {}\n",
    "          for act_i in range(len(actions_logits_foracc[el_i])):\n",
    "            #todo: controllare che la probabilità predetta sia in scala logaritmica (?? potrebbe essere fonte di errori)\n",
    "            action_log_prob[le.classes_[act_i]] = np.log(actions_logits_foracc[el_i][act_i])\n",
    "          #attributes = {}\n",
    "          attributes = []\n",
    "          #attributes_list = np.rint(attributes_logits_foracc[el_i])\n",
    "          attributes_list = np.array(attributes_logits_foracc[el_i])\n",
    "          for attr in range(len(attributes_list)):\n",
    "            attribute = mlb.classes_[attr]\n",
    "            #attributes[mlb.classes_[attr]] = attributes_list[attr]\n",
    "            if attributes_list[attr] >= 0.5:\n",
    "              attributes.append(attribute)\n",
    "          prediction = {\n",
    "              'action': le.classes_[np.argmax(actions_logits_foracc[el_i])],\n",
    "              'action_log_prob': action_log_prob,\n",
    "              'attributes': {'attributes': attributes},\n",
    "              'turn_id': b_turn_idxs[el_i]\n",
    "          }\n",
    "          if dialog_id in model_actions:\n",
    "            model_actions[dialog_id]['predictions'].append(prediction)\n",
    "          else:\n",
    "            predictions = list()\n",
    "            predictions.append(prediction)\n",
    "            model_actions[dialog_id] = {\n",
    "                'dialog_id': dialog_id,\n",
    "                'predictions': predictions\n",
    "            }\n",
    "          \n",
    "\n",
    "    # Report the final accuracy for this validation \n",
    "\n",
    "    #avg_val_accuracy_classification = total_eval_accuracy_classification / len(validation_dataloader)\n",
    "    #avg_val_accuracy_multilabel = total_eval_accuracy_multilabel / len(validation_dataloader)\n",
    "    avg_val_accuracy_classification = total_eval_accuracy_classification['matched'] / total_eval_accuracy_classification['counts']\n",
    "    avg_val_accuracy_multilabel = total_eval_accuracy_multilabel['matched'] / total_eval_accuracy_multilabel['counts']\n",
    "    print(\"  Accuracy for classification (actions): {0:.4f}\".format(avg_val_accuracy_classification))\n",
    "    print(\"  Accuracy for multilabel-classification (attributes): {0:.4f}\".format(avg_val_accuracy_multilabel))\n",
    "\n",
    "    # Reference implementation: evaluation of action prediction along with attributes\n",
    "    metrics = evaluation.evaluate_action_prediction(dev_dials, model_actions.values())\n",
    "    # print(\"model_actions passed to the evaluator:\")\n",
    "    # for v in model_actions.values():\n",
    "    #   print(v)\n",
    "    print(\"***************************************\")\n",
    "    print(\"Reference evaluation metrics:\")\n",
    "    print(metrics)\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.4f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,  \n",
    "            'Valid. Accur. class.': avg_val_accuracy_classification,\n",
    "            'Valid. Accur. mult.label': avg_val_accuracy_multilabel,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time,\n",
    "            'metrics': metrics\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ac0f0f",
   "metadata": {},
   "source": [
    "## Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b6d29e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy for classification (actions): 0.8514\n",
      "  Accuracy for multilabel-classification (attributes): 0.9296\n",
      "#Instances evaluated API: 5397\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8513989253288864, 'action_perplexity': 2.7179633114317627, 'attribute_accuracy': 0.7593449044686459, 'confusion_matrix': array([[ 746.,   51.,   10.,    4.,   13.],\n",
      "       [  28., 1087.,  109.,   15.,   37.],\n",
      "       [  11.,  179.,  727.,   68.,   29.],\n",
      "       [   0.,    3.,   10.,   40.,   14.],\n",
      "       [   8.,   66.,   88.,   59., 1995.]])}\n"
     ]
    }
   ],
   "source": [
    "#Prediction on test set\n",
    "#quale modello gli viene passato? da controllare se BERT da solo riesce a tenere traccia del modello che ha dato l'epoca migliore\n",
    "\n",
    "\n",
    "with open('./extr_output/fashion_devtest_dials_api_calls.json') as f:\n",
    "  devtest_dials = json.load(f)\n",
    "\n",
    "# Tracking variables \n",
    "total_eval_accuracy_classification = { 'matched': 0, 'counts': 0}\n",
    "total_eval_accuracy_multilabel = { 'matched': 0, 'counts': 0}\n",
    "\n",
    "model_actions = {}\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "for batch in evaluation_dataloader:\n",
    "\n",
    "    # Unpack this training batch from our dataloader. \n",
    "    #\n",
    "    # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "    # the `to` method.\n",
    "    #\n",
    "    # `batch` contains three pytorch tensors:\n",
    "    #   [0]: input ids \n",
    "    #   [1]: attention masks\n",
    "    #   [2]: labels \n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels_actions = batch[2].to(device)\n",
    "    b_labels_attributes = batch[3].to(device)\n",
    "    b_dialog_ids = batch[4].to(device).detach().cpu().numpy()\n",
    "    b_turn_idxs = batch[5].to(device).detach().cpu().numpy()\n",
    "    \n",
    "    # Tell pytorch not to bother with constructing the compute graph during\n",
    "    # the forward pass, since this is only needed for backprop (training).\n",
    "    with torch.no_grad():        \n",
    "        # Forward pass, calculate logit predictions.\n",
    "        # token_type_ids is the same as the \"segment ids\", which \n",
    "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "        result = model(b_input_ids,mask=b_input_mask)\n",
    "\n",
    "    \n",
    "    actions_logits_foracc=result['actions'].detach().cpu().numpy()\n",
    "    attributes_logits_foracc=result['attributes'].detach().cpu().numpy()\n",
    "    actions_labels_foracc= b_labels_actions.to('cpu').numpy()\n",
    "    attributes_labels_foracc =b_labels_attributes.to('cpu').numpy()\n",
    "\n",
    "    # Calculate the accuracy for this batch of test sentences, and\n",
    "    # accumulate it over all batches.\n",
    "    accuracy_classification = flat_accuracy_actions(actions_logits_foracc, actions_labels_foracc)\n",
    "    accuracy_multilabel = flat_accuracy_attributes(attributes_logits_foracc, attributes_labels_foracc)\n",
    "    \n",
    "    total_eval_accuracy_classification['matched'] += accuracy_classification['matched']\n",
    "    total_eval_accuracy_classification['counts'] += accuracy_classification['counts']\n",
    "    total_eval_accuracy_multilabel['matched'] += accuracy_multilabel['matched']\n",
    "    total_eval_accuracy_multilabel['counts'] += accuracy_multilabel['counts']\n",
    "    \n",
    "\n",
    "    # Fill dictionary for action_evaluation\n",
    "    for el_i in range(len(actions_logits_foracc)):\n",
    "      dialog_id = b_dialog_ids[el_i]\n",
    "      action_log_prob = {}\n",
    "      for act_i in range(len(actions_logits_foracc[el_i])):\n",
    "        #todo: controllare che la probabilità predetta sia in scala logaritmica (?? potrebbe essere fonte di errori)\n",
    "        action_log_prob[le.classes_[act_i]] = np.log(actions_logits_foracc[el_i][act_i])\n",
    "      #attributes = {}\n",
    "      attributes = []\n",
    "      #attributes_list = np.rint(attributes_logits_foracc[el_i])\n",
    "      attributes_list = np.array(attributes_logits_foracc[el_i])\n",
    "      for attr in range(len(attributes_list)):\n",
    "        attribute = mlb.classes_[attr]\n",
    "        #attributes[mlb.classes_[attr]] = attributes_list[attr]\n",
    "        if attributes_list[attr] >= 0.5:\n",
    "          attributes.append(attribute)\n",
    "      prediction = {\n",
    "          'action': le.classes_[np.argmax(actions_logits_foracc[el_i])],\n",
    "          'action_log_prob': action_log_prob,\n",
    "          'attributes': {'attributes': attributes},\n",
    "          'turn_id': b_turn_idxs[el_i]\n",
    "      }\n",
    "      if dialog_id in model_actions:\n",
    "        model_actions[dialog_id]['predictions'].append(prediction)\n",
    "      else:\n",
    "        predictions = list()\n",
    "        predictions.append(prediction)\n",
    "        model_actions[dialog_id] = {\n",
    "            'dialog_id': dialog_id,\n",
    "            'predictions': predictions\n",
    "        }\n",
    "      \n",
    "\n",
    "# Report the final accuracy for this validation \n",
    "\n",
    "#avg_val_accuracy_classification = total_eval_accuracy_classification / len(validation_dataloader)\n",
    "#avg_val_accuracy_multilabel = total_eval_accuracy_multilabel / len(validation_dataloader)\n",
    "avg_val_accuracy_classification = total_eval_accuracy_classification['matched'] / total_eval_accuracy_classification['counts']\n",
    "avg_val_accuracy_multilabel = total_eval_accuracy_multilabel['matched'] / total_eval_accuracy_multilabel['counts']\n",
    "print(\"  Accuracy for classification (actions): {0:.4f}\".format(avg_val_accuracy_classification))\n",
    "print(\"  Accuracy for multilabel-classification (attributes): {0:.4f}\".format(avg_val_accuracy_multilabel))\n",
    "\n",
    "# Reference implementation: evaluation of action prediction along with attributes\n",
    "metrics = evaluation.evaluate_action_prediction(devtest_dials, model_actions.values())\n",
    "# print(\"model_actions passed to the evaluator:\")\n",
    "# for v in model_actions.values():\n",
    "#   print(v)\n",
    "print(\"***************************************\")\n",
    "print(\"Reference evaluation metrics:\")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a059e49",
   "metadata": {},
   "source": [
    "# OTHER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ca179f",
   "metadata": {},
   "source": [
    "Let's view the summary of the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "03bdf5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "401e879c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>batchnum</th>\n",
       "      <th>actions_logits</th>\n",
       "      <th>actions_labels</th>\n",
       "      <th>attributes_logits</th>\n",
       "      <th>attributes_labels</th>\n",
       "      <th>accuracy_classification</th>\n",
       "      <th>accuracy_multilabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.0002614487, 0.99973065, 0.0010042107, 9.08...</td>\n",
       "      <td>[1, 4, 2, 4, 0, 1, 1, 4, 4, 0, 1, 2]</td>\n",
       "      <td>[[0.00059911225, 0.00044125016, 0.003959917, 0...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>{'matched': 11, 'counts': 12}</td>\n",
       "      <td>{'matched': 10, 'counts': 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0.00067364104, 0.9996393, 0.00068487134, 3.3...</td>\n",
       "      <td>[1, 4, 2, 2, 0, 1, 2, 1, 1, 1, 1, 4]</td>\n",
       "      <td>[[0.000239827, 0.00013463515, 0.0020558322, 0....</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>{'matched': 9, 'counts': 12}</td>\n",
       "      <td>{'matched': 10, 'counts': 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[[0.00086305, 0.0019251241, 0.0005041322, 7.61...</td>\n",
       "      <td>[4, 1, 1, 1, 4, 2, 1, 2, 0, 1, 1, 1]</td>\n",
       "      <td>[[0.00021357411, 0.00015839678, 0.9533265, 0.0...</td>\n",
       "      <td>[[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>{'matched': 9, 'counts': 12}</td>\n",
       "      <td>{'matched': 11, 'counts': 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[[0.9994312, 0.005943647, 0.00013449784, 0.000...</td>\n",
       "      <td>[0, 0, 1, 2, 0, 1, 4, 4, 0, 1, 1, 4]</td>\n",
       "      <td>[[0.0008835664, 0.0001793721, 0.012007329, 0.0...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>{'matched': 9, 'counts': 12}</td>\n",
       "      <td>{'matched': 11, 'counts': 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[[0.0001449171, 0.90476733, 0.00021041828, 6.8...</td>\n",
       "      <td>[1, 4, 2, 4, 0, 3, 1, 1, 2, 4, 1, 1]</td>\n",
       "      <td>[[0.0002996792, 0.00031230514, 0.018295739, 0....</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>{'matched': 9, 'counts': 12}</td>\n",
       "      <td>{'matched': 12, 'counts': 12}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  batchnum                                     actions_logits  \\\n",
       "0      1         1  [[0.0002614487, 0.99973065, 0.0010042107, 9.08...   \n",
       "1      1         2  [[0.00067364104, 0.9996393, 0.00068487134, 3.3...   \n",
       "2      1         3  [[0.00086305, 0.0019251241, 0.0005041322, 7.61...   \n",
       "3      1         4  [[0.9994312, 0.005943647, 0.00013449784, 0.000...   \n",
       "4      1         5  [[0.0001449171, 0.90476733, 0.00021041828, 6.8...   \n",
       "\n",
       "                         actions_labels  \\\n",
       "0  [1, 4, 2, 4, 0, 1, 1, 4, 4, 0, 1, 2]   \n",
       "1  [1, 4, 2, 2, 0, 1, 2, 1, 1, 1, 1, 4]   \n",
       "2  [4, 1, 1, 1, 4, 2, 1, 2, 0, 1, 1, 1]   \n",
       "3  [0, 0, 1, 2, 0, 1, 4, 4, 0, 1, 1, 4]   \n",
       "4  [1, 4, 2, 4, 0, 3, 1, 1, 2, 4, 1, 1]   \n",
       "\n",
       "                                   attributes_logits  \\\n",
       "0  [[0.00059911225, 0.00044125016, 0.003959917, 0...   \n",
       "1  [[0.000239827, 0.00013463515, 0.0020558322, 0....   \n",
       "2  [[0.00021357411, 0.00015839678, 0.9533265, 0.0...   \n",
       "3  [[0.0008835664, 0.0001793721, 0.012007329, 0.0...   \n",
       "4  [[0.0002996792, 0.00031230514, 0.018295739, 0....   \n",
       "\n",
       "                                   attributes_labels  \\\n",
       "0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "2  [[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "3  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "4  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "         accuracy_classification            accuracy_multilabel  \n",
       "0  {'matched': 11, 'counts': 12}  {'matched': 10, 'counts': 12}  \n",
       "1   {'matched': 9, 'counts': 12}  {'matched': 10, 'counts': 12}  \n",
       "2   {'matched': 9, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
       "3   {'matched': 9, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
       "4   {'matched': 9, 'counts': 12}  {'matched': 12, 'counts': 12}  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert test data to dataframe\n",
    "df_test = pd.DataFrame(data = test_batch)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dbd5290d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur. class.</th>\n",
       "      <th>Valid. Accur. mult.label</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "      <th>metrics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.13</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0:08:29</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8377455166524338, 'actio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.06</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0:08:26</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.842869342442357, 'action...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.05</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0:08:27</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8482778252206091, 'actio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.03</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0:08:27</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8531169940222032, 'actio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.01</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0:08:30</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8514090520922288, 'actio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0:08:32</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8525476800455452, 'actio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. class.  \\\n",
       "epoch                                                     \n",
       "1               1.13         1.07                  0.84   \n",
       "2               1.06         1.07                  0.84   \n",
       "3               1.05         1.06                  0.85   \n",
       "4               1.03         1.06                  0.85   \n",
       "5               1.01         1.06                  0.85   \n",
       "6               1.00         1.05                  0.85   \n",
       "\n",
       "       Valid. Accur. mult.label Training Time Validation Time  \\\n",
       "epoch                                                           \n",
       "1                          0.87       0:08:29         0:00:27   \n",
       "2                          0.91       0:08:26         0:00:27   \n",
       "3                          0.92       0:08:27         0:00:27   \n",
       "4                          0.91       0:08:27         0:00:27   \n",
       "5                          0.93       0:08:30         0:00:27   \n",
       "6                          0.94       0:08:32         0:00:27   \n",
       "\n",
       "                                                 metrics  \n",
       "epoch                                                     \n",
       "1      {'action_accuracy': 0.8377455166524338, 'actio...  \n",
       "2      {'action_accuracy': 0.842869342442357, 'action...  \n",
       "3      {'action_accuracy': 0.8482778252206091, 'actio...  \n",
       "4      {'action_accuracy': 0.8531169940222032, 'actio...  \n",
       "5      {'action_accuracy': 0.8514090520922288, 'actio...  \n",
       "6      {'action_accuracy': 0.8525476800455452, 'actio...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display floats with two decimal places.\n",
    "pd.set_option('precision', 2)\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap.\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Display the table.\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "69386886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Objects serialization\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "testdata_filename = f\"testdata-{timestr}\"\n",
    "stats_filename = f\"stats-{timestr}\"\n",
    "#outtest = open(testdata_filename, \"wb\")\n",
    "#outstats = open(stats_filename, \"wb\")\n",
    "#pk.dump(obj=df_test, file=outtest)\n",
    "#outtest.close()\n",
    "#pk.dump(obj=df_stats, file=outstats)\n",
    "#outstats.close()\n",
    "df_test.to_pickle(testdata_filename)\n",
    "df_stats.to_pickle(stats_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb5a6cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testdata-20210801-121941\n",
      "       Training Loss  Valid. Loss  Valid. Accur. class.  \\\n",
      "epoch                                                     \n",
      "1               1.13         1.07                  0.84   \n",
      "2               1.06         1.07                  0.84   \n",
      "3               1.05         1.06                  0.85   \n",
      "4               1.03         1.06                  0.85   \n",
      "5               1.01         1.06                  0.85   \n",
      "\n",
      "       Valid. Accur. mult.label Training Time Validation Time  \\\n",
      "epoch                                                           \n",
      "1                          0.87       0:08:29         0:00:27   \n",
      "2                          0.91       0:08:26         0:00:27   \n",
      "3                          0.92       0:08:27         0:00:27   \n",
      "4                          0.91       0:08:27         0:00:27   \n",
      "5                          0.93       0:08:30         0:00:27   \n",
      "\n",
      "                                                 metrics  \n",
      "epoch                                                     \n",
      "1      {'action_accuracy': 0.8377455166524338, 'actio...  \n",
      "2      {'action_accuracy': 0.842869342442357, 'action...  \n",
      "3      {'action_accuracy': 0.8482778252206091, 'actio...  \n",
      "4      {'action_accuracy': 0.8531169940222032, 'actio...  \n",
      "5      {'action_accuracy': 0.8514090520922288, 'actio...  \n",
      "   epoch  batchnum                                     actions_logits  \\\n",
      "0      1         1  [[0.0002614487, 0.99973065, 0.0010042107, 9.08...   \n",
      "1      1         2  [[0.00067364104, 0.9996393, 0.00068487134, 3.3...   \n",
      "2      1         3  [[0.00086305, 0.0019251241, 0.0005041322, 7.61...   \n",
      "3      1         4  [[0.9994312, 0.005943647, 0.00013449784, 0.000...   \n",
      "4      1         5  [[0.0001449171, 0.90476733, 0.00021041828, 6.8...   \n",
      "\n",
      "                         actions_labels  \\\n",
      "0  [1, 4, 2, 4, 0, 1, 1, 4, 4, 0, 1, 2]   \n",
      "1  [1, 4, 2, 2, 0, 1, 2, 1, 1, 1, 1, 4]   \n",
      "2  [4, 1, 1, 1, 4, 2, 1, 2, 0, 1, 1, 1]   \n",
      "3  [0, 0, 1, 2, 0, 1, 4, 4, 0, 1, 1, 4]   \n",
      "4  [1, 4, 2, 4, 0, 3, 1, 1, 2, 4, 1, 1]   \n",
      "\n",
      "                                   attributes_logits  \\\n",
      "0  [[0.00059911225, 0.00044125016, 0.003959917, 0...   \n",
      "1  [[0.000239827, 0.00013463515, 0.0020558322, 0....   \n",
      "2  [[0.00021357411, 0.00015839678, 0.9533265, 0.0...   \n",
      "3  [[0.0008835664, 0.0001793721, 0.012007329, 0.0...   \n",
      "4  [[0.0002996792, 0.00031230514, 0.018295739, 0....   \n",
      "\n",
      "                                   attributes_labels  \\\n",
      "0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
      "1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
      "2  [[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
      "3  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
      "4  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
      "\n",
      "         accuracy_classification            accuracy_multilabel  \n",
      "0  {'matched': 11, 'counts': 12}  {'matched': 10, 'counts': 12}  \n",
      "1   {'matched': 9, 'counts': 12}  {'matched': 10, 'counts': 12}  \n",
      "2   {'matched': 9, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
      "3   {'matched': 9, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
      "4   {'matched': 9, 'counts': 12}  {'matched': 12, 'counts': 12}  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Test reimport data\n",
    "df_stats_reload = pd.read_pickle(stats_filename)\n",
    "df_test_reload = pd.read_pickle(testdata_filename)\n",
    "\n",
    "print(testdata_filename)\n",
    "print(df_stats_reload.head())\n",
    "print(df_test_reload.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1af435",
   "metadata": {},
   "source": [
    "## Plot di training & validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2c4fe674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks([x+1 for x in range(exec_params['epochs'])])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1c7b1f",
   "metadata": {},
   "source": [
    "## Plot accuracy and perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cc6f0929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "act_acc = [x['action_accuracy'] for x in df_stats.metrics]\n",
    "att_acc = [x['attribute_accuracy'] for x in df_stats.metrics]\n",
    "x_ticks = [x for x in range(len(act_acc))]\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(act_acc, 'b-o', label=\"Actions\")\n",
    "plt.plot(att_acc, 'g-o', label=\"Attributes\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Actions and attributes accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.xticks(ticks = x_ticks, labels = [str(x+1) for x in x_ticks])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "200b7acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "act_per = [x['action_perplexity'] for x in df_stats.metrics]\n",
    "x_ticks = [x for x in range(len(act_acc))]\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(act_per, 'b-o')\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Actions perplexity\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Perplexity\")\n",
    "plt.xticks(ticks = x_ticks, labels = [str(x+1) for x in x_ticks])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea495ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
