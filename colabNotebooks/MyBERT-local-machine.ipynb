{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4e26663",
   "metadata": {},
   "source": [
    "# Download GitHub repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9f42ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gian/content\n",
      "Clone in 'ActionPrediction4CA' in corso...\n",
      "remote: Enumerating objects: 366, done.\u001b[K\n",
      "remote: Counting objects: 100% (366/366), done.\u001b[K\n",
      "remote: Compressing objects: 100% (277/277), done.\u001b[K\n",
      "remote: Total 366 (delta 183), reused 257 (delta 82), pack-reused 0\u001b[K\n",
      "Ricezione degli oggetti: 100% (366/366), 47.41 MiB | 10.45 MiB/s, fatto.\n",
      "Risoluzione dei delta: 100% (183/183), fatto.\n"
     ]
    }
   ],
   "source": [
    "%cd ~/content/\n",
    "%rm -rf ~/content/ActionPrediction4CA\n",
    "%rm -rf ~/content/ActionPredictionBERT\n",
    "!git clone  --branch colab_exe https://github.com/jmcrav/ActionPrediction4CA.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36cb4f3",
   "metadata": {},
   "source": [
    "# Elimino i file inutili al modello \n",
    "Per fare il fine tuning del modello, abbiamo bisogno solo dei dati grezzi.\n",
    "Il tutor ha puntualizzato di usare SOLO lo script `simmc/mm_action_prediction/tools/extract_actions_fashion.py`, che costruisce un json con le lables associate alle azioni e agli attributi (è lo step 1 del preprocessing).\n",
    "Questo credo sia necessario perchè credo che la loro implementazione sia di un livello molto più basso di quello a cui dovremo lavorare noi.\n",
    "BERT è un metodo per effettuare il  pre-trained di modelli per il NLP di cui dobbiamo solo fare un fine-tuning accettabile, mentre il SIMMC deve addestrare un intero modello da zero(o comunque credo che il loro obiettivo sia cercare di creare un modello che riesca a funzionare bene col linguaggio multimodale.Non ho capito perchè non sia statu usato BERT anche da loro onestamente -  il task finale è diviso in 3 sottotask, e la prima è un problema di classificazione multi-classe per il quale BERT dovrebbe poter funzionare - forse perchè quella fornita è solo un implementazione di partenza e i concorrenti alla challenge hanno fornito le loro implementazioni dei modelli?). Praticamente tutte le operazioni che fanno loro sui dati credo servano ai loro dettagli implementativi di bassissimo livello; con BERT noi dovremo usare solo i metodi forniti dalla classe.\n",
    "In pratica, partendo dai dati grezzi, dobbiamo solo darli in pasto ai metodi forniti da BERT e magari lavorare un po' per migliorare i risultati, senza che sia necessario scendere fino al livello dei transformers\n",
    "\n",
    "\n",
    "**DA TENERE**\n",
    "* Output dell'extract actions\n",
    "*  `fashion_train_dials.json`:  per il training\n",
    "*  `fashion_dev_dials.json` : per la validation\n",
    "*  `fashion_teststd_dials_public.json` :per il \"report dei risultati finali\" (forse per darlo in pasto allo script di evaluation?) \n",
    "*   `fashion_metadata.json`, `fashion_devtest_dials.json` : necessari per il funzionamento dello script `extract_actions_fashion.py `\n",
    "\n",
    "**DA VERIFICARE**:\n",
    "\n",
    " forse potrebbe convenire anche usare il vocabolario che loro si costruiscono (step 2 del preprocessing) per inizializzare il Tokenizer di Bert, come fanno loro nel data loader (in `loaders/loader_simmc.py`)\n",
    " ![linea codice loader.jpg](data:image/jpeg;base64,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)\n",
    "\n",
    " Questo comando istanzia il tokenizer con una versione default o definita dall'utente (devo capire bene cosa significa, l'ho letto su https://huggingface.co/transformers/quickstart.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cd41deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gian/content/ActionPrediction4CA/tools\n",
      "/home/gian/content/ActionPrediction4CA/data/simmc_fashion\n",
      "/home/gian/content\n"
     ]
    }
   ],
   "source": [
    "%mkdir ~/content/ActionPredictionBERT ActionPredictionBERT/input_data ActionPredictionBERT/extr_output\n",
    "%cd ~/content/ActionPrediction4CA/tools\n",
    "%mv extract_actions_fashion.py ~/content/ActionPredictionBERT\n",
    "%mv action_evaluation.py ~/content/ActionPredictionBERT\n",
    "\n",
    "%cd ~/content/ActionPrediction4CA/data/simmc_fashion/\n",
    "%mv fashion_train_dials.json fashion_dev_dials.json fashion_teststd_dials_public.json fashion_metadata.json fashion_devtest_dials.json ~/content/ActionPredictionBERT/input_data\n",
    "%cd ~/content/\n",
    "%rm -rf ./ActionPrediction4CA/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c76fc6c",
   "metadata": {},
   "source": [
    "# Extract_actions_fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86671584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gian/content/ActionPredictionBERT\n",
      "Reading: ./input_data/fashion_train_dials.json\n",
      "Dialogue task Id missing: 3406\n",
      "Dialogue task Id missing: 3969\n",
      "Dialogue task Id missing: 4847\n",
      "Dialogue task Id missing: 321\n",
      "Dialogue task Id missing: 3455\n",
      "Dialogue task Id missing: 3414\n",
      "Saving: ./extr_output/fashion_train_dials_api_calls.json\n",
      "Reading: ./input_data/fashion_dev_dials.json\n",
      "Dialogue task Id missing: 2117\n",
      "Saving: ./extr_output/fashion_dev_dials_api_calls.json\n",
      "Reading: ./input_data/fashion_devtest_dials.json\n",
      "Dialogue task Id missing: 9308\n",
      "Saving: ./extr_output/fashion_devtest_dials_api_calls.json\n"
     ]
    }
   ],
   "source": [
    "%cd ~/content/ActionPredictionBERT/\n",
    "!python extract_actions_fashion.py --json_path=\"./input_data/fashion_train_dials.json ./input_data/fashion_dev_dials.json ./input_data/fashion_devtest_dials.json\" --save_root=\"./extr_output\"  --metadata_path=\"./fashion_metadata.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98da7846",
   "metadata": {},
   "source": [
    "# Notebook originale\n",
    "Script copiato dal colab di Chris McCormick e Nick Ryan\n",
    "https://colab.research.google.com/drive/1pTuQhug6Dhl9XalKB0zUGf4FIdYFlpcX#scrollTo=nSU7yERLP_66"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34794cb2",
   "metadata": {},
   "source": [
    "## 1.2. Installing the Hugging Face Library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1b3c76",
   "metadata": {},
   "source": [
    "\n",
    "Next, let's install the [transformers](https://github.com/huggingface/transformers) package from Hugging Face which will give us a pytorch interface for working with BERT. (This library contains interfaces for other pretrained language models like OpenAI's GPT and GPT-2.) We've selected the pytorch interface because it strikes a nice balance between the high-level APIs (which are easy to use but don't provide insight into how things work) and tensorflow code (which contains lots of details but often sidetracks us into lessons about tensorflow, when the purpose here is BERT!).\n",
    "\n",
    "At the moment, the Hugging Face library seems to be the most widely accepted and powerful pytorch interface for working with BERT. In addition to supporting a variety of different pre-trained transformer models, the library also includes pre-built modifications of these models suited to your specific task. For example, in this tutorial we will use `BertForSequenceClassification`.\n",
    "\n",
    "The library also includes task-specific classes for token classification, question answering, next sentence prediciton, etc. Using these pre-built classes simplifies the process of modifying BERT for your purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1744f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install markdown\n",
    "#!pip install transformers\n",
    "#!pip install pandas\n",
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcac06cc",
   "metadata": {},
   "source": [
    "# Impostazione parametri esecuzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "453e6bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_params = {\n",
    "    'batch': 12,\n",
    "    'epochs': 2,\n",
    "    'hidden_output_dim': 256,\n",
    "    'seed': 24\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d9eda3",
   "metadata": {},
   "source": [
    "# Analisi Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4f4432",
   "metadata": {},
   "source": [
    "## train_dials\n",
    "\n",
    "Dati grezzi da preprocessare con lo script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7f4abad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "      <th>dialogue_idx</th>\n",
       "      <th>domains</th>\n",
       "      <th>dialogue_task_id</th>\n",
       "      <th>dialogue_coref_map.1426</th>\n",
       "      <th>dialogue_coref_map.1429</th>\n",
       "      <th>dialogue_coref_map.708</th>\n",
       "      <th>dialogue_coref_map.712</th>\n",
       "      <th>dialogue_coref_map.2401</th>\n",
       "      <th>dialogue_coref_map.2402</th>\n",
       "      <th>...</th>\n",
       "      <th>dialogue_coref_map.2335</th>\n",
       "      <th>dialogue_coref_map.713</th>\n",
       "      <th>dialogue_coref_map.1507</th>\n",
       "      <th>dialogue_coref_map.1509</th>\n",
       "      <th>dialogue_coref_map.949</th>\n",
       "      <th>dialogue_coref_map.1137</th>\n",
       "      <th>dialogue_coref_map.1872</th>\n",
       "      <th>dialogue_coref_map.1873</th>\n",
       "      <th>dialogue_coref_map.1753</th>\n",
       "      <th>dialogue_coref_map.834</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'belief_state': [{'act': 'DA:ASK:CHECK:CLOTH...</td>\n",
       "      <td>3094</td>\n",
       "      <td>[fashion]</td>\n",
       "      <td>1785.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'belief_state': [{'act': 'DA:INFORM:PREFER:C...</td>\n",
       "      <td>822</td>\n",
       "      <td>[fashion]</td>\n",
       "      <td>1720.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'belief_state': [{'act': 'DA:REQUEST:GET:CLO...</td>\n",
       "      <td>7411</td>\n",
       "      <td>[fashion]</td>\n",
       "      <td>2038.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'belief_state': [{'act': 'DA:INFORM:DISPREFE...</td>\n",
       "      <td>7029</td>\n",
       "      <td>[fashion]</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'belief_state': [{'act': 'DA:INFORM:DISPREFE...</td>\n",
       "      <td>1506</td>\n",
       "      <td>[fashion]</td>\n",
       "      <td>1686.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1648 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            dialogue  dialogue_idx    domains  \\\n",
       "0  [{'belief_state': [{'act': 'DA:ASK:CHECK:CLOTH...          3094  [fashion]   \n",
       "1  [{'belief_state': [{'act': 'DA:INFORM:PREFER:C...           822  [fashion]   \n",
       "2  [{'belief_state': [{'act': 'DA:REQUEST:GET:CLO...          7411  [fashion]   \n",
       "3  [{'belief_state': [{'act': 'DA:INFORM:DISPREFE...          7029  [fashion]   \n",
       "4  [{'belief_state': [{'act': 'DA:INFORM:DISPREFE...          1506  [fashion]   \n",
       "\n",
       "   dialogue_task_id  dialogue_coref_map.1426  dialogue_coref_map.1429  \\\n",
       "0            1785.0                      0.0                      1.0   \n",
       "1            1720.0                      NaN                      NaN   \n",
       "2            2038.0                      NaN                      NaN   \n",
       "3            2011.0                      NaN                      NaN   \n",
       "4            1686.0                      NaN                      NaN   \n",
       "\n",
       "   dialogue_coref_map.708  dialogue_coref_map.712  dialogue_coref_map.2401  \\\n",
       "0                     NaN                     NaN                      NaN   \n",
       "1                     0.0                     1.0                      NaN   \n",
       "2                     NaN                     NaN                      4.0   \n",
       "3                     NaN                     NaN                      NaN   \n",
       "4                     NaN                     NaN                      NaN   \n",
       "\n",
       "   dialogue_coref_map.2402  ...  dialogue_coref_map.2335  \\\n",
       "0                      NaN  ...                      NaN   \n",
       "1                      NaN  ...                      NaN   \n",
       "2                      0.0  ...                      NaN   \n",
       "3                      NaN  ...                      NaN   \n",
       "4                      NaN  ...                      NaN   \n",
       "\n",
       "   dialogue_coref_map.713  dialogue_coref_map.1507  dialogue_coref_map.1509  \\\n",
       "0                     NaN                      NaN                      NaN   \n",
       "1                     NaN                      NaN                      NaN   \n",
       "2                     NaN                      NaN                      NaN   \n",
       "3                     NaN                      NaN                      NaN   \n",
       "4                     NaN                      NaN                      NaN   \n",
       "\n",
       "   dialogue_coref_map.949  dialogue_coref_map.1137  dialogue_coref_map.1872  \\\n",
       "0                     NaN                      NaN                      NaN   \n",
       "1                     NaN                      NaN                      NaN   \n",
       "2                     NaN                      NaN                      NaN   \n",
       "3                     NaN                      NaN                      NaN   \n",
       "4                     NaN                      NaN                      NaN   \n",
       "\n",
       "   dialogue_coref_map.1873  dialogue_coref_map.1753  dialogue_coref_map.834  \n",
       "0                      NaN                      NaN                     NaN  \n",
       "1                      NaN                      NaN                     NaN  \n",
       "2                      NaN                      NaN                     NaN  \n",
       "3                      NaN                      NaN                     NaN  \n",
       "4                      NaN                      NaN                     NaN  \n",
       "\n",
       "[5 rows x 1648 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prima parte del fashion_train_dials\n",
    "import json \n",
    "import pandas as pd\n",
    "with open ('./input_data/fashion_train_dials.json',\"r\") as f:\n",
    "   data= json.load(f)\n",
    "\n",
    "result=[]\n",
    "row ={}\n",
    "for k in data:\n",
    "  row[k] = data[k]\n",
    "# []\n",
    "#prima parte del fashion_train_dials\n",
    "import json \n",
    "import pandas as pd\n",
    "with open ('./input_data/fashion_train_dials.json',\"r\") as f:\n",
    "   data= json.load(f)\n",
    "\n",
    "result=[]\n",
    "row ={}\n",
    "for k in data:\n",
    "  row[k] = data[k]\n",
    "# []\n",
    "\n",
    "dialogue_data = pd.json_normalize(row['dialogue_data'])\n",
    "type(dialogue_data)\n",
    "# dialogue = dialogue_data[\"dialogue\"]\n",
    "# for x in dialogue.head(1):\n",
    "#   display(x)\n",
    "# #dialogue.head(1)\n",
    "dialogue_data.head()\n",
    "\n",
    "\n",
    "\n",
    "dialogue_data = pd.json_normalize(row['dialogue_data'])\n",
    "type(dialogue_data)\n",
    "# dialogue = dialogue_data[\"dialogue\"]\n",
    "# for x in dialogue.head(1):\n",
    "#   display(x)\n",
    "# #dialogue.head(1)\n",
    "dialogue_data.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "625e5f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>image_ids</th>\n",
       "      <th>focus_image</th>\n",
       "      <th>memory_images</th>\n",
       "      <th>database_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2042</td>\n",
       "      <td>[2441, 2442, 2443, 2444, 2445, 2446, 2447, 244...</td>\n",
       "      <td>2441</td>\n",
       "      <td>[2442, 2443, 2444]</td>\n",
       "      <td>[2445, 2446, 2447, 2448, 2449, 2450]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2041</td>\n",
       "      <td>[2431, 2432, 2433, 2434, 2435, 2436, 2437, 243...</td>\n",
       "      <td>2431</td>\n",
       "      <td>[2432, 2433, 2434]</td>\n",
       "      <td>[2435, 2436, 2437, 2438, 2439, 2440]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2040</td>\n",
       "      <td>[2421, 2422, 2423, 2424, 2425, 2426, 2427, 242...</td>\n",
       "      <td>2421</td>\n",
       "      <td>[2422, 2423, 2424]</td>\n",
       "      <td>[2425, 2426, 2427, 2428, 2429, 2430]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2039</td>\n",
       "      <td>[2411, 2412, 2413, 2414, 2415, 2416, 2417, 241...</td>\n",
       "      <td>2411</td>\n",
       "      <td>[2412, 2413, 2414]</td>\n",
       "      <td>[2415, 2416, 2417, 2418, 2419, 2420]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2038</td>\n",
       "      <td>[2401, 2402, 2403, 2404, 2405, 2406, 2407, 240...</td>\n",
       "      <td>2401</td>\n",
       "      <td>[2402, 2403, 2404]</td>\n",
       "      <td>[2405, 2406, 2407, 2408, 2409, 2410]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   task_id                                          image_ids  focus_image  \\\n",
       "0     2042  [2441, 2442, 2443, 2444, 2445, 2446, 2447, 244...         2441   \n",
       "1     2041  [2431, 2432, 2433, 2434, 2435, 2436, 2437, 243...         2431   \n",
       "2     2040  [2421, 2422, 2423, 2424, 2425, 2426, 2427, 242...         2421   \n",
       "3     2039  [2411, 2412, 2413, 2414, 2415, 2416, 2417, 241...         2411   \n",
       "4     2038  [2401, 2402, 2403, 2404, 2405, 2406, 2407, 240...         2401   \n",
       "\n",
       "        memory_images                       database_images  \n",
       "0  [2442, 2443, 2444]  [2445, 2446, 2447, 2448, 2449, 2450]  \n",
       "1  [2432, 2433, 2434]  [2435, 2436, 2437, 2438, 2439, 2440]  \n",
       "2  [2422, 2423, 2424]  [2425, 2426, 2427, 2428, 2429, 2430]  \n",
       "3  [2412, 2413, 2414]  [2415, 2416, 2417, 2418, 2419, 2420]  \n",
       "4  [2402, 2403, 2404]  [2405, 2406, 2407, 2408, 2409, 2410]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#seconda parte del fashion_train_dials\n",
    "task_mapping = pd.json_normalize(row['task_mapping'])\n",
    "task_mapping.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9867cff",
   "metadata": {},
   "source": [
    "## dev_dials_api_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d5d29b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialog_id</th>\n",
       "      <th>actions</th>\n",
       "      <th>focus_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4146</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'None', 'action_sup...</td>\n",
       "      <td>[1646, 1646, 1646, 1649, 1649, 1649, 1649]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4260</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...</td>\n",
       "      <td>[2161, 2161, 2161, 2161]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8022</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SearchDatabase', '...</td>\n",
       "      <td>[1971, 1972, 1972, 1972, 1977, 1978]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4992</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'None', 'action_sup...</td>\n",
       "      <td>[1931, 1931, 1936, 1936, 1936]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5606</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'None', 'action_sup...</td>\n",
       "      <td>[1931, 1931, 1931, 1931, 1931]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dialog_id                                            actions  \\\n",
       "0       4146  [{'turn_idx': 0, 'action': 'None', 'action_sup...   \n",
       "1       4260  [{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...   \n",
       "2       8022  [{'turn_idx': 0, 'action': 'SearchDatabase', '...   \n",
       "3       4992  [{'turn_idx': 0, 'action': 'None', 'action_sup...   \n",
       "4       5606  [{'turn_idx': 0, 'action': 'None', 'action_sup...   \n",
       "\n",
       "                                 focus_images  \n",
       "0  [1646, 1646, 1646, 1649, 1649, 1649, 1649]  \n",
       "1                    [2161, 2161, 2161, 2161]  \n",
       "2        [1971, 1972, 1972, 1972, 1977, 1978]  \n",
       "3              [1931, 1931, 1936, 1936, 1936]  \n",
       "4              [1931, 1931, 1931, 1931, 1931]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dev_dials_api = pd.read_json('./extr_output/fashion_dev_dials_api_calls.json')\n",
    "dev_dials_api.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b899ff34",
   "metadata": {},
   "source": [
    "## devtest_dials_api_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f9c6435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialog_id</th>\n",
       "      <th>actions</th>\n",
       "      <th>focus_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2494</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SearchDatabase', '...</td>\n",
       "      <td>[1836, 1841, 1841, 1841, 1841]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3731</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SearchDatabase', '...</td>\n",
       "      <td>[1676, 1681, 1681, 1683, 1683]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8546</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...</td>\n",
       "      <td>[840, 840, 840, 849, 849, 843]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5590</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SearchDatabase', '...</td>\n",
       "      <td>[1616, 1618, 1618, 1618, 1618]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5452</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...</td>\n",
       "      <td>[2231, 2231, 2231, 2236, 2236]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dialog_id                                            actions  \\\n",
       "0       2494  [{'turn_idx': 0, 'action': 'SearchDatabase', '...   \n",
       "1       3731  [{'turn_idx': 0, 'action': 'SearchDatabase', '...   \n",
       "2       8546  [{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...   \n",
       "3       5590  [{'turn_idx': 0, 'action': 'SearchDatabase', '...   \n",
       "4       5452  [{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...   \n",
       "\n",
       "                     focus_images  \n",
       "0  [1836, 1841, 1841, 1841, 1841]  \n",
       "1  [1676, 1681, 1681, 1683, 1683]  \n",
       "2  [840, 840, 840, 849, 849, 843]  \n",
       "3  [1616, 1618, 1618, 1618, 1618]  \n",
       "4  [2231, 2231, 2231, 2236, 2236]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "devtest_dials_api = pd.read_json('./extr_output/fashion_devtest_dials_api_calls.json')\n",
    "devtest_dials_api.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3ba47e",
   "metadata": {},
   "source": [
    "## Funzione generazione dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe1973e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def createDataframe(json_file):\n",
    "  with open(json_file) as f:\n",
    "    dictftdac = json.load(f)\n",
    "\n",
    "  data = []\n",
    "\n",
    "  for e in dictftdac:\n",
    "    dialog_id = e['dialog_id']\n",
    "    actions = e['actions']\n",
    "    focus_images = e['focus_images']\n",
    "\n",
    "    for a in actions:\n",
    "      \n",
    "      turn_idx = a['turn_idx']\n",
    "      action = a['action']\n",
    "      action_supervision = a['action_supervision']\n",
    "      transcript = a['transcript']\n",
    "      transcript_annotated = a['transcript_annotated']\n",
    "      system_transcript = a['system_transcript']\n",
    "      system_transcript_annotated = a['system_transcript_annotated']\n",
    "\n",
    "      row = {\n",
    "          \"dialog_id\" : dialog_id,\n",
    "          'turn_idx' : turn_idx,\n",
    "          'action' : action,\n",
    "          'action_supervision' : action_supervision,\n",
    "          'focus_images' : focus_images,\n",
    "          'transcript': transcript,\n",
    "          'transcript_annotated': transcript_annotated,\n",
    "          'system_transcript': system_transcript,\n",
    "          'system_transcript_annotated':system_transcript_annotated,\n",
    "          'previous_transcript': \"\",\n",
    "          'previous_system_transcript': \"\"\n",
    "      }\n",
    "      if (action_supervision != None):\n",
    "        if 'focus' in action_supervision:\n",
    "          acsf = {'focus':action_supervision['focus']}\n",
    "        else:\n",
    "          acsf = {'focus':None}\n",
    "        \n",
    "        if 'attributes' in action_supervision:\n",
    "          acsa = {'attributes':action_supervision['attributes']}\n",
    "        else:\n",
    "          acsa = {'attributes':[]}\n",
    "      else:\n",
    "          acsf = {'focus':None}\n",
    "          acsa = {'attributes':[]}\n",
    "      \n",
    "        \n",
    "      row.update(acsf)\n",
    "      row.update(acsa)\n",
    "    \n",
    "      data.append(row)\n",
    "\n",
    "  # Conservo id turno e risposta sistema per provare a implementare una soluzione articolata\n",
    "  df = pd.DataFrame(data,columns=['dialog_id','turn_idx','transcript','action','attributes', 'system_transcript','transcript_annotated','system_transcript_annotated','previous_transcript','previous_system_transcript'])\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a30c6d",
   "metadata": {},
   "source": [
    "## train_dials_api_calls with transcript\n",
    "Dati per il training che usiamo ( per ora semplificati)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9d78e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  21196  elementi\n"
     ]
    }
   ],
   "source": [
    "df_training = createDataframe('./extr_output/fashion_train_dials_api_calls.json')\n",
    "print(\"Training: \",len(df_training),\" elementi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e542c9",
   "metadata": {},
   "source": [
    "## fashion_dev_dials_api_calls\n",
    "Dati per la validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d7d98f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:  3513  elementi\n"
     ]
    }
   ],
   "source": [
    "df_validation = createDataframe('./extr_output/fashion_dev_dials_api_calls.json')\n",
    "print(\"Validation: \",len(df_validation),\" elementi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f272d647",
   "metadata": {},
   "source": [
    "## fashion_devtest_dials_api_calls\n",
    "Dati per la valutazione delle performance del modello (test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8e22d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  5397  elementi\n"
     ]
    }
   ],
   "source": [
    "df_test = createDataframe('./extr_output/fashion_devtest_dials_api_calls.json')\n",
    "print(\"Test: \",len(df_test),\" elementi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc25d11d",
   "metadata": {},
   "source": [
    "# BERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4c901c",
   "metadata": {},
   "source": [
    "## Scelta tipo input\n",
    "\n",
    "Il valore di questa variabile determinerà se utilizzare i singoli transcript, o se concatenare ogni transcript a quello successivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef5cc083",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_next = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d30106",
   "metadata": {},
   "source": [
    "## Preparazione input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e090913a",
   "metadata": {},
   "source": [
    "### Generazione colonna previous_transcript\n",
    "\n",
    "Generazione della colonna contenente la frase del turno successivo del dialogo (se presente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fb54823",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "df_training.sort_values(by=['dialog_id', 'turn_idx'])\n",
    "for i in range(1,(len(df_training))):\n",
    "  if(i<(len(df_training)) and  df_training['dialog_id'][i] == df_training['dialog_id'][i-1]):\n",
    "    df_training.loc[i,'previous_transcript'] = df_training['transcript'][i-1]\n",
    "    df_training.loc[i,'previous_system_transcript'] = df_training['system_transcript'][i-1]\n",
    "\n",
    "#Validation\n",
    "df_validation.sort_values(by=['dialog_id', 'turn_idx'])\n",
    "for i in range(1,(len(df_validation))):\n",
    "  if(i<(len(df_validation)) and  df_validation['dialog_id'][i] == df_validation['dialog_id'][i-1]):\n",
    "    df_validation.loc[i,'previous_transcript'] = df_validation['transcript'][i-1]\n",
    "    df_validation.loc[i,'previous_system_transcript'] = df_validation['system_transcript'][i-1]\n",
    "\n",
    "#Evaluation\n",
    "df_test.sort_values(by=['dialog_id', 'turn_idx'])\n",
    "for i in range(1,(len(df_test))):\n",
    "  if(i<(len(df_test)) and  df_test['dialog_id'][i] == df_test['dialog_id'][i-1]):\n",
    "    df_test.loc[i,'previous_transcript'] = df_test['transcript'][i-1]\n",
    "    df_test.loc[i,'previous_system_transcript'] = df_test['system_transcript'][i-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb106a56",
   "metadata": {},
   "source": [
    "### Estrazione vettori colonna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78177045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de95a8f0",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f65ef34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA:\n",
      " Original:  Is there a pattern on this one? It's hard to see in the image.\n",
      "Tokenized:  ['is', 'there', 'a', 'pattern', 'on', 'this', 'one', '?', 'it', \"'\", 's', 'hard', 'to', 'see', 'in', 'the', 'image', '.']\n",
      "Token IDs:  [2003, 2045, 1037, 5418, 2006, 2023, 2028, 1029, 2009, 1005, 1055, 2524, 2000, 2156, 1999, 1996, 3746, 1012]\n"
     ]
    }
   ],
   "source": [
    "transcripts_tr = df_training.transcript.values\n",
    "previous_transcript_tr = df_training.previous_transcript.values\n",
    "previous_system_transcript_tr = df_training.previous_system_transcript.values\n",
    "action_labels_tr = df_training.action.values\n",
    "attributes_labels_tr=df_training.attributes.values\n",
    "\n",
    "print (\"TRAINING DATA:\")\n",
    "# Print the original sentence.\n",
    "print(' Original: ', transcripts_tr[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(transcripts_tr[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(transcripts_tr[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b5da556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T: Is there a pattern on this one? It's hard to see in the image. | PT:  | PST: \n",
      "T: That's fancy. Do you have anything in warmer colors like yellow or red? | PT: Is there a pattern on this one? It's hard to see in the image. | PST: I don't have any information on the pattern, but it has pointelle embellishments.\n",
      "T: Yeah, that sounds good. | PT: That's fancy. Do you have anything in warmer colors like yellow or red? | PST: I have a crew neck sweater in red, would you like to see it?\n",
      "T: Oh, I love that. Please tell me you have a small. | PT: Yeah, that sounds good. | PST: This is $187 from Downtown Stylists with a 3.62 rating.\n",
      "T: Yes, please! Thank you for your help with this | PT: Oh, I love that. Please tell me you have a small. | PST: It does come in small, shall I put one in your cart?\n",
      "T: How nice! Does this come in other colors? | PT:  | PST: \n",
      "T: Oh well.  Can you show me a dress that comes in red? | PT: How nice! Does this come in other colors? | PST: No, I'm sorry, It comes only in blue.\n",
      "T: Cute! Do these come in Small? | PT: Oh well.  Can you show me a dress that comes in red? | PST: This dress comes in many colors, including a bright red and a pinkish-red. What do you think?\n",
      "T: Awesome. Would you add a red one in S to my cart please? | PT: Cute! Do these come in Small? | PST: Yes, they do!\n",
      "T: That's all. Thanks! | PT: Awesome. Would you add a red one in S to my cart please? | PST: The red one is in your cart. Is there anything else I can find for you?\n"
     ]
    }
   ],
   "source": [
    "for k in range(0,10):\n",
    "  print(f\"T: {transcripts_tr[k]} | PT: {previous_transcript_tr[k]} | PST: {previous_system_transcript_tr[k]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef35705",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcd4e529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION DATA:\n",
      " Original:  What's the price of this sweater compared to the other blue and gray one I looked at?\n",
      "Tokenized:  ['what', \"'\", 's', 'the', 'price', 'of', 'this', 'sweater', 'compared', 'to', 'the', 'other', 'blue', 'and', 'gray', 'one', 'i', 'looked', 'at', '?']\n",
      "Token IDs:  [2054, 1005, 1055, 1996, 3976, 1997, 2023, 14329, 4102, 2000, 1996, 2060, 2630, 1998, 3897, 2028, 1045, 2246, 2012, 1029]\n",
      "Dialog IDs: [4146 4146 4146 4146 4146 4146 4146 4260 4260 4260 4260 8022 8022 8022\n",
      " 8022 8022 8022 4992 4992 4992]\n",
      "Turn IDs: [0 1 2 3 4 5 6 0 1 2 3 0 1 2 3 4 5 0 1 2]\n"
     ]
    }
   ],
   "source": [
    "transcripts_vd = df_validation.transcript.values\n",
    "previous_transcript_vd = df_validation.previous_transcript.values\n",
    "previous_system_transcript_vd = df_validation.previous_system_transcript.values\n",
    "action_labels_vd = df_validation.action.values\n",
    "attributes_labels_vd=df_validation.attributes.values\n",
    "dialog_ids_vd = df_validation.dialog_id.values\n",
    "turn_idxs_vd = df_validation.turn_idx.values\n",
    "\n",
    "print (\"VALIDATION DATA:\")\n",
    "\n",
    "# Print the original sentence.\n",
    "print(' Original: ', transcripts_vd[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(transcripts_vd[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(transcripts_vd[0])))\n",
    "\n",
    "# Print the dialog ids.\n",
    "print(f\"Dialog IDs: {dialog_ids_vd[0:20]}\")\n",
    "\n",
    "# Print the turn idxs.\n",
    "print(f\"Turn IDs: {turn_idxs_vd[0:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba6e6ef",
   "metadata": {},
   "source": [
    "#### Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "886bcaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATION DATA:\n",
      " Original:  That looks a little too light for what I need, do you have something else with a high customer rating?\n",
      "Tokenized:  ['that', 'looks', 'a', 'little', 'too', 'light', 'for', 'what', 'i', 'need', ',', 'do', 'you', 'have', 'something', 'else', 'with', 'a', 'high', 'customer', 'rating', '?']\n",
      "Token IDs:  [2008, 3504, 1037, 2210, 2205, 2422, 2005, 2054, 1045, 2342, 1010, 2079, 2017, 2031, 2242, 2842, 2007, 1037, 2152, 8013, 5790, 1029]\n",
      "Dialog IDs: [2494 2494 2494 2494 2494 3731 3731 3731 3731 3731 8546 8546 8546 8546\n",
      " 8546 8546 5590 5590 5590 5590]\n",
      "Turn IDs: [0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 5 0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "transcripts_tst = df_test.transcript.values\n",
    "previous_transcript_tst = df_test.previous_transcript.values\n",
    "previous_system_transcript_tst = df_test.previous_system_transcript.values\n",
    "action_labels_tst = df_test.action.values\n",
    "attributes_labels_tst=df_test.attributes.values\n",
    "dialog_ids_tst = df_test.dialog_id.values\n",
    "turn_idxs_tst = df_test.turn_idx.values\n",
    "\n",
    "print (\"EVALUATION DATA:\")\n",
    "\n",
    "# Print the original sentence.\n",
    "print(' Original: ', transcripts_tst[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(transcripts_tst[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(transcripts_tst[0])))\n",
    "\n",
    "# Print the dialog ids.\n",
    "print(f\"Dialog IDs: {dialog_ids_tst[0:20]}\")\n",
    "\n",
    "# Print the turn idxs.\n",
    "print(f\"Turn IDs: {turn_idxs_tst[0:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c049bbf",
   "metadata": {},
   "source": [
    "## Calcolo dimensione massima\n",
    "\n",
    "The above code left out a few required formatting steps that we'll look at here.\n",
    "\n",
    "We are required to:\n",
    "1. Add special tokens to the start and end of each sentence.\n",
    "2. Pad & truncate all sentences to a single constant length.\n",
    "3. Explicitly differentiate real tokens from padding tokens with the \"attention mask\".\n",
    "\n",
    "\n",
    "The sentences in our dataset obviously have varying lengths, so how does BERT handle this?\n",
    "\n",
    "BERT has two constraints:\n",
    "\n",
    "\n",
    "1.   All sentences must be padded or truncated to a single, fixed length.\n",
    "2.   The maximum sentence length is 512 tokens.\n",
    "\n",
    "\n",
    "Padding is done with a special [PAD] token, which is at index 0 in the BERT vocabulary. The below illustration demonstrates padding out to a \"MAX_LEN\" of 8 tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c16396",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8e5132e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max transcript length for training:  177\n"
     ]
    }
   ],
   "source": [
    "max_len_tr = 0\n",
    "\n",
    "# For every sentence...\n",
    "for i in range(0,len(transcripts_tr)):\n",
    "    \n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "\n",
    "    if (previous_transcript_tr[i] != \"\" and use_next):\n",
    "      input_ids = tokenizer.encode(previous_transcript_tr[i]+ \" \" + previous_system_transcript_tr[i],transcripts_tr[i], add_special_tokens=True)\n",
    "    else:\n",
    "      input_ids = tokenizer.encode(transcripts_tr[i], add_special_tokens=True)\n",
    "        \n",
    "    # Update the maximum sentence length.\n",
    "    max_len_tr = max(max_len_tr, len(input_ids))\n",
    "\n",
    "print('Max transcript length for training: ', max_len_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17363e3c",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92914388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max transcript length for validation:  133\n"
     ]
    }
   ],
   "source": [
    "max_len_vd = 0\n",
    "\n",
    "# For every sentence...\n",
    "for i in range(0,len(transcripts_vd)):\n",
    "\n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    if (previous_transcript_vd[i] != \"\" and use_next):\n",
    "      input_ids = tokenizer.encode(previous_transcript_vd[i]+ \" \" + previous_system_transcript_vd[i],transcripts_vd[i], add_special_tokens=True)\n",
    "    else:\n",
    "      input_ids = tokenizer.encode(transcripts_vd[i], add_special_tokens=True)\n",
    "    \n",
    "    # Update the maximum sentence length.\n",
    "    max_len_vd = max(max_len_vd, len(input_ids))\n",
    "\n",
    "print('Max transcript length for validation: ', max_len_vd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3412aa8",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aab75df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max transcript length for evaluation:  150\n"
     ]
    }
   ],
   "source": [
    "max_len_tst = 0\n",
    "\n",
    "#non sono sicuro che il controllo della lunghezza vada fatto anche sul test set, dopo la performance non è determinata\n",
    "#dalla conoscenza del test set?\n",
    "#è anche vero che in teoria per far funzionare BERT bisogna dargli in pasto dei dati tokenizzati, quindi in un caso reale il nostro\n",
    "#model non potrebbe prendere in ingresso del testo non trattato. Nel dubbio ho controllato le dimensioni\n",
    "\n",
    "for i in range(0,len(transcripts_tst)):\n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    if (previous_transcript_tst[i] != \"\" and use_next):\n",
    "      input_ids = tokenizer.encode(previous_transcript_tst[i]+ \" \" + previous_system_transcript_tst[i],transcripts_tst[i], add_special_tokens=True)\n",
    "    else:\n",
    "      input_ids = tokenizer.encode(transcripts_tst[i], add_special_tokens=True)\n",
    "\n",
    "    # Update the maximum sentence length.\n",
    "    max_len_tst = max(max_len_tst, len(input_ids))\n",
    "\n",
    "print(\"Max transcript length for evaluation: \",max_len_tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c277f0",
   "metadata": {},
   "source": [
    "### Risultato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26bd8ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La massima lunghezza dei token da gestire è quindi  177\n"
     ]
    }
   ],
   "source": [
    "max_len = max(max_len_tr, max_len_vd, max_len_tst)\n",
    "\n",
    "# if (max_len_tr >= max_len_vd):\n",
    "#   max_len = max_len_tr\n",
    "# else:\n",
    "#   max_len = max_len_vd\n",
    "# if (max_len_tst >= max_len):\n",
    "#   max_len = max_len_tst\n",
    "\n",
    "print(\"La massima lunghezza dei token da gestire è quindi \",max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcefd1f1",
   "metadata": {},
   "source": [
    "## Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54bc7c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "[('availableSizes',)]\n",
      "['ageRange' 'amountInStock' 'availableSizes' 'brand' 'clothingCategory'\n",
      " 'clothingStyle' 'color' 'customerRating' 'dressStyle' 'embellishment'\n",
      " 'forGender' 'forOccasion' 'hasPart' 'hemLength' 'hemStyle' 'info'\n",
      " 'jacketStyle' 'madeIn' 'material' 'necklineStyle' 'pattern' 'price'\n",
      " 'sequential' 'size' 'skirtLength' 'skirtStyle' 'sleeveLength'\n",
      " 'sleeveStyle' 'soldBy' 'sweaterStyle' 'waistStyle' 'warmthRating'\n",
      " 'waterResistance']\n",
      "Totale: 30106, Training: 21196, Validation: 3513, Evaluation: 5397\n",
      "Training: 21196, Validation: 3513, Evaluation: 5397\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "attributes_labels_all = np.concatenate((attributes_labels_tr, attributes_labels_vd,attributes_labels_tst), axis=None)\n",
    "attr_yt = mlb.fit_transform(attributes_labels_all)\n",
    "print(attr_yt[0:15])\n",
    "print(mlb.inverse_transform(attr_yt[3].reshape(1, -1)))\n",
    "print(mlb.classes_)\n",
    "print(f\"Totale: {len(attr_yt)}, Training: {len(attributes_labels_tr)}, Validation: {len(attributes_labels_vd)}, Evaluation: {len(attributes_labels_tst)}\")\n",
    "attributes_labels_tr_vect = attr_yt[0:len(attributes_labels_tr)]\n",
    "attributes_labels_vd_vect = attr_yt[len(attributes_labels_tr):(len(attributes_labels_tr)+len(attributes_labels_vd))]\n",
    "attributes_labels_tst_vect = attr_yt[(len(attributes_labels_tr)+len(attributes_labels_vd)):]\n",
    "print(f\"Training: {len(attributes_labels_tr_vect)}, Validation: {len(attributes_labels_vd_vect)}, Evaluation: {len(attributes_labels_tst_vect)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63925873",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9505e37",
   "metadata": {},
   "source": [
    "Now we're ready to perform the real tokenization.\n",
    "\n",
    "The tokenizer.encode_plus function combines multiple steps for us:\n",
    "\n",
    "Split the sentence into tokens.\n",
    "Add the special [CLS] and [SEP] tokens.\n",
    "Map the tokens to their IDs.\n",
    "Pad or truncate all sentences to the same length.\n",
    "Create the attention masks which explicitly differentiate real tokens from [PAD] tokens.\n",
    "The first four features are in tokenizer.encode, but I'm using tokenizer.encode_plus to get the fifth item (attention masks). Documentation is here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aff8d187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8bcc0562f0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "# backends cudnn for out memory not necessary (resolved by batch size)\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "# torch.backends.cudnn.enabled = True\n",
    "# Set torch seed for deterministic behaviour\n",
    "torch.manual_seed(exec_params['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45855e8f",
   "metadata": {},
   "source": [
    "### Tokenize Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e32c330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21196 records to encode.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gian/anaconda3/envs/testcuda1/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2126: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING : \n",
      "Original:  Is there a pattern on this one? It's hard to see in the image.\n",
      "Token IDs: tensor([ 101, 2003, 2045, 1037, 5418, 2006, 2023, 2028, 1029, 2009, 1005, 1055,\n",
      "        2524, 2000, 2156, 1999, 1996, 3746, 1012,  102,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "\n",
    "#dobbiamo convertire le nostre lables da string a valori numerici, usiamo il metodo fornito da sklearn\n",
    "\n",
    "#TRAINING DATASET\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "action_labels_encoded_tr = le.fit_transform(action_labels_tr)\n",
    "\n",
    "input_ids_tr = []\n",
    "attention_masks_tr = []\n",
    "print(f\"{len(df_training)} records to encode.\")\n",
    "# For every sentence...\n",
    "for i in range(0,len(df_training)):\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "\n",
    "  if (previous_transcript_tr[i] != \"\" and use_next):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        previous_transcript_tr[i]+ \" \" + previous_system_transcript_tr[i],  # Sentence to encode.\n",
    "                        transcripts_tr[i], #next sentece to encode\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        truncation = True,\n",
    "                        max_length = max_len,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                    )\n",
    "  else:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        transcripts_tr[i],  # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        truncation = True,\n",
    "                        max_length = max_len,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                    )\n",
    "    \n",
    "\n",
    "    \n",
    "  # Add the encoded sentence to the list.    \n",
    "  input_ids_tr.append(encoded_dict['input_ids'])\n",
    "\n",
    "  # And its attention mask (simply differentiates padding from non-padding).\n",
    "  attention_masks_tr.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids_tr = torch.cat(input_ids_tr, dim=0)\n",
    "attention_masks_tr = torch.cat(attention_masks_tr, dim=0)\n",
    "labels_actions_tr = torch.tensor(action_labels_encoded_tr)\n",
    "labels_attributes_tr = torch.tensor(attributes_labels_tr_vect) \n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print (\"TRAINING : \")\n",
    "if (use_next):\n",
    "  print('Original: ', transcripts_tr[0])\n",
    "else:\n",
    "  print('Original: ', transcripts_tr[0])\n",
    "print('Token IDs:', input_ids_tr[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cda4541",
   "metadata": {},
   "source": [
    "### Tokenize Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5da13a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3513 records to encode.\n",
      "VALIDATION : \n",
      "Original:  What's the price of this sweater compared to the other blue and gray one I looked at?\n",
      "Token IDs: tensor([  101,  2054,  1005,  1055,  1996,  3976,  1997,  2023, 14329,  4102,\n",
      "         2000,  1996,  2060,  2630,  1998,  3897,  2028,  1045,  2246,  2012,\n",
      "         1029,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0])\n",
      "Dialog IDs: tensor([4146, 4146, 4146, 4146, 4146, 4146, 4146, 4260, 4260, 4260, 4260, 8022,\n",
      "        8022, 8022, 8022, 8022, 8022, 4992, 4992, 4992])\n",
      "Turn IDXs: tensor([0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 0, 1, 2, 3, 4, 5, 0, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "\n",
    "#dobbiamo convertire le nostre lables da string a valori numerici, usiamo il metodo fornito da sklearn\n",
    "\n",
    "#VALIDATION DATASET\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "action_labels_encoded_vd = le.fit_transform(action_labels_vd)\n",
    "\n",
    "input_ids_vd = []\n",
    "attention_masks_vd = []\n",
    "print(f\"{len(df_validation)} records to encode.\")\n",
    "# For every sentence...\n",
    "for i in range(0,len(df_validation)):\n",
    "  # `encode_plus` will:\n",
    "  #   (1) Tokenize the sentence.\n",
    "  #   (2) Prepend the `[CLS]` token to the start.\n",
    "  #   (3) Append the `[SEP]` token to the end.\n",
    "  #   (4) Map tokens to their IDs.\n",
    "  #   (5) Pad or truncate the sentence to `max_length`\n",
    "  #   (6) Create attention masks for [PAD] tokens.\n",
    "\n",
    "  if (previous_transcript_vd[i] != \"\" and use_next):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        previous_transcript_vd[i]+ \" \" + previous_system_transcript_vd[i],  # Sentence to encode.\n",
    "                        transcripts_vd[i], #next sentece to encode\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        truncation = True,\n",
    "                        max_length = max_len,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                    )\n",
    "  else:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        transcripts_vd[i],  # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        truncation = True,\n",
    "                        max_length = max_len,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                    )\n",
    "    \n",
    "  # Add the encoded sentence to the list.    \n",
    "  input_ids_vd.append(encoded_dict['input_ids'])\n",
    "  \n",
    "  # And its attention mask (simply differentiates padding from non-padding).\n",
    "  attention_masks_vd.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids_vd = torch.cat(input_ids_vd, dim=0)\n",
    "attention_masks_vd = torch.cat(attention_masks_vd, dim=0)\n",
    "labels_actions_vd = torch.tensor(action_labels_encoded_vd)\n",
    "labels_attributes_vd = torch.tensor(attributes_labels_vd_vect)\n",
    "# Check warning:\n",
    "# /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
    "dialog_ids_vd = torch.tensor(dialog_ids_vd)\n",
    "turn_idxs_vd = torch.tensor(turn_idxs_vd) \n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print (\"VALIDATION : \")\n",
    "if (use_next):\n",
    "  print('Original: ', transcripts_vd[0])\n",
    "else:\n",
    "  print('Original: ', transcripts_vd[0])\n",
    "print('Token IDs:', input_ids_vd[0])\n",
    "print(f\"Dialog IDs: {dialog_ids_vd[0:20]}\")\n",
    "print(f\"Turn IDXs: {turn_idxs_vd[0:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d364715",
   "metadata": {},
   "source": [
    "### Tokenize Evaluation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23888911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5397 records to encode.\n",
      "Evaluation : \n",
      "Original:  That looks a little too light for what I need, do you have something else with a high customer rating?\n",
      "Token IDs: tensor([ 101, 2008, 3504, 1037, 2210, 2205, 2422, 2005, 2054, 1045, 2342, 1010,\n",
      "        2079, 2017, 2031, 2242, 2842, 2007, 1037, 2152, 8013, 5790, 1029,  102,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0])\n",
      "Dialog IDs: tensor([2494, 2494, 2494, 2494, 2494, 3731, 3731, 3731, 3731, 3731, 8546, 8546,\n",
      "        8546, 8546, 8546, 8546, 5590, 5590, 5590, 5590])\n",
      "Turn IDXs: tensor([0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "\n",
    "#dobbiamo convertire le nostre lables da string a valori numerici, usiamo il metodo fornito da sklearn\n",
    "\n",
    "#EVALUATION DATASET\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "action_labels_encoded_tst = le.fit_transform(action_labels_tst)\n",
    "\n",
    "input_ids_tst = []\n",
    "attention_masks_tst = []\n",
    "print(f\"{len(df_test)} records to encode.\")\n",
    "# For every sentence...\n",
    "for i in range(0,len(df_test)):\n",
    "# for t in transcripts_tst:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "  \n",
    "  #Aggiungere \"and False\" PER UTILIZZARE sempre la tokenizzazione senza concatenazione\n",
    "  if (previous_transcript_tst[i] != \"\" and use_next):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                      previous_transcript_tst[i]+ \" \" + previous_system_transcript_tst[i],  # Sentence to encode.\n",
    "                      transcripts_tst[i], #next sentece to encode\n",
    "                      add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                      truncation = True,\n",
    "                      max_length = max_len,           # Pad & truncate all sentences.\n",
    "                      pad_to_max_length = True,\n",
    "                      return_attention_mask = True,   # Construct attn. masks.\n",
    "                      return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                  )\n",
    "  else:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                      transcripts_tst[i],  # Sentence to encode.\n",
    "                      add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                      truncation = True,\n",
    "                      max_length = max_len,           # Pad & truncate all sentences.\n",
    "                      pad_to_max_length = True,\n",
    "                      return_attention_mask = True,   # Construct attn. masks.\n",
    "                      return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                  )\n",
    "    \n",
    "  # Add the encoded sentence to the list.    \n",
    "  input_ids_tst.append(encoded_dict['input_ids'])\n",
    "  \n",
    "  # And its attention mask (simply differentiates padding from non-padding).\n",
    "  attention_masks_tst.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids_tst = torch.cat(input_ids_tst, dim=0)\n",
    "attention_masks_tst = torch.cat(attention_masks_tst, dim=0)\n",
    "labels_actions_tst = torch.tensor(action_labels_encoded_tst)\n",
    "labels_attributes_tst = torch.tensor(attributes_labels_tst_vect)\n",
    "# Check warning:\n",
    "# /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
    "dialog_ids_tst = torch.tensor(dialog_ids_tst)\n",
    "turn_idxs_tst = torch.tensor(turn_idxs_tst) \n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print (\"Evaluation : \")\n",
    "if (use_next):\n",
    "  print('Original: ', transcripts_tst[0])\n",
    "else:\n",
    "  print('Original: ', transcripts_tst[0])\n",
    "print('Token IDs:', input_ids_tst[0])\n",
    "print(f\"Dialog IDs: {dialog_ids_tst[0:20]}\")\n",
    "print(f\"Turn IDXs: {turn_idxs_tst[0:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af23bb7",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96157e27",
   "metadata": {},
   "source": [
    "# Data Split - AP4CA\n",
    "La nostra versione di split di dati per training e validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "680bdf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21,196 training samples\n",
      "3,513 validation samples\n",
      "5,397 evaluation samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "#labels_tr = {'actions': labels_actions_tr, 'attributes': labels_attributes_tr}\n",
    "#labels_vd = {'actions': labels_actions_vd, 'attributes': labels_attributes_vd}\n",
    "\n",
    "train_dataset = TensorDataset(input_ids_tr, attention_masks_tr, labels_actions_tr, labels_attributes_tr)\n",
    "val_dataset = TensorDataset(input_ids_vd, attention_masks_vd, labels_actions_vd, labels_attributes_vd, dialog_ids_vd, turn_idxs_vd)\n",
    "tst_dataset = TensorDataset(input_ids_tst, attention_masks_tst, labels_actions_tst, labels_attributes_tst, dialog_ids_tst, turn_idxs_tst)\n",
    "\n",
    "print('{:>5,} training samples'.format(len(train_dataset)))\n",
    "print('{:>5,} validation samples'.format(len(val_dataset)))\n",
    "print('{:>5,} evaluation samples'.format(len(tst_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed1196fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 101, 2008, 3504,  ...,    0,    0,    0],\n",
       "         [ 101, 2008, 3504,  ...,    0,    0,    0],\n",
       "         [ 101, 2040, 5617,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [ 101, 2821, 1045,  ...,    0,    0,    0],\n",
       "         [ 101, 4086, 1010,  ...,    0,    0,    0],\n",
       "         [ 101, 1045, 2066,  ...,    0,    0,    0]]),\n",
       " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " tensor([2, 4, 4, 0, 1, 2, 1, 2, 0, 1]),\n",
       " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " tensor([2494, 2494, 2494, 2494, 2494, 3731, 3731, 3731, 3731, 3731]),\n",
       " tensor([0, 1, 2, 3, 4, 0, 1, 2, 3, 4]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check evaluation TensorDataset content\n",
    "tst_dataset[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d01df19",
   "metadata": {},
   "source": [
    "## Check GPU for Training\n",
    "\n",
    "In questa versione la GPU è impostata fissa.\n",
    "Con una GPU in più a disposizione possiamo usare DataParallel e aumentare il batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31bf32c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2060\n"
     ]
    }
   ],
   "source": [
    "# Tell PyTorch to use the GPU.    \n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "print('We will use the GPU:', torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2045d72f",
   "metadata": {},
   "source": [
    "### Creazione Data Loaders per Training, Validation ed Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d9f42ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "# With size 32 GeForce RTX 2060 with 6GB run out of memory\n",
    "batch_size = exec_params['batch']\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )\n",
    "\n",
    "#ho controllato nel colab su cui ci basiamo, anche lui usa un Sequential Sampler per il dataset di evaluation\n",
    "evaluation_dataloader = DataLoader(\n",
    "            tst_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(tst_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040d27c5",
   "metadata": {},
   "source": [
    "## Train BERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc8111f",
   "metadata": {},
   "source": [
    "For this task, we first want to modify the pre-trained BERT model to give outputs for classification, and then we want to continue training the model on our dataset until that the entire model, end-to-end, is well-suited for our task. \n",
    "\n",
    "Thankfully, the huggingface pytorch implementation includes a set of interfaces designed for a variety of NLP tasks. Though these interfaces are all built on top of a trained BERT model, each has different top layers and output types designed to accomodate their specific NLP task.  \n",
    "\n",
    "Here is the current list of classes provided for fine-tuning:\n",
    "* BertModel\n",
    "* BertForPreTraining\n",
    "* BertForMaskedLM\n",
    "* BertForNextSentencePrediction\n",
    "* **BertForSequenceClassification** - The one we'll use.\n",
    "* BertForTokenClassification\n",
    "* BertForQuestionAnswering\n",
    "\n",
    "The documentation for these can be found under [here](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbd23ca",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We'll be using [BertForSequenceClassification](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#bertforsequenceclassification). This is the normal BERT model with an added single linear layer on top for classification that we will use as a sentence classifier. As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task. \n",
    "\n",
    "NB anche nell'articolo che sto leggendo sulla classificazione multi-label si parte da questo modello\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba0360b",
   "metadata": {},
   "source": [
    "OK, let's load BERT! There are a few different pre-trained BERT models available. \"bert-base-uncased\" means the version that has only lowercase letters (\"uncased\") and is the smaller version of the two (\"base\" vs \"large\").\n",
    "\n",
    "The documentation for `from_pretrained` can be found [here](https://huggingface.co/transformers/v2.2.0/main_classes/model.html#transformers.PreTrainedModel.from_pretrained), with the additional parameters defined [here](https://huggingface.co/transformers/v2.2.0/main_classes/configuration.html#transformers.PretrainedConfig)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "242aa137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DA SISTEMARE\n",
    "from transformers import BertModel\n",
    "from  torch import  nn\n",
    "\n",
    "class CustomBERTModel(nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "\n",
    "    super(CustomBERTModel, self).__init__()\n",
    "    self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "    ### New layers:\n",
    "    self.linear_intermedio = nn.Linear(768, exec_params['hidden_output_dim'])\n",
    "    #provare ad aggiungere ulteriori layer intermedi per ridurre le dimensioni fino ad arrivare all'output richiesto\n",
    "    self.linear_actions = nn.Linear(exec_params['hidden_output_dim'], 5) \n",
    "    self.linear_attributes = nn.Linear(exec_params['hidden_output_dim'], len(mlb.classes_)) #num attributi? \n",
    "\n",
    "  def forward(self, ids, mask):\n",
    "    #controllare che l'output non rappresenti solo lo stato interno dovuto al token CLS\n",
    "    output = self.bert(ids,attention_mask=mask)\n",
    "    # print(f\"Type output{type(output)}\")\n",
    "    # for p in output:\n",
    "    #   print(p)\n",
    "    #   print(type(output[p]))\n",
    "    #   print(output[p])\n",
    "\n",
    "    #prendiamo il campo last_hidden_state dall'oggetto output; last hidden state rappresenta il tensore\n",
    "    #in uscita dallo step di forward del BertModel\n",
    "    last_hidden_state_output = output[\"last_hidden_state\"]\n",
    "    # last_hidden_state has the following shape: (batch_size, sequence_length, 768)\n",
    "    #stiamo passando solo il token CLS ai layer successivi\n",
    "    linear_output_intermedio = self.linear_intermedio(last_hidden_state_output[:,0,:].view(-1,768)) \n",
    "    # linear_output_intermedio = self.linear_intermedio(pooled_output) \n",
    "    \n",
    "    linear_output_actions = self.linear_actions(linear_output_intermedio)\n",
    "    # linear_output_actions = self.sftmx(linear_output_actions)\n",
    "    # linear_output_actions = nn.functional.softmax(linear_output_actions)\n",
    "    # Test sigmoid for increasing perplexity performance\n",
    "    linear_output_actions = torch.sigmoid(linear_output_actions)\n",
    "    linear_output_attributes = self.linear_attributes(linear_output_intermedio)\n",
    "    # linear_output_attributes = self.sig(linear_output_attributes)\n",
    "    linear_output_attributes = torch.sigmoid(linear_output_attributes)\n",
    "\n",
    "    return {'actions': linear_output_actions, 'attributes': linear_output_attributes}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ceefd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomBERTModel(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (linear_intermedio): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (linear_actions): Linear(in_features=256, out_features=5, bias=True)\n",
       "  (linear_attributes): Linear(in_features=256, out_features=33, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test istanziazione del custom model\n",
    "model = CustomBERTModel()\n",
    "\n",
    "# model.bert.config\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cb0c4c",
   "metadata": {},
   "source": [
    "Just for curiosity's sake, we can browse all of the model's parameters by name here.\n",
    "\n",
    "In the below cell, I've printed out the names and dimensions of the weights for:\n",
    "\n",
    "1. The embedding layer.\n",
    "2. The first of the twelve transformers.\n",
    "3. The output layer.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c48662a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 205 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "linear_actions.weight                                       (5, 256)\n",
      "linear_actions.bias                                             (5,)\n",
      "linear_attributes.weight                                   (33, 256)\n",
      "linear_attributes.bias                                         (33,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655b5929",
   "metadata": {},
   "source": [
    "## 4.2. Optimizer & Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2ee817",
   "metadata": {},
   "source": [
    "Now that we have our model loaded we need to grab the training hyperparameters from within the stored model.\n",
    "\n",
    "For the purposes of fine-tuning, the authors recommend choosing from the following values (from Appendix A.3 of the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf)):\n",
    "\n",
    ">- **Batch size:** 16, 32  \n",
    "- **Learning rate (Adam):** 5e-5, 3e-5, 2e-5  \n",
    "- **Number of epochs:** 2, 3, 4 \n",
    "\n",
    "We chose:\n",
    "* Batch size: 32 (set when creating our DataLoaders)\n",
    "* Learning rate: 2e-5\n",
    "* Epochs: 4 (we'll see that this is probably too many...)\n",
    "\n",
    "The epsilon parameter `eps = 1e-8` is \"a very small number to prevent any division by zero in the implementation\" (from [here](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)).\n",
    "\n",
    "You can find the creation of the AdamW optimizer in `run_glue.py` [here](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "295fde1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 5e-5, # args.learning_rate - default is 5e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4faef5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = exec_params['epochs']\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eccdf3c",
   "metadata": {},
   "source": [
    "## 4.3. Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1141dfa",
   "metadata": {},
   "source": [
    "Below is our training loop. There's a lot going on, but fundamentally for each pass in our loop we have a trianing phase and a validation phase. \n",
    "\n",
    "> *Thank you to [Stas Bekman](https://ca.linkedin.com/in/stasbekman) for contributing the insights and code for using validation loss to detect over-fitting!*\n",
    "\n",
    "**Training:**\n",
    "- Unpack our data inputs and labels\n",
    "- Load data onto the GPU for acceleration\n",
    "- Clear out the gradients calculated in the previous pass. \n",
    "    - In pytorch the gradients accumulate by default (useful for things like RNNs) unless you explicitly clear them out.\n",
    "- Forward pass (feed input data through the network)\n",
    "- Backward pass (backpropagation)\n",
    "- Tell the network to update parameters with optimizer.step()\n",
    "- Track variables for monitoring progress\n",
    "\n",
    "**Evalution:**\n",
    "- Unpack our data inputs and labels\n",
    "- Load data onto the GPU for acceleration\n",
    "- Forward pass (feed input data through the network)\n",
    "- Compute loss on our validation data and track variables for monitoring progress\n",
    "\n",
    "Pytorch hides all of the detailed calculations from us, but we've commented the code to point out which of the above steps are happening on each line. \n",
    "\n",
    "> *PyTorch also has some [beginner tutorials](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py) which you may also find helpful.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d699904",
   "metadata": {},
   "source": [
    "Define a helper function for calculating accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df633469",
   "metadata": {},
   "source": [
    "### Flat accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef1a2d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy_actions(preds, labels):\n",
    "    #print(f\"[FA] preds: {preds} / labels: {labels}\")\n",
    "    #print(f\"[FA-Actions] {type(preds)} {type(labels)}\")\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()   \n",
    "    return {'matched': np.sum(pred_flat == labels_flat), 'counts': len(labels_flat)}\n",
    "\n",
    "def flat_accuracy_attributes(preds, labels):\n",
    "  #print(f\"[FA-Attributess] {type(preds)} {type(labels)}\")\n",
    "  tot_preds = preds.shape[0]\n",
    "  preds_int = np.rint(preds)\n",
    "  tot_eq = 0\n",
    "  for i in range(tot_preds):\n",
    "    comparison = preds_int[i] == labels[i]\n",
    "    if comparison.all():\n",
    "      tot_eq += 1\n",
    "  return {'matched': tot_eq, 'counts' : tot_preds}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc1a792",
   "metadata": {},
   "source": [
    "Helper function for formatting elapsed times as `hh:mm:ss`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "903c3769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdd0590",
   "metadata": {},
   "source": [
    "### Loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0629812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "# Loss function definition\n",
    "def MyBERT_loss(logits, actions_labels, attributes_labels):\n",
    "  actions_logits = logits['actions']\n",
    "  attributes_logits = logits['attributes']\n",
    "  loss_actions_fn = nn.CrossEntropyLoss()\n",
    "  loss_attributes_fn = nn.BCELoss()\n",
    "  loss_actions = loss_actions_fn(actions_logits, actions_labels)\n",
    "  loss_attributes = loss_attributes_fn(attributes_logits, attributes_labels.float())\n",
    "  return loss_actions + loss_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fea679",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We're ready to kick off the training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aab27b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 11% | 33% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 11% | 33% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:54.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 91% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:48.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:42.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:36.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "End of epoch 0\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "\n",
      "  Average training loss: 1.13\n",
      "  Training epcoh took: 0:08:24\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8523\n",
      "  Accuracy for multilabel-classification (attributes): 0.8802\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.852263023057216, 'action_perplexity': 1.6975113069760073, 'attribute_accuracy': 0.6764537556626856, 'confusion_matrix': array([[ 457.,   33.,    0.,    0.,    9.],\n",
      "       [  23.,  678.,   26.,    9.,   21.],\n",
      "       [  10.,  156.,  540.,   53.,   26.],\n",
      "       [   0.,    0.,    0.,    0.,    0.],\n",
      "       [   2.,   41.,   58.,   52., 1319.]])}\n",
      "  Validation Loss: 1.0620\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 82% | 91% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:55.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:49.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:44.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:38.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 90% |\n",
      "End of epoch 1\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "\n",
      "  Average training loss: 1.05\n",
      "  Training epcoh took: 0:08:26\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8591\n",
      "  Accuracy for multilabel-classification (attributes): 0.9103\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8590947907771136, 'action_perplexity': 1.8826671646139026, 'attribute_accuracy': 0.7297405559934468, 'confusion_matrix': array([[4.720e+02, 3.500e+01, 5.000e+00, 0.000e+00, 6.000e+00],\n",
      "       [8.000e+00, 6.820e+02, 3.100e+01, 8.000e+00, 1.800e+01],\n",
      "       [1.100e+01, 1.440e+02, 5.280e+02, 4.800e+01, 1.500e+01],\n",
      "       [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
      "       [1.000e+00, 4.700e+01, 6.000e+01, 5.800e+01, 1.336e+03]])}\n",
      "  Validation Loss: 1.0499\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:17:43 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import action_evaluation as evaluation\n",
    "import json\n",
    "from  GPUtil import showUtilization as gpu_usage\n",
    "with open('./extr_output/fashion_dev_dials_api_calls.json') as f:\n",
    "  dev_dials = json.load(f)\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = exec_params['seed']\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "#torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "test_batch = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    print(\"GPU before train\")\n",
    "    gpu_usage()\n",
    "\n",
    "    model.train()\n",
    "    print(\"GPU after train\")\n",
    "    gpu_usage()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 400 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "            gpu_usage()\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: actions labels \n",
    "        #   [3]: attributes labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels_actions = batch[2].to(device)\n",
    "        b_labels_attributes = batch[3].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
    "        # function and pass down the arguments. The `forward` function is \n",
    "        # documented here: \n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
    "        # The results are returned in a results object, documented here:\n",
    "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
    "        # Specifically, we'll get the loss (because we provided labels) and the\n",
    "        # \"logits\"--the model outputs prior to activation.\n",
    "        result = model(b_input_ids, \n",
    "                       mask=b_input_mask)\n",
    "        \n",
    "        loss = MyBERT_loss(result, b_labels_actions, b_labels_attributes)\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.from transformers import BertModel, BertConfig\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    print(f\"End of epoch {epoch_i}\")\n",
    "    gpu_usage()\n",
    "    \n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.mlb.inverse_transform(attr_yt[3].reshape(1, -1))\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy_classification = { 'matched': 0, 'counts': 0}\n",
    "    total_eval_accuracy_multilabel = { 'matched': 0, 'counts': 0}\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    batch_number = 0\n",
    "\n",
    "    # Dictionary for action_evaluation\n",
    "    model_actions = {}\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        batch_number += 1\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels_actions = batch[2].to(device)\n",
    "        b_labels_attributes = batch[3].to(device)\n",
    "        b_dialog_ids = batch[4].to(device).detach().cpu().numpy()\n",
    "        b_turn_idxs = batch[5].to(device).detach().cpu().numpy()\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            result = model(b_input_ids, \n",
    "                       mask=b_input_mask)\n",
    "\n",
    "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
    "        # output values prior to applying an activation function like the \n",
    "        # softmax.\n",
    "        loss = MyBERT_loss(result, b_labels_actions, b_labels_attributes)\n",
    "            \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        # logits = logits.detach().cpu().numpy()\n",
    "        # label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        \n",
    "        actions_logits_foracc=result['actions'].detach().cpu().numpy()\n",
    "        attributes_logits_foracc=result['attributes'].detach().cpu().numpy()\n",
    "        actions_labels_foracc= b_labels_actions.to('cpu').numpy()\n",
    "        attributes_labels_foracc =b_labels_attributes.to('cpu').numpy()\n",
    "\n",
    "        #TODO: definire la nostra funzione di accuracy\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        accuracy_classification = flat_accuracy_actions(actions_logits_foracc, actions_labels_foracc)\n",
    "        accuracy_multilabel = flat_accuracy_attributes(attributes_logits_foracc, attributes_labels_foracc)\n",
    "        \n",
    "        total_eval_accuracy_classification['matched'] += accuracy_classification['matched']\n",
    "        total_eval_accuracy_classification['counts'] += accuracy_classification['counts']\n",
    "        total_eval_accuracy_multilabel['matched'] += accuracy_multilabel['matched']\n",
    "        total_eval_accuracy_multilabel['counts'] += accuracy_multilabel['counts']\n",
    "        # Salvo dati elaborazione batch per debug/analisi\n",
    "        test_batch.append({\n",
    "            'epoch' : epoch_i + 1,\n",
    "            'batchnum' : batch_number,\n",
    "            'actions_logits' : actions_logits_foracc,\n",
    "            'actions_labels' : actions_labels_foracc,\n",
    "            'attributes_logits' : attributes_logits_foracc,\n",
    "            'attributes_labels' : attributes_labels_foracc,\n",
    "            'accuracy_classification' : accuracy_classification,\n",
    "            'accuracy_multilabel' : accuracy_multilabel,\n",
    "        })\n",
    "\n",
    "        # Fill dictionary for action_evaluation\n",
    "        for el_i in range(len(actions_logits_foracc)):\n",
    "          dialog_id = b_dialog_ids[el_i]\n",
    "          action_log_prob = {}\n",
    "          for act_i in range(len(actions_logits_foracc[el_i])):\n",
    "            #todo: controllare che la probabilità predetta sia in scala logaritmica (?? potrebbe essere fonte di errori)\n",
    "            action_log_prob[le.classes_[act_i]] = np.log(actions_logits_foracc[el_i][act_i])\n",
    "          #attributes = {}\n",
    "          attributes = []\n",
    "          #attributes_list = np.rint(attributes_logits_foracc[el_i])\n",
    "          attributes_list = np.array(attributes_logits_foracc[el_i])\n",
    "          for attr in range(len(attributes_list)):\n",
    "            attribute = mlb.classes_[attr]\n",
    "            #attributes[mlb.classes_[attr]] = attributes_list[attr]\n",
    "            if attributes_list[attr] >= 0.5:\n",
    "              attributes.append(attribute)\n",
    "          prediction = {\n",
    "              'action': le.classes_[np.argmax(actions_logits_foracc[el_i])],\n",
    "              'action_log_prob': action_log_prob,\n",
    "              'attributes': {'attributes': attributes},\n",
    "              'turn_id': b_turn_idxs[el_i]\n",
    "          }\n",
    "          if dialog_id in model_actions:\n",
    "            model_actions[dialog_id]['predictions'].append(prediction)\n",
    "          else:\n",
    "            predictions = list()\n",
    "            predictions.append(prediction)\n",
    "            model_actions[dialog_id] = {\n",
    "                'dialog_id': dialog_id,\n",
    "                'predictions': predictions\n",
    "            }\n",
    "          \n",
    "\n",
    "    # Report the final accuracy for this validation \n",
    "\n",
    "    #avg_val_accuracy_classification = total_eval_accuracy_classification / len(validation_dataloader)\n",
    "    #avg_val_accuracy_multilabel = total_eval_accuracy_multilabel / len(validation_dataloader)\n",
    "    avg_val_accuracy_classification = total_eval_accuracy_classification['matched'] / total_eval_accuracy_classification['counts']\n",
    "    avg_val_accuracy_multilabel = total_eval_accuracy_multilabel['matched'] / total_eval_accuracy_multilabel['counts']\n",
    "    print(\"  Accuracy for classification (actions): {0:.4f}\".format(avg_val_accuracy_classification))\n",
    "    print(\"  Accuracy for multilabel-classification (attributes): {0:.4f}\".format(avg_val_accuracy_multilabel))\n",
    "\n",
    "    # Reference implementation: evaluation of action prediction along with attributes\n",
    "    metrics = evaluation.evaluate_action_prediction(dev_dials, model_actions.values())\n",
    "    # print(\"model_actions passed to the evaluator:\")\n",
    "    # for v in model_actions.values():\n",
    "    #   print(v)\n",
    "    print(\"***************************************\")\n",
    "    print(\"Reference evaluation metrics:\")\n",
    "    print(metrics)\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.4f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,  \n",
    "            'Valid. Accur. class.': avg_val_accuracy_classification,\n",
    "            'Valid. Accur. mult.label': avg_val_accuracy_multilabel,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time,\n",
    "            'metrics': metrics\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ac0f0f",
   "metadata": {},
   "source": [
    "## Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b6d29e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy for classification (actions): 0.8521\n",
      "  Accuracy for multilabel-classification (attributes): 0.9085\n",
      "#Instances evaluated API: 5397\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8521400778210116, 'action_perplexity': 2.0297623222348573, 'attribute_accuracy': 0.7200792766149513, 'confusion_matrix': array([[ 750.,   51.,    8.,    4.,   17.],\n",
      "       [  24., 1051.,   39.,   16.,   36.],\n",
      "       [  14.,  207.,  782.,   92.,   19.],\n",
      "       [   0.,    0.,    0.,    0.,    0.],\n",
      "       [   5.,   77.,  115.,   74., 2016.]])}\n"
     ]
    }
   ],
   "source": [
    "#Prediction on test set\n",
    "#quale modello gli viene passato? da controllare se BERT da solo riesce a tenere traccia del modello che ha dato l'epoca migliore\n",
    "\n",
    "\n",
    "with open('./extr_output/fashion_devtest_dials_api_calls.json') as f:\n",
    "  devtest_dials = json.load(f)\n",
    "\n",
    "# Tracking variables \n",
    "total_eval_accuracy_classification = { 'matched': 0, 'counts': 0}\n",
    "total_eval_accuracy_multilabel = { 'matched': 0, 'counts': 0}\n",
    "\n",
    "model_actions = {}\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "for batch in evaluation_dataloader:\n",
    "\n",
    "    # Unpack this training batch from our dataloader. \n",
    "    #\n",
    "    # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "    # the `to` method.\n",
    "    #\n",
    "    # `batch` contains three pytorch tensors:\n",
    "    #   [0]: input ids \n",
    "    #   [1]: attention masks\n",
    "    #   [2]: labels \n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels_actions = batch[2].to(device)\n",
    "    b_labels_attributes = batch[3].to(device)\n",
    "    b_dialog_ids = batch[4].to(device).detach().cpu().numpy()\n",
    "    b_turn_idxs = batch[5].to(device).detach().cpu().numpy()\n",
    "    \n",
    "    # Tell pytorch not to bother with constructing the compute graph during\n",
    "    # the forward pass, since this is only needed for backprop (training).\n",
    "    with torch.no_grad():        \n",
    "        # Forward pass, calculate logit predictions.\n",
    "        # token_type_ids is the same as the \"segment ids\", which \n",
    "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "        result = model(b_input_ids,mask=b_input_mask)\n",
    "\n",
    "    \n",
    "    actions_logits_foracc=result['actions'].detach().cpu().numpy()\n",
    "    attributes_logits_foracc=result['attributes'].detach().cpu().numpy()\n",
    "    actions_labels_foracc= b_labels_actions.to('cpu').numpy()\n",
    "    attributes_labels_foracc =b_labels_attributes.to('cpu').numpy()\n",
    "\n",
    "    # Calculate the accuracy for this batch of test sentences, and\n",
    "    # accumulate it over all batches.\n",
    "    accuracy_classification = flat_accuracy_actions(actions_logits_foracc, actions_labels_foracc)\n",
    "    accuracy_multilabel = flat_accuracy_attributes(attributes_logits_foracc, attributes_labels_foracc)\n",
    "    \n",
    "    total_eval_accuracy_classification['matched'] += accuracy_classification['matched']\n",
    "    total_eval_accuracy_classification['counts'] += accuracy_classification['counts']\n",
    "    total_eval_accuracy_multilabel['matched'] += accuracy_multilabel['matched']\n",
    "    total_eval_accuracy_multilabel['counts'] += accuracy_multilabel['counts']\n",
    "    \n",
    "\n",
    "    # Fill dictionary for action_evaluation\n",
    "    for el_i in range(len(actions_logits_foracc)):\n",
    "      dialog_id = b_dialog_ids[el_i]\n",
    "      action_log_prob = {}\n",
    "      for act_i in range(len(actions_logits_foracc[el_i])):\n",
    "        #todo: controllare che la probabilità predetta sia in scala logaritmica (?? potrebbe essere fonte di errori)\n",
    "        action_log_prob[le.classes_[act_i]] = np.log(actions_logits_foracc[el_i][act_i])\n",
    "      #attributes = {}\n",
    "      attributes = []\n",
    "      #attributes_list = np.rint(attributes_logits_foracc[el_i])\n",
    "      attributes_list = np.array(attributes_logits_foracc[el_i])\n",
    "      for attr in range(len(attributes_list)):\n",
    "        attribute = mlb.classes_[attr]\n",
    "        #attributes[mlb.classes_[attr]] = attributes_list[attr]\n",
    "        if attributes_list[attr] >= 0.5:\n",
    "          attributes.append(attribute)\n",
    "      prediction = {\n",
    "          'action': le.classes_[np.argmax(actions_logits_foracc[el_i])],\n",
    "          'action_log_prob': action_log_prob,\n",
    "          'attributes': {'attributes': attributes},\n",
    "          'turn_id': b_turn_idxs[el_i]\n",
    "      }\n",
    "      if dialog_id in model_actions:\n",
    "        model_actions[dialog_id]['predictions'].append(prediction)\n",
    "      else:\n",
    "        predictions = list()\n",
    "        predictions.append(prediction)\n",
    "        model_actions[dialog_id] = {\n",
    "            'dialog_id': dialog_id,\n",
    "            'predictions': predictions\n",
    "        }\n",
    "      \n",
    "\n",
    "# Report the final accuracy for this validation \n",
    "\n",
    "#avg_val_accuracy_classification = total_eval_accuracy_classification / len(validation_dataloader)\n",
    "#avg_val_accuracy_multilabel = total_eval_accuracy_multilabel / len(validation_dataloader)\n",
    "avg_val_accuracy_classification = total_eval_accuracy_classification['matched'] / total_eval_accuracy_classification['counts']\n",
    "avg_val_accuracy_multilabel = total_eval_accuracy_multilabel['matched'] / total_eval_accuracy_multilabel['counts']\n",
    "print(\"  Accuracy for classification (actions): {0:.4f}\".format(avg_val_accuracy_classification))\n",
    "print(\"  Accuracy for multilabel-classification (attributes): {0:.4f}\".format(avg_val_accuracy_multilabel))\n",
    "\n",
    "# Reference implementation: evaluation of action prediction along with attributes\n",
    "metrics = evaluation.evaluate_action_prediction(devtest_dials, model_actions.values())\n",
    "# print(\"model_actions passed to the evaluator:\")\n",
    "# for v in model_actions.values():\n",
    "#   print(v)\n",
    "print(\"***************************************\")\n",
    "print(\"Reference evaluation metrics:\")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a059e49",
   "metadata": {},
   "source": [
    "# OTHER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ca179f",
   "metadata": {},
   "source": [
    "Let's view the summary of the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "03bdf5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "401e879c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>batchnum</th>\n",
       "      <th>actions_logits</th>\n",
       "      <th>actions_labels</th>\n",
       "      <th>attributes_logits</th>\n",
       "      <th>attributes_labels</th>\n",
       "      <th>accuracy_classification</th>\n",
       "      <th>accuracy_multilabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.00012775407, 0.9990305, 0.007433771, 0.000...</td>\n",
       "      <td>[1, 4, 2, 4, 0, 1, 1, 4, 4, 0, 1, 2]</td>\n",
       "      <td>[[0.0011405462, 0.002420093, 0.002571559, 0.00...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>{'matched': 11, 'counts': 12}</td>\n",
       "      <td>{'matched': 10, 'counts': 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0.0008707369, 0.99978465, 0.0009919585, 9.45...</td>\n",
       "      <td>[1, 4, 2, 2, 0, 1, 2, 1, 1, 1, 1, 4]</td>\n",
       "      <td>[[0.0006193937, 0.0013647107, 0.0020359512, 0....</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>{'matched': 9, 'counts': 12}</td>\n",
       "      <td>{'matched': 11, 'counts': 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[[0.031486362, 0.0045203012, 0.0018814882, 3.8...</td>\n",
       "      <td>[4, 1, 1, 1, 4, 2, 1, 2, 0, 1, 1, 1]</td>\n",
       "      <td>[[0.00018081916, 8.821573e-05, 0.7277622, 0.00...</td>\n",
       "      <td>[[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>{'matched': 9, 'counts': 12}</td>\n",
       "      <td>{'matched': 11, 'counts': 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[[0.99914634, 0.14081885, 0.0003918337, 7.6451...</td>\n",
       "      <td>[0, 0, 1, 2, 0, 1, 4, 4, 0, 1, 1, 4]</td>\n",
       "      <td>[[0.000613431, 0.0003168408, 0.005333657, 0.00...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>{'matched': 10, 'counts': 12}</td>\n",
       "      <td>{'matched': 11, 'counts': 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[[0.00014606996, 0.008120971, 0.00012942124, 0...</td>\n",
       "      <td>[1, 4, 2, 4, 0, 3, 1, 1, 2, 4, 1, 1]</td>\n",
       "      <td>[[0.00086097204, 0.00094119355, 0.036018785, 0...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>{'matched': 9, 'counts': 12}</td>\n",
       "      <td>{'matched': 11, 'counts': 12}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  batchnum                                     actions_logits  \\\n",
       "0      1         1  [[0.00012775407, 0.9990305, 0.007433771, 0.000...   \n",
       "1      1         2  [[0.0008707369, 0.99978465, 0.0009919585, 9.45...   \n",
       "2      1         3  [[0.031486362, 0.0045203012, 0.0018814882, 3.8...   \n",
       "3      1         4  [[0.99914634, 0.14081885, 0.0003918337, 7.6451...   \n",
       "4      1         5  [[0.00014606996, 0.008120971, 0.00012942124, 0...   \n",
       "\n",
       "                         actions_labels  \\\n",
       "0  [1, 4, 2, 4, 0, 1, 1, 4, 4, 0, 1, 2]   \n",
       "1  [1, 4, 2, 2, 0, 1, 2, 1, 1, 1, 1, 4]   \n",
       "2  [4, 1, 1, 1, 4, 2, 1, 2, 0, 1, 1, 1]   \n",
       "3  [0, 0, 1, 2, 0, 1, 4, 4, 0, 1, 1, 4]   \n",
       "4  [1, 4, 2, 4, 0, 3, 1, 1, 2, 4, 1, 1]   \n",
       "\n",
       "                                   attributes_logits  \\\n",
       "0  [[0.0011405462, 0.002420093, 0.002571559, 0.00...   \n",
       "1  [[0.0006193937, 0.0013647107, 0.0020359512, 0....   \n",
       "2  [[0.00018081916, 8.821573e-05, 0.7277622, 0.00...   \n",
       "3  [[0.000613431, 0.0003168408, 0.005333657, 0.00...   \n",
       "4  [[0.00086097204, 0.00094119355, 0.036018785, 0...   \n",
       "\n",
       "                                   attributes_labels  \\\n",
       "0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "2  [[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "3  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "4  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "         accuracy_classification            accuracy_multilabel  \n",
       "0  {'matched': 11, 'counts': 12}  {'matched': 10, 'counts': 12}  \n",
       "1   {'matched': 9, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
       "2   {'matched': 9, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
       "3  {'matched': 10, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
       "4   {'matched': 9, 'counts': 12}  {'matched': 11, 'counts': 12}  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert test data to dataframe\n",
    "df_test = pd.DataFrame(data = test_batch)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dbd5290d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur. class.</th>\n",
       "      <th>Valid. Accur. mult.label</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "      <th>metrics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.13</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0:08:24</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.852263023057216, 'action...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.05</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0:08:26</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8590947907771136, 'actio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. class.  \\\n",
       "epoch                                                     \n",
       "1               1.13         1.06                  0.85   \n",
       "2               1.05         1.05                  0.86   \n",
       "\n",
       "       Valid. Accur. mult.label Training Time Validation Time  \\\n",
       "epoch                                                           \n",
       "1                          0.88       0:08:24         0:00:27   \n",
       "2                          0.91       0:08:26         0:00:27   \n",
       "\n",
       "                                                 metrics  \n",
       "epoch                                                     \n",
       "1      {'action_accuracy': 0.852263023057216, 'action...  \n",
       "2      {'action_accuracy': 0.8590947907771136, 'actio...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display floats with two decimal places.\n",
    "pd.set_option('precision', 2)\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap.\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Display the table.\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "69386886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Objects serialization\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "testdata_filename = f\"testdata-{timestr}\"\n",
    "stats_filename = f\"stats-{timestr}\"\n",
    "#outtest = open(testdata_filename, \"wb\")\n",
    "#outstats = open(stats_filename, \"wb\")\n",
    "#pk.dump(obj=df_test, file=outtest)\n",
    "#outtest.close()\n",
    "#pk.dump(obj=df_stats, file=outstats)\n",
    "#outstats.close()\n",
    "df_test.to_pickle(testdata_filename)\n",
    "df_stats.to_pickle(stats_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb5a6cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testdata-20210801-003823\n",
      "       Training Loss  Valid. Loss  Valid. Accur. class.  \\\n",
      "epoch                                                     \n",
      "1               1.13         1.06                  0.85   \n",
      "2               1.05         1.05                  0.86   \n",
      "\n",
      "       Valid. Accur. mult.label Training Time Validation Time  \\\n",
      "epoch                                                           \n",
      "1                          0.88       0:08:24         0:00:27   \n",
      "2                          0.91       0:08:26         0:00:27   \n",
      "\n",
      "                                                 metrics  \n",
      "epoch                                                     \n",
      "1      {'action_accuracy': 0.852263023057216, 'action...  \n",
      "2      {'action_accuracy': 0.8590947907771136, 'actio...  \n",
      "   epoch  batchnum                                     actions_logits  \\\n",
      "0      1         1  [[0.00012775407, 0.9990305, 0.007433771, 0.000...   \n",
      "1      1         2  [[0.0008707369, 0.99978465, 0.0009919585, 9.45...   \n",
      "2      1         3  [[0.031486362, 0.0045203012, 0.0018814882, 3.8...   \n",
      "3      1         4  [[0.99914634, 0.14081885, 0.0003918337, 7.6451...   \n",
      "4      1         5  [[0.00014606996, 0.008120971, 0.00012942124, 0...   \n",
      "\n",
      "                         actions_labels  \\\n",
      "0  [1, 4, 2, 4, 0, 1, 1, 4, 4, 0, 1, 2]   \n",
      "1  [1, 4, 2, 2, 0, 1, 2, 1, 1, 1, 1, 4]   \n",
      "2  [4, 1, 1, 1, 4, 2, 1, 2, 0, 1, 1, 1]   \n",
      "3  [0, 0, 1, 2, 0, 1, 4, 4, 0, 1, 1, 4]   \n",
      "4  [1, 4, 2, 4, 0, 3, 1, 1, 2, 4, 1, 1]   \n",
      "\n",
      "                                   attributes_logits  \\\n",
      "0  [[0.0011405462, 0.002420093, 0.002571559, 0.00...   \n",
      "1  [[0.0006193937, 0.0013647107, 0.0020359512, 0....   \n",
      "2  [[0.00018081916, 8.821573e-05, 0.7277622, 0.00...   \n",
      "3  [[0.000613431, 0.0003168408, 0.005333657, 0.00...   \n",
      "4  [[0.00086097204, 0.00094119355, 0.036018785, 0...   \n",
      "\n",
      "                                   attributes_labels  \\\n",
      "0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
      "1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
      "2  [[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
      "3  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
      "4  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
      "\n",
      "         accuracy_classification            accuracy_multilabel  \n",
      "0  {'matched': 11, 'counts': 12}  {'matched': 10, 'counts': 12}  \n",
      "1   {'matched': 9, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
      "2   {'matched': 9, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
      "3  {'matched': 10, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
      "4   {'matched': 9, 'counts': 12}  {'matched': 11, 'counts': 12}  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Test reimport data\n",
    "df_stats_reload = pd.read_pickle(stats_filename)\n",
    "df_test_reload = pd.read_pickle(testdata_filename)\n",
    "\n",
    "print(testdata_filename)\n",
    "print(df_stats_reload.head())\n",
    "print(df_test_reload.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1af435",
   "metadata": {},
   "source": [
    "## Plot di training & validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2c4fe674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks([x+1 for x in range(exec_params['epochs'])])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12797b69",
   "metadata": {},
   "source": [
    "## Plot accuracy and perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a0e4a134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "act_acc = [x['action_accuracy'] for x in df_stats.metrics]\n",
    "att_acc = [x['attribute_accuracy'] for x in df_stats.metrics]\n",
    "x_ticks = [x for x in range(len(act_acc))]\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(act_acc, 'b-o', label=\"Actions\")\n",
    "plt.plot(att_acc, 'g-o', label=\"Attributes\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Actions and attributes accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.xticks(ticks = x_ticks, labels = [str(x+1) for x in x_ticks])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2a8d2984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "act_per = [x['action_perplexity'] for x in df_stats.metrics]\n",
    "x_ticks = [x for x in range(len(act_acc))]\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(act_per, 'b-o')\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Actions perplexity\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Perplexity\")\n",
    "plt.xticks(ticks = x_ticks, labels = [str(x+1) for x in x_ticks])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a0c4ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
