{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4e26663",
   "metadata": {},
   "source": [
    "# Download GitHub repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9f42ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gian/content\n",
      "Clone in 'ActionPrediction4CA' in corso...\n",
      "remote: Enumerating objects: 437, done.\u001b[K\n",
      "remote: Counting objects: 100% (437/437), done.\u001b[K\n",
      "remote: Compressing objects: 100% (345/345), done.\u001b[K\n",
      "remote: Total 437 (delta 220), reused 294 (delta 85), pack-reused 0\u001b[K\n",
      "Ricezione degli oggetti: 100% (437/437), 53.35 MiB | 10.65 MiB/s, fatto.\n",
      "Risoluzione dei delta: 100% (220/220), fatto.\n"
     ]
    }
   ],
   "source": [
    "%cd ~/content/\n",
    "%rm -rf ~/content/ActionPrediction4CA\n",
    "%rm -rf ~/content/ActionPredictionBERT\n",
    "!git clone  --branch colab_exe https://github.com/jmcrav/ActionPrediction4CA.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36cb4f3",
   "metadata": {},
   "source": [
    "# Elimino i file inutili al modello \n",
    "Per fare il fine tuning del modello, abbiamo bisogno solo dei dati grezzi.\n",
    "Il tutor ha puntualizzato di usare SOLO lo script `simmc/mm_action_prediction/tools/extract_actions_fashion.py`, che costruisce un json con le lables associate alle azioni e agli attributi (è lo step 1 del preprocessing).\n",
    "Questo credo sia necessario perchè credo che la loro implementazione sia di un livello molto più basso di quello a cui dovremo lavorare noi.\n",
    "BERT è un metodo per effettuare il  pre-trained di modelli per il NLP di cui dobbiamo solo fare un fine-tuning accettabile, mentre il SIMMC deve addestrare un intero modello da zero(o comunque credo che il loro obiettivo sia cercare di creare un modello che riesca a funzionare bene col linguaggio multimodale.Non ho capito perchè non sia statu usato BERT anche da loro onestamente -  il task finale è diviso in 3 sottotask, e la prima è un problema di classificazione multi-classe per il quale BERT dovrebbe poter funzionare - forse perchè quella fornita è solo un implementazione di partenza e i concorrenti alla challenge hanno fornito le loro implementazioni dei modelli?). Praticamente tutte le operazioni che fanno loro sui dati credo servano ai loro dettagli implementativi di bassissimo livello; con BERT noi dovremo usare solo i metodi forniti dalla classe.\n",
    "In pratica, partendo dai dati grezzi, dobbiamo solo darli in pasto ai metodi forniti da BERT e magari lavorare un po' per migliorare i risultati, senza che sia necessario scendere fino al livello dei transformers\n",
    "\n",
    "\n",
    "**DA TENERE**\n",
    "* Output dell'extract actions\n",
    "*  `fashion_train_dials.json`:  per il training\n",
    "*  `fashion_dev_dials.json` : per la validation\n",
    "*  `fashion_teststd_dials_public.json` :per il \"report dei risultati finali\" (forse per darlo in pasto allo script di evaluation?) \n",
    "*   `fashion_metadata.json`, `fashion_devtest_dials.json` : necessari per il funzionamento dello script `extract_actions_fashion.py `\n",
    "\n",
    "**DA VERIFICARE**:\n",
    "\n",
    " forse potrebbe convenire anche usare il vocabolario che loro si costruiscono (step 2 del preprocessing) per inizializzare il Tokenizer di Bert, come fanno loro nel data loader (in `loaders/loader_simmc.py`)\n",
    " ![linea codice loader.jpg](data:image/jpeg;base64,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)\n",
    "\n",
    " Questo comando istanzia il tokenizer con una versione default o definita dall'utente (devo capire bene cosa significa, l'ho letto su https://huggingface.co/transformers/quickstart.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cd41deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gian/content/ActionPrediction4CA/tools\n",
      "/home/gian/content/ActionPrediction4CA/data/simmc_fashion\n",
      "/home/gian/content\n"
     ]
    }
   ],
   "source": [
    "%mkdir ~/content/ActionPredictionBERT ActionPredictionBERT/input_data ActionPredictionBERT/extr_output\n",
    "%cd ~/content/ActionPrediction4CA/tools\n",
    "%mv extract_actions_fashion.py ~/content/ActionPredictionBERT\n",
    "%mv action_evaluation.py ~/content/ActionPredictionBERT\n",
    "\n",
    "%cd ~/content/ActionPrediction4CA/data/simmc_fashion/\n",
    "%mv fashion_train_dials.json fashion_dev_dials.json fashion_teststd_dials_public.json fashion_metadata.json fashion_devtest_dials.json ~/content/ActionPredictionBERT/input_data\n",
    "%cd ~/content/\n",
    "%rm -rf ./ActionPrediction4CA/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c76fc6c",
   "metadata": {},
   "source": [
    "# Extract_actions_fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86671584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gian/content/ActionPredictionBERT\n",
      "Reading: ./input_data/fashion_train_dials.json\n",
      "Dialogue task Id missing: 3406\n",
      "Dialogue task Id missing: 3969\n",
      "Dialogue task Id missing: 4847\n",
      "Dialogue task Id missing: 321\n",
      "Dialogue task Id missing: 3455\n",
      "Dialogue task Id missing: 3414\n",
      "Saving: ./extr_output/fashion_train_dials_api_calls.json\n",
      "Reading: ./input_data/fashion_dev_dials.json\n",
      "Dialogue task Id missing: 2117\n",
      "Saving: ./extr_output/fashion_dev_dials_api_calls.json\n",
      "Reading: ./input_data/fashion_devtest_dials.json\n",
      "Dialogue task Id missing: 9308\n",
      "Saving: ./extr_output/fashion_devtest_dials_api_calls.json\n"
     ]
    }
   ],
   "source": [
    "%cd ~/content/ActionPredictionBERT/\n",
    "!python extract_actions_fashion.py --json_path=\"./input_data/fashion_train_dials.json ./input_data/fashion_dev_dials.json ./input_data/fashion_devtest_dials.json\" --save_root=\"./extr_output\"  --metadata_path=\"./fashion_metadata.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98da7846",
   "metadata": {},
   "source": [
    "# Notebook originale\n",
    "Script copiato dal colab di Chris McCormick e Nick Ryan\n",
    "https://colab.research.google.com/drive/1pTuQhug6Dhl9XalKB0zUGf4FIdYFlpcX#scrollTo=nSU7yERLP_66"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34794cb2",
   "metadata": {},
   "source": [
    "## 1.2. Installing the Hugging Face Library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1b3c76",
   "metadata": {},
   "source": [
    "\n",
    "Next, let's install the [transformers](https://github.com/huggingface/transformers) package from Hugging Face which will give us a pytorch interface for working with BERT. (This library contains interfaces for other pretrained language models like OpenAI's GPT and GPT-2.) We've selected the pytorch interface because it strikes a nice balance between the high-level APIs (which are easy to use but don't provide insight into how things work) and tensorflow code (which contains lots of details but often sidetracks us into lessons about tensorflow, when the purpose here is BERT!).\n",
    "\n",
    "At the moment, the Hugging Face library seems to be the most widely accepted and powerful pytorch interface for working with BERT. In addition to supporting a variety of different pre-trained transformer models, the library also includes pre-built modifications of these models suited to your specific task. For example, in this tutorial we will use `BertForSequenceClassification`.\n",
    "\n",
    "The library also includes task-specific classes for token classification, question answering, next sentence prediciton, etc. Using these pre-built classes simplifies the process of modifying BERT for your purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "466b6732",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install markdown\n",
    "#!pip install transformers\n",
    "#!pip install pandas\n",
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26608292",
   "metadata": {},
   "source": [
    "# Impostazione parametri esecuzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4aaed826",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_params = {\n",
    "    'batch': 12,\n",
    "    'epochs': 10,\n",
    "    'hidden_output_dim': 256,\n",
    "    'seed': 29869798,\n",
    "    'learning_rate': 5e-5,\n",
    "    'tolerance': 1e-8\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d9eda3",
   "metadata": {},
   "source": [
    "# Analisi Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4f4432",
   "metadata": {},
   "source": [
    "## train_dials\n",
    "\n",
    "Dati grezzi da preprocessare con lo script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7f4abad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "      <th>dialogue_idx</th>\n",
       "      <th>domains</th>\n",
       "      <th>dialogue_task_id</th>\n",
       "      <th>dialogue_coref_map.1426</th>\n",
       "      <th>dialogue_coref_map.1429</th>\n",
       "      <th>dialogue_coref_map.708</th>\n",
       "      <th>dialogue_coref_map.712</th>\n",
       "      <th>dialogue_coref_map.2401</th>\n",
       "      <th>dialogue_coref_map.2402</th>\n",
       "      <th>...</th>\n",
       "      <th>dialogue_coref_map.2335</th>\n",
       "      <th>dialogue_coref_map.713</th>\n",
       "      <th>dialogue_coref_map.1507</th>\n",
       "      <th>dialogue_coref_map.1509</th>\n",
       "      <th>dialogue_coref_map.949</th>\n",
       "      <th>dialogue_coref_map.1137</th>\n",
       "      <th>dialogue_coref_map.1872</th>\n",
       "      <th>dialogue_coref_map.1873</th>\n",
       "      <th>dialogue_coref_map.1753</th>\n",
       "      <th>dialogue_coref_map.834</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'belief_state': [{'act': 'DA:ASK:CHECK:CLOTH...</td>\n",
       "      <td>3094</td>\n",
       "      <td>[fashion]</td>\n",
       "      <td>1785.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'belief_state': [{'act': 'DA:INFORM:PREFER:C...</td>\n",
       "      <td>822</td>\n",
       "      <td>[fashion]</td>\n",
       "      <td>1720.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'belief_state': [{'act': 'DA:REQUEST:GET:CLO...</td>\n",
       "      <td>7411</td>\n",
       "      <td>[fashion]</td>\n",
       "      <td>2038.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'belief_state': [{'act': 'DA:INFORM:DISPREFE...</td>\n",
       "      <td>7029</td>\n",
       "      <td>[fashion]</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'belief_state': [{'act': 'DA:INFORM:DISPREFE...</td>\n",
       "      <td>1506</td>\n",
       "      <td>[fashion]</td>\n",
       "      <td>1686.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1648 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            dialogue  dialogue_idx    domains  \\\n",
       "0  [{'belief_state': [{'act': 'DA:ASK:CHECK:CLOTH...          3094  [fashion]   \n",
       "1  [{'belief_state': [{'act': 'DA:INFORM:PREFER:C...           822  [fashion]   \n",
       "2  [{'belief_state': [{'act': 'DA:REQUEST:GET:CLO...          7411  [fashion]   \n",
       "3  [{'belief_state': [{'act': 'DA:INFORM:DISPREFE...          7029  [fashion]   \n",
       "4  [{'belief_state': [{'act': 'DA:INFORM:DISPREFE...          1506  [fashion]   \n",
       "\n",
       "   dialogue_task_id  dialogue_coref_map.1426  dialogue_coref_map.1429  \\\n",
       "0            1785.0                      0.0                      1.0   \n",
       "1            1720.0                      NaN                      NaN   \n",
       "2            2038.0                      NaN                      NaN   \n",
       "3            2011.0                      NaN                      NaN   \n",
       "4            1686.0                      NaN                      NaN   \n",
       "\n",
       "   dialogue_coref_map.708  dialogue_coref_map.712  dialogue_coref_map.2401  \\\n",
       "0                     NaN                     NaN                      NaN   \n",
       "1                     0.0                     1.0                      NaN   \n",
       "2                     NaN                     NaN                      4.0   \n",
       "3                     NaN                     NaN                      NaN   \n",
       "4                     NaN                     NaN                      NaN   \n",
       "\n",
       "   dialogue_coref_map.2402  ...  dialogue_coref_map.2335  \\\n",
       "0                      NaN  ...                      NaN   \n",
       "1                      NaN  ...                      NaN   \n",
       "2                      0.0  ...                      NaN   \n",
       "3                      NaN  ...                      NaN   \n",
       "4                      NaN  ...                      NaN   \n",
       "\n",
       "   dialogue_coref_map.713  dialogue_coref_map.1507  dialogue_coref_map.1509  \\\n",
       "0                     NaN                      NaN                      NaN   \n",
       "1                     NaN                      NaN                      NaN   \n",
       "2                     NaN                      NaN                      NaN   \n",
       "3                     NaN                      NaN                      NaN   \n",
       "4                     NaN                      NaN                      NaN   \n",
       "\n",
       "   dialogue_coref_map.949  dialogue_coref_map.1137  dialogue_coref_map.1872  \\\n",
       "0                     NaN                      NaN                      NaN   \n",
       "1                     NaN                      NaN                      NaN   \n",
       "2                     NaN                      NaN                      NaN   \n",
       "3                     NaN                      NaN                      NaN   \n",
       "4                     NaN                      NaN                      NaN   \n",
       "\n",
       "   dialogue_coref_map.1873  dialogue_coref_map.1753  dialogue_coref_map.834  \n",
       "0                      NaN                      NaN                     NaN  \n",
       "1                      NaN                      NaN                     NaN  \n",
       "2                      NaN                      NaN                     NaN  \n",
       "3                      NaN                      NaN                     NaN  \n",
       "4                      NaN                      NaN                     NaN  \n",
       "\n",
       "[5 rows x 1648 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prima parte del fashion_train_dials\n",
    "import json \n",
    "import pandas as pd\n",
    "with open ('./input_data/fashion_train_dials.json',\"r\") as f:\n",
    "   data= json.load(f)\n",
    "\n",
    "result=[]\n",
    "row ={}\n",
    "for k in data:\n",
    "  row[k] = data[k]\n",
    "# []\n",
    "#prima parte del fashion_train_dials\n",
    "import json \n",
    "import pandas as pd\n",
    "with open ('./input_data/fashion_train_dials.json',\"r\") as f:\n",
    "   data= json.load(f)\n",
    "\n",
    "result=[]\n",
    "row ={}\n",
    "for k in data:\n",
    "  row[k] = data[k]\n",
    "# []\n",
    "\n",
    "dialogue_data = pd.json_normalize(row['dialogue_data'])\n",
    "type(dialogue_data)\n",
    "# dialogue = dialogue_data[\"dialogue\"]\n",
    "# for x in dialogue.head(1):\n",
    "#   display(x)\n",
    "# #dialogue.head(1)\n",
    "dialogue_data.head()\n",
    "\n",
    "\n",
    "\n",
    "dialogue_data = pd.json_normalize(row['dialogue_data'])\n",
    "type(dialogue_data)\n",
    "# dialogue = dialogue_data[\"dialogue\"]\n",
    "# for x in dialogue.head(1):\n",
    "#   display(x)\n",
    "# #dialogue.head(1)\n",
    "dialogue_data.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "625e5f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>image_ids</th>\n",
       "      <th>focus_image</th>\n",
       "      <th>memory_images</th>\n",
       "      <th>database_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2042</td>\n",
       "      <td>[2441, 2442, 2443, 2444, 2445, 2446, 2447, 244...</td>\n",
       "      <td>2441</td>\n",
       "      <td>[2442, 2443, 2444]</td>\n",
       "      <td>[2445, 2446, 2447, 2448, 2449, 2450]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2041</td>\n",
       "      <td>[2431, 2432, 2433, 2434, 2435, 2436, 2437, 243...</td>\n",
       "      <td>2431</td>\n",
       "      <td>[2432, 2433, 2434]</td>\n",
       "      <td>[2435, 2436, 2437, 2438, 2439, 2440]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2040</td>\n",
       "      <td>[2421, 2422, 2423, 2424, 2425, 2426, 2427, 242...</td>\n",
       "      <td>2421</td>\n",
       "      <td>[2422, 2423, 2424]</td>\n",
       "      <td>[2425, 2426, 2427, 2428, 2429, 2430]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2039</td>\n",
       "      <td>[2411, 2412, 2413, 2414, 2415, 2416, 2417, 241...</td>\n",
       "      <td>2411</td>\n",
       "      <td>[2412, 2413, 2414]</td>\n",
       "      <td>[2415, 2416, 2417, 2418, 2419, 2420]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2038</td>\n",
       "      <td>[2401, 2402, 2403, 2404, 2405, 2406, 2407, 240...</td>\n",
       "      <td>2401</td>\n",
       "      <td>[2402, 2403, 2404]</td>\n",
       "      <td>[2405, 2406, 2407, 2408, 2409, 2410]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   task_id                                          image_ids  focus_image  \\\n",
       "0     2042  [2441, 2442, 2443, 2444, 2445, 2446, 2447, 244...         2441   \n",
       "1     2041  [2431, 2432, 2433, 2434, 2435, 2436, 2437, 243...         2431   \n",
       "2     2040  [2421, 2422, 2423, 2424, 2425, 2426, 2427, 242...         2421   \n",
       "3     2039  [2411, 2412, 2413, 2414, 2415, 2416, 2417, 241...         2411   \n",
       "4     2038  [2401, 2402, 2403, 2404, 2405, 2406, 2407, 240...         2401   \n",
       "\n",
       "        memory_images                       database_images  \n",
       "0  [2442, 2443, 2444]  [2445, 2446, 2447, 2448, 2449, 2450]  \n",
       "1  [2432, 2433, 2434]  [2435, 2436, 2437, 2438, 2439, 2440]  \n",
       "2  [2422, 2423, 2424]  [2425, 2426, 2427, 2428, 2429, 2430]  \n",
       "3  [2412, 2413, 2414]  [2415, 2416, 2417, 2418, 2419, 2420]  \n",
       "4  [2402, 2403, 2404]  [2405, 2406, 2407, 2408, 2409, 2410]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#seconda parte del fashion_train_dials\n",
    "task_mapping = pd.json_normalize(row['task_mapping'])\n",
    "task_mapping.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9867cff",
   "metadata": {},
   "source": [
    "## dev_dials_api_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d5d29b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialog_id</th>\n",
       "      <th>actions</th>\n",
       "      <th>focus_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4146</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'None', 'action_sup...</td>\n",
       "      <td>[1646, 1646, 1646, 1649, 1649, 1649, 1649]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4260</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...</td>\n",
       "      <td>[2161, 2161, 2161, 2161]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8022</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SearchDatabase', '...</td>\n",
       "      <td>[1971, 1972, 1972, 1972, 1977, 1978]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4992</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'None', 'action_sup...</td>\n",
       "      <td>[1931, 1931, 1936, 1936, 1936]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5606</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'None', 'action_sup...</td>\n",
       "      <td>[1931, 1931, 1931, 1931, 1931]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dialog_id                                            actions  \\\n",
       "0       4146  [{'turn_idx': 0, 'action': 'None', 'action_sup...   \n",
       "1       4260  [{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...   \n",
       "2       8022  [{'turn_idx': 0, 'action': 'SearchDatabase', '...   \n",
       "3       4992  [{'turn_idx': 0, 'action': 'None', 'action_sup...   \n",
       "4       5606  [{'turn_idx': 0, 'action': 'None', 'action_sup...   \n",
       "\n",
       "                                 focus_images  \n",
       "0  [1646, 1646, 1646, 1649, 1649, 1649, 1649]  \n",
       "1                    [2161, 2161, 2161, 2161]  \n",
       "2        [1971, 1972, 1972, 1972, 1977, 1978]  \n",
       "3              [1931, 1931, 1936, 1936, 1936]  \n",
       "4              [1931, 1931, 1931, 1931, 1931]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dev_dials_api = pd.read_json('./extr_output/fashion_dev_dials_api_calls.json')\n",
    "dev_dials_api.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b899ff34",
   "metadata": {},
   "source": [
    "## devtest_dials_api_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f9c6435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialog_id</th>\n",
       "      <th>actions</th>\n",
       "      <th>focus_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2494</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SearchDatabase', '...</td>\n",
       "      <td>[1836, 1841, 1841, 1841, 1841]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3731</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SearchDatabase', '...</td>\n",
       "      <td>[1676, 1681, 1681, 1683, 1683]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8546</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...</td>\n",
       "      <td>[840, 840, 840, 849, 849, 843]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5590</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SearchDatabase', '...</td>\n",
       "      <td>[1616, 1618, 1618, 1618, 1618]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5452</td>\n",
       "      <td>[{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...</td>\n",
       "      <td>[2231, 2231, 2231, 2236, 2236]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dialog_id                                            actions  \\\n",
       "0       2494  [{'turn_idx': 0, 'action': 'SearchDatabase', '...   \n",
       "1       3731  [{'turn_idx': 0, 'action': 'SearchDatabase', '...   \n",
       "2       8546  [{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...   \n",
       "3       5590  [{'turn_idx': 0, 'action': 'SearchDatabase', '...   \n",
       "4       5452  [{'turn_idx': 0, 'action': 'SpecifyInfo', 'act...   \n",
       "\n",
       "                     focus_images  \n",
       "0  [1836, 1841, 1841, 1841, 1841]  \n",
       "1  [1676, 1681, 1681, 1683, 1683]  \n",
       "2  [840, 840, 840, 849, 849, 843]  \n",
       "3  [1616, 1618, 1618, 1618, 1618]  \n",
       "4  [2231, 2231, 2231, 2236, 2236]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "devtest_dials_api = pd.read_json('./extr_output/fashion_devtest_dials_api_calls.json')\n",
    "devtest_dials_api.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3ba47e",
   "metadata": {},
   "source": [
    "## Funzione generazione dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe1973e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def createDataframe(json_file):\n",
    "  with open(json_file) as f:\n",
    "    dictftdac = json.load(f)\n",
    "\n",
    "  data = []\n",
    "\n",
    "  for e in dictftdac:\n",
    "    dialog_id = e['dialog_id']\n",
    "    actions = e['actions']\n",
    "    focus_images = e['focus_images']\n",
    "\n",
    "    for a in actions:\n",
    "      \n",
    "      turn_idx = a['turn_idx']\n",
    "      action = a['action']\n",
    "      action_supervision = a['action_supervision']\n",
    "      transcript = a['transcript']\n",
    "      transcript_annotated = a['transcript_annotated']\n",
    "      system_transcript = a['system_transcript']\n",
    "      system_transcript_annotated = a['system_transcript_annotated']\n",
    "\n",
    "      row = {\n",
    "          \"dialog_id\" : dialog_id,\n",
    "          'turn_idx' : turn_idx,\n",
    "          'action' : action,\n",
    "          'action_supervision' : action_supervision,\n",
    "          'focus_images' : focus_images,\n",
    "          'transcript': transcript,\n",
    "          'transcript_annotated': transcript_annotated,\n",
    "          'system_transcript': system_transcript,\n",
    "          'system_transcript_annotated':system_transcript_annotated,\n",
    "          'previous_transcript': \"\",\n",
    "          'previous_system_transcript': \"\"\n",
    "      }\n",
    "      if (action_supervision != None):\n",
    "        if 'focus' in action_supervision:\n",
    "          acsf = {'focus':action_supervision['focus']}\n",
    "        else:\n",
    "          acsf = {'focus':None}\n",
    "        \n",
    "        if 'attributes' in action_supervision:\n",
    "          acsa = {'attributes':action_supervision['attributes']}\n",
    "        else:\n",
    "          acsa = {'attributes':[]}\n",
    "      else:\n",
    "          acsf = {'focus':None}\n",
    "          acsa = {'attributes':[]}\n",
    "      \n",
    "        \n",
    "      row.update(acsf)\n",
    "      row.update(acsa)\n",
    "    \n",
    "      data.append(row)\n",
    "\n",
    "  # Conservo id turno e risposta sistema per provare a implementare una soluzione articolata\n",
    "  df = pd.DataFrame(data,columns=['dialog_id','turn_idx','transcript','action','attributes', 'system_transcript','transcript_annotated','system_transcript_annotated','previous_transcript','previous_system_transcript'])\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a30c6d",
   "metadata": {},
   "source": [
    "## train_dials_api_calls with transcript\n",
    "Dati per il training che usiamo ( per ora semplificati)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9d78e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  21196  elementi\n"
     ]
    }
   ],
   "source": [
    "df_training = createDataframe('./extr_output/fashion_train_dials_api_calls.json')\n",
    "print(\"Training: \",len(df_training),\" elementi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e542c9",
   "metadata": {},
   "source": [
    "## fashion_dev_dials_api_calls\n",
    "Dati per la validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d7d98f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:  3513  elementi\n"
     ]
    }
   ],
   "source": [
    "df_validation = createDataframe('./extr_output/fashion_dev_dials_api_calls.json')\n",
    "print(\"Validation: \",len(df_validation),\" elementi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f272d647",
   "metadata": {},
   "source": [
    "## fashion_devtest_dials_api_calls\n",
    "Dati per la valutazione delle performance del modello (test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8e22d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  5397  elementi\n"
     ]
    }
   ],
   "source": [
    "df_test = createDataframe('./extr_output/fashion_devtest_dials_api_calls.json')\n",
    "print(\"Test: \",len(df_test),\" elementi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc25d11d",
   "metadata": {},
   "source": [
    "# BERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4c901c",
   "metadata": {},
   "source": [
    "## Scelta tipo input\n",
    "\n",
    "Il valore di questa variabile determinerà se utilizzare i singoli transcript, o se concatenare ogni transcript a quello successivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef5cc083",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_next = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d30106",
   "metadata": {},
   "source": [
    "## Preparazione input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e090913a",
   "metadata": {},
   "source": [
    "### Generazione colonna previous_transcript\n",
    "\n",
    "Generazione della colonna contenente la frase del turno successivo del dialogo (se presente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fb54823",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "df_training.sort_values(by=['dialog_id', 'turn_idx'])\n",
    "for i in range(1,(len(df_training))):\n",
    "  if(i<(len(df_training)) and  df_training['dialog_id'][i] == df_training['dialog_id'][i-1]):\n",
    "    df_training.loc[i,'previous_transcript'] = df_training['transcript'][i-1]\n",
    "    df_training.loc[i,'previous_system_transcript'] = df_training['system_transcript'][i-1]\n",
    "\n",
    "#Validation\n",
    "df_validation.sort_values(by=['dialog_id', 'turn_idx'])\n",
    "for i in range(1,(len(df_validation))):\n",
    "  if(i<(len(df_validation)) and  df_validation['dialog_id'][i] == df_validation['dialog_id'][i-1]):\n",
    "    df_validation.loc[i,'previous_transcript'] = df_validation['transcript'][i-1]\n",
    "    df_validation.loc[i,'previous_system_transcript'] = df_validation['system_transcript'][i-1]\n",
    "\n",
    "#Evaluation\n",
    "df_test.sort_values(by=['dialog_id', 'turn_idx'])\n",
    "for i in range(1,(len(df_test))):\n",
    "  if(i<(len(df_test)) and  df_test['dialog_id'][i] == df_test['dialog_id'][i-1]):\n",
    "    df_test.loc[i,'previous_transcript'] = df_test['transcript'][i-1]\n",
    "    df_test.loc[i,'previous_system_transcript'] = df_test['system_transcript'][i-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb106a56",
   "metadata": {},
   "source": [
    "### Estrazione vettori colonna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78177045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de95a8f0",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f65ef34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA:\n",
      " Original:  Is there a pattern on this one? It's hard to see in the image.\n",
      "Tokenized:  ['is', 'there', 'a', 'pattern', 'on', 'this', 'one', '?', 'it', \"'\", 's', 'hard', 'to', 'see', 'in', 'the', 'image', '.']\n",
      "Token IDs:  [2003, 2045, 1037, 5418, 2006, 2023, 2028, 1029, 2009, 1005, 1055, 2524, 2000, 2156, 1999, 1996, 3746, 1012]\n"
     ]
    }
   ],
   "source": [
    "transcripts_tr = df_training.transcript.values\n",
    "previous_transcript_tr = df_training.previous_transcript.values\n",
    "previous_system_transcript_tr = df_training.previous_system_transcript.values\n",
    "action_labels_tr = df_training.action.values\n",
    "attributes_labels_tr=df_training.attributes.values\n",
    "\n",
    "print (\"TRAINING DATA:\")\n",
    "# Print the original sentence.\n",
    "print(' Original: ', transcripts_tr[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(transcripts_tr[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(transcripts_tr[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b5da556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T: Is there a pattern on this one? It's hard to see in the image. | PT:  | PST: \n",
      "T: That's fancy. Do you have anything in warmer colors like yellow or red? | PT: Is there a pattern on this one? It's hard to see in the image. | PST: I don't have any information on the pattern, but it has pointelle embellishments.\n",
      "T: Yeah, that sounds good. | PT: That's fancy. Do you have anything in warmer colors like yellow or red? | PST: I have a crew neck sweater in red, would you like to see it?\n",
      "T: Oh, I love that. Please tell me you have a small. | PT: Yeah, that sounds good. | PST: This is $187 from Downtown Stylists with a 3.62 rating.\n",
      "T: Yes, please! Thank you for your help with this | PT: Oh, I love that. Please tell me you have a small. | PST: It does come in small, shall I put one in your cart?\n",
      "T: How nice! Does this come in other colors? | PT:  | PST: \n",
      "T: Oh well.  Can you show me a dress that comes in red? | PT: How nice! Does this come in other colors? | PST: No, I'm sorry, It comes only in blue.\n",
      "T: Cute! Do these come in Small? | PT: Oh well.  Can you show me a dress that comes in red? | PST: This dress comes in many colors, including a bright red and a pinkish-red. What do you think?\n",
      "T: Awesome. Would you add a red one in S to my cart please? | PT: Cute! Do these come in Small? | PST: Yes, they do!\n",
      "T: That's all. Thanks! | PT: Awesome. Would you add a red one in S to my cart please? | PST: The red one is in your cart. Is there anything else I can find for you?\n"
     ]
    }
   ],
   "source": [
    "for k in range(0,10):\n",
    "  print(f\"T: {transcripts_tr[k]} | PT: {previous_transcript_tr[k]} | PST: {previous_system_transcript_tr[k]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef35705",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcd4e529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION DATA:\n",
      " Original:  What's the price of this sweater compared to the other blue and gray one I looked at?\n",
      "Tokenized:  ['what', \"'\", 's', 'the', 'price', 'of', 'this', 'sweater', 'compared', 'to', 'the', 'other', 'blue', 'and', 'gray', 'one', 'i', 'looked', 'at', '?']\n",
      "Token IDs:  [2054, 1005, 1055, 1996, 3976, 1997, 2023, 14329, 4102, 2000, 1996, 2060, 2630, 1998, 3897, 2028, 1045, 2246, 2012, 1029]\n",
      "Dialog IDs: [4146 4146 4146 4146 4146 4146 4146 4260 4260 4260 4260 8022 8022 8022\n",
      " 8022 8022 8022 4992 4992 4992]\n",
      "Turn IDs: [0 1 2 3 4 5 6 0 1 2 3 0 1 2 3 4 5 0 1 2]\n"
     ]
    }
   ],
   "source": [
    "transcripts_vd = df_validation.transcript.values\n",
    "previous_transcript_vd = df_validation.previous_transcript.values\n",
    "previous_system_transcript_vd = df_validation.previous_system_transcript.values\n",
    "action_labels_vd = df_validation.action.values\n",
    "attributes_labels_vd=df_validation.attributes.values\n",
    "dialog_ids_vd = df_validation.dialog_id.values\n",
    "turn_idxs_vd = df_validation.turn_idx.values\n",
    "\n",
    "print (\"VALIDATION DATA:\")\n",
    "\n",
    "# Print the original sentence.\n",
    "print(' Original: ', transcripts_vd[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(transcripts_vd[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(transcripts_vd[0])))\n",
    "\n",
    "# Print the dialog ids.\n",
    "print(f\"Dialog IDs: {dialog_ids_vd[0:20]}\")\n",
    "\n",
    "# Print the turn idxs.\n",
    "print(f\"Turn IDs: {turn_idxs_vd[0:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba6e6ef",
   "metadata": {},
   "source": [
    "#### Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "886bcaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATION DATA:\n",
      " Original:  That looks a little too light for what I need, do you have something else with a high customer rating?\n",
      "Tokenized:  ['that', 'looks', 'a', 'little', 'too', 'light', 'for', 'what', 'i', 'need', ',', 'do', 'you', 'have', 'something', 'else', 'with', 'a', 'high', 'customer', 'rating', '?']\n",
      "Token IDs:  [2008, 3504, 1037, 2210, 2205, 2422, 2005, 2054, 1045, 2342, 1010, 2079, 2017, 2031, 2242, 2842, 2007, 1037, 2152, 8013, 5790, 1029]\n",
      "Dialog IDs: [2494 2494 2494 2494 2494 3731 3731 3731 3731 3731 8546 8546 8546 8546\n",
      " 8546 8546 5590 5590 5590 5590]\n",
      "Turn IDs: [0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 5 0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "transcripts_tst = df_test.transcript.values\n",
    "previous_transcript_tst = df_test.previous_transcript.values\n",
    "previous_system_transcript_tst = df_test.previous_system_transcript.values\n",
    "action_labels_tst = df_test.action.values\n",
    "attributes_labels_tst=df_test.attributes.values\n",
    "dialog_ids_tst = df_test.dialog_id.values\n",
    "turn_idxs_tst = df_test.turn_idx.values\n",
    "\n",
    "print (\"EVALUATION DATA:\")\n",
    "\n",
    "# Print the original sentence.\n",
    "print(' Original: ', transcripts_tst[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(transcripts_tst[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(transcripts_tst[0])))\n",
    "\n",
    "# Print the dialog ids.\n",
    "print(f\"Dialog IDs: {dialog_ids_tst[0:20]}\")\n",
    "\n",
    "# Print the turn idxs.\n",
    "print(f\"Turn IDs: {turn_idxs_tst[0:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c049bbf",
   "metadata": {},
   "source": [
    "## Calcolo dimensione massima\n",
    "\n",
    "The above code left out a few required formatting steps that we'll look at here.\n",
    "\n",
    "We are required to:\n",
    "1. Add special tokens to the start and end of each sentence.\n",
    "2. Pad & truncate all sentences to a single constant length.\n",
    "3. Explicitly differentiate real tokens from padding tokens with the \"attention mask\".\n",
    "\n",
    "\n",
    "The sentences in our dataset obviously have varying lengths, so how does BERT handle this?\n",
    "\n",
    "BERT has two constraints:\n",
    "\n",
    "\n",
    "1.   All sentences must be padded or truncated to a single, fixed length.\n",
    "2.   The maximum sentence length is 512 tokens.\n",
    "\n",
    "\n",
    "Padding is done with a special [PAD] token, which is at index 0 in the BERT vocabulary. The below illustration demonstrates padding out to a \"MAX_LEN\" of 8 tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c16396",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8e5132e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max transcript length for training:  177\n"
     ]
    }
   ],
   "source": [
    "max_len_tr = 0\n",
    "\n",
    "# For every sentence...\n",
    "for i in range(0,len(transcripts_tr)):\n",
    "    \n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "\n",
    "    if (previous_transcript_tr[i] != \"\" and use_next):\n",
    "      input_ids = tokenizer.encode(previous_transcript_tr[i]+ \" \" + previous_system_transcript_tr[i],transcripts_tr[i], add_special_tokens=True)\n",
    "    else:\n",
    "      input_ids = tokenizer.encode(transcripts_tr[i], add_special_tokens=True)\n",
    "        \n",
    "    # Update the maximum sentence length.\n",
    "    max_len_tr = max(max_len_tr, len(input_ids))\n",
    "\n",
    "print('Max transcript length for training: ', max_len_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17363e3c",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92914388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max transcript length for validation:  133\n"
     ]
    }
   ],
   "source": [
    "max_len_vd = 0\n",
    "\n",
    "# For every sentence...\n",
    "for i in range(0,len(transcripts_vd)):\n",
    "\n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    if (previous_transcript_vd[i] != \"\" and use_next):\n",
    "      input_ids = tokenizer.encode(previous_transcript_vd[i]+ \" \" + previous_system_transcript_vd[i],transcripts_vd[i], add_special_tokens=True)\n",
    "    else:\n",
    "      input_ids = tokenizer.encode(transcripts_vd[i], add_special_tokens=True)\n",
    "    \n",
    "    # Update the maximum sentence length.\n",
    "    max_len_vd = max(max_len_vd, len(input_ids))\n",
    "\n",
    "print('Max transcript length for validation: ', max_len_vd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3412aa8",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aab75df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max transcript length for evaluation:  150\n"
     ]
    }
   ],
   "source": [
    "max_len_tst = 0\n",
    "\n",
    "#non sono sicuro che il controllo della lunghezza vada fatto anche sul test set, dopo la performance non è determinata\n",
    "#dalla conoscenza del test set?\n",
    "#è anche vero che in teoria per far funzionare BERT bisogna dargli in pasto dei dati tokenizzati, quindi in un caso reale il nostro\n",
    "#model non potrebbe prendere in ingresso del testo non trattato. Nel dubbio ho controllato le dimensioni\n",
    "\n",
    "for i in range(0,len(transcripts_tst)):\n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    if (previous_transcript_tst[i] != \"\" and use_next):\n",
    "      input_ids = tokenizer.encode(previous_transcript_tst[i]+ \" \" + previous_system_transcript_tst[i],transcripts_tst[i], add_special_tokens=True)\n",
    "    else:\n",
    "      input_ids = tokenizer.encode(transcripts_tst[i], add_special_tokens=True)\n",
    "\n",
    "    # Update the maximum sentence length.\n",
    "    max_len_tst = max(max_len_tst, len(input_ids))\n",
    "\n",
    "print(\"Max transcript length for evaluation: \",max_len_tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c277f0",
   "metadata": {},
   "source": [
    "### Risultato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26bd8ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La massima lunghezza dei token da gestire è quindi  177\n"
     ]
    }
   ],
   "source": [
    "max_len = max(max_len_tr, max_len_vd, max_len_tst)\n",
    "\n",
    "# if (max_len_tr >= max_len_vd):\n",
    "#   max_len = max_len_tr\n",
    "# else:\n",
    "#   max_len = max_len_vd\n",
    "# if (max_len_tst >= max_len):\n",
    "#   max_len = max_len_tst\n",
    "\n",
    "print(\"La massima lunghezza dei token da gestire è quindi \",max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcefd1f1",
   "metadata": {},
   "source": [
    "## Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54bc7c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "[('availableSizes',)]\n",
      "['ageRange' 'amountInStock' 'availableSizes' 'brand' 'clothingCategory'\n",
      " 'clothingStyle' 'color' 'customerRating' 'dressStyle' 'embellishment'\n",
      " 'forGender' 'forOccasion' 'hasPart' 'hemLength' 'hemStyle' 'info'\n",
      " 'jacketStyle' 'madeIn' 'material' 'necklineStyle' 'pattern' 'price'\n",
      " 'sequential' 'size' 'skirtLength' 'skirtStyle' 'sleeveLength'\n",
      " 'sleeveStyle' 'soldBy' 'sweaterStyle' 'waistStyle' 'warmthRating'\n",
      " 'waterResistance']\n",
      "Totale: 30106, Training: 21196, Validation: 3513, Evaluation: 5397\n",
      "Training: 21196, Validation: 3513, Evaluation: 5397\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "attributes_labels_all = np.concatenate((attributes_labels_tr, attributes_labels_vd,attributes_labels_tst), axis=None)\n",
    "attr_yt = mlb.fit_transform(attributes_labels_all)\n",
    "print(attr_yt[0:15])\n",
    "print(mlb.inverse_transform(attr_yt[3].reshape(1, -1)))\n",
    "print(mlb.classes_)\n",
    "print(f\"Totale: {len(attr_yt)}, Training: {len(attributes_labels_tr)}, Validation: {len(attributes_labels_vd)}, Evaluation: {len(attributes_labels_tst)}\")\n",
    "attributes_labels_tr_vect = attr_yt[0:len(attributes_labels_tr)]\n",
    "attributes_labels_vd_vect = attr_yt[len(attributes_labels_tr):(len(attributes_labels_tr)+len(attributes_labels_vd))]\n",
    "attributes_labels_tst_vect = attr_yt[(len(attributes_labels_tr)+len(attributes_labels_vd)):]\n",
    "print(f\"Training: {len(attributes_labels_tr_vect)}, Validation: {len(attributes_labels_vd_vect)}, Evaluation: {len(attributes_labels_tst_vect)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63925873",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9505e37",
   "metadata": {},
   "source": [
    "Now we're ready to perform the real tokenization.\n",
    "\n",
    "The tokenizer.encode_plus function combines multiple steps for us:\n",
    "\n",
    "Split the sentence into tokens.\n",
    "Add the special [CLS] and [SEP] tokens.\n",
    "Map the tokens to their IDs.\n",
    "Pad or truncate all sentences to the same length.\n",
    "Create the attention masks which explicitly differentiate real tokens from [PAD] tokens.\n",
    "The first four features are in tokenizer.encode, but I'm using tokenizer.encode_plus to get the fifth item (attention masks). Documentation is here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aff8d187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f1a1865a8f0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "# backends cudnn for out memory not necessary (resolved by batch size)\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "# torch.backends.cudnn.enabled = True\n",
    "# Set torch seed for deterministic behaviour\n",
    "torch.manual_seed(exec_params['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45855e8f",
   "metadata": {},
   "source": [
    "### Tokenize Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e32c330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21196 records to encode.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gian/anaconda3/envs/testcuda1/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2126: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING : \n",
      "Original:  Is there a pattern on this one? It's hard to see in the image.\n",
      "Token IDs: tensor([ 101, 2003, 2045, 1037, 5418, 2006, 2023, 2028, 1029, 2009, 1005, 1055,\n",
      "        2524, 2000, 2156, 1999, 1996, 3746, 1012,  102,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "\n",
    "#dobbiamo convertire le nostre lables da string a valori numerici, usiamo il metodo fornito da sklearn\n",
    "\n",
    "#TRAINING DATASET\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "action_labels_encoded_tr = le.fit_transform(action_labels_tr)\n",
    "\n",
    "input_ids_tr = []\n",
    "attention_masks_tr = []\n",
    "print(f\"{len(df_training)} records to encode.\")\n",
    "# For every sentence...\n",
    "for i in range(0,len(df_training)):\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "\n",
    "  if (previous_transcript_tr[i] != \"\" and use_next):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        previous_transcript_tr[i]+ \" \" + previous_system_transcript_tr[i],  # Sentence to encode.\n",
    "                        transcripts_tr[i], #next sentece to encode\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        truncation = True,\n",
    "                        max_length = max_len,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                    )\n",
    "  else:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        transcripts_tr[i],  # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        truncation = True,\n",
    "                        max_length = max_len,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                    )\n",
    "    \n",
    "\n",
    "    \n",
    "  # Add the encoded sentence to the list.    \n",
    "  input_ids_tr.append(encoded_dict['input_ids'])\n",
    "\n",
    "  # And its attention mask (simply differentiates padding from non-padding).\n",
    "  attention_masks_tr.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids_tr = torch.cat(input_ids_tr, dim=0)\n",
    "attention_masks_tr = torch.cat(attention_masks_tr, dim=0)\n",
    "labels_actions_tr = torch.tensor(action_labels_encoded_tr)\n",
    "labels_attributes_tr = torch.tensor(attributes_labels_tr_vect) \n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print (\"TRAINING : \")\n",
    "if (use_next):\n",
    "  print('Original: ', transcripts_tr[0])\n",
    "else:\n",
    "  print('Original: ', transcripts_tr[0])\n",
    "print('Token IDs:', input_ids_tr[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cda4541",
   "metadata": {},
   "source": [
    "### Tokenize Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5da13a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3513 records to encode.\n",
      "VALIDATION : \n",
      "Original:  What's the price of this sweater compared to the other blue and gray one I looked at?\n",
      "Token IDs: tensor([  101,  2054,  1005,  1055,  1996,  3976,  1997,  2023, 14329,  4102,\n",
      "         2000,  1996,  2060,  2630,  1998,  3897,  2028,  1045,  2246,  2012,\n",
      "         1029,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0])\n",
      "Dialog IDs: tensor([4146, 4146, 4146, 4146, 4146, 4146, 4146, 4260, 4260, 4260, 4260, 8022,\n",
      "        8022, 8022, 8022, 8022, 8022, 4992, 4992, 4992])\n",
      "Turn IDXs: tensor([0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 0, 1, 2, 3, 4, 5, 0, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "\n",
    "#dobbiamo convertire le nostre lables da string a valori numerici, usiamo il metodo fornito da sklearn\n",
    "\n",
    "#VALIDATION DATASET\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "action_labels_encoded_vd = le.fit_transform(action_labels_vd)\n",
    "\n",
    "input_ids_vd = []\n",
    "attention_masks_vd = []\n",
    "print(f\"{len(df_validation)} records to encode.\")\n",
    "# For every sentence...\n",
    "for i in range(0,len(df_validation)):\n",
    "  # `encode_plus` will:\n",
    "  #   (1) Tokenize the sentence.\n",
    "  #   (2) Prepend the `[CLS]` token to the start.\n",
    "  #   (3) Append the `[SEP]` token to the end.\n",
    "  #   (4) Map tokens to their IDs.\n",
    "  #   (5) Pad or truncate the sentence to `max_length`\n",
    "  #   (6) Create attention masks for [PAD] tokens.\n",
    "\n",
    "  if (previous_transcript_vd[i] != \"\" and use_next):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        previous_transcript_vd[i]+ \" \" + previous_system_transcript_vd[i],  # Sentence to encode.\n",
    "                        transcripts_vd[i], #next sentece to encode\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        truncation = True,\n",
    "                        max_length = max_len,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                    )\n",
    "  else:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        transcripts_vd[i],  # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        truncation = True,\n",
    "                        max_length = max_len,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                    )\n",
    "    \n",
    "  # Add the encoded sentence to the list.    \n",
    "  input_ids_vd.append(encoded_dict['input_ids'])\n",
    "  \n",
    "  # And its attention mask (simply differentiates padding from non-padding).\n",
    "  attention_masks_vd.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids_vd = torch.cat(input_ids_vd, dim=0)\n",
    "attention_masks_vd = torch.cat(attention_masks_vd, dim=0)\n",
    "labels_actions_vd = torch.tensor(action_labels_encoded_vd)\n",
    "labels_attributes_vd = torch.tensor(attributes_labels_vd_vect)\n",
    "# Check warning:\n",
    "# /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
    "dialog_ids_vd = torch.tensor(dialog_ids_vd)\n",
    "turn_idxs_vd = torch.tensor(turn_idxs_vd) \n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print (\"VALIDATION : \")\n",
    "if (use_next):\n",
    "  print('Original: ', transcripts_vd[0])\n",
    "else:\n",
    "  print('Original: ', transcripts_vd[0])\n",
    "print('Token IDs:', input_ids_vd[0])\n",
    "print(f\"Dialog IDs: {dialog_ids_vd[0:20]}\")\n",
    "print(f\"Turn IDXs: {turn_idxs_vd[0:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d364715",
   "metadata": {},
   "source": [
    "### Tokenize Evaluation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23888911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5397 records to encode.\n",
      "Evaluation : \n",
      "Original:  That looks a little too light for what I need, do you have something else with a high customer rating?\n",
      "Token IDs: tensor([ 101, 2008, 3504, 1037, 2210, 2205, 2422, 2005, 2054, 1045, 2342, 1010,\n",
      "        2079, 2017, 2031, 2242, 2842, 2007, 1037, 2152, 8013, 5790, 1029,  102,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0])\n",
      "Dialog IDs: tensor([2494, 2494, 2494, 2494, 2494, 3731, 3731, 3731, 3731, 3731, 8546, 8546,\n",
      "        8546, 8546, 8546, 8546, 5590, 5590, 5590, 5590])\n",
      "Turn IDXs: tensor([0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "\n",
    "#dobbiamo convertire le nostre lables da string a valori numerici, usiamo il metodo fornito da sklearn\n",
    "\n",
    "#EVALUATION DATASET\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "action_labels_encoded_tst = le.fit_transform(action_labels_tst)\n",
    "\n",
    "input_ids_tst = []\n",
    "attention_masks_tst = []\n",
    "print(f\"{len(df_test)} records to encode.\")\n",
    "# For every sentence...\n",
    "for i in range(0,len(df_test)):\n",
    "# for t in transcripts_tst:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "  \n",
    "  #Aggiungere \"and False\" PER UTILIZZARE sempre la tokenizzazione senza concatenazione\n",
    "  if (previous_transcript_tst[i] != \"\" and use_next):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                      previous_transcript_tst[i]+ \" \" + previous_system_transcript_tst[i],  # Sentence to encode.\n",
    "                      transcripts_tst[i], #next sentece to encode\n",
    "                      add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                      truncation = True,\n",
    "                      max_length = max_len,           # Pad & truncate all sentences.\n",
    "                      pad_to_max_length = True,\n",
    "                      return_attention_mask = True,   # Construct attn. masks.\n",
    "                      return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                  )\n",
    "  else:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                      transcripts_tst[i],  # Sentence to encode.\n",
    "                      add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                      truncation = True,\n",
    "                      max_length = max_len,           # Pad & truncate all sentences.\n",
    "                      pad_to_max_length = True,\n",
    "                      return_attention_mask = True,   # Construct attn. masks.\n",
    "                      return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                  )\n",
    "    \n",
    "  # Add the encoded sentence to the list.    \n",
    "  input_ids_tst.append(encoded_dict['input_ids'])\n",
    "  \n",
    "  # And its attention mask (simply differentiates padding from non-padding).\n",
    "  attention_masks_tst.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids_tst = torch.cat(input_ids_tst, dim=0)\n",
    "attention_masks_tst = torch.cat(attention_masks_tst, dim=0)\n",
    "labels_actions_tst = torch.tensor(action_labels_encoded_tst)\n",
    "labels_attributes_tst = torch.tensor(attributes_labels_tst_vect)\n",
    "# Check warning:\n",
    "# /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
    "dialog_ids_tst = torch.tensor(dialog_ids_tst)\n",
    "turn_idxs_tst = torch.tensor(turn_idxs_tst) \n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print (\"Evaluation : \")\n",
    "if (use_next):\n",
    "  print('Original: ', transcripts_tst[0])\n",
    "else:\n",
    "  print('Original: ', transcripts_tst[0])\n",
    "print('Token IDs:', input_ids_tst[0])\n",
    "print(f\"Dialog IDs: {dialog_ids_tst[0:20]}\")\n",
    "print(f\"Turn IDXs: {turn_idxs_tst[0:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af23bb7",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96157e27",
   "metadata": {},
   "source": [
    "# Data Split - AP4CA\n",
    "La nostra versione di split di dati per training e validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "680bdf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21,196 training samples\n",
      "3,513 validation samples\n",
      "5,397 evaluation samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "#labels_tr = {'actions': labels_actions_tr, 'attributes': labels_attributes_tr}\n",
    "#labels_vd = {'actions': labels_actions_vd, 'attributes': labels_attributes_vd}\n",
    "\n",
    "train_dataset = TensorDataset(input_ids_tr, attention_masks_tr, labels_actions_tr, labels_attributes_tr)\n",
    "val_dataset = TensorDataset(input_ids_vd, attention_masks_vd, labels_actions_vd, labels_attributes_vd, dialog_ids_vd, turn_idxs_vd)\n",
    "tst_dataset = TensorDataset(input_ids_tst, attention_masks_tst, labels_actions_tst, labels_attributes_tst, dialog_ids_tst, turn_idxs_tst)\n",
    "\n",
    "print('{:>5,} training samples'.format(len(train_dataset)))\n",
    "print('{:>5,} validation samples'.format(len(val_dataset)))\n",
    "print('{:>5,} evaluation samples'.format(len(tst_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed1196fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 101, 2008, 3504,  ...,    0,    0,    0],\n",
       "         [ 101, 2008, 3504,  ...,    0,    0,    0],\n",
       "         [ 101, 2040, 5617,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [ 101, 2821, 1045,  ...,    0,    0,    0],\n",
       "         [ 101, 4086, 1010,  ...,    0,    0,    0],\n",
       "         [ 101, 1045, 2066,  ...,    0,    0,    0]]),\n",
       " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " tensor([2, 4, 4, 0, 1, 2, 1, 2, 0, 1]),\n",
       " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " tensor([2494, 2494, 2494, 2494, 2494, 3731, 3731, 3731, 3731, 3731]),\n",
       " tensor([0, 1, 2, 3, 4, 0, 1, 2, 3, 4]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check evaluation TensorDataset content\n",
    "tst_dataset[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d01df19",
   "metadata": {},
   "source": [
    "## Check GPU for Training\n",
    "\n",
    "In questa versione la GPU è impostata fissa.\n",
    "Con una GPU in più a disposizione possiamo usare DataParallel e aumentare il batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31bf32c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2060\n"
     ]
    }
   ],
   "source": [
    "# Tell PyTorch to use the GPU.    \n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "print('We will use the GPU:', torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2045d72f",
   "metadata": {},
   "source": [
    "### Creazione Data Loaders per Training, Validation ed Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d9f42ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "# With size 32 GeForce RTX 2060 with 6GB run out of memory\n",
    "batch_size = exec_params['batch']\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )\n",
    "\n",
    "#ho controllato nel colab su cui ci basiamo, anche lui usa un Sequential Sampler per il dataset di evaluation\n",
    "evaluation_dataloader = DataLoader(\n",
    "            tst_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(tst_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040d27c5",
   "metadata": {},
   "source": [
    "## Train BERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc8111f",
   "metadata": {},
   "source": [
    "For this task, we first want to modify the pre-trained BERT model to give outputs for classification, and then we want to continue training the model on our dataset until that the entire model, end-to-end, is well-suited for our task. \n",
    "\n",
    "Thankfully, the huggingface pytorch implementation includes a set of interfaces designed for a variety of NLP tasks. Though these interfaces are all built on top of a trained BERT model, each has different top layers and output types designed to accomodate their specific NLP task.  \n",
    "\n",
    "Here is the current list of classes provided for fine-tuning:\n",
    "* BertModel\n",
    "* BertForPreTraining\n",
    "* BertForMaskedLM\n",
    "* BertForNextSentencePrediction\n",
    "* **BertForSequenceClassification** - The one we'll use.\n",
    "* BertForTokenClassification\n",
    "* BertForQuestionAnswering\n",
    "\n",
    "The documentation for these can be found under [here](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbd23ca",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We'll be using [BertForSequenceClassification](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#bertforsequenceclassification). This is the normal BERT model with an added single linear layer on top for classification that we will use as a sentence classifier. As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task. \n",
    "\n",
    "NB anche nell'articolo che sto leggendo sulla classificazione multi-label si parte da questo modello\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba0360b",
   "metadata": {},
   "source": [
    "OK, let's load BERT! There are a few different pre-trained BERT models available. \"bert-base-uncased\" means the version that has only lowercase letters (\"uncased\") and is the smaller version of the two (\"base\" vs \"large\").\n",
    "\n",
    "The documentation for `from_pretrained` can be found [here](https://huggingface.co/transformers/v2.2.0/main_classes/model.html#transformers.PreTrainedModel.from_pretrained), with the additional parameters defined [here](https://huggingface.co/transformers/v2.2.0/main_classes/configuration.html#transformers.PretrainedConfig)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "242aa137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DA SISTEMARE\n",
    "from transformers import BertModel\n",
    "from  torch import  nn\n",
    "\n",
    "class CustomBERTModel(nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "\n",
    "    super(CustomBERTModel, self).__init__()\n",
    "    self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "    ### New layers:\n",
    "    self.linear_intermedio = nn.Linear(768, exec_params['hidden_output_dim'])\n",
    "    #provare ad aggiungere ulteriori layer intermedi per ridurre le dimensioni fino ad arrivare all'output richiesto\n",
    "    self.linear_actions = nn.Linear(exec_params['hidden_output_dim'], 5) \n",
    "    self.linear_attributes = nn.Linear(exec_params['hidden_output_dim'], len(mlb.classes_)) #num attributi? \n",
    "\n",
    "  def forward(self, ids, mask):\n",
    "    #controllare che l'output non rappresenti solo lo stato interno dovuto al token CLS\n",
    "    output = self.bert(ids,attention_mask=mask)\n",
    "    # print(f\"Type output{type(output)}\")\n",
    "    # for p in output:\n",
    "    #   print(p)\n",
    "    #   print(type(output[p]))\n",
    "    #   print(output[p])\n",
    "\n",
    "    #prendiamo il campo last_hidden_state dall'oggetto output; last hidden state rappresenta il tensore\n",
    "    #in uscita dallo step di forward del BertModel\n",
    "    last_hidden_state_output = output[\"last_hidden_state\"]\n",
    "    # last_hidden_state has the following shape: (batch_size, sequence_length, 768)\n",
    "    #stiamo passando solo il token CLS ai layer successivi\n",
    "    linear_output_intermedio = self.linear_intermedio(last_hidden_state_output[:,0,:].view(-1,768)) \n",
    "    # linear_output_intermedio = self.linear_intermedio(pooled_output) \n",
    "    \n",
    "    linear_output_actions = self.linear_actions(linear_output_intermedio)\n",
    "    # linear_output_actions = self.sftmx(linear_output_actions)\n",
    "    # linear_output_actions = nn.functional.softmax(linear_output_actions)\n",
    "    # Test sigmoid for increasing perplexity performance\n",
    "    # linear_output_actions = torch.sigmoid(linear_output_actions)\n",
    "    linear_output_actions = nn.functional.relu(linear_output_actions)\n",
    "    linear_output_actions = nn.functional.softmax(linear_output_actions, dim=1)\n",
    "    linear_output_attributes = self.linear_attributes(linear_output_intermedio)\n",
    "    # linear_output_attributes = self.sig(linear_output_attributes)\n",
    "    linear_output_attributes = torch.sigmoid(linear_output_attributes)\n",
    "\n",
    "    return {'actions': linear_output_actions, 'attributes': linear_output_attributes}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ceefd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomBERTModel(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (linear_intermedio): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (linear_actions): Linear(in_features=256, out_features=5, bias=True)\n",
       "  (linear_attributes): Linear(in_features=256, out_features=33, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test istanziazione del custom model\n",
    "model = CustomBERTModel()\n",
    "\n",
    "# model.bert.config\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cb0c4c",
   "metadata": {},
   "source": [
    "Just for curiosity's sake, we can browse all of the model's parameters by name here.\n",
    "\n",
    "In the below cell, I've printed out the names and dimensions of the weights for:\n",
    "\n",
    "1. The embedding layer.\n",
    "2. The first of the twelve transformers.\n",
    "3. The output layer.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c48662a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 205 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "linear_actions.weight                                       (5, 256)\n",
      "linear_actions.bias                                             (5,)\n",
      "linear_attributes.weight                                   (33, 256)\n",
      "linear_attributes.bias                                         (33,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655b5929",
   "metadata": {},
   "source": [
    "## 4.2. Optimizer & Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2ee817",
   "metadata": {},
   "source": [
    "Now that we have our model loaded we need to grab the training hyperparameters from within the stored model.\n",
    "\n",
    "For the purposes of fine-tuning, the authors recommend choosing from the following values (from Appendix A.3 of the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf)):\n",
    "\n",
    ">- **Batch size:** 16, 32  \n",
    "- **Learning rate (Adam):** 5e-5, 3e-5, 2e-5  \n",
    "- **Number of epochs:** 2, 3, 4 \n",
    "\n",
    "We chose:\n",
    "* Batch size: 32 (set when creating our DataLoaders)\n",
    "* Learning rate: 2e-5\n",
    "* Epochs: 4 (we'll see that this is probably too many...)\n",
    "\n",
    "The epsilon parameter `eps = 1e-8` is \"a very small number to prevent any division by zero in the implementation\" (from [here](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)).\n",
    "\n",
    "You can find the creation of the AdamW optimizer in `run_glue.py` [here](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "295fde1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = exec_params['learning_rate'], # args.learning_rate - default is 5e-5\n",
    "                  eps = exec_params['tolerance'] # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4faef5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = exec_params['epochs']\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eccdf3c",
   "metadata": {},
   "source": [
    "## 4.3. Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1141dfa",
   "metadata": {},
   "source": [
    "Below is our training loop. There's a lot going on, but fundamentally for each pass in our loop we have a trianing phase and a validation phase. \n",
    "\n",
    "> *Thank you to [Stas Bekman](https://ca.linkedin.com/in/stasbekman) for contributing the insights and code for using validation loss to detect over-fitting!*\n",
    "\n",
    "**Training:**\n",
    "- Unpack our data inputs and labels\n",
    "- Load data onto the GPU for acceleration\n",
    "- Clear out the gradients calculated in the previous pass. \n",
    "    - In pytorch the gradients accumulate by default (useful for things like RNNs) unless you explicitly clear them out.\n",
    "- Forward pass (feed input data through the network)\n",
    "- Backward pass (backpropagation)\n",
    "- Tell the network to update parameters with optimizer.step()\n",
    "- Track variables for monitoring progress\n",
    "\n",
    "**Evalution:**\n",
    "- Unpack our data inputs and labels\n",
    "- Load data onto the GPU for acceleration\n",
    "- Forward pass (feed input data through the network)\n",
    "- Compute loss on our validation data and track variables for monitoring progress\n",
    "\n",
    "Pytorch hides all of the detailed calculations from us, but we've commented the code to point out which of the above steps are happening on each line. \n",
    "\n",
    "> *PyTorch also has some [beginner tutorials](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py) which you may also find helpful.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d699904",
   "metadata": {},
   "source": [
    "Define a helper function for calculating accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df633469",
   "metadata": {},
   "source": [
    "### Flat accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef1a2d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy_actions(preds, labels):\n",
    "    #print(f\"[FA] preds: {preds} / labels: {labels}\")\n",
    "    #print(f\"[FA-Actions] {type(preds)} {type(labels)}\")\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()   \n",
    "    return {'matched': np.sum(pred_flat == labels_flat), 'counts': len(labels_flat)}\n",
    "\n",
    "def flat_accuracy_attributes(preds, labels):\n",
    "  #print(f\"[FA-Attributess] {type(preds)} {type(labels)}\")\n",
    "  tot_preds = preds.shape[0]\n",
    "  preds_int = np.rint(preds)\n",
    "  tot_eq = 0\n",
    "  for i in range(tot_preds):\n",
    "    comparison = preds_int[i] == labels[i]\n",
    "    if comparison.all():\n",
    "      tot_eq += 1\n",
    "  return {'matched': tot_eq, 'counts' : tot_preds}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc1a792",
   "metadata": {},
   "source": [
    "Helper function for formatting elapsed times as `hh:mm:ss`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "903c3769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdd0590",
   "metadata": {},
   "source": [
    "### Loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0629812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "# Loss function definition\n",
    "def MyBERT_loss(logits, actions_labels, attributes_labels):\n",
    "  actions_logits = logits['actions']\n",
    "  attributes_logits = logits['attributes']\n",
    "  loss_actions_fn = nn.CrossEntropyLoss()\n",
    "  loss_attributes_fn = nn.BCELoss()\n",
    "  loss_actions = loss_actions_fn(actions_logits, actions_labels)\n",
    "  loss_attributes = loss_attributes_fn(attributes_logits, attributes_labels.float())\n",
    "  return loss_actions + loss_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fea679",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We're ready to kick off the training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aab27b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 10 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  8% | 33% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  8% | 33% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:53.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 90% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:48.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:43.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:38.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "End of epoch 0\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "\n",
      "  Average training loss: 1.16\n",
      "  Training epcoh took: 0:08:25\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8412\n",
      "  Accuracy for multilabel-classification (attributes): 0.9058\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8411614005123825, 'action_perplexity': 3.6962720848942707, 'attribute_accuracy': 0.7190469171112925, 'confusion_matrix': array([[4.540e+02, 5.000e+01, 1.200e+01, 0.000e+00, 1.100e+01],\n",
      "       [2.900e+01, 6.680e+02, 3.600e+01, 9.000e+00, 2.300e+01],\n",
      "       [8.000e+00, 1.450e+02, 5.000e+02, 3.900e+01, 8.000e+00],\n",
      "       [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
      "       [1.000e+00, 4.500e+01, 7.600e+01, 6.600e+01, 1.333e+03]])}\n",
      "  Validation Loss: 1.0773\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "======== Epoch 2 / 10 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:55.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 90% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:49.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 90% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:44.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 90% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:39.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 90% |\n",
      "End of epoch 1\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 90% |\n",
      "\n",
      "  Average training loss: 1.08\n",
      "  Training epcoh took: 0:08:27\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8340\n",
      "  Accuracy for multilabel-classification (attributes): 0.9132\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.834044975804156, 'action_perplexity': 5.344686429733567, 'attribute_accuracy': 0.7190411642837331, 'confusion_matrix': array([[ 441.,   25.,    5.,    0.,    6.],\n",
      "       [  33.,  705.,   82.,   10.,   30.],\n",
      "       [  11.,  134.,  457.,   47.,   12.],\n",
      "       [   0.,    0.,    0.,    0.,    0.],\n",
      "       [   7.,   44.,   80.,   57., 1327.]])}\n",
      "  Validation Loss: 1.0814\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "======== Epoch 3 / 10 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 98% | 90% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 84% | 90% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:55.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 90% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:49.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 90% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:44.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 90% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:38.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 90% |\n",
      "End of epoch 2\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 93% |\n",
      "\n",
      "  Average training loss: 1.07\n",
      "  Training epcoh took: 0:08:27\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8491\n",
      "  Accuracy for multilabel-classification (attributes): 0.9317\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8491317961855963, 'action_perplexity': 5.165759677798513, 'attribute_accuracy': 0.7814521906338908, 'confusion_matrix': array([[ 444.,   33.,    2.,    0.,    5.],\n",
      "       [  28.,  682.,   27.,    6.,   20.],\n",
      "       [  18.,  150.,  543.,   61.,   36.],\n",
      "       [   0.,    0.,    0.,    0.,    0.],\n",
      "       [   2.,   43.,   52.,   47., 1314.]])}\n",
      "  Validation Loss: 1.0649\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "======== Epoch 4 / 10 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 92% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 77% | 92% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:54.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 92% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:51.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 92% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:48.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 94% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:44.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 93% |\n",
      "End of epoch 3\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 94% |\n",
      "\n",
      "  Average training loss: 1.07\n",
      "  Training epcoh took: 0:08:33\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8352\n",
      "  Accuracy for multilabel-classification (attributes): 0.9357\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8351836037574722, 'action_perplexity': 5.774489173153557, 'attribute_accuracy': 0.7537773878800815, 'confusion_matrix': array([[ 450.,   31.,   10.,    0.,    4.],\n",
      "       [  31.,  716.,   99.,   15.,   30.],\n",
      "       [   7.,  121.,  434.,   36.,    7.],\n",
      "       [   0.,    0.,    0.,    0.,    0.],\n",
      "       [   4.,   40.,   81.,   63., 1334.]])}\n",
      "  Validation Loss: 1.0777\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "======== Epoch 5 / 10 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 88% | 93% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 88% | 93% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:55.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 93% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:49.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 94% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:44.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:39.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "End of epoch 4\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 91% |\n",
      "\n",
      "  Average training loss: 1.06\n",
      "  Training epcoh took: 0:08:26\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8508\n",
      "  Accuracy for multilabel-classification (attributes): 0.9425\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8508397381155708, 'action_perplexity': 5.612034105568062, 'attribute_accuracy': 0.8014003475247936, 'confusion_matrix': array([[ 458.,   40.,    3.,    0.,    5.],\n",
      "       [  12.,  670.,   20.,    4.,   12.],\n",
      "       [  12.,  146.,  519.,   45.,   16.],\n",
      "       [   0.,    0.,    0.,    0.,    0.],\n",
      "       [  10.,   52.,   82.,   65., 1342.]])}\n",
      "  Validation Loss: 1.0618\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "======== Epoch 6 / 10 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 90% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 90% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:55.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 92% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:49.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 92% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:43.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 92% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:38.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 92% |\n",
      "End of epoch 5\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 92% |\n",
      "\n",
      "  Average training loss: 1.05\n",
      "  Training epcoh took: 0:08:25\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8540\n",
      "  Accuracy for multilabel-classification (attributes): 0.9459\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8539709649871904, 'action_perplexity': 5.695361306369015, 'attribute_accuracy': 0.8047755161994964, 'confusion_matrix': array([[ 453.,   32.,    2.,    0.,    4.],\n",
      "       [  16.,  693.,   30.,    9.,   25.],\n",
      "       [  13.,  148.,  527.,   52.,   19.],\n",
      "       [   0.,    0.,    0.,    0.,    0.],\n",
      "       [  10.,   35.,   65.,   53., 1327.]])}\n",
      "  Validation Loss: 1.0584\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "======== Epoch 7 / 10 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 92% |\n",
      "GPU after train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 92% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:54.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 92% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:48.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:43.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:37.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "End of epoch 6\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "\n",
      "  Average training loss: 1.04\n",
      "  Training epcoh took: 0:08:25\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8557\n",
      "  Accuracy for multilabel-classification (attributes): 0.9482\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8556789069171649, 'action_perplexity': 5.633652438170332, 'attribute_accuracy': 0.805002135702273, 'confusion_matrix': array([[ 471.,   42.,    4.,    0.,    8.],\n",
      "       [   8.,  682.,   28.,    7.,   21.],\n",
      "       [  11.,  148.,  521.,   49.,   14.],\n",
      "       [   0.,    0.,    0.,    0.,    0.],\n",
      "       [   2.,   36.,   71.,   58., 1332.]])}\n",
      "  Validation Loss: 1.0560\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "======== Epoch 8 / 10 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:54.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:49.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:43.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:37.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "End of epoch 7\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "\n",
      "  Average training loss: 1.04\n",
      "  Training epcoh took: 0:08:25\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8565\n",
      "  Accuracy for multilabel-classification (attributes): 0.9496\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.856532877882152, 'action_perplexity': 5.688460670689874, 'attribute_accuracy': 0.8091956026607439, 'confusion_matrix': array([[4.670e+02, 3.900e+01, 2.000e+00, 0.000e+00, 9.000e+00],\n",
      "       [1.000e+01, 6.790e+02, 2.600e+01, 6.000e+00, 1.300e+01],\n",
      "       [1.400e+01, 1.480e+02, 5.190e+02, 4.500e+01, 9.000e+00],\n",
      "       [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
      "       [1.000e+00, 4.200e+01, 7.700e+01, 6.300e+01, 1.344e+03]])}\n",
      "  Validation Loss: 1.0561\n",
      "  Validation took: 0:00:28\n",
      "\n",
      "======== Epoch 9 / 10 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 98% | 91% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 98% | 91% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:54.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:49.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:43.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:37.\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 91% |\n",
      "End of epoch 8\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epcoh took: 0:08:25\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8574\n",
      "  Accuracy for multilabel-classification (attributes): 0.9525\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8573868488471392, 'action_perplexity': 5.242008798905791, 'attribute_accuracy': 0.8107832821448703, 'confusion_matrix': array([[4.65e+02, 3.80e+01, 1.00e+00, 0.00e+00, 6.00e+00],\n",
      "       [1.10e+01, 6.82e+02, 2.60e+01, 7.00e+00, 1.80e+01],\n",
      "       [1.40e+01, 1.49e+02, 5.35e+02, 5.60e+01, 2.10e+01],\n",
      "       [0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00],\n",
      "       [2.00e+00, 3.90e+01, 6.20e+01, 5.10e+01, 1.33e+03]])}\n",
      "  Validation Loss: 1.0549\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "======== Epoch 10 / 10 ========\n",
      "Training...\n",
      "GPU before train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 98% | 91% |\n",
      "GPU after train\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 78% | 91% |\n",
      "  Batch   400  of  1,767.    Elapsed: 0:01:54.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch   800  of  1,767.    Elapsed: 0:03:49.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 90% |\n",
      "  Batch 1,200  of  1,767.    Elapsed: 0:05:43.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "  Batch 1,600  of  1,767.    Elapsed: 0:07:37.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "End of epoch 9\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 99% | 91% |\n",
      "\n",
      "  Average training loss: 1.02\n",
      "  Training epcoh took: 0:08:25\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy for classification (actions): 0.8557\n",
      "  Accuracy for multilabel-classification (attributes): 0.9508\n",
      "#Instances evaluated API: 3513\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8556789069171649, 'action_perplexity': 4.924593525474257, 'attribute_accuracy': 0.8114303940074165, 'confusion_matrix': array([[4.610e+02, 3.700e+01, 1.000e+00, 0.000e+00, 4.000e+00],\n",
      "       [1.500e+01, 6.800e+02, 2.800e+01, 7.000e+00, 1.500e+01],\n",
      "       [1.300e+01, 1.480e+02, 5.310e+02, 5.700e+01, 2.200e+01],\n",
      "       [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
      "       [3.000e+00, 4.300e+01, 6.400e+01, 5.000e+01, 1.334e+03]])}\n",
      "  Validation Loss: 1.0561\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "Training complete!\n",
      "Total training took 1:28:51 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import action_evaluation as evaluation\n",
    "import json\n",
    "from  GPUtil import showUtilization as gpu_usage\n",
    "with open('./extr_output/fashion_dev_dials_api_calls.json') as f:\n",
    "  dev_dials = json.load(f)\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = exec_params['seed']\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "#torch.manual_seed(seed_val)  must be done before RandomSampler instantiation\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "test_batch = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    print(\"GPU before train\")\n",
    "    gpu_usage()\n",
    "\n",
    "    model.train()\n",
    "    print(\"GPU after train\")\n",
    "    gpu_usage()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 400 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "            gpu_usage()\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: actions labels \n",
    "        #   [3]: attributes labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels_actions = batch[2].to(device)\n",
    "        b_labels_attributes = batch[3].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
    "        # function and pass down the arguments. The `forward` function is \n",
    "        # documented here: \n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
    "        # The results are returned in a results object, documented here:\n",
    "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
    "        # Specifically, we'll get the loss (because we provided labels) and the\n",
    "        # \"logits\"--the model outputs prior to activation.\n",
    "        result = model(b_input_ids, \n",
    "                       mask=b_input_mask)\n",
    "        \n",
    "        loss = MyBERT_loss(result, b_labels_actions, b_labels_attributes)\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.from transformers import BertModel, BertConfig\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    print(f\"End of epoch {epoch_i}\")\n",
    "    gpu_usage()\n",
    "    \n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.mlb.inverse_transform(attr_yt[3].reshape(1, -1))\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy_classification = { 'matched': 0, 'counts': 0}\n",
    "    total_eval_accuracy_multilabel = { 'matched': 0, 'counts': 0}\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    batch_number = 0\n",
    "\n",
    "    # Dictionary for action_evaluation\n",
    "    model_actions = {}\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        batch_number += 1\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels_actions = batch[2].to(device)\n",
    "        b_labels_attributes = batch[3].to(device)\n",
    "        b_dialog_ids = batch[4].to(device).detach().cpu().numpy()\n",
    "        b_turn_idxs = batch[5].to(device).detach().cpu().numpy()\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            result = model(b_input_ids, \n",
    "                       mask=b_input_mask)\n",
    "\n",
    "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
    "        # output values prior to applying an activation function like the \n",
    "        # softmax.\n",
    "        loss = MyBERT_loss(result, b_labels_actions, b_labels_attributes)\n",
    "            \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        # logits = logits.detach().cpu().numpy()\n",
    "        # label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        \n",
    "        actions_logits_foracc=result['actions'].detach().cpu().numpy()\n",
    "        attributes_logits_foracc=result['attributes'].detach().cpu().numpy()\n",
    "        actions_labels_foracc= b_labels_actions.to('cpu').numpy()\n",
    "        attributes_labels_foracc =b_labels_attributes.to('cpu').numpy()\n",
    "\n",
    "        #TODO: definire la nostra funzione di accuracy\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        accuracy_classification = flat_accuracy_actions(actions_logits_foracc, actions_labels_foracc)\n",
    "        accuracy_multilabel = flat_accuracy_attributes(attributes_logits_foracc, attributes_labels_foracc)\n",
    "        \n",
    "        total_eval_accuracy_classification['matched'] += accuracy_classification['matched']\n",
    "        total_eval_accuracy_classification['counts'] += accuracy_classification['counts']\n",
    "        total_eval_accuracy_multilabel['matched'] += accuracy_multilabel['matched']\n",
    "        total_eval_accuracy_multilabel['counts'] += accuracy_multilabel['counts']\n",
    "        # Salvo dati elaborazione batch per debug/analisi\n",
    "        test_batch.append({\n",
    "            'epoch' : epoch_i + 1,\n",
    "            'batchnum' : batch_number,\n",
    "            'actions_logits' : actions_logits_foracc,\n",
    "            'actions_labels' : actions_labels_foracc,\n",
    "            'attributes_logits' : attributes_logits_foracc,\n",
    "            'attributes_labels' : attributes_labels_foracc,\n",
    "            'accuracy_classification' : accuracy_classification,\n",
    "            'accuracy_multilabel' : accuracy_multilabel,\n",
    "        })\n",
    "\n",
    "        # Fill dictionary for action_evaluation\n",
    "        for el_i in range(len(actions_logits_foracc)):\n",
    "          dialog_id = b_dialog_ids[el_i]\n",
    "          action_log_prob = {}\n",
    "          for act_i in range(len(actions_logits_foracc[el_i])):\n",
    "            #todo: controllare che la probabilità predetta sia in scala logaritmica (?? potrebbe essere fonte di errori)\n",
    "            action_log_prob[le.classes_[act_i]] = np.log(actions_logits_foracc[el_i][act_i])\n",
    "          #attributes = {}\n",
    "          attributes = []\n",
    "          #attributes_list = np.rint(attributes_logits_foracc[el_i])\n",
    "          attributes_list = np.array(attributes_logits_foracc[el_i])\n",
    "          for attr in range(len(attributes_list)):\n",
    "            attribute = mlb.classes_[attr]\n",
    "            #attributes[mlb.classes_[attr]] = attributes_list[attr]\n",
    "            if attributes_list[attr] >= 0.5:\n",
    "              attributes.append(attribute)\n",
    "          prediction = {\n",
    "              'action': le.classes_[np.argmax(actions_logits_foracc[el_i])],\n",
    "              'action_log_prob': action_log_prob,\n",
    "              'attributes': {'attributes': attributes},\n",
    "              'turn_id': b_turn_idxs[el_i]\n",
    "          }\n",
    "          if dialog_id in model_actions:\n",
    "            model_actions[dialog_id]['predictions'].append(prediction)\n",
    "          else:\n",
    "            predictions = list()\n",
    "            predictions.append(prediction)\n",
    "            model_actions[dialog_id] = {\n",
    "                'dialog_id': dialog_id,\n",
    "                'predictions': predictions\n",
    "            }\n",
    "          \n",
    "\n",
    "    # Report the final accuracy for this validation \n",
    "\n",
    "    #avg_val_accuracy_classification = total_eval_accuracy_classification / len(validation_dataloader)\n",
    "    #avg_val_accuracy_multilabel = total_eval_accuracy_multilabel / len(validation_dataloader)\n",
    "    avg_val_accuracy_classification = total_eval_accuracy_classification['matched'] / total_eval_accuracy_classification['counts']\n",
    "    avg_val_accuracy_multilabel = total_eval_accuracy_multilabel['matched'] / total_eval_accuracy_multilabel['counts']\n",
    "    print(\"  Accuracy for classification (actions): {0:.4f}\".format(avg_val_accuracy_classification))\n",
    "    print(\"  Accuracy for multilabel-classification (attributes): {0:.4f}\".format(avg_val_accuracy_multilabel))\n",
    "\n",
    "    # Reference implementation: evaluation of action prediction along with attributes\n",
    "    metrics = evaluation.evaluate_action_prediction(dev_dials, model_actions.values())\n",
    "    # print(\"model_actions passed to the evaluator:\")\n",
    "    # for v in model_actions.values():\n",
    "    #   print(v)\n",
    "    print(\"***************************************\")\n",
    "    print(\"Reference evaluation metrics:\")\n",
    "    print(metrics)\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.4f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,  \n",
    "            'Valid. Accur. class.': avg_val_accuracy_classification,\n",
    "            'Valid. Accur. mult.label': avg_val_accuracy_multilabel,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time,\n",
    "            'metrics': metrics\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ac0f0f",
   "metadata": {},
   "source": [
    "## Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b6d29e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy for classification (actions): 0.8471\n",
      "  Accuracy for multilabel-classification (attributes): 0.9411\n",
      "#Instances evaluated API: 5397\n",
      "***************************************\n",
      "Reference evaluation metrics:\n",
      "{'action_accuracy': 0.8471372984991662, 'action_perplexity': 5.599259268391769, 'attribute_accuracy': 0.78864057919496, 'confusion_matrix': array([[ 747.,   48.,    9.,    3.,   12.],\n",
      "       [  26., 1043.,   45.,    9.,   47.],\n",
      "       [  13.,  224.,  786.,  112.,   33.],\n",
      "       [   0.,    0.,    0.,    0.,    0.],\n",
      "       [   7.,   71.,  104.,   62., 1996.]])}\n"
     ]
    }
   ],
   "source": [
    "#Prediction on test set\n",
    "#quale modello gli viene passato? da controllare se BERT da solo riesce a tenere traccia del modello che ha dato l'epoca migliore\n",
    "\n",
    "\n",
    "with open('./extr_output/fashion_devtest_dials_api_calls.json') as f:\n",
    "  devtest_dials = json.load(f)\n",
    "\n",
    "# Tracking variables \n",
    "total_eval_accuracy_classification = { 'matched': 0, 'counts': 0}\n",
    "total_eval_accuracy_multilabel = { 'matched': 0, 'counts': 0}\n",
    "\n",
    "model_actions = {}\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "for batch in evaluation_dataloader:\n",
    "\n",
    "    # Unpack this training batch from our dataloader. \n",
    "    #\n",
    "    # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "    # the `to` method.\n",
    "    #\n",
    "    # `batch` contains three pytorch tensors:\n",
    "    #   [0]: input ids \n",
    "    #   [1]: attention masks\n",
    "    #   [2]: labels \n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels_actions = batch[2].to(device)\n",
    "    b_labels_attributes = batch[3].to(device)\n",
    "    b_dialog_ids = batch[4].to(device).detach().cpu().numpy()\n",
    "    b_turn_idxs = batch[5].to(device).detach().cpu().numpy()\n",
    "    \n",
    "    # Tell pytorch not to bother with constructing the compute graph during\n",
    "    # the forward pass, since this is only needed for backprop (training).\n",
    "    with torch.no_grad():        \n",
    "        # Forward pass, calculate logit predictions.\n",
    "        # token_type_ids is the same as the \"segment ids\", which \n",
    "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "        result = model(b_input_ids,mask=b_input_mask)\n",
    "\n",
    "    \n",
    "    actions_logits_foracc=result['actions'].detach().cpu().numpy()\n",
    "    attributes_logits_foracc=result['attributes'].detach().cpu().numpy()\n",
    "    actions_labels_foracc= b_labels_actions.to('cpu').numpy()\n",
    "    attributes_labels_foracc =b_labels_attributes.to('cpu').numpy()\n",
    "\n",
    "    # Calculate the accuracy for this batch of test sentences, and\n",
    "    # accumulate it over all batches.\n",
    "    accuracy_classification = flat_accuracy_actions(actions_logits_foracc, actions_labels_foracc)\n",
    "    accuracy_multilabel = flat_accuracy_attributes(attributes_logits_foracc, attributes_labels_foracc)\n",
    "    \n",
    "    total_eval_accuracy_classification['matched'] += accuracy_classification['matched']\n",
    "    total_eval_accuracy_classification['counts'] += accuracy_classification['counts']\n",
    "    total_eval_accuracy_multilabel['matched'] += accuracy_multilabel['matched']\n",
    "    total_eval_accuracy_multilabel['counts'] += accuracy_multilabel['counts']\n",
    "    \n",
    "\n",
    "    # Fill dictionary for action_evaluation\n",
    "    for el_i in range(len(actions_logits_foracc)):\n",
    "      dialog_id = b_dialog_ids[el_i]\n",
    "      action_log_prob = {}\n",
    "      for act_i in range(len(actions_logits_foracc[el_i])):\n",
    "        #todo: controllare che la probabilità predetta sia in scala logaritmica (?? potrebbe essere fonte di errori)\n",
    "        action_log_prob[le.classes_[act_i]] = np.log(actions_logits_foracc[el_i][act_i])\n",
    "      #attributes = {}\n",
    "      attributes = []\n",
    "      #attributes_list = np.rint(attributes_logits_foracc[el_i])\n",
    "      attributes_list = np.array(attributes_logits_foracc[el_i])\n",
    "      for attr in range(len(attributes_list)):\n",
    "        attribute = mlb.classes_[attr]\n",
    "        #attributes[mlb.classes_[attr]] = attributes_list[attr]\n",
    "        if attributes_list[attr] >= 0.5:\n",
    "          attributes.append(attribute)\n",
    "      prediction = {\n",
    "          'action': le.classes_[np.argmax(actions_logits_foracc[el_i])],\n",
    "          'action_log_prob': action_log_prob,\n",
    "          'attributes': {'attributes': attributes},\n",
    "          'turn_id': b_turn_idxs[el_i]\n",
    "      }\n",
    "      if dialog_id in model_actions:\n",
    "        model_actions[dialog_id]['predictions'].append(prediction)\n",
    "      else:\n",
    "        predictions = list()\n",
    "        predictions.append(prediction)\n",
    "        model_actions[dialog_id] = {\n",
    "            'dialog_id': dialog_id,\n",
    "            'predictions': predictions\n",
    "        }\n",
    "      \n",
    "\n",
    "# Report the final accuracy for this validation \n",
    "\n",
    "#avg_val_accuracy_classification = total_eval_accuracy_classification / len(validation_dataloader)\n",
    "#avg_val_accuracy_multilabel = total_eval_accuracy_multilabel / len(validation_dataloader)\n",
    "avg_val_accuracy_classification = total_eval_accuracy_classification['matched'] / total_eval_accuracy_classification['counts']\n",
    "avg_val_accuracy_multilabel = total_eval_accuracy_multilabel['matched'] / total_eval_accuracy_multilabel['counts']\n",
    "print(\"  Accuracy for classification (actions): {0:.4f}\".format(avg_val_accuracy_classification))\n",
    "print(\"  Accuracy for multilabel-classification (attributes): {0:.4f}\".format(avg_val_accuracy_multilabel))\n",
    "\n",
    "# Reference implementation: evaluation of action prediction along with attributes\n",
    "metrics = evaluation.evaluate_action_prediction(devtest_dials, model_actions.values())\n",
    "# print(\"model_actions passed to the evaluator:\")\n",
    "# for v in model_actions.values():\n",
    "#   print(v)\n",
    "print(\"***************************************\")\n",
    "print(\"Reference evaluation metrics:\")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a059e49",
   "metadata": {},
   "source": [
    "# OTHER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ca179f",
   "metadata": {},
   "source": [
    "Let's view the summary of the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "03bdf5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "401e879c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>batchnum</th>\n",
       "      <th>actions_logits</th>\n",
       "      <th>actions_labels</th>\n",
       "      <th>attributes_logits</th>\n",
       "      <th>attributes_labels</th>\n",
       "      <th>accuracy_classification</th>\n",
       "      <th>accuracy_multilabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[[4.995138e-05, 0.99980026, 4.995138e-05, 4.99...</td>\n",
       "      <td>[1, 4, 2, 4, 0, 1, 1, 4, 4, 0, 1, 2]</td>\n",
       "      <td>[[0.0020820214, 0.0036640947, 0.0055418806, 0....</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>{'matched': 12, 'counts': 12}</td>\n",
       "      <td>{'matched': 11, 'counts': 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[[2.8056607e-05, 0.9999205, 2.7110715e-05, 1.2...</td>\n",
       "      <td>[1, 4, 2, 2, 0, 1, 2, 1, 1, 1, 1, 4]</td>\n",
       "      <td>[[0.0001478568, 0.00028644415, 0.0019145217, 0...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>{'matched': 10, 'counts': 12}</td>\n",
       "      <td>{'matched': 11, 'counts': 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[[1.9743271e-05, 0.0001572934, 3.824866e-05, 1...</td>\n",
       "      <td>[4, 1, 1, 1, 4, 2, 1, 2, 0, 1, 1, 1]</td>\n",
       "      <td>[[8.696537e-05, 7.193404e-05, 0.8102605, 0.000...</td>\n",
       "      <td>[[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>{'matched': 9, 'counts': 12}</td>\n",
       "      <td>{'matched': 11, 'counts': 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[[0.9997187, 0.00013980923, 4.2770298e-05, 4.1...</td>\n",
       "      <td>[0, 0, 1, 2, 0, 1, 4, 4, 0, 1, 1, 4]</td>\n",
       "      <td>[[8.305823e-05, 0.000103810155, 0.0031216003, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>{'matched': 9, 'counts': 12}</td>\n",
       "      <td>{'matched': 11, 'counts': 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[[0.00012100079, 0.00046736174, 9.6225005e-05,...</td>\n",
       "      <td>[1, 4, 2, 4, 0, 3, 1, 1, 2, 4, 1, 1]</td>\n",
       "      <td>[[0.00024389611, 0.00015452066, 0.0067515895, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>{'matched': 8, 'counts': 12}</td>\n",
       "      <td>{'matched': 11, 'counts': 12}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  batchnum                                     actions_logits  \\\n",
       "0      1         1  [[4.995138e-05, 0.99980026, 4.995138e-05, 4.99...   \n",
       "1      1         2  [[2.8056607e-05, 0.9999205, 2.7110715e-05, 1.2...   \n",
       "2      1         3  [[1.9743271e-05, 0.0001572934, 3.824866e-05, 1...   \n",
       "3      1         4  [[0.9997187, 0.00013980923, 4.2770298e-05, 4.1...   \n",
       "4      1         5  [[0.00012100079, 0.00046736174, 9.6225005e-05,...   \n",
       "\n",
       "                         actions_labels  \\\n",
       "0  [1, 4, 2, 4, 0, 1, 1, 4, 4, 0, 1, 2]   \n",
       "1  [1, 4, 2, 2, 0, 1, 2, 1, 1, 1, 1, 4]   \n",
       "2  [4, 1, 1, 1, 4, 2, 1, 2, 0, 1, 1, 1]   \n",
       "3  [0, 0, 1, 2, 0, 1, 4, 4, 0, 1, 1, 4]   \n",
       "4  [1, 4, 2, 4, 0, 3, 1, 1, 2, 4, 1, 1]   \n",
       "\n",
       "                                   attributes_logits  \\\n",
       "0  [[0.0020820214, 0.0036640947, 0.0055418806, 0....   \n",
       "1  [[0.0001478568, 0.00028644415, 0.0019145217, 0...   \n",
       "2  [[8.696537e-05, 7.193404e-05, 0.8102605, 0.000...   \n",
       "3  [[8.305823e-05, 0.000103810155, 0.0031216003, ...   \n",
       "4  [[0.00024389611, 0.00015452066, 0.0067515895, ...   \n",
       "\n",
       "                                   attributes_labels  \\\n",
       "0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "2  [[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "3  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "4  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "         accuracy_classification            accuracy_multilabel  \n",
       "0  {'matched': 12, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
       "1  {'matched': 10, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
       "2   {'matched': 9, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
       "3   {'matched': 9, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
       "4   {'matched': 8, 'counts': 12}  {'matched': 11, 'counts': 12}  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert test data to dataframe\n",
    "df_test = pd.DataFrame(data = test_batch)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dbd5290d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur. class.</th>\n",
       "      <th>Valid. Accur. mult.label</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "      <th>metrics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.16</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0:08:25</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8411614005123825, 'actio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.08</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0:08:27</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.834044975804156, 'action...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.07</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0:08:27</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8491317961855963, 'actio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.07</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0:08:33</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8351836037574722, 'actio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.06</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0:08:26</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8508397381155708, 'actio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.05</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0:08:25</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8539709649871904, 'actio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.04</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0:08:25</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8556789069171649, 'actio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.04</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0:08:25</td>\n",
       "      <td>0:00:28</td>\n",
       "      <td>{'action_accuracy': 0.856532877882152, 'action...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.03</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0:08:25</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8573868488471392, 'actio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.02</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0:08:25</td>\n",
       "      <td>0:00:27</td>\n",
       "      <td>{'action_accuracy': 0.8556789069171649, 'actio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. class.  \\\n",
       "epoch                                                     \n",
       "1               1.16         1.08                  0.84   \n",
       "2               1.08         1.08                  0.83   \n",
       "3               1.07         1.06                  0.85   \n",
       "4               1.07         1.08                  0.84   \n",
       "5               1.06         1.06                  0.85   \n",
       "6               1.05         1.06                  0.85   \n",
       "7               1.04         1.06                  0.86   \n",
       "8               1.04         1.06                  0.86   \n",
       "9               1.03         1.05                  0.86   \n",
       "10              1.02         1.06                  0.86   \n",
       "\n",
       "       Valid. Accur. mult.label Training Time Validation Time  \\\n",
       "epoch                                                           \n",
       "1                          0.91       0:08:25         0:00:27   \n",
       "2                          0.91       0:08:27         0:00:27   \n",
       "3                          0.93       0:08:27         0:00:27   \n",
       "4                          0.94       0:08:33         0:00:27   \n",
       "5                          0.94       0:08:26         0:00:27   \n",
       "6                          0.95       0:08:25         0:00:27   \n",
       "7                          0.95       0:08:25         0:00:27   \n",
       "8                          0.95       0:08:25         0:00:28   \n",
       "9                          0.95       0:08:25         0:00:27   \n",
       "10                         0.95       0:08:25         0:00:27   \n",
       "\n",
       "                                                 metrics  \n",
       "epoch                                                     \n",
       "1      {'action_accuracy': 0.8411614005123825, 'actio...  \n",
       "2      {'action_accuracy': 0.834044975804156, 'action...  \n",
       "3      {'action_accuracy': 0.8491317961855963, 'actio...  \n",
       "4      {'action_accuracy': 0.8351836037574722, 'actio...  \n",
       "5      {'action_accuracy': 0.8508397381155708, 'actio...  \n",
       "6      {'action_accuracy': 0.8539709649871904, 'actio...  \n",
       "7      {'action_accuracy': 0.8556789069171649, 'actio...  \n",
       "8      {'action_accuracy': 0.856532877882152, 'action...  \n",
       "9      {'action_accuracy': 0.8573868488471392, 'actio...  \n",
       "10     {'action_accuracy': 0.8556789069171649, 'actio...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display floats with two decimal places.\n",
    "pd.set_option('precision', 2)\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap.\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Display the table.\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "69386886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Objects serialization\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "testdata_filename = f\"testdata-{timestr}\"\n",
    "stats_filename = f\"stats-{timestr}\"\n",
    "#outtest = open(testdata_filename, \"wb\")\n",
    "#outstats = open(stats_filename, \"wb\")\n",
    "#pk.dump(obj=df_test, file=outtest)\n",
    "#outtest.close()\n",
    "#pk.dump(obj=df_stats, file=outstats)\n",
    "#outstats.close()\n",
    "df_test.to_pickle(testdata_filename)\n",
    "df_stats.to_pickle(stats_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb5a6cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testdata-20210807-221213\n",
      "       Training Loss  Valid. Loss  Valid. Accur. class.  \\\n",
      "epoch                                                     \n",
      "1               1.16         1.08                  0.84   \n",
      "2               1.08         1.08                  0.83   \n",
      "3               1.07         1.06                  0.85   \n",
      "4               1.07         1.08                  0.84   \n",
      "5               1.06         1.06                  0.85   \n",
      "\n",
      "       Valid. Accur. mult.label Training Time Validation Time  \\\n",
      "epoch                                                           \n",
      "1                          0.91       0:08:25         0:00:27   \n",
      "2                          0.91       0:08:27         0:00:27   \n",
      "3                          0.93       0:08:27         0:00:27   \n",
      "4                          0.94       0:08:33         0:00:27   \n",
      "5                          0.94       0:08:26         0:00:27   \n",
      "\n",
      "                                                 metrics  \n",
      "epoch                                                     \n",
      "1      {'action_accuracy': 0.8411614005123825, 'actio...  \n",
      "2      {'action_accuracy': 0.834044975804156, 'action...  \n",
      "3      {'action_accuracy': 0.8491317961855963, 'actio...  \n",
      "4      {'action_accuracy': 0.8351836037574722, 'actio...  \n",
      "5      {'action_accuracy': 0.8508397381155708, 'actio...  \n",
      "   epoch  batchnum                                     actions_logits  \\\n",
      "0      1         1  [[4.995138e-05, 0.99980026, 4.995138e-05, 4.99...   \n",
      "1      1         2  [[2.8056607e-05, 0.9999205, 2.7110715e-05, 1.2...   \n",
      "2      1         3  [[1.9743271e-05, 0.0001572934, 3.824866e-05, 1...   \n",
      "3      1         4  [[0.9997187, 0.00013980923, 4.2770298e-05, 4.1...   \n",
      "4      1         5  [[0.00012100079, 0.00046736174, 9.6225005e-05,...   \n",
      "\n",
      "                         actions_labels  \\\n",
      "0  [1, 4, 2, 4, 0, 1, 1, 4, 4, 0, 1, 2]   \n",
      "1  [1, 4, 2, 2, 0, 1, 2, 1, 1, 1, 1, 4]   \n",
      "2  [4, 1, 1, 1, 4, 2, 1, 2, 0, 1, 1, 1]   \n",
      "3  [0, 0, 1, 2, 0, 1, 4, 4, 0, 1, 1, 4]   \n",
      "4  [1, 4, 2, 4, 0, 3, 1, 1, 2, 4, 1, 1]   \n",
      "\n",
      "                                   attributes_logits  \\\n",
      "0  [[0.0020820214, 0.0036640947, 0.0055418806, 0....   \n",
      "1  [[0.0001478568, 0.00028644415, 0.0019145217, 0...   \n",
      "2  [[8.696537e-05, 7.193404e-05, 0.8102605, 0.000...   \n",
      "3  [[8.305823e-05, 0.000103810155, 0.0031216003, ...   \n",
      "4  [[0.00024389611, 0.00015452066, 0.0067515895, ...   \n",
      "\n",
      "                                   attributes_labels  \\\n",
      "0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
      "1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
      "2  [[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
      "3  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
      "4  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
      "\n",
      "         accuracy_classification            accuracy_multilabel  \n",
      "0  {'matched': 12, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
      "1  {'matched': 10, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
      "2   {'matched': 9, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
      "3   {'matched': 9, 'counts': 12}  {'matched': 11, 'counts': 12}  \n",
      "4   {'matched': 8, 'counts': 12}  {'matched': 11, 'counts': 12}  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Test reimport data\n",
    "df_stats_reload = pd.read_pickle(stats_filename)\n",
    "df_test_reload = pd.read_pickle(testdata_filename)\n",
    "\n",
    "print(testdata_filename)\n",
    "print(df_stats_reload.head())\n",
    "print(df_test_reload.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1af435",
   "metadata": {},
   "source": [
    "## Plot di training & validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2c4fe674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks([x+1 for x in range(exec_params['epochs'])])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add9f100",
   "metadata": {},
   "source": [
    "## Plot accuracy and perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5c6601f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "act_acc = [x['action_accuracy'] for x in df_stats.metrics]\n",
    "att_acc = [x['attribute_accuracy'] for x in df_stats.metrics]\n",
    "x_ticks = [x for x in range(len(act_acc))]\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(act_acc, 'b-o', label=\"Actions\")\n",
    "plt.plot(att_acc, 'g-o', label=\"Attributes\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Actions and attributes accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.xticks(ticks = x_ticks, labels = [str(x+1) for x in x_ticks])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1a2d0d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuUAAAGXCAYAAAAUOC6pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABjpUlEQVR4nO3deVxU5f4H8M8MA8M6rMOOyCI7KOGSSppLWWbhkpq5VZaZ2q3Mtpt1b11/VrfMrliWZmm5pOGamqZplvsuoCA6o4IL27DvDHN+f6BjE5igwBlmPu/Xq9eVM+fMfOfRC595+J7nkQiCIICIiIiIiEQjFbsAIiIiIiJzx1BORERERCQyhnIiIiIiIpExlBMRERERiYyhnIiIiIhIZAzlREREREQiYygnImpD69atQ2hoKA4dOiR2KSbh8uXLCA0NRWJiYqu/1ptvvonQ0NBWfx0iMk8M5UREAIqLixEdHY3Q0FBs3Ljxrp7r0KFDSExMRElJSQtVR8Zq586dbfKBgIhMH0M5ERGAn376CbW1tfD19UVSUtJdPdfhw4exYMGCRkN5QkICkpOT0a1bt7t6DWp7//nPf5CcnGxwbOfOnViwYIFIFRGRKWEoJyICkJSUhB49emDixIk4cuQIMjMzW+V1LCwsIJfLIZXy2++fCYKA8vJyscv4W5aWlpDL5WKXQUQmij8ViMjsnT59GmlpaRg2bBgeffRRyGQyrF27ttFza2pqsHjxYiQkJKBz586Ii4vD8OHDsXz5cgD1fcc3Zk4HDBiA0NBQg57nW/WUFxQU4L333kPfvn0RFRWFvn374r333kNhYaHBeTeuP3DgAJYsWYKBAwciKioKgwYNwvr16xvU+9tvv2HcuHHo0aMHYmJicP/992P69Om4cOHCbcelf//+GD9+PE6fPo0JEyYgNjYW3bt3xxtvvAGNRtPo2Hz55Zd45JFHEB0dja5du2LKlCk4c+aMwXmHDh1CaGgo1q1bhxUrVmDw4MGIjo7GN998AwAYP348+vfvj6ysLLzwwguIi4vDPffcg2nTpiErK+u2dd+wdetWjBkzBrGxsejcuTNGjhyJbdu26R/XarV44oknEBsbC5VKZXDt6tWrERoaiv/973/6Y3/tKR8/frx+zG/8Pd94X7Nnz0ZoaCguXrzYoK7c3FxERETgn//8Z5PfCxGZPpnYBRARiS0pKQm2trZ48MEHYWtri/vvvx8bNmzASy+9ZDCjXVNTg0mTJuHw4cOIj4/HY489BrlcjoyMDPzyyy8YN24cRo8ejbKyMuzYsQNvvfUWnJ2dAeBvbxAsLS3FmDFjcOnSJYwYMQIRERFIS0vDqlWrcPDgQfz444+wt7c3uGbevHmoqqrC6NGjYWVlhVWrVuHNN99Ehw4dEBcXB6C+jeaFF15ASEgInn/+eTg4OCA3NxcHDhxAZmYmAgICbjs22dnZeOqpp/Dggw9i0KBBOHPmDNauXYvU1FQkJSXBxsYGAFBbW4tJkybhxIkTSEhIwNixY1FWVoY1a9ZgzJgxWL58OaKjow2ee9myZSgqKsLIkSOhVCrh6empf6yiogITJkxAdHQ0ZsyYgUuXLmHlypU4deoU1q9fD6VS+bd1z5s3D19++SXuu+8+/d/jjh078NJLL+Hdd9/F2LFjIZPJMHfuXAwdOhQzZszAmjVrIJfLce7cOcyZMwdxcXGYPn36LV9jypQp0Ol0OHr0KP773//qj99zzz2Ijo7G999/j7Vr1+LVV181uG7Dhg2oq6vD448/ftvxJyIzIhARmbGqqiqhW7duwhtvvKE/tmPHDiEkJET47bffDM5dtGiREBISIsydO7fB89TV1en/PH/+fCEkJETIyspqcN7atWuFkJAQ4eDBg/pjn376qRASEiIsX77c4Nzly5cLISEhwrx58xpcn5CQIFRXV+uPZ2dnC5GRkcIrr7yiPzZnzhwhJCREyM/Pb8JINNSvXz8hJCRE+Pbbbw2Of/vtt0JISIjw1VdfNTj2+++/G5xbWloq9O3bVxg3bpz+2MGDB4WQkBChW7dujdY2btw4ISQkRJg9e7bB8V9++UUICQkR3nnnHf2xrKwsISQkRJg/f77+WGpq6i3/nl544QUhNjZWKC0t1R/bvn27EBISIrz33ntCZWWlMGTIEKFbt27ClStXDK594403hJCQkNseu2H06NFC7969hdraWoPjDz74oPDwww83eg0RmS+2rxCRWfvll19QXFyMoUOH6o/df//9cHV1bdDC8tNPP8HR0RHTpk1r8Dx30yO+Y8cOuLi4YPTo0QbHR48eDWdnZ+zcubPBNU8++SSsrKz0X3t4eCAgIMCgXcLBwQEAsH37dmi12juqzd7eHk8++WSD17a3t8eOHTv0xzZt2oTAwEBERkaioKBA/19NTQ169eqFY8eOoaqqyuB5EhIS4OrqesvXnjx5ssHXDzzwAAICAvDrr7/+bc0//fQTJBIJhg4dalBLQUEB+vfvj/Lycpw8eVJ//oMPPogxY8ZgxYoVeOqpp5CRkYHZs2fD29v7dsPzt0aNGoW8vDz8/vvv+mNHjhzBxYsXOUtORA2wfYWIzFpSUhJcXFzg6emJS5cu6Y/36tUL27ZtQ0FBAVxcXAAAly5dQnh4eIvf7Hf58mVERUVBJjP8liyTyRAQENCgJxsA/Pz8GhxzcnLClStX9F+PHTsWv/76K9577z188skniIuLw3333YchQ4bo39Pt+Pn5GYR/ALCysoKfn59Bf7dKpUJVVRV69ux5y+cqLCyEl5eX/uuOHTve8lyFQtFoi0pQUBB27tyJiooK2NraNnqtSqWCIAh4+OGHb/n8+fn5Bl+/9dZb2LdvH06cOIFRo0bhwQcfvOW1TTV48GDMmTMHSUlJ6N+/P4D6f2+WlpYGHwKJiACGciIyY1lZWTh06BAEQcCgQYMaPWfTpk146qmn2rawJmjKzLyzszOSkpJw9OhR7N+/H0eOHMEHH3yAxMRELFq0CLGxsbd9DolE0uhxQRAafB0SEoK33nrrls/11w8CN/rR7+Z1b3WORCLB4sWLYWFh0eg5wcHBBl+fPXsW165dAwCcO3cOWq22wYek5rK2tsZjjz2G1atXIy8vDzY2Nti+fTv69+/f5A9FRGQ+GMqJyGytW7cOgiBg9uzZ+laPP/vss8+wdu1afSjv2LEj1Go1ampqGswe/9mtAuWt+Pn54cKFCw2CoFarxcWLFxudFW8qCwsL9OjRAz169AAApKenY8SIEVi4cCEWLVp02+szMzMbvN+amhpcvnwZgYGB+mP+/v4oLCzEvffe2yLLPRYXFyMvL6/BbLlarYarq+stZ8mB+r+nP/74A97e3ggKCrrta5WVleGVV16Bk5MTxo0bh3nz5iExMRGvvPLKba+93d/1qFGjsGLFCmzYsAEODg6orKxk6woRNYo95URklnQ6HdavX4+QkBCMHDkSDz30UIP/hgwZgoyMDP2GMY8++iiKi4vxxRdfNHi+P8/g3giMxcXFTapl4MCBKCgowI8//mhwfM2aNSgoKMDAgQPv6D0WFBQ0OBYYGAi5XN7k2srKyrBy5UqDYytXrkRZWZlBXUOHDkVeXh6+/fbbRp/nr+0iTfHXDw07duzAhQsXbjsejz32GADg008/RV1dXYPH/7qc47vvvourV6/i448/xpQpU/DQQw9h0aJFOHjw4G1rvPF3XVRU1OjjYWFhiImJwdq1a5GUlARvb2/Ex8ff9nmJyPxwppyIzNLevXtx7dq1v521fPDBB5GYmIikpCTExMRgwoQJ2L17NxYuXIiUlBTEx8fDysoK58+fx4ULF7B06VIAQOfOnQEAn3zyCR599FHI5XJ06tQJISEhjb7Os88+i23btuH999/HmTNnEB4ejrS0NCQlJSEgIADPPvvsHb3Hd955B9nZ2YiPj4e3tzeqqqrw888/o7y8HAkJCU16jg4dOuDzzz/HuXPnEBkZidOnT2Pt2rUIDAzE+PHj9edNmDAB+/fvx3//+18cPHgQ9957L+zt7XH16lUcPHgQVlZW+P7775tcu7OzM3bs2IHc3Fx0795dvySim5vb3y5TCAAxMTF48cUXkZiYiKFDh2LQoEHw8PBAbm4uTp8+jd9//x2pqakAgB9//BFbtmzBlClT9P3w//nPf5CSkoLXXnsNmzZt0i9r2ZjOnTtj+fLl+jXmLS0tERMTY/DbjVGjRmHWrFkAgOnTp3PjKCJqFEM5EZmlpKQkAPUretxKSEgIOnbsiK1bt+Kf//wnrK2t8c033+Cbb77B5s2b8emnn0Iul8Pf3x/Dhw/XXxcXF4eZM2fihx9+wDvvvAOtVovp06ffMpQ7ODhg1apVmD9/Pnbt2oV169bB1dUVTzzxBF588cUGa5Q3VUJCAtatW4f169ejoKAA9vb2CA4Oxvz582/ZQ/9Xnp6e+Oyzz/DRRx9hy5YtsLS0xKOPPoo33njDoIXE0tISX331FVauXImNGzfqN0tyd3dHdHQ0hg0b1qzabW1tsWzZMsyZMwdz586FIAi477778Oabb8Ld3f2210+fPh1RUVH4/vvv8d1336GiogKurq7o1KmTftMelUqF//u//0NsbCxefPFF/bUKhQJz587FuHHj8NZbb+HLL7+85esMGTIEaWlp2LJlC7Zt2wadTocPPvjAIJQ/8sgj+PDDD1FRUWHw74SI6M8kQlPumiEiIrPTv39/+Pj4NGuGuyWMHz8eV65cwa5du9r0dVtLTU0N4uPjER0djSVLlohdDhEZKf4OjYiIqBVt2rQJxcXFDdahJyL6M7avEBERtYJdu3bh6tWrSExMRHBwMAYMGCB2SURkxBjKiYiIWsHs2bORm5uLyMhIzJ49+5ZrphMRAewpJyIiIiISHXvKiYiIiIhExlBORERERCQy9pRfV1hYDp2ubTt5XF3todGUtelrGjOOhyGOx00cC0McD0Mcj5s4FoY4HjdxLAyJNR5SqQTOznaNPsZQfp1OJ7R5KL/xunQTx8MQx+MmjoUhjochjsdNHAtDHI+bOBaGjG082L5CRERERCQyhnIiIiIiIpExlBMRERERiYyhnIiIiIhIZAzlREREREQiYygnIiIiIhIZQzkRERERkcgYyomIiIiIRMZQTkREREQkMu7oSURG68DpbKzbo0JBSTVcFHIM7xuEnpGeYpdFRETU4hjKicgoHTidjWU/p6NGqwMAaEqqsezndABgMCciIpPD9hUiMkrr9qj0gfyGGq0O6/aoRKqIiIio9TCUE5FR0pRU3/L476euoqyyto0rIiIiaj1sXyEio+TiIEdBacNgLpVKsPTndHy//SwiA1zQI9wDXTq5wUbOb2dERNR+8acYERkdQRDgomgYyq1kUkx4KBTebnY4nJaLw2k5SFZpYCmTIibIFd3DPRAT5Aq5pYVIlRMREd0ZhnIiMjq7T1zB+SsliAtxw8Xs0kZXX+noqcDj9wdBfaUEh9JycDQ9F8fO5kFuaYHYTm7oHu6ByAAXWMrYpUdERMaPoZyIjIrqSjFW7TyHmCBXvDAsGlKJBEqlA/LyShucK5VIEOzriGBfR4wZ0Alns4pw+HpAP3gmBzZyGeJClOge7o4wf2fILBjQiYjIODGUE5HRKCmvwRcbUuHsIMezQyIglUiafK1UKkG4vzPC/Z0x9oEQpF0qxOEzOTiWkYu9Kddgb2OJrmHu6BHujk6+TpBKm/7cRERErY2hnIiMQp1Oh682nUZZZS3+OS4O9jaWd/xcMgspogNdER3oignaOqSqC3AoLQf7U6/htxNX4GhvhW5h7ugR7oFAbwUkzQj/RERErYGhnIiMwvrfLyDtUiGeHhwGf0+HFnteS5kFYkOUiA1RorqmDqdU+TiclovfTlzFzqOX4aqwRvdwd3QP90AHD3sGdCIiEgVDORGJ7nhGHrYevIS+XbxxX4x3q72O3MoC3cM90D3cAxVVWpw4l4cj6bn45UgWfj6UCQ8XW/QId0e3cA/4uNm1Wh3UMg6czsa6PapGbwQmImpvGMqJSFQ5BRVYsuUMOno64MmBndrsdW2tZegd7YXe0V4oq6zFsbO5OJyWi5/2X8SmfRfhq7S7HuDd4e5s22Z1UdMcOJ2NZT+n63d91ZRUY9nP6QDAYE78wEbtEkM5EYmmuqYOC9anwEIqxdRhUbCUibO+uL2NJfp28UHfLj4oLqvG0bN5OJSWg3W/q7HudzU6ejroA7qLwlqUGukmnU7Aj7vP6wP5DTVaHdbuUTF8mTl+YKP2iqGciEQhCAKWbUvH1bxyvDK6M9wcbcQuCQDgaC/HgDhfDIjzRUFJlX6TojW7z2PN7vMI9nVEj3APdA1VwtFeLna5Jk0QBJSU1+ByXjku55Vd/68c1/LLGwTyGwpKqvHGl/uhdLKBm6MNlE7W+j+7OVnDwcaS9w2YKG2dDoWl1Vj967lGP7Ct4wc2MnIM5UQkil3Hr+DgmRwMuy8AUQGuYpfTKBeFNR7q0QEP9eiAnMIKHLke0FfsyMDKnRkI6+CM7uHuiAt1v6vVYgioqtHiSn45ruSV43LuzQBeVlmrP0dhZwVfpR3uj/XBvpRrKK/SNngeGysLBHgpkF9chZPn8lBSUWvwuNzKAkpH6+uBvT6oK6+HdzdHG8ituBusMdIJAkoralFQUoWCkipoSqoN/1xahZKyGgh/8xyakuq/eZRIfAzlRNTmzl8uxg+/nkPnIFc80quj2OU0iYezLYb06oghvTriSl6ZfgZ92bazWP5LBiIDXNAtzB33hChhI+e31lup0+mQU1CpD91Xrs+A5xVV6c+xspTCx80esZ3c4Ku0h6/SDj7u9lDYWunP8fd0MGhRAAArmRTjBoUazIZW1WiRX1yF/KIq5BVVIq+4sv7PxZVIu1SI6to6g/oUtpbXw7oN3BzrZ9mVjtZwc7KBi0IOCyk3oGoNldVaFJRWXw/ZVSj4U+guuB66tXWGkdvKUgpXhTVcHOTwVbrCVWENZ4Uca39TNfgwBgCuCv5mi4wbf3IQUZsqLq/BFxtS4KKQ47lHm7dBkLHwUdpjmNIeQ+8LQGZOGQ6n5eBwWi6SVWlYtu0sYoJc0T3cHZ2D3Mx25lUQBBSV1dxsO8mtD+BXNRXQ1tUHaYkE8HSxhb+nAr2jvfQB3M3J5rb/Lm4E79vdzGdtJbv+vPaN1lhaWYu8ovqgnl9cWR/ci6qgvlqMI2m50Ak3g6BUIoGLQl4f1K/PrN+cabeBgy1bYxqjrdOhqLS6PmyXVuuDtuZPobui2vC3HlKJBE4OVnBRWKOjlwPiQpVwUVjDRSGvD+IKa9hZyxodb5mFtMEHNgCICTLO38gR3cBQTkRtpk6nw1cbU1FepcXb4+Nga92+Wz4kEgn8PR3g7+mAx+8PgvpqCQ6l5eBIei6OZ+TBylKKLsFu6BHugahAV1jKTHOWtbJaW9928qe+7yt5ZQbtJU72VvBV2iOiowt8lHbwVdrD2832rm7u7RnpiZ6RnlAqHZCXV9rs6yUSCRS2VlDYWiHI27HB43U6HQpLqpFXXD/Lnn9jlr2oEifPa1BSXmNwvtzSQj+77nZ9dl15PbS7OVnD2sr0fuQKN9pKSqugKa6f0b7RUlJ4fda7uJG2EnsbS7g4yOHmaINQP2e4KOQGodvR3uqOfyvx1w9sTg5yWFtK8duJq/B1d0C/WJ+7fNdErcP0vkMQkdFat0eN9MwiTHokHB08Wm6DIGMgkUgQ5OOIIB9HPNG/E85dLsKhtFwcTa9fatFGboF7OinRPcID4f7OkFm0v4CurdMhu6ACl/PK/tT7XQ5Nyc3WE2srC/go7dA1zP1m64nSvl323FtIpfVtLE42CPd3bvB4dU1d/ex6cRXyr8+w18+2VyEtsxDVNYatMQ62ln+5+fRGcLeBi4PcKP9NVNVo9e0jBSXV0BRX6f9ccH3mu/YvM9KWMilcFNZwVcgRFeCqD9yu10O3i4N1q/8G6a8f2Gq1dfhifSq+334WldVaDL7Xv1Vfn+hOMJQTUZs4djYXPx/KxP2xPugd7SV2Oa1KKpUgtIMzQjs448mBnZB+qRCH03JxLCMP+1KzYW9jibhQJbqHeyDUzwlSqXG1PAiCgIKSav3M941Z8GuaCtTp6uc8LaQSeLrYIshHgb5dvPUB3NXR2mxaOORWFvBR2sPnFq0xZZW1yL8+y14/017/54vXSnHsbJ5+LIH6Vh4XB+v6tpjrfew3etuVjtZQ2Fn97bjeybrcdTodikprbraRXG8xKfxTa8lfb6aVSAAnezlcFHL4ezogtpPSoKXERSGHvRGucGMps8C04dH4evMZJP2mQmW1FsP7BBpdnWTeGMqJqNVd05RjyZY0BHgpMGZA220QZAxkFlJEBboiKtAV4weFIvWCBofTcnHwdA72nLwKRzsrdA1zR49wDwT6KNq8x76iqvZPSw6W60N45Z96fF0Ucvgq7REd5Krvz/Z0sTXZdpyWIJFI4GBrBQdbKwR4KRo8XqerX77vxk2nN2bZ84uqkKLSoPgvrTFWMmmjN58qnWygvlqMVTvPNViXu6pGi0Avx5s3T/7lRsqismoIf+krsbOW1YdrBzmCfR31N1LeCNxO9sY5o98UMgspJj8aCRu5DFsOXEJVdR3GPNCpXd7XQqaJoZyIWlVVjRZfrE+FzEKKqUOjzDrIWcqkiO2kRGwnJapr65Cs0uDwmfpw/uuxy3BVyNHt+iZF/h4OLTqLV6vV4Zqm/E+93/X/W1h6c5k4G7kMvko73BvhoW878VXatfvef2NkIZXW3yjqaIMwNNIaU1t3fdWYygaz7RlZRaj6S2vMX9Vodfh+e4bBMZmFVD+rHdHRGS4O1nB1NAzdptj3/mdSqQQTBoXCRi7DtkOZqKzR4unBYVxVh4yCaf+/j4hEJQgClv6cjquacswY3QWujtwN8wa5pQW6hbmjW5g7Kqu1OHkuH4fScrDjSBa2HcqEu7MNuod7oEe4u749oiktCjpBgKa46i9LDpYjp8Cw9cTL1Q6hHZz0bSe+Sns4O8j563wjIbe0gI+bHXzc7Bo8JggCyqu0+qD+5cbTt3yeacOi4epY38fN1WHqSSQSjLw/CDZyGdb/rkZVTR2efyzSrCcMyDgwlBNRq9l57DIOp+ViRN9ARHZ0Ebsco2Ujl6FnlCd6RnmirLIWxzPycDgtB1sOXMTm/Rfh42YHL1cbnFIV6G+q05RUY+nP6biWXw6FndXNAJ5fbnCDoZujNXyVhmt+e7jYttsWBKoPlfY2lrC3sUSAlwI/7j7f6MY4rgo54kKVIlRo/CQSCR7t1RE2VhZYufMc5iedwvThMWa7hCkZB4ZyImoV5y4XYc2u8+gS7IaHudJBk9nbWKJPZ2/06eyN4vIaHE3PxZG0HBw9m9/g3FqtDpsPXAJQ3wvsq7RHfJQXfNzrZ7593Oy4kZEZGN43qNGNlIb3DRKxqvZhYFc/2Mhl+GZrGuauPomXR8awXYtEw+/WRNTiisuq8cWGVLgqrPHskHDeSHWHHO2sMCDOFwPifPHMh7tued7cab3hZP/3q3OQ6WrqRkrUuN7RXpBbWuCrTafx35UnMGN0FyjsrG5/IVELYygnohalrdNh4cbTqKzSYsaELpx1aiGuCvktWxScHbh9uLm7242UzF3XMHdYW1lgwboUfLjiOGY+0QUuCt4DQ22LTYVE1KLW7lEhI6sIEx8Kg597w/Wb6c4M7xsEq7/ciMYWBaKWExXoihmju6C4vBofLD+OnMIKsUsiM8NQTkQt5mh6LrYfzkK/e3zQM4q/Om9JPSM9MfHhMLgq5JCgfoZ84sNhbFEgakEhfk54fcw9qK6tw4fLj+NybpnYJZEZYfsKEbWIa5pyLNmahiBv89sgqK2wRYGo9fl7OuDNsfdg7uqT+GjlcbwyqgsCvRtuAEXU0jhTTkR3rapGiwXrUmAlk+KFoVFcbo+I2jVvNzu8OfYe2FrL8PEPJ5B2qVDsksgM8CcnEd0VQRDw7dZ0ZBdUYMpjkbw5iohMgtLJBm+OjYObwhrz1pzCyfMNlyUlakkM5UR0V3YcvYwj6bkY0TcI4dwgiIhMiLODHG+MvQe+Sjt8vi4Fh87kiF0SmTCGciK6YxlZ9RsExXZyw8M9OohdDhFRi7O3scRrY2IR7OOIRZtO47eTV8QuiUwUQzkR3ZGismos3JAKpZM1Jj0SwY1riMhk2chleGVUZ0QHueK7bWex7VCm2CWRCRJt9ZVDhw5hwoQJjT62detWBAXdeu3dxMRELFiwoMFxNzc37Nu3r8VqJKLGaet0+HJDKiprtHj1iS6wteZCTkRk2qwsLTB9eDQW/3QGa3afR0W1FsPuC+CEBLUY0X+Szpw5E926dTM45uvr26Rrv/32W9ja2uq/trTkzoFEbSHpNxUyLhdj8qMR8FVygyAiMg8yCymefywSNnILbN5/EZXVWowZ2AlSBnNqAaKH8oCAAHTp0uWOro2KioJCwbVDidrS4bQc/HIkCwPifHEvN64hIjMjlUow8aEwWFvJ8MuRLFTVaPHUw2GwkLIjmO6O6KGciNqPK/nl+HZrOoJ8FBjdP1jscoiIRCGRSDC6fzBs5TJs2HsBVTV1mPxoJCxlDOZ050T/1/Puu+8iIiICcXFxeP7555GamtrkawcPHozw8HDEx8dj1qxZ0Gg0rVgpkXmrrNbii/UpkFtKMXVoNDcIIiKzJpFI8Fh8AMYM6IRjZ/OQuDYZ1bV1YpdF7ZhoM+UODg6YOHEiunfvDicnJ6hUKixatAhjxozB8uXL0blz51te6+fnhxkzZiA8PByWlpY4fvw4vv76axw4cADr1q2Do6NjG74TItNXv0FQGnIKKjHziS5wdpCLXRIRkVF4oJsfrK0ssHRbOj5dfRIvPd6ZN7/THZEIgiCIXcQNeXl5GDJkCMLDw7F06dJmXbtv3z4888wzeOmllzB16tTWKZDITK3/7Ty++ek0nh4SgeH9OoldDhGR0dl76grmrjgGfy8F3nuuJxztOXlBzWNUH+WUSiXi4+Oxa9euZl/bu3dvKJVKnDx58o5eW6Mpg07Xtp9PlEoH5OWVtulrGjOOhyFjGY+zmYVYuvkM4kKUiI/0EKUmYxkLY8HxMMTxuIljYagtxyPUW4Hpw2Pw+foUvDb/d8x8ItaofqvIfxuGxBoPqVQCV9fGVy0zuqZQnU53x9cKggAp734majGFpdVYuPE0lM42eOaRcK7HS0T0N2KCXDFjVGcUllbjg+XHkFtYIXZJ1I4YVYLNy8vD/v3772iJxL179yI/P/9ve9GJqOm0dTos3JiKqhotpg+Lgo3cqH6xRkRklEI7OOO1MbGoqqnDByuO40pemdglUTsh2k/ZV199FX5+foiMjIRCoYBarcbixYtRVVWFGTNm6M8bP348Dh8+jLNnz+qPDR06FEOHDkVAQABkMhlOnDiBJUuWwN/fH2PHjhXj7RCZnDW7z+P85WI8/1gkfLhBEBFRkwV4KfDG2HvwyQ8n8OGK45gxugsCvLivCv090UJ5aGgotmzZguXLl6OyshJOTk7o3r07XnjhBYSEhPzttYGBgVi5ciVyc3Oh1Wrh6emJkSNHYurUqdxMiKgFHDqTg51HL2NgV1/0iPAQuxwionbHx80Ob42LwyerTuDjVSfw0uMxCO3gLHZZZMSMavUVMfFGT/FxPAyJNR5X8srwn++OooOHA14fE2sU65Hz34YhjochjsdNHAtDxjAehaXV+OSHE8gvrsK0YVGICXITpQ5jGAtjwhs9icioVVZrsWB9KqytZHghIcooAjkRUXvm7CDHm2PvgbebHRLXpuBwWo7YJZGR4k9cIgJQv3rRN1vSkFdYiRcSIo1qKS8iovbMwdYKrz0RiyBvBb7aeBq/n7oqdklkhBjKiQgAsO1wJo5l5OHx+4PY90hE1MJsrWV4ZXQXRAa6YOnP6fjlcKbYJZGRYSgnIqRdKkTSbyp0DVViUHc/scshIjJJcksL/GNEDLqGKvHDrvPY8IcavLWPbmAoJzJzhaXV+GpjKjxdbPH0YG4QRETUmmQWUjyfEIn4aC9s2ncRP/x6nsGcAIi4JCIRiU9bp8MXG1JQXavD609Gc4MgIqI2YCGV4qnBYbCWW2DH0SxU1mjx1ENhkEo5KWLO+BOYyIyt3nUeqislmJIQCW83O7HLISIyG1KJBGMGdIKtXIZN+y6iqqYOkx+N4KpXZoyhnMhMHTidjV+PXcaD3fzQPZwbBBERtTWJRIKh9wXCRi7D6l3nUV1Th6nDoiC3tBC7NBIBP44RmaHLuWVYti0dIb6OePz+ILHLISIya4O6d8BTD4chVa3BvDWnUFmtFbskEgFDOZGZqajSYsH6FNhYyTBlKDcIIiIyBn06e+P5hEiorhTj41UnUFpRI3ZJ1Mb405jIjAiCgCVbziC/qAovDI2Ckz03CCIiMhbdwz0wfXg0ruSX46OVJ1BYWi12SdSGGMqJzMjPhzJx4lw+RvUPRoifk9jlEBHRX3QOdsMrIztDU1KFD5YfQ25RpdglURthKCfRHTidjde+2IfHXt2I177YhwOns8UuySSduViAtXtU6B7ujge6+opdDhER3UKYvzNeeyIWldVafLj8GK7kl4tdErUBhnIS1YHT2Vj2czo0JdUQAGhKqrHs53QG8xZWUFKFrzadhqeLLZ56OIwbBBERGblAbwXeGHsPBAH4aMVxXMwuEbskamUM5SSqdXtUqNHqDI7VaHVYt0clUkWmp1arwxcbUlGj1WH68GhYW3ElVCKi9sBXaY+3xt0DaysLfLzqBDKyisQuiVoRQzmJSlPS+E0smpJqbjvcQn7YdQ7qqyWYNDgcXq7cIIiIqD1xd7bFm2PvgZO9HJ+uPokUtUbskqiVMJSTqFwVt179490lh7HtUCaKy7ks1J06kJqN3cevYFB3P3QNcxe7HCIiugMuCmu8MfYeeLraYn5SMo6m54pdErUChnIS1fC+QbCQGvY3W8qkiI/2hNzKAmt2n8erC/ZhflIyjp3Ng7ZOd4tnor/Kur5BUKifEzcIIiJq5xS2Vnh9TCwCvBVYuDEVfyRfFbskamFsLiVR9Yz0xC+HM5GVWwZBAFwUcgzvG4SekZ4AgKv55diXcg37U7Nx8nw+7G0scW+kB+KjvdDBw0Hk6o1XRVUtPl+XAhtrGaYkRMJCys/fRETtna21JV4d1QUL1qfg263pqKquwwPd/MQui1oIQzmJqlarQ3ZhJfp08cGr47oiL6/U4HFvNzuM7BeM4X0DcfpCAfYmX8NvJ65g59HL6OBuj94xXrg3wgMOtlYivQPjoxMEfL05DZqSKrz+ZCwcuUEQEZHJkFtZ4B8jYrBo02ms+vUcKmu0eLRXR66qZQIYyklU5y4XobqmDtGBLn97noVUipggN8QEuaGsshaHzuRgb8o1rNp5Dmt2nUeXYDf0jvFCdKCL2c8Kbz1wCSfP52PMwE7o5OskdjlERNTCLGVSTBkaiaVb07HhjwuorNZiVL9gBvN2jqGcRJWi1kBmIUG4v3OTr7G3scSAOF8MiPNFVm4Z9qVcw4HT2TiWkQeFnRV6RXqid4wXfNzMb6WR0xcLsP4PNXpEeGBgHDcIIiIyVRZSKZ5+JBzWVjJsP5yFyuo6TBgUCqmUwby9YignUSWrNAjxc7rjtbP93O3xxIBOePz+IKSoNNibcg07jmZh2+FMBHg5ID7aC90jPGBnbdnClRsfTXEVvtp4Gt6udpj4UChnTIiITJxUIsGTD3SCjbUFNu+/hKoaLZ4dEgGZhXn/xri9Yign0eQXVeKapgJ9O3vf9XPJLKSIDVEiNkSJkvIaHDydjb0p1/D9LxlY9et53BPihvhoL0R0dDHJWYT6DYJSoK3TYRo3CCIiMhsSiQTD+wTBRi7Dj7tVqKqpw9ShUbCytBC7NGom/uQm0dzYACE6yLVFn1dhZ4UHu3fAA938kJlThr3J13DwTDYOp+XC2UGOXlGe6B3tBU8X2xZ9XTGt+vUcLlwrxbRhUSb1voiIqGke7uEPGysZvt9+FvPWnMI/Ho+BjZwxrz3h3xaJJlmlgZujdauFSIlEAn9PB/h7OmBU/2CcOp+PvSnXsPXgJWw5cAnBPo6Ij/FCtzD3dv2Na19K/Yo0D/fogLhQbhBERGSu7o/1gbXcAl//lIZPfjiBV0Z1gb2N6bdvmor2m0SoXavV1iEtsxDx0V5t0vtsKZOia5g7uoa5o6isGgdS69tblv6cjpU7MhAXqkR8tBdC/Z0hbUe92Jk5pfhu+1mEdXDC8L6BYpdDREQiuzfCE9aWMnyxIRUfrTyOV0d3gROXxm0XGMpJFGezilBTq0NMC7euNIWTvRwP3+uPh3p0gPpaCfYlX8OhtFwcOJ0DV4U1ekd7ole0F9ydbNq8tuYor6rF5+tTYGctw/MJUWa/FCQREdXr0skNr4yMwfy1KfjXksOwsJCguKymwQZ9ZFwYykkUySoNZBZShHZo+lKILU0ikSDI2xFB3o54YkAnHD+Xh30p2fhp30Vs2ncRoX5OiI/xQlyo0uhunNQJAr7+6QwKSqrxxth74GjHzZOIiOim8I4ueKiHHzbuvag/pimpxrKf0wGAwdwIGVfSILORoi5AmL8T5EZyd7iVpQXujfDEvRGeKCipwr7UbOxLuYYlW9KwfEcGuoW6Iz7GC518HY1iqcEt+y/ilEqDsQ+EINjHUexyiIjICO1NvtbgWI1Wh3V7VAzlRoihnNpcbmEFcgoq0P8eH7FLaZSLwhqP9uqIIT39ce5yMfamXMOR9FzsTbkGdyeb+vaWKC+4OlqLUl/qBQ02/HEB90Z6GO0YEhGR+DQl1c06TuJiKKc2l6IuAABR+smbQyKRIMTPCSF+Thg7MARHz+ZiX8o1rP/jAjb8cQHhHZ0RH+2Fe0KUbbYebH5xZf0GQUo7TBwUZhSz9kREZJxcFfJGA7hUAqSqNYgKNO6fw+aGoZzaXLJKAw9nG3g4t5/1tOVWFugd7YXe0V7IK6rE/uvtLYt+OgMbuQW6h3sgPtoLgd6KVgvKtdo6fLE+FTpBwPRh0ZBbGUfrDxERGafhfYOw7Od01Gh1+mOWFlLYWlvg0zWn0KezF0b379SulwU2JfxboDZVU1uH9MzCFtnFUyxKJxskxAfg0d4dcTazCPtSruHA6WzsOXkVXq626B3thZ6RnnB2aNklqFbuPIeL2aV4cXg0PLhBEBER3caNvvF1e1QoKKnWr77SNVSJDXsvYNuhTKReKMDTD4cjMsBF5GqJoZzaVHpmEWq14iyF2NKkEgnC/Z0R7u+MsQ+E4Eh6fXtL0m8qrN2jQlSAK+JjvNAl2A2WsrtbrvCP5KvYc/IqBt/rj9gQZQu9AyIiMnU9Iz3RM9ITSqUD8vJK9cdH3h+Mezop8c3WNMxdfRJ9u3hjVL9gzpqLiCNPbSpFpYGVTIrQDk5il9KibOQy9OnsjT6dvZFTUIF9qdewLyUbCzekws5ahh4RHoiP8YK/h0Oz21suZZdi+S8ZCPd3xrA+Aa30DoiIyNwE+TjiX091w4a9F7D9UCZS1QV4enAYIjpy1lwMDOXUZgRBQLI6H2H+zrCUmW4/tIeLLYb3CcLQ+ECcuVSAfSnZ+P3UNew6fgU+SjvEX29vUTRhbfGyyvoNguxtLPH8Y5HcIIiIiFqUlaUFRvWrnzVfsjUNn/xwEv1ifTCyX5DR7dFh6jja1GZyCiuRV1SFQd07iF1Km5BKJYgKcEVUgCsqqmpxOK1+WcXVu84j6TcVogPr21tiglwhs2gYtnU6AV9vPoPC0mq8Oe6eJoV4IiKiOxHs64j3nu6Gdb+rseNIFlLUGjw9OBzh/uJt8mduGMqpzSSrNACAaDNcgsnW2hL3x/rg/lgfXMkvx/6Ua9ifmo2T5/Nhb2OJnpGe6B3tiQ4eDjhwOhvr9qj0y1j1jvJEkDc3CCIiotZlZWmBJwZ0QlyoEku2pOHjVSfQ/x4fPH4/Z83bAkeY2kyKWgMvV1sonWzELkVUPm52GNkvGMP7BiJVXYB9Kdew6/hl7DiaBReFHMVlNajTCfrzj6TnIiLAhbuvERFRm+jk64T3numOdXvU2Hk0C8kqDSY9Eo7QDpw1b01sUKU2UV1Th7OZhWY5S34rFlIpOge7YeqwaMx7MR5jHwhpEMiBm1siExERtRW5pQXGDOyEN8beA6lEgo9WnsCKHRmorqkTuzSTxVBObSLtUiG0dQKiTWApxNZgb2OJAXG+DQL5DdwSmYiIxBDiVz9rPiDOF78eu4x/fXMYGVlFYpdlkhjKqU2kqDWQW1ogxNdJ7FKMmqui8Q2HbnWciIiotcmtLDD2gRC88WQsBAj4aMVxrNp5DtW1nDVvSQzl1OoEQUCySoOIjs53vYmOqRveNwhWfxkjK5kUw/sGiVQRERFRvdAOznjvme7od48PdhzNwr+/OYxzl4vELstkMCFRq7uqqYCmpIr95E3QM9ITEx8Og6tCDgnqZ8gnPhzGmzyJiMgoWFvJMO7BULw2JhZ1OgEfLj+OH349hxrOmt81rr5CrS7FjJdCvBO32hKZiIjIWIT7O+P9Sd3x424VfjmShVPXV2gJ9uESvneKM+XU6lLUGvi42cHV0VrsUoiIiKiFWFvJMH5QKGY+0QVabR0+WH4Ma3ad56z5HWIop1ZVWa1FRlYRV10hIiIyUREdXfD+pB7o29kb2w5n4t/fHoHqSrHYZbU7DOXUqtIuFaJOJyCGrStEREQmy0Yuw4SHwvDq6C6o0dZhzvJj+HH3edRqOWveVAzl1KqSVRpYW1kg2Jc9ZkRERKYuMsAF/5nUA/fFeOHnQ/Wz5uqrJWKX1S4wlFOrEQQBKWoNIju6QGbBf2pERETmwEYuw1MPh2PGqM6oqqnD/31/FEm/qVCr1YldmlFjUqJWcyWvHIWl1ewnJyIiMkNRga74z6Qe6B3tha0HL+H9pUdw4RpnzW+FoZxaTbKaSyESERGZM1trGZ4ZHI6XR3ZGeVUt/u+7Y1i7h7PmjWEop1aTotLAz90ezg7cIp6IiMicxQS5YvazPdAzygNbDlzC+8uO4FI29+L4M4ZyahUVVVqcu1zMWXIiIiICANhaW2LSIxF46fEYlFXW4j/LjmL972po6zhrDjCUUys5c7EAOkFADPvJiYiI6E86B7th9rM9cG+kB37afxHvLz3KWXMwlFMrSVZrYCOXIchHIXYpREREZGTsrC3x7JAI/GNEDEorajD7u6PY8Id5z5rLxC6ATI9+KcQAF1hI+bmPiIiIGtelkxuCfXtg1c4MbNp3ESfP5eOZR8LRwcNB7NLaHBMTtbis3DIUl9VwF08iIiK6LXsbSzz3aCReHB6NovIa/GfZUWzae8HsZs1Fmyk/dOgQJkyY0OhjW7duRVBQ0N9en5mZiQ8//BCHDh2CTqdD165d8cYbbyA4OLg1yqVmSFbdWArRReRKiIiIqL2IDVGik58TVuzIwIa9F3D8XB6efSQCvu72YpfWJkRvX5k5cya6detmcMzX1/dvr9FoNHjyySfh6uqKjz76CBYWFli4cCHGjRuHDRs2wNPTszVLpttIVmvg7+EAR3suhUhERERNZ29jiecfi0TXUHd8vz0d7y09gsfiAzD43g4m3xLb7FA+aNAgjBgxAsOGDYNSqbzrAgICAtClS5dmXbNkyRKUlJRg7dq18PDwAAB06dIFAwYMwMKFC/Hee+/ddV10Z8qraqG6UoxHenYUuxQiIiJqp+JClQjxc8SKHRlY/7saxzPyMOmRcPgqTXfWvNkfOWQyGT799FP069cPU6dOxe7du6HTtW3Pz86dO9GrVy99IAcAZ2dn9OvXDzt27GjTWsjQ6QsFEASwn5yIiIjuioOtFaYkRGHq0CgUlFTh/aVHsOXARdS1ce5sK80O5Vu2bMEPP/yAoUOH4tChQ5g6dSr69u2LefPmITMzs9kFvPvuu4iIiEBcXByef/55pKam/u35VVVVyMzMREhISIPHQkNDodFooNFoml0HtYwUlQZ21jIEenMpRCIiIrp7XcPc8Z9ne6BLJyXW7lFjzvfHcCW/XOyyWpxEEAThTi+urKzE1q1bkZSUhBMnTkAikaBbt24YOXIkBg0aBCsrq1tee+bMGWzYsAHdu3eHk5MTVCoVFi1ahNzcXCxfvhydO3du9LqcnBz06dMHr7/+OiZNmmTw2Jo1a/DOO+806UZRank6nYCJ721HTCc3vDauq9jlEBERkYn54+QVLFybjMpqLcY+FIZhfYNgYWEaveZ3daOnjY0NRowYgREjRuDChQtYsGABtmzZgiNHjmD27NlISEjAU089BW9v7wbXRkREICIiQv91165d0b9/fwwZMgTz5s3D0qVL//a1JRLJ3ZTegEZTBp3ujj+f3BGl0gF5eaazg9WFayUoKqtGiI/ijt6XqY3H3eJ43MSxMMTxMMTxuIljYYjjcZOpjEWYjwL/mdQd3/9yFsu2nMHvxy9j0iPh8Haza9bziDUeUqkErq6N98Xf9UeLuro67NixAx9++CF+/vlnSCQS9OjRA507d8by5csxePBg7Ny5s0nPpVQqER8fj1OnTt3yHEdHR0gkEhQVFTV47MYxJyenO3gndLdS1BpIAEQFsJ+ciIiIWofCzgpTh0bh+ccikVtYgX9/ewQ/H7rU5pOrLe2OZ8pVKhWSkpKwadMmaDQauLq64plnnsGoUaPQoUMHAMClS5fw8ssv4+OPP8bAgQOb9Ly3u2nU2toafn5+yMjIaPBYRkYGXFxc4OrKUCiGFJUGHb0UUNjdum2JiIiI6G5JJBL0iPBAWAcnfLf9LH7crcLxjDw8MzgcXq7NmzU3Fs0O5UlJSUhKStLPZvfq1QujRo3CgAEDIJMZPp2/vz/Gjx+PWbNmNem58/LysH///tsukThw4ECsWLECeXl5+mUZi4qKsHv3bjzyyCPNfUvUAkoraqC+WoJHe3cUuxQiIiIyE472ckwfHo1DZ3KwYkcG/v3tEQy7LxAPdvODVNqyrc6trdmhfNasWXBzc8PkyZMxcuTI2270ExwcjISEhAbHX331Vfj5+SEyMhIKhQJqtRqLFy9GVVUVZsyYoT9v/PjxOHz4MM6ePas/NmnSJGzatAmTJ0/GtGnTIJPJsHDhQshkMkyZMqW5b4lawOkLBRAAxAS5iV0KERERmRGJRIJ7Iz0R5u+M77adxZrd5+tnzR8Jh6eLrdjlNVmzQ3liYiL69+8PCwuLJp0fExODmJiYBsdDQ0OxZcsWLF++HJWVlXByckL37t3xwgsvNLrc4Z+5ublhxYoV+Oijj/D6669DEATExcVh+fLljd5USq0vWa2BvY0lOno5iF0KERERmSEnezleHBGNg6frZ83/9c1hjOgTiIFd28esebND+a5du+Du7n7LJQuTk5OxatUqfPDBB3/7PJMnT8bkyZNv+3rff/99o8c7duyIhQsX3r5ganU6nYBUdQGiA10gbeFVcYiIiIiaSiKRoGfUjVnzdPyw6zyOXZ8193A27lnzZq++sn79+r/dJOjy5cvYsGHD3dRE7cyF7BKUVdYiOog32BIREZH4nB3k+MfjMZj0SDgu55XjX0sOY8fRLOxPvYbXvtiHx17diNe+2IcDp7PFLlXvrtYpb0xFRUWDGz7JtKWoNJBIuBQiERERGQ+JRILe0V6I6OiCZdvSsWrnOUgkwI1tMzUl1Vj2czoAoGekp4iV1mtSer569SquXLmi/1qtVuPIkSMNzisuLsaqVavg7+/fchWS0UtRaxDorYC9jaXYpRAREREZcHaQ46XHY/CP//2B8iqtwWM1Wh3W7VG1n1C+bt06LFiwABKJBBKJBF9++SW+/PLLBucJggCpVIo5c+a0eKFknErKa3DhWimG3RcgdilEREREjZJIJA0C+Q2akuo2rqZxTQrlAwcOhI+PDwRBwD//+U+MGjUKsbGxBudIJBLY2toiOjoaXl5erVIsGZ/UCxoAYD85ERERGTVXhbzRAO6qkItQTUNNCuVhYWEICwsDUN/K8uCDD9522UIyD8kqDRR2VujgwaUQiYiIyHgN7xuEZT+no0Z7c/d4K5kUw/sGiVjVTc2+I3P69OmtUQe1Q3U6HU5fKECXYDcuhUhERERG7Ubf+Lo9KhSUVMNFIcfwvkFG0U8ONCGU37ihs1u3bgZf386N88l0XbhaivIqLVtXiIiIqF3oGemJnpGeUCodkJdXKnY5Bm4bysePHw+JRIJTp07ByspK//WtCIIAiUSCtLS0Fi2UjE+yOh9SiQSRAS5il0JERETUrt02lM+ZMwcSiQSWlvXL3d1up04yH8kqDYJ8FLCz5lKIRERERHfjtqF8+PDhBl8PGzas1Yqh9qOorBqZOWUY0TdQ7FKIiIiI2j1pazxpaalx9ehQy0tRX18KMZD95ERERER3q9mhfOLEicjLy7vl48eOHUNCQsJdFUXGL0VdACd7K/i524tdChEREVG71+xQfuLECSQkJGDPnj0GxwVBwOeff46JEydCEIQWK5CMj7aufinE6EDXv73pl4iIiIiaptmhfM2aNXBycsKUKVPwwQcfoLa2Fjk5OZgwYQISExNx//33Y8OGDa1QKhkL1ZViVFZr2bpCRERE1EKavXlQWFgY1q1bh/fffx/Lli3DgQMHkJubi8rKSrzzzjsYO3Zsa9RJRiRFXQALqQQRHbkUIhEREVFLaHYoBwBra2u89957uHjxIo4fPw6JRIJZs2YxkJuJZJUGnXwdYWt9R/98iIiIiOgv7mj1lczMTDzxxBM4ceIEHn30UXh5eWHOnDn4/PPP2U9u4gpKqnA5r4ytK0REREQtqNmhfNOmTRg2bBgyMzPx6aef4uOPP8bGjRsxYMAAJCYmYsKECcjNzW2NWskIpF4oAABEBzGUExEREbWUZofy119/HcHBwVi/fj0efvhhAICDgwPmz5+Pf/3rX0hJSeGSiCYsWaWBi0IOHzc7sUshIiIiMhnNDuWTJk3CihUr4Ovr2+CxMWPGYM2aNXBzc2uR4si4aOt0OHORSyESERERtbRm36n32muv/e3jISEhSEpKuuOCyHidu1yMqpo6xLCfnIiIiKhF3fHyGUeOHMHevXuh0Wjw9NNPIygoCOXl5Thz5gxCQ0Mhl8tbsk4yAikqDSykEoT5O4tdChEREZFJaXYor6urw6uvvort27dDEARIJBI88sgjCAoKgkwmw7Rp0/DMM89gypQprVEviShFrUGInxNs5FwKkYiIiKglNbunfPHixfjll1/w5ptvYuvWrQZLIMrlcgwcOBB79uxp0SJJfPnFlbiSX44YrrpCRERE1OKaHco3bNiAhIQETJw4Ec7ODdsYgoKCkJWV1SLFkfFIUV9fCpH95EREREQtrtmh/MqVK4iNjb3l4wqFAsXFxXdVFBmfFJUGbo7W8HK1FbsUIiIiIpPT7FBuZ2eHoqKiWz5+6dIluLi43E1NZGRqtTqkXSpEdBCXQiQiIiJqDc0O5XFxcfjpp58MeslvKC4uxtq1a9GjR48WKY6MQ8blIlTX1rF1hYiIiKiVNDuUT5kyBRcvXsSECRPw22+/AQDOnj2LH374AcOGDUNlZSUmT57c0nWSiFJUGsgspAjvwKUQiYiIiFpDs9e2i46OxoIFC/D222/jrbfeAgB89NFHEAQBrq6uWLBgAYKDg1u8UBJPskqD0A5OkFtZiF0KERERkUm6owWn+/bti127dmHfvn1QqVQQBAEdO3ZEfHw8bGxsWrpGElFuUSWyCyrQL9ZH7FKIiIiITNYd7wJjZWWFfv36oV+/fi1ZDxmZFJUGALg+OREREVEranZPOZmXFLUG7k428HDhUohEREREreW2M+UTJkxo9pNKJBIsW7bsjgoi41FTW4f0S4W4r7O32KUQERERmbTbhvLLly+3RR1khM5mFaFGq2PrChEREVEru20o37VrV1vUQUYoRaWBpUyKUD8nsUshIiIiMmnsKadbSlZrEO7vDCtLLoVIRERE1JruePUVAFCr1cjKygIA+Pn5ITAwsEWKIvHlFFQgt7ASD3T1E7sUIiIiIpN3R6H8wIEDmD17NtRqtcHxwMBAzJo1Cz179myR4kg8yer6pRCj2U9ORERE1OqaHcoPHDiA5557DpaWlhg5ciSCg4MhCAJUKhU2b96M5557DosXL2Ywb+dSVBp4utjC3YmbQRERERG1tmaH8nnz5sHV1RVr1qyBh4eHwWNTp07FqFGj8NlnnzGUt2PVtXVIzyziLp5EREREbaTZN3qePXsWo0ePbhDIAcDT0xOjR49Genp6ixRH4ki/VAhtHZdCJCIiImorzQ7lDg4OsLOzu+Xj9vb2cHBwuKuiSFzJag2sLKUI4VKIRERERG2i2aH8oYcewpYtW6DVahs8Vltbiy1btuChhx5qkeKo7QmCgBSVBhH+LrCUccVMIiIiorbQ7J7yJ554AsePH8e4ceMwceJEBAYGQiKR4Pz581i2bBnq6uowZswYXL161eA6b29u1d4eZBdUIL+4Cg/f6y92KURERERmo9mhfMiQIZBIJBAEAadOnTJ4TBAE/Tl/lZaWdoclUltKVl1fCjHQReRKiIiIiMxHs0P5tGnTIJFIWqMWMgIpag283ezg5silEImIiIjaSrND+YsvvtgadZARqKrR4mxmEXfxJCIiImpjzbqTr7y8HBMmTMCPP/7YWvWQiNIuFqJOJ7B1hYiIiKiNNSuU29nZISUlpbVqIZGlqDWQW1mgE5dCJCIiImpTzV7zLjw8HGq1ujVqIREJgoBktQaRHV0gs+BSiERERERtqdnp68UXX8SaNWtw8ODB1qiHRHI1vxwFJdVsXSEiIiISQbNv9Ny0aRO8vb3x9NNPIywsDB07doS1tbXBORKJBHPmzGmxIqn1JatvLIXoKnIlREREROan2aF8/fr1+j+npaU1uv44Q3n7k6LSwFdpBxeF9e1PJiIiIqIW1exQnp6e3hp1kIgqq7U4d7kYD3bnUohEREREYuAdfYQzFwtQpxMQw9YVIiIiIlE0e6b8hoqKCpw8eRL5+fno1asX3NzcWrIuakPJKg1s5BYI8nEUuxQiIiIis3RHM+UrV65Enz598Mwzz+CNN97AuXPnAAAFBQWIjo7G6tWr76iYxMREhIaGIiEhocnn/vW/3r1739FrmytBEJDCpRCJiIiIRNXsmfLt27fj/fffx4ABA9CvXz/MmjVL/5iLiwvuu+8+/Prrrxg9enSznvfcuXNYvHhxs2fcv/32W9ja2uq/trS0bNb15i4rtwxFZTWIDmLrChEREZFYmh3KlyxZgh49euDzzz9HYWGhQSgHgKioKPz444/Nek6dToe3334bI0eOREZGBkpKSpp8bVRUFBQKRbNej25K4VKIRERERKJrdr9CRkYGHnjggVs+rlQqodFomvWcS5cuRXZ2Nl555ZXmlkN3KUWlQQcPezjZy8UuhYiIiMhsNTuUS6VS6HS6Wz6em5sLGxubJj9fVlYW5s+fj3fffRf29vbNLQeDBw9GeHg44uPjMWvWrGZ/IDBnFVW1OH+lhLPkRERERCJrdvtKWFgY9u7diwkTJjR4TKfTYdu2bYiOjm7ScwmCgFmzZiE+Ph4DBw5sVh1+fn6YMWMGwsPDYWlpiePHj+Prr7/GgQMHsG7dOjg6ciWR2zl9sRA6QUAM+8mJiIiIRNXsUD5u3DjMmDEDn332GYYOHQqgPlyr1WrMmzcP58+fx8yZM5v0XGvWrEFqaiq2bt3a3DL0r31Dz5490aVLFzzzzDNYsWIFpk6d2qznc3Vt/ix9S1AqHUR5XQDI+PUc7G0s0SPGBxZGsvKKmONhjDgeN3EsDHE8DHE8buJYGOJ43MSxMGRs49HsUD548GCcPXsWX375JRYtWgQAePbZZyEIAgRBwIsvvoi+ffve9nkKCgrw8ccf4/nnn4eNjY3+5k6tVgudToeSkhLI5XLI5U3vde7duzeUSiVOnjzZ3LcFjaYMOp3Q7OvuhlLpgLy80jZ9zRt0goAjZ3IQ0dEZBQXlotTwV2KOhzHieNzEsTDE8TDE8biJY2GI43ETx8KQWOMhlUpuORHcrFBeUFCArKwsjBgxAoMGDcKmTZugVqshCAL8/f2RkJDQ5NaVnJwclJaWYu7cuZg7d26Dx7t164bnnnuuybPuNwiCAKnUOGZ9jVlWThlKymvYT05ERERkBJoUynU6Hf79738jKSkJglA/m9ylSxd8/vnncHFxuaMX7tChA7777rsGx+fMmYOKigrMnj0b3t7ezXrOvXv3Ij8/H507d76jmsxJsiofABDFUE5EREQkuiaF8uXLl2PNmjVwd3dHly5dcOnSJZw4cQLvvvsuFixYcEcvbGdnhx49ejQ4fmPN8T8/Nn78eBw+fBhnz57VHxs6dCiGDh2KgIAAyGQynDhxAkuWLIG/vz/Gjh17RzWZkxR1ATp6OsDRzkrsUoiIiIjMXpNC+YYNGxAUFITVq1frly2cNWsW1q9fj5KSElE27wkMDMTKlSuRm5sLrVYLT09PjBw5ElOnTuVmQrdRVlkL1dViPNqro9ilEBERERGaGMovXLiAadOmGawjPm7cOCQlJeHixYuIiYlpsYK+//77Jh379NNPW+w1zU3qBQ0Egbt4EhERERmLJt0RWVlZCXd3d4NjN76uqKho+aqoVaWoCmBvY4kAL/5GgYiIiMgYNHmZEolE0ujXN278pPZBJwhIvaBBVKALpFLJ7S8gIiIiolbX5CUR9+zZg/z8fP3XlZWVkEgk2LZtG9LT0w3OlUgkeOqpp1qsSGo5l7JLUVpRy9YVIiIiIiPS5FC+efNmbN68ucHx1atXNzjGUG68klUaSABEBdzZUpZERERE1PKaFMobW0+c2qdklQYB3go42HIpRCIiIiJj0aRQ3r1799aug9pASUUNLl4rQUJ8gNilEBEREdGfcD96M3JaXQABQHQQ+8mJiIiIjAlDuRlJVmugsLWEv6eD2KUQERER0Z8wlJsJnU5AqlqDqEBXSCVcCpGIiIjImDCUmwn1tRKUV2kRw9YVIiIiIqPDUG4mUlQaSCRAREcuhUhERERkbBjKzUSyWoMgH0fY21iKXQoRERER/QVDuRkoLqvGpexS7uJJREREZKQYys1A6oUCAEAMQzkRERGRUWIoNwPJKg0c7a3QwcNe7FKIiIiIqBEM5SauTqfD6QsFiA5whYRLIRIREREZJYZyE6e6UoKKai6FSERERGTMGMpNXIpaA6lEwqUQiYiIiIwYQ7mJS1FpEOzrCFtrmdilEBEREdEtMJSbsMLSamTmlrF1hYiIiMjIMZSbsBS1BgC4PjkRERGRkWMoN2Epag2cHeTwVdqJXQoRERER/Q2GchOlrbu+FGIgl0IkIiIiMnYM5Sbq/OViVNXUsXWFiIiIqB1gKDdRKWoNLKQSRHR0FrsUIiIiIroNhnITlazWIMTPCTZyLoVIREREZOwYyk1QQUkVruSVs3WFiIiIqJ1gKDdByTeWQuT65ERERETtAkO5CUpRaeCqkMPb1VbsUoiIiIioCRjKTUytVoczlwoRHeTGpRCJiIiI2gmGchNz7nIRqmvqEMN+ciIiIqJ2g6HcxCSrNJBZSBDuz6UQiYiIiNoLhnITk6LWINTPCXIrC7FLISIiIqImYig3IflFlbimqUB0kJvYpRARERFRMzCUm5CUG0shBrqIXAkRERERNQdDuQlJVmmgdLKGpwuXQiQiIiJqTxjKTUSttg5plwoRHejKpRCJiIiI2hmGchNxNqsINVodYriLJxEREVG7w1BuIpJVGljKpAjtwKUQiYiIiNobhnITkaLSILSDE+SWXAqRiIiIqL1hKDcBOYUVyCms5C6eRERERO0UQ7kJSFFdXwqR/eRERERE7RJDuQlIURfAw9kGHs5cCpGIiIioPWIob+eqa+uQnlnIWXIiIiKidoyhvJ07m1mIWq2O/eRERERE7RhDeTuXoiqAlUyK0A5OYpdCRERERHeIobwdEwQByep8hPs7w1LGpRCJiIiI2iuG8nYsu6ACeUVV7CcnIiIiaucYytuxFHUBACCa/eRERERE7RpDeTuWosqHl6stlE42YpdCRERERHeBobydqq6pw9msIs6SExEREZkAhvJ2Ku1SIbR1AmLYT05ERETU7jGUt1PJag3klhbo5OskdilEREREdJcYytshQRCQotIgoqMzLGX8KyQiIiJq75jo2qGrmgpoSrgUIhEREZGpYChvh1JUGgBADG/yJCIiIjIJDOXtUIpaAx+lHVwU1mKXQkREREQtgKG8nams1iIjq4iz5EREREQmxKhCeWJiIkJDQ5GQkNCk8zMzMzF16lTExcUhNjYWzz33HM6fP9/KVYor7VIh6nQC1ycnIiIiMiFGE8rPnTuHxYsXw83NrUnnazQaPPnkk7hy5Qo++ugjfPrppyguLsa4ceOQnZ3dytWKJ1mlgbWVBYJ9HcUuhYiIiIhaiFGEcp1Oh7fffhsjR45EYGBgk65ZsmQJSkpKsGjRIgwcOBD9+vXDV199hZqaGixcuLCVKxaHIAhIUWsQ2dEFMguj+KsjIiIiohZgFMlu6dKlyM7OxiuvvNLka3bu3IlevXrBw8NDf8zZ2Rn9+vXDjh07WqNM0V3JK0dhaTWXQiQiIiIyMaKH8qysLMyfPx/vvvsu7O3tm3RNVVUVMjMzERIS0uCx0NBQaDQaaDSali5VdMnq+vfEfnIiIiIi0yJqKBcEAbNmzUJ8fDwGDhzY5OuKi4shCAIcHRv2VTs5OQEAioqKWqhK45Gs0sDP3R7ODnKxSyEiIiKiFiQT88XXrFmD1NRUbN269Y6ul0gkLVaLq2vTZulbmlLp0KTzyitrcf5KMUb0C27yNe2RKb+3O8HxuIljYYjjYYjjcRPHwhDH4yaOhSFjGw/RQnlBQQE+/vhjPP/887CxsUFJSQkAQKvVQqfToaSkBHK5HHJ5w1lhR0dHSCSSRmfDbxy7MWPeVBpNGXQ6oblv464olQ7Iyytt0rlH03Oh0wkI8mz6Ne1Nc8bDHHA8buJYGOJ4GOJ43MSxMMTxuIljYUis8ZBKJbecCBYtlOfk5KC0tBRz587F3LlzGzzerVs3PPfcc5g5c2aDx6ytreHn54eMjIwGj2VkZMDFxQWurqbVd52s1sBWLkOQj0LsUoiIiIiohYkWyjt06IDvvvuuwfE5c+agoqICs2fPhre39y2vHzhwIFasWIG8vDwolUoA9bPku3fvxiOPPNJqdYtBEASkqDSIDHCBhVT0e3OJiIiIqIWJFsrt7OzQo0ePBscVivqZ4D8/Nn78eBw+fBhnz57VH5s0aRI2bdqEyZMnY9q0aZDJZFi4cCFkMhmmTJnS+m+gDWXmlKG4vIarrhARERGZqHY77erm5oYVK1bA09MTr7/+Ol555RU4ODhg+fLlfzvD3h6l6JdCdBG5EiIiIiJqDaKuvtKY77//vknHAKBjx44mu3vnnyWrNfD3dICjPZdCJCIiIjJF7Xam3FyUVdZCdaWYrStEREREJoyh3MiduVgAQQBighjKiYiIiEwVQ7mRS1ZpYGctQ6AXl0IkIiIiMlUM5UZMJwhIVWsQFegKqbTldi8lIiIiIuPCUG7ELmWXoqSiFjHsJyciIiIyaQzlRixFpYEEQCSXQiQiIiIyaQzlRixFrUFHLwUUtlZil0JERERErYih3EiVVtRAfbWEq64QERERmQGGciN1+kIBBIDrkxMRERGZAYZyI5Ws1sDB1hIdvRzELoWIiIiIWhlDuRHS6QSkqgsQFeAKqYRLIRIRERGZOoZyI3QhuwRllbWIDuKqK0RERETmgKHcCKWoNJBIgKgA9pMTERERmQOGciOUrNIg0FsBextLsUshIiIiojbAUG5kistrcDG7lLt4EhEREZkRhnIjk6rWAABigtxEroSIiIiI2gpDuZFJUWugsLOCn4e92KUQERERURthKDcidTodTl8oQHSgC5dCJCIiIjIjDOVGRH21BOVVWrauEBEREZkZhnIjkqLWQCqRILKjs9ilEBEREVEbYig3IskqDYJ9FLC15lKIREREROaEodxIFJVVIzOnDNFBXAqRiIiIyNwwlBuJlOtLIUZzfXIiIiIis8NQbiRSVBo42VvBz51LIRIRERGZG4ZyI6Ct0+H0xUJEB7pCwqUQiYiIiMwOQ7kRUF0pRmW1FjHsJyciIiIySwzlRiBZrYGFVIKIji5il0JEREREImAoNwIpqgJ08nWEjVwmdilEREREJAKGcpEVlFThch6XQiQiIiIyZwzlIuNSiERERETEUC6yFHUBXBRy+LjZiV0KEREREYmEoVxEtVodTl8sQAyXQiQiIiIyawzlIkq7qEF1TR1bV4iIiIjMHJf7EMGB09lYt0cFTUk1AKC0skbkioiIiIhITAzlbezA6Wws+zkdNVqd/tjKHedgKbNAz0hPESsjIiIiIrGwfaWNrdujMgjkAFCj1WHdHpVIFRERERGR2BjK29iNlpWmHiciIiIi08dQ3sZcFfJmHSciIiIi08dQ3saG9w2Clcxw2K1kUgzvGyRSRUREREQkNt7o2cZu3My5bo8KBSXVcFHIMbxvEG/yJCIiIjJjDOUi6BnpiZ6RnlAqHZCXVyp2OUREREQkMravEBERERGJjKGciIiIiEhkDOVERERERCJjKCciIiIiEhlDORERERGRyBjKiYiIiIhExlBORERERCQyhnIiIiIiIpExlBMRERERiYw7el4nlUrM6nWNFcfDEMfjJo6FIY6HIY7HTRwLQxyPmzgWhsQYj797TYkgCEIb1kJERERERH/B9hUiIiIiIpExlBMRERERiYyhnIiIiIhIZAzlREREREQiYygnIiIiIhIZQzkRERERkcgYyomIiIiIRMZQTkREREQkMoZyIiIiIiKRycQuwNxkZ2fj66+/xunTp5Geno6Kigp899136NGjh9iltbkDBw5g48aNOHHiBLKzs+Ho6IiYmBi8+OKLCA0NFbu8Nnf8+HF8/vnnyMjIQFFREezs7BASEoJJkyahb9++YpcnusTERCxYsABhYWHYuHGj2OW0qUOHDmHChAmNPrZ161YEBQW1cUXiO3ToEL766iskJyejtrYWPj4+mDhxIkaPHi12aW3qzTffxPr162/5+N69e6FUKtuwIvGdOXMGCxYsQHJyMsrKyuDt7Y2hQ4fiqaeegpWVldjltaljx47hf//7H5KTkyGVShEXF4eZM2ea/M/Y5mStffv24X//+x/S09NhZ2eHBx54ADNnzoRCoWjzuhnK29ilS5ewZcsWRERE4N5778WuXbvELkk0q1atQlFREZ566ikEBQUhPz8fX3/9NR5//HF8//336NKli9gltqmSkhIEBARg+PDhcHNzQ0lJCVavXo3Jkyfj008/xSOPPCJ2iaI5d+4cFi9eDDc3N7FLEdXMmTPRrVs3g2O+vr4iVSOe9evX4+2338bIkSPx1FNPwdLSEmq1GrW1tWKX1uamTp2KJ554wuCYVqvFpEmTEBoaanaBXKVS4YknnkBAQAD++c9/wtnZGQcPHsS8efNw/vx5/Pe//xW7xDZz8uRJTJw4EZ07d8Ynn3wCnU6HRYsWYdy4cUhKSoK/v7/YJbaapmatQ4cOYfLkyRgwYABefvll5Obm4pNPPkFGRgZWrlwJqbSNG0oEalN1dXX6P+/YsUMICQkRDh48KGJF4snPz29wrLi4WOjataswffp0ESoyPrW1tUKfPn2E8ePHi12KaOrq6oSRI0cK77//vjBu3DjhscceE7ukNnfw4EEhJCRE2LFjh9iliO7q1atCTEyMsGjRIrFLMVrbt28XQkJChNWrV4tdSpubP3++EBISIly6dMng+MyZM4WIiAihpqZGpMra3tNPPy307t1bqKys1B8rLi4WunXrJsyYMUPEylpfU7PWiBEjhISEBIPz9+7dK4SEhAhbtmxpk1r/jD3lbazNP3UZMVdX1wbHFAoF/P39kZ2dLUJFxkcmk8HBwQGWlpZilyKapUuXIjs7G6+88orYpZARSEpKAgCMHz9e5EqM19q1a2FjY4PBgweLXUqbk8nqGwDs7e0Njjs4OEAmk8HCwkKMskRx4sQJ3HvvvbC2ttYfUygUiIuLw6+//oq6ujoRq2tdTclaOTk5SElJQUJCgsH5vXv3hoeHB7Zv396aJTaKCZGMSkFBAc6dO4dOnTqJXYpodDodtFotcnJyMH/+fFy8eBETJ04UuyxRZGVlYf78+Xj33Xcb/JA1R++++y4iIiIQFxeH559/HqmpqWKX1OaOHDmCoKAg/PLLLxg0aBDCw8PRp08ffPLJJ6ipqRG7PNHl5ubijz/+wKBBg8zy/zMJCQlwcnLCv//9b2RlZaGsrAw7d+7E+vXr8fTTT5vVxFhtbW2jPfRWVlaorKxEVlaWCFUZj4yMDABoNG+EhITg3LlzbV0Se8rJeAiCgHfeeQc6nQ6TJk0SuxzRvPzyy/pP6Pb29vjss8/Qp08fkatqe4IgYNasWYiPj8fAgQPFLkdUDg4OmDhxIrp37w4nJyeoVCosWrQIY8aMwfLly9G5c2exS2wzubm5yM3NxezZs/HSSy8hODgYBw8exKJFi3Dt2jXMnTtX7BJFtWHDBtTV1eHxxx8XuxRReHt7Y/Xq1Zg2bZrB940pU6bg5ZdfFq8wEQQHB+PUqVMQBAESiQRAfVBPSUkBABQWFqJjx44iViiuoqIiAICjo2ODxxwdHXHmzJk2roihnIzIf//7X+zcuRMffPCBWa4mccNrr72GZ599Fvn5+di8eTNefvllfPjhhxgyZIjYpbWpNWvWIDU1FVu3bhW7FNFFREQgIiJC/3XXrl3Rv39/DBkyBPPmzcPSpUvFK66NCYKA8vJyg5ufe/TogaqqKnzzzTf4xz/+YdI3sN3OunXr4O/v3+CGYHNx5coVTJkyBUqlEp9//jkcHBxw5MgRfPXVV5BIJGYVzMeNG4e3334bs2fPxuTJk6HT6TB//nx9e6g5/dbg79z4wNLU462JoZyMwrx58/DNN9/g7bffxvDhw8UuR1R+fn7w8/MDAPTv3x9TpkzB+++/j8GDB5vNN9GCggJ8/PHHeP7552FjY4OSkhIA9atK6HQ6lJSUQC6XQy6Xi1ypeJRKJeLj481uBScnJycAQHx8vMHxPn364JtvvsHp06fNNpQfPXoUFy5cMOv7L+bOnYvy8nJs2LBB30t9Yxm8zz//HI8//rjZrFj0+OOPo6CgAAsXLsTy5csBALGxsXjmmWewePFiuLu7i1yhuG58L7kxY/5nxcXFjc6gtzbz+AlPRu1///sfvvzyS7z22mu3XIvZnEVHR6O4uBgFBQVil9JmcnJyUFpairlz56Jbt276/44fP46MjAx069YNiYmJYpcpOp1OJ3YJbS4kJORvHzeXD66NWbt2LSwsLDBs2DCxSxHNmTNnEBwcbHBzIwBERUVBp9NBrVaLVJk4Jk+ejEOHDuGnn37Crl278MMPP6C4uBg+Pj7w8vISuzxR3eglb6x3PCMjQ5R72zhTTqJasGABvvjiC7z00kt49tlnxS7H6AiCgMOHD0OhUOg/1ZuDDh064LvvvmtwfM6cOaioqMDs2bPh7e0tQmXGIy8vD/v37ze79fwfeOABrFmzBnv27MFjjz2mP75nzx5IJBJER0eLWJ14KioqsG3bNsTHx8PDw0PsckTj7u6Oc+fOobKyEjY2NvrjJ06cAACzHBsrKyv9h9nLly9j69atmDp1qshVic/T0xNRUVH46aefMHHiRP0H+gMHDiAnJwcPPvhgm9fEUC6Cbdu2AYD+ZosjR46gsLAQNjY2ZrVz4zfffIPExET069cPvXr1wsmTJ/WPWVlZGfTQmoNXX30VPj4+iIyMhLOzM/Ly8rB+/XocPHgQ77zzjn6pL3NgZ2fX6M5rN3ZYM7cdcF999VX4+fkhMjISCoUCarUaixcvRlVVFWbMmCF2eW2qT58+6NOnD95//30UFhaiU6dOOHjwIL777js88cQT8PHxEbtEUWzduhUVFRUYMWKE2KWIasKECZg2bRomTZqEiRMnwsHBAYcOHcKSJUvQq1cvk9/J8s/S09Oxc+dOREVFwcrKCmlpaVi0aBFiYmLMYkWvpmStmTNnYtKkSZgxYwZGjx6NnJwcfPLJJ+jcuTMeeuihNq9ZIgiC0OavauZu9U3Bx8fHrPpDx48fj8OHDzf6mLmNBQAsX74cP/30Ey5evIjS0lI4ODggKioKY8eORf/+/cUuzyiMHz8eJSUl2Lhxo9iltKlFixZhy5YtuHLlCiorK+Hk5ITu3bvjhRdeuG07hymqqKhAYmIiNm/ejMLCQnh5eWHkyJF49tlnzbZ95cknn4RarcYff/xh1vsaAMD+/fuxaNEiZGRkoKKiAj4+Phg8eDCefvpp2Nrail1em1GpVHj33Xdx7tw5VFRUwM/PD0OHDsXTTz/d6FKJpqapWev3339HYmIi0tPTYWdnh4EDB+K1114TpaecoZyIiIiISGTmOaVARERERGREGMqJiIiIiETGUE5EREREJDKGciIiIiIikTGUExERERGJjKGciIiIiEhkDOVERCSa8ePHcx1+IiJwR08iIpNz6NAhTJgw4ZaPW1hY4MyZM21YERER3Q5DORGRiRoyZAj69OnT4Li57npJRGTMGMqJiExUREQEEhISxC6DiIiagNMlRERm6vLlywgNDUViYiI2b96MRx99FNHR0bj//vuRmJgIrVbb4Jr09HRMmzYNPXr0QHR0NAYPHozFixejrq6uwbl5eXmYPXs2BgwYgKioKPTs2RNPP/009u3b1+DcnJwczJgxA926dUOXLl0wadIkXLhwoVXeNxGRMeJMORGRiaqsrERBQUGD41ZWVrC3t9d/vXv3bixbtgxjx46Fm5sbdu3ahQULFuDq1av44IMP9OelpKRg/PjxkMlk+nN3796NTz75BOnp6Zg7d67+3MuXL2PMmDHQaDRISEhAVFQUKisrcerUKezfvx+9e/fWn1tRUYFx48ahc+fOeOWVV3D58mV89913mDp1KjZv3gwLC4tWGiEiIuPBUE5EZKISExORmJjY4Pj999+Pr776Sv91WloakpKSEBkZCQAYN24cpk+fjnXr1mH06NHo0qULAOD//u//UFNTgx9++AFhYWH6c19++WVs3rwZjz/+OHr27AkAeO+995Cbm4uvv/4a9913n8Hr63Q6g68LCwsxadIkPPfcc/pjLi4u+Pjjj7F///4G1xMRmSKGciIiEzV69Gg89NBDDY67uLgYfN2rVy99IAcAiUSCZ599Fjt37sSOHTvQpUsXaDQanDhxAg888IA+kN84d8qUKdi2bRt27NiBnj17oqioCH/88Qfuu+++RgP1X280lUqlDVaLuffeewEAly5dYignIrPAUE5EZKL8/f3Rq1ev254XFBTU4FhwcDAAICsrC0B9O8qfj//1eqlUqj83MzMTgiAgIiKiSXW6u7tDLpcbHHNycgIAFBUVNek5iIjaO97oSURk5iQSyW3PEQShyc9349ymPC+Av+0Zb87rEhG1ZwzlRERm7vz587c85ufnZ/C/jZ2rVquh0+n05/j7+0MikXCDIiKiZmAoJyIyc/v378fp06f1XwuCgK+//hoAMHDgQACAq6srYmNjsXv3bmRkZBicu2jRIgDAAw88AKC+9aRPnz74/fffsX///gavx9lvIqKG2FNORGSizpw5g40bNzb62I2wDQBhYWGYOHEixo4dC6VSiV9//RX79+9HQkICYmNj9ee9/fbbGD9+PMaOHYsnn3wSSqUSu3fvxt69ezFkyBD9yisA8M477+DMmTN47rnnMHToUERGRqK6uhqnTp2Cj48PXnvttdZ740RE7RBDORGRidq8eTM2b97c6GO//PKLvpe7f//+CAgIwFdffYULFy7A1dUVU6dOxdSpUw2uiY6Oxg8//ID58+dj1apVqKiogJ+fH2bOnIlnnnnG4Fw/Pz+sXbsWn3/+OX7//Xds3LgRCoUCYWFhGD16dOu8YSKidkwi8PeIRERm6fLlyxgwYACmT5+OF198UexyiIjMGnvKiYiIiIhExlBORERERCQyhnIiIiIiIpGxp5yIiIiISGScKSciIiIiEhlDORERERGRyBjKiYiIiIhExlBORERERCQyhnIiIiIiIpExlBMRERERiez/AT/gwrbuqKfzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "act_per = [x['action_perplexity'] for x in df_stats.metrics]\n",
    "x_ticks = [x for x in range(len(act_acc))]\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(act_per, 'b-o')\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Actions perplexity\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Perplexity\")\n",
    "plt.xticks(ticks = x_ticks, labels = [str(x+1) for x in x_ticks])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bea685a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
