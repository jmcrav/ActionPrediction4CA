{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   action_accuracy  action_perplexity  attribute_accuracy  \\\n",
      "0         0.840467           4.647734            0.760981   \n",
      "0         0.844543           4.939461            0.763818   \n",
      "0         0.851399           3.448803            0.776654   \n",
      "0         0.845655           4.842728            0.771190   \n",
      "0         0.841949           4.911037            0.757051   \n",
      "\n",
      "                                    confusion_matrix  params.batch  \\\n",
      "0  [[751.0, 53.0, 9.0, 7.0, 18.0], [23.0, 1084.0,...            12   \n",
      "0  [[749.0, 46.0, 12.0, 10.0, 13.0], [26.0, 1081....            12   \n",
      "0  [[746.0, 49.0, 10.0, 4.0, 11.0], [27.0, 1084.0...            12   \n",
      "0  [[742.0, 45.0, 13.0, 13.0, 15.0], [29.0, 1086....            12   \n",
      "0  [[750.0, 45.0, 16.0, 11.0, 12.0], [21.0, 1089....            12   \n",
      "\n",
      "   params.epochs  params.hidden_output_dim  params.seed  params.learning_rate  \\\n",
      "0             10                       256      9555209               0.00005   \n",
      "0             10                       256       971371               0.00005   \n",
      "0             10                       256      8287925               0.00005   \n",
      "0             10                       256      2213980               0.00005   \n",
      "0             10                       256      1298636               0.00005   \n",
      "\n",
      "   params.tolerance                                   category  \\\n",
      "0      1.000000e-08  B12-E10-H256-LR5e-05-eps1e-08-ACT-sigmoid   \n",
      "0      1.000000e-08  B12-E10-H256-LR5e-05-eps1e-08-ACT-sigmoid   \n",
      "0      1.000000e-08  B12-E10-H256-LR5e-05-eps1e-08-ACT-sigmoid   \n",
      "0      1.000000e-08  B12-E10-H256-LR5e-05-eps1e-08-ACT-sigmoid   \n",
      "0      1.000000e-08  B12-E10-H256-LR5e-05-eps1e-08-ACT-sigmoid   \n",
      "\n",
      "               filename params.action_activation  \n",
      "0  eval-20210815-142648                      NaN  \n",
      "0  eval-20210815-160400                      NaN  \n",
      "0  eval-20210815-174729                      NaN  \n",
      "0  eval-20210815-205317                      NaN  \n",
      "0  eval-20210815-222849                      NaN  \n",
      "(62, 13)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "curdir = Path('./statoutput')\n",
    "\n",
    "# Dati relativi alla validazione sul TEST SET\n",
    "test_validation_data = pd.DataFrame()\n",
    "for f in curdir.glob('eval*'):\n",
    "    filename = f.name\n",
    "    df = pd.read_pickle(f)\n",
    "    actfunc = df.get('params.action_activation', ['sigmoid'])\n",
    "    df['category'] = f\"B{df.at[0, 'params.batch']}-E{df.at[0, 'params.epochs']}-H{df.at[0, 'params.hidden_output_dim']}\\\n",
    "-LR{df.at[0, 'params.learning_rate']}-eps{df.at[0, 'params.tolerance']}-ACT-{actfunc[0]}\"\n",
    "    df['filename'] = filename\n",
    "    test_validation_data = pd.concat([test_validation_data, df])\n",
    "print(test_validation_data.head())\n",
    "print(test_validation_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Training Loss  Valid. Loss  Valid. Accur. class.  \\\n",
      "epoch                                                     \n",
      "1           1.133720     1.064887              0.845147   \n",
      "2           1.070569     1.071257              0.840307   \n",
      "3           1.054355     1.063280              0.845147   \n",
      "4           1.045294     1.057506              0.849986   \n",
      "5           1.038272     1.064757              0.841731   \n",
      "\n",
      "       Valid. Accur. mult.label Training Time Validation Time  \\\n",
      "epoch                                                           \n",
      "1                      0.895531       0:08:33         0:00:28   \n",
      "2                      0.906633       0:08:37         0:00:27   \n",
      "3                      0.920011       0:08:34         0:00:28   \n",
      "4                      0.921719       0:08:34         0:00:27   \n",
      "5                      0.932252       0:08:34         0:00:27   \n",
      "\n",
      "                                                 metrics  \\\n",
      "epoch                                                      \n",
      "1      {'action_accuracy': 0.8451465983489894, 'actio...   \n",
      "2      {'action_accuracy': 0.8403074295473953, 'actio...   \n",
      "3      {'action_accuracy': 0.8451465983489894, 'actio...   \n",
      "4      {'action_accuracy': 0.8499857671505835, 'actio...   \n",
      "5      {'action_accuracy': 0.8417307144890407, 'actio...   \n",
      "\n",
      "                    filename  \n",
      "epoch                         \n",
      "1      stats-20210815-142648  \n",
      "2      stats-20210815-142648  \n",
      "3      stats-20210815-142648  \n",
      "4      stats-20210815-142648  \n",
      "5      stats-20210815-142648  \n",
      "(388, 8)\n"
     ]
    }
   ],
   "source": [
    "# Dati relativi al training\n",
    "training_stat = pd.DataFrame()\n",
    "for f in curdir.glob('stats*'):\n",
    "    filename = f.name\n",
    "    df = pd.read_pickle(f)\n",
    "    df['filename'] = filename\n",
    "    training_stat = pd.concat([training_stat, df])\n",
    "print(training_stat.head())\n",
    "print(training_stat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dati relativi alla validazione durante il training\n",
    "validation_data = pd.DataFrame()\n",
    "for f in curdir.glob('testdata*'):\n",
    "    filename = f.name\n",
    "    df = pd.read_pickle(f)\n",
    "    df['filename'] = filename\n",
    "    validation_data = pd.concat([validation_data, df])\n",
    "print(validation_data.head())\n",
    "print(validation_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisi dati per selezione da test dei casi scelti per recupero dati migliore esecuzione\n",
    "case_study = test_validation_data[test_validation_data['category']=='B12-E6-H768-LR5e-05-eps1e-08-ACT-softmax']\n",
    "print(case_study.shape)\n",
    "print(f\"MAX action accuracy: {max(case_study['action_accuracy'])}, MAX attribute accuracy: {max(case_study['attribute_accuracy'])}\")\n",
    "print(case_study)\n",
    "print('Äction accuracy order')\n",
    "print(case_study.sort_values(by=['action_accuracy']))\n",
    "print('Ättribute accuracy order')\n",
    "print(case_study.sort_values(by=['attribute_accuracy']))\n",
    "print('Order by act_acc+att_acc-act_per')\n",
    "arbitrary_choice = case_study['action_accuracy'] + case_study['attribute_accuracy'] - case_study['action_perplexity']\n",
    "case_study['arbitrary_choice'] = arbitrary_choice\n",
    "print(case_study.sort_values(by=['arbitrary_choice']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scelta in base a calcolo arbitrario\n",
    "choice = max(case_study['arbitrary_choice'])\n",
    "df_test_validation = case_study[case_study['arbitrary_choice']==choice]\n",
    "print(df_test_validation)\n",
    "filename = df_test_validation['filename'][0]\n",
    "training_filename = f\"stats{filename[4:]}\"\n",
    "validation_filename = f\"testdata{filename[4:]}\"\n",
    "print(f\"{training_filename} {validation_filename}\")\n",
    "df_training = training_stat[training_stat['filename']==training_filename]\n",
    "df_validation = validation_data[validation_data['filename']==validation_filename]\n",
    "print(f\"Dimensioni statistiche training: {df_training.shape}\")\n",
    "print(f\"Dimensioni statische validazione training: {df_validation.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confronto tra tutti i campioni del valore \"migliore\" con peso perplexity in centesimi\n",
    "df = test_validation_data.copy()\n",
    "arbitrary_choice = df['action_accuracy'] + df['attribute_accuracy'] - df['action_perplexity']/100\n",
    "df['arbitrary_choice'] = arbitrary_choice\n",
    "print(df.sort_values(by='arbitrary_choice', ascending=False).loc[:, ['action_accuracy', 'action_perplexity', 'attribute_accuracy', 'arbitrary_choice', 'category']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confronto tra tutti i campioni del valore \"migliore\" con peso perplexity in centesimi ma dimezzato\n",
    "df = test_validation_data.copy()\n",
    "arbitrary_choice = df['action_accuracy'] + df['attribute_accuracy'] - df['action_perplexity']/200\n",
    "df['arbitrary_choice'] = arbitrary_choice\n",
    "print(df.sort_values(by='arbitrary_choice', ascending=False).loc[:, ['action_accuracy', 'action_perplexity', 'attribute_accuracy', 'arbitrary_choice', 'category']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confronto tra tutti i campioni del valore \"migliore\" con peso perplexity in millesimi\n",
    "df = test_validation_data.copy()\n",
    "arbitrary_choice = df['action_accuracy'] + df['attribute_accuracy'] - df['action_perplexity']/1000\n",
    "df['arbitrary_choice'] = arbitrary_choice\n",
    "print(df.sort_values(by='arbitrary_choice', ascending=False).loc[:, ['action_accuracy', 'action_perplexity', 'attribute_accuracy', 'arbitrary_choice', 'category']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(df_training['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_training['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "epochs = df_test_validation['params.epochs'][0]\n",
    "plt.xticks([x+1 for x in range(epochs)])\n",
    "\n",
    "plt.savefig(f\"./plots/loss-{df_test_validation['category'][0]}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "act_acc = [x['action_accuracy'] for x in df_training.metrics]\n",
    "att_acc = [x['attribute_accuracy'] for x in df_training.metrics]\n",
    "x_ticks = [x for x in range(len(act_acc))]\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(act_acc, 'b-o', label=\"Actions\")\n",
    "plt.plot(att_acc, 'g-o', label=\"Attributes\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Actions and attributes accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.xticks(ticks = x_ticks, labels = [str(x+1) for x in x_ticks])\n",
    "\n",
    "plt.savefig(f\"./plots/accuracy-{df_test_validation['category'][0]}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "act_per = [x['action_perplexity'] for x in df_training.metrics]\n",
    "x_ticks = [x for x in range(len(act_per))]\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(act_per, 'b-o')\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Actions perplexity\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Perplexity\")\n",
    "plt.xticks(ticks = x_ticks, labels = [str(x+1) for x in x_ticks])\n",
    "\n",
    "plt.savefig(f\"./plots/perplexity-{df_test_validation['category'][0]}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "znp = np.array(df_test_validation.confusion_matrix[0])\n",
    "print(\"original:\")\n",
    "print(znp)\n",
    "z = znp.transpose()\n",
    "print(\"transpose:\")\n",
    "print(z)\n",
    "x = ['AddToCart', 'None', 'SearchDatabase', 'SearchMemory', 'SpecifyInfo']\n",
    "y = ['AddToCart', 'None', 'SearchDatabase', 'SearchMemory', 'SpecifyInfo']\n",
    "     \n",
    "# change each element of z to type string for annotations\n",
    "z_text = [[str(y) for y in x] for x in z]\n",
    "     \n",
    "# set up figure \n",
    "fig = ff.create_annotated_heatmap(z, x=x, y=y, annotation_text=z_text, colorscale='Viridis')\n",
    "\n",
    "# add title\n",
    "fig.update_layout(title_text='<i><b>Actions confusion matrix</b></i>',title_x=0.5\n",
    "                  #xaxis = dict(title='x'),\n",
    "                  #yaxis = dict(title='x')\n",
    "                 )\n",
    "\n",
    "# add custom xaxis title\n",
    "fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n",
    "                        x=0.5,\n",
    "                        y=-0.15,\n",
    "                        showarrow=False,\n",
    "                        text=\"Predicted value\",\n",
    "                        xref=\"paper\",\n",
    "                        yref=\"paper\"))\n",
    "\n",
    "# add custom yaxis title\n",
    "fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n",
    "                        x=-0.25,\n",
    "                        y=0.5,\n",
    "                        showarrow=False,\n",
    "                        text=\"Real value\",\n",
    "                        textangle=-90,\n",
    "                        xref=\"paper\",\n",
    "                        yref=\"paper\"))\n",
    "\n",
    "# adjust margins to make room for yaxis title\n",
    "fig.update_layout(margin=dict(t=50, l=200))\n",
    "\n",
    "# add colorbar\n",
    "fig['data'][0]['showscale'] = True\n",
    "fig.show()\n",
    "# fig.write_image(\"plots/action_confusion_matrix.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataAnalytics",
   "language": "python",
   "name": "dataanalytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
